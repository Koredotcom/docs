{"config":{"lang":["tr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"alternatives/","title":"Alternatives","text":"<p>There are tons of static site generators and themes out there and choosing the right one for your tech stack is a tough decision. If you're unsure if Material for MkDocs is the right solution for you, this section should help you evaluate alternative solutions.</p>"},{"location":"alternatives/#docusaurus","title":"Docusaurus","text":"<p>Docusaurus by Facebook is a very popular documentation generator and a good choice if you or your company are already using React to build your site. It will generate a single page application which is fundamentally different from the site Material for MkDocs generates for you.</p> <p>Advantages</p> <ul> <li>Very powerful, customizable and extendable</li> <li>Provides many components that aid in technical writing</li> <li>Large and rich ecosystem, backed by Facebook</li> </ul> <p>Challenges</p> <ul> <li>High learning curve, JavaScript knowledge mandatory</li> <li>JavaScript ecosystem is very volatile, rather high maintenance</li> <li>More time needed to get up and running</li> </ul> <p>While Docusaurus is one of the best choices when it comes to documentation sites that output a single page application, there are many more solutions, including Docz, Gatsby, Vuepress and Docsify that approach this problem similarly.</p>"},{"location":"alternatives/#jekyll","title":"Jekyll","text":"<p>Jekyll is probably one of the most mature and widespread static site generators and is written in Ruby. It is not specifically geared towards technical project documentation and has many themes to choose from, which can be challenging.</p> <p>Advantages</p> <ul> <li>Battle-tested, rich ecosystem, many themes to choose from</li> <li>Brings great capabilities for blogging  (permalinks, tags, etc.)</li> <li>Generates a SEO-friendly site, similar to Material for MkDocs</li> </ul> <p>Challenges</p> <ul> <li>Not specifically geared towards technical project documentation</li> <li>Limited Markdown capabilities, not as advanced as Python Markdown</li> <li>More time needed to get up and running</li> </ul>"},{"location":"alternatives/#sphinx","title":"Sphinx","text":"<p>Sphinx is an alternative static site generator specifically geared towards generating reference documentation, offering powerful capabilities that are lacking in MkDocs. It uses reStructured text, a format similar to Markdown, which some users find harder to use.</p> <p>Advantages</p> <ul> <li>Very powerful, customizable and extendable</li> <li>Generates reference documentation from Python docstrings</li> <li>Large and rich ecosystem, used by many Python projects</li> </ul> <p>Challenges</p> <ul> <li>High learning curve, reStructured text syntax might be challenging</li> <li>Search is less powerful than the one provided by MkDocs</li> <li>More time needed to get up and running</li> </ul> <p>If you're considering using Sphinx because you need to generate reference documentation, you should give mkdocstrings a try \u2013 an actively maintained and popular framework building on top of MkDocs, implementing Sphinx-like functionality.</p>"},{"location":"alternatives/#gitbook","title":"GitBook","text":"<p>GitBook offers a hosted documentation solution that generates a beautiful and functional site from Markdown files in your GitHub repository. However, it was once Open Source, but turned into a closed source solution some time ago.</p> <p>Advantages</p> <ul> <li>Hosted solution, minimal technical knowledge required</li> <li>Custom domains, authentication and other enterprise features</li> <li>Great collaboration features for teams</li> </ul> <p>Challenges</p> <ul> <li>Closed source, not free for proprietary projects</li> <li>Limited Markdown capabilities, not as advanced as Python Markdown</li> <li>Many Open Source projects moved away from GitBook</li> </ul> <p>Many users switched from GitBook to Material for MkDocs, as they want to keep control and ownership of their documentation, favoring an Open Source solution.</p>"},{"location":"browser-support/","title":"Browser support","text":"<p>Material for MkDocs goes at great lengths to support the largest possible range of browsers while retaining the simplest possibilities for customization via modern CSS features like custom properties and mask images.</p>"},{"location":"browser-support/#supported-browsers","title":"Supported browsers","text":"<p>The following table lists all browsers for which Material for MkDocs offers full support, so it can be assumed that all features work without degradation. If you find that something doesn't look right in a browser which is in the supported version range, please open an issue:</p> Browser Version Release date Usage desktop mobile overall  Chrome 49+ 03/2016 25.65% 38.33% 63.98%  Safari 10+ 09/2016 4.63% 14.96% 19.59%  Edge 79+ 01/2020 3.95% n/a 3.95%  Firefox 53+ 04/2017 3.40% .30% 3.70%  Opera 36+ 03/2016 1.44% .01% 1.45% 92.67% <p>Browser support matrix sourced from caniuse.com.1</p> <p>Note that the usage data is based on global browser market share, so it could in fact be entirely different for your target demographic. It's a good idea to check the distribution of browser types and versions among your users.</p>"},{"location":"browser-support/#other-browsers","title":"Other browsers","text":"<p>Albeit your site might not look as perfect as when viewed with a modern browser, the following older browser versions might work with some additional effort:</p> <ul> <li> Firefox 31-52 \u2013 icons will render as little   boxes due to missing support for mask images. While this cannot be   polyfilled, it might be mitigated by hiding the icons altogether.</li> <li> Edge 16-18 \u2013 the spacing of some elements might   be a little off due to missing support for the :is pseudo selector, which   can be mitigated with some additional effort.</li> <li> Internet Explorer - no support,   mainly due to missing support for custom properties. The last version of   Material for MkDocs to support Internet Explorer is    4.6.3.</li> </ul> <ol> <li> <p>The data was collected from caniuse.com in January 2022, and is primarily based on browser support for custom properties, mask images and the :is pseudo selector which are not entirely polyfillable. Browsers with a cumulated market share of less than 1% were not considered, but might still be fully or partially supported.\u00a0\u21a9</p> </li> </ol>"},{"location":"creating-your-site/","title":"Creating your site","text":"<p>After you've installed Material for MkDocs, you can bootstrap your project  documentation using the <code>mkdocs</code> executable. Go to the directory where you want your project to be located and enter:</p> <pre><code>mkdocs new .\n</code></pre> <p>Alternatively, if you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material new .\n</code></pre> <pre><code>docker run --rm -it -v \"%cd%\":/docs squidfunk/mkdocs-material new .\n</code></pre> <p>This will create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre>"},{"location":"creating-your-site/#configuration","title":"Configuration","text":""},{"location":"creating-your-site/#minimal-configuration","title":"Minimal configuration","text":"<p>Simply add the following lines to <code>mkdocs.yml</code> to enable the theme:</p> <pre><code>theme:\nname: material\n</code></pre> Recommended: configuration validation and auto-complete <p>In order to minimize friction and maximize productivity, Material for MkDocs  provides its own schema.json1 for <code>mkdocs.yml</code>. If your editor supports YAML schema validation, it's definitely recommended to set it up:</p> Visual Studio CodeOther <ol> <li>Install <code>vscode-yaml</code> for YAML language support.</li> <li> <p>Add the schema under the <code>yaml.schemas</code> key in your user or     workspace <code>settings.json</code>:</p> <pre><code>{\n\"yaml.schemas\": {\n\"https://squidfunk.github.io/mkdocs-material/schema.json\": \"mkdocs.yml\"\n},\n\"yaml.customTags\": [ // (1)!\n\"!ENV scalar\",\n\"!ENV sequence\",\n\"tag:yaml.org,2002:python/name:materialx.emoji.to_svg\",\n\"tag:yaml.org,2002:python/name:materialx.emoji.twemoji\",\n\"tag:yaml.org,2002:python/name:pymdownx.superfences.fence_code_format\"\n]\n}\n</code></pre> <ol> <li>This setting is necessary if you plan to use icons and emojis,     or Visual Studio Code will show errors on certain lines.</li> </ol> </li> </ol> <ol> <li>Ensure your editor of choice has support for YAML schema validation.</li> <li> <p>Add the following lines at the top of <code>mkdocs.yml</code>:</p> <pre><code># yaml-language-server: $schema=https://squidfunk.github.io/mkdocs-material/schema.json\n</code></pre> </li> </ol>"},{"location":"creating-your-site/#advanced-configuration","title":"Advanced configuration","text":"<p>Material for MkDocs comes with many configuration options. The setup section explains in great detail how to configure and customize colors, fonts, icons and much more:</p> <ul> <li>Changing the colors</li> <li>Changing the fonts</li> <li>Changing the language</li> <li>Changing the logo and icons</li> <li>Ensuring data privacy</li> <li>Setting up navigation</li> <li>Setting up site search</li> <li>Setting up site analytics</li> <li>Setting up social cards</li> <li>Setting up a blog</li> <li>Setting up tags</li> <li>Setting up versioning</li> <li>Setting up the header</li> <li>Setting up the footer</li> <li>Adding a git repository</li> <li>Adding a comment system</li> <li>Building an optimized site</li> <li>Building for offline usage</li> </ul> <p>Furthermore, see the list of supported Markdown extensions that are natively integrated with Material for MkDocs, delivering an unprecedented low-effort technical writing experience.</p>"},{"location":"creating-your-site/#previewing-as-you-write","title":"Previewing as you write","text":"<p>MkDocs includes a live preview server, so you can preview your changes as you write your documentation. The server will automatically rebuild the site upon saving. Start it with:</p> <pre><code>mkdocs serve # (1)!\n</code></pre> <ol> <li> <p>If you have a large documentation project, it might take minutes until     MkDocs has rebuilt all pages for you to preview. If you're only interested     in the current page, the <code>--dirtyreload</code> flag will make     rebuilds much faster:</p> <pre><code>mkdocs serve --dirtyreload\n</code></pre> </li> </ol> <p>If you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material\n</code></pre> <pre><code>docker run --rm -it -p 8000:8000 -v \"%cd%\":/docs squidfunk/mkdocs-material\n</code></pre> <p>Point your browser to localhost:8000 and you should see:</p> <p></p>"},{"location":"creating-your-site/#building-your-site","title":"Building your site","text":"<p>When you're finished editing, you can build a static site from your Markdown files with:</p> <pre><code>mkdocs build\n</code></pre> <p>If you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material build\n</code></pre> <pre><code>docker run --rm -it -v \"%cd%\":/docs squidfunk/mkdocs-material build\n</code></pre> <p>The contents of this directory make up your project documentation. There's no need for operating a database or server, as it is completely self-contained. The site can be hosted on GitHub Pages, GitLab Pages, a CDN of your choice or your private web space.</p> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>If you're a MkDocs plugin or Markdown extension author and your project works with Material for MkDocs, you're very much invited to contribute a schema for your extension or plugin as part of a pull request on GitHub. If you already have a schema defined, or wish to self-host your schema to reduce duplication, you can add it via $ref.\u00a0\u21a9</p> </li> </ol>"},{"location":"customization/","title":"Customization","text":"<p>Project documentation is as diverse as the projects themselves and Material for MkDocs is a great starting point for making it look beautiful. However, as you write your documentation, you may reach a point where small adjustments are necessary to preserve your brand's style.</p>"},{"location":"customization/#adding-assets","title":"Adding assets","text":"<p>MkDocs provides several ways to customize a theme. In order to make a few small tweaks to Material for MkDocs, you can just add CSS and JavaScript files to the <code>docs</code> directory.</p>"},{"location":"customization/#additional-css","title":"Additional CSS","text":"<p>If you want to tweak some colors or change the spacing of certain elements, you can do this in a separate style sheet. The easiest way is by creating a new style sheet file in the <code>docs</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 stylesheets/\n\u2502     \u2514\u2500 extra.css\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"customization/#additional-javascript","title":"Additional JavaScript","text":"<p>If you want to integrate another syntax highlighter or add some custom logic to your theme, create a new JavaScript file in the <code>docs</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 javascripts/\n\u2502     \u2514\u2500 extra.js\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra_javascript:\n- javascripts/extra.js\n</code></pre>"},{"location":"customization/#extending-the-theme","title":"Extending the theme","text":"<p>If you want to alter the HTML source (e.g. add or remove some parts), you can extend the theme. MkDocs supports theme extension, an easy way to override parts of Material for MkDocs without forking from git. This ensures that you can update to the latest version more easily.</p>"},{"location":"customization/#setup-and-theme-structure","title":"Setup and theme structure","text":"<p>Enable Material for MkDocs as usual in <code>mkdocs.yml</code>, and create a new folder for <code>overrides</code> which you then reference using the <code>custom_dir</code> setting:</p> <pre><code>theme:\nname: material\ncustom_dir: overrides\n</code></pre> <p>Theme extension prerequisites</p> <p>As the <code>custom_dir</code> setting is used for the theme extension process, Material for MkDocs needs to be installed via <code>pip</code> and referenced with the <code>name</code> setting in <code>mkdocs.yml</code>. It will not work when cloning from <code>git</code>.</p> <p>The structure in the <code>overrides</code> directory must mirror the directory structure of the original theme, as any file in the <code>overrides</code> directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 .icons/                             # Bundled icon sets\n\u251c\u2500 assets/\n\u2502  \u251c\u2500 images/                          # Images and icons\n\u2502  \u251c\u2500 javascripts/                     # JavaScript files\n\u2502  \u2514\u2500 stylesheets/                     # Style sheets\n\u251c\u2500 partials/\n\u2502  \u251c\u2500 integrations/                    # Third-party integrations\n\u2502  \u2502  \u251c\u2500 analytics/                    # Analytics integrations\n\u2502  \u2502  \u2514\u2500 analytics.html                # Analytics setup\n\u2502  \u251c\u2500 languages/                       # Translation languages\n\u2502  \u251c\u2500 actions.html                     # Actions\n\u2502  \u251c\u2500 comments.html                    # Comment system (empty by default)\n\u2502  \u251c\u2500 consent.html                     # Consent\n\u2502  \u251c\u2500 content.html                     # Page content\n\u2502  \u251c\u2500 copyright.html                   # Copyright and theme information\n\u2502  \u251c\u2500 feedback.html                    # Was this page helpful?\n\u2502  \u251c\u2500 footer.html                      # Footer bar\n\u2502  \u251c\u2500 header.html                      # Header bar\n\u2502  \u251c\u2500 icons.html                       # Custom icons\n\u2502  \u251c\u2500 language.html                    # Translation setup\n\u2502  \u251c\u2500 logo.html                        # Logo in header and sidebar\n\u2502  \u251c\u2500 nav.html                         # Main navigation\n\u2502  \u251c\u2500 nav-item.html                    # Main navigation item\n\u2502  \u251c\u2500 pagination.html                  # Pagination (used for blog)\n\u2502  \u251c\u2500 post.html                        # Blog post excerpt\n\u2502  \u251c\u2500 search.html                      # Search interface\n\u2502  \u251c\u2500 social.html                      # Social links\n\u2502  \u251c\u2500 source.html                      # Repository information\n\u2502  \u251c\u2500 source-file.html                 # Source file information\n\u2502  \u251c\u2500 tabs.html                        # Tabs navigation\n\u2502  \u251c\u2500 tabs-item.html                   # Tabs navigation item\n\u2502  \u251c\u2500 tags.html                        # Tags\n\u2502  \u251c\u2500 toc.html                         # Table of contents\n\u2502  \u2514\u2500 toc-item.html                    # Table of contents item\n\u251c\u2500 404.html                            # 404 error page\n\u251c\u2500 base.html                           # Base template\n\u251c\u2500 blog.html                           # Blog index page\n\u251c\u2500 blog-archive.html                   # Blog archive index page\n\u251c\u2500 blog-category.html                  # Blog category index page\n\u251c\u2500 blog-post.html                      # Blog post page\n\u2514\u2500 main.html                           # Default page\n</code></pre>"},{"location":"customization/#overriding-partials","title":"Overriding partials","text":"<p>In order to override a partial, we can replace it with a file of the same name and location in the <code>overrides</code> directory. For example, to replace the original <code>footer.html</code> partial, create a new <code>footer.html</code> partial in the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 partials/\n\u2502     \u2514\u2500 footer.html\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>MkDocs will now use the new partial when rendering the theme. This can be done with any file.</p>"},{"location":"customization/#overriding-blocks","title":"Overriding blocks recommended","text":"<p>Besides overriding partials, it's also possible to override (and extend) template blocks, which are defined inside the templates and wrap specific features. In order to set up block overrides, create a <code>main.html</code> file inside the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 main.html\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, e.g. to override the site title, add the following lines to <code>main.html</code>:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block htmltitle %}\n  &lt;title&gt;Lorem ipsum dolor sit amet&lt;/title&gt;\n{% endblock %}\n</code></pre> <p>If you intend to add something to a block rather than to replace it altogether with new content, use <code>{{ super() }}</code> inside the block to include the  original block content. This is particularly useful when adding third-party scripts to your docs, e.g.</p> <pre><code>{% extends \"base.html\" %}\n\n{% block scripts %}\n  &lt;!-- Add scripts that need to run before here --&gt;\n  {{ super() }}\n  &lt;!-- Add scripts that need to run afterwards here --&gt;\n{% endblock %}\n</code></pre> <p>The following template blocks are provided by the theme:</p> Block name Purpose <code>analytics</code> Wraps the Google Analytics integration <code>announce</code> Wraps the announcement bar <code>config</code> Wraps the JavaScript application config <code>container</code> Wraps the main content container <code>content</code> Wraps the main content <code>extrahead</code> Empty block to add custom meta tags <code>fonts</code> Wraps the font definitions <code>footer</code> Wraps the footer with navigation and copyright <code>header</code> Wraps the fixed header bar <code>hero</code> Wraps the hero teaser (if available) <code>htmltitle</code> Wraps the <code>&lt;title&gt;</code> tag <code>libs</code> Wraps the JavaScript libraries (header) <code>outdated</code> Wraps the version warning <code>scripts</code> Wraps the JavaScript application (footer) <code>site_meta</code> Wraps the meta tags in the document head <code>site_nav</code> Wraps the site navigation and table of contents <code>styles</code> Wraps the style sheets (also extra sources) <code>tabs</code> Wraps the tabs navigation (if available)"},{"location":"customization/#theme-development","title":"Theme development","text":"<p>Material for MkDocs is built on top of TypeScript, RxJS and SASS, and uses a lean, custom build process to put everything together.1 If you want to make more fundamental changes, it may be necessary to make the adjustments directly in the source of the theme and recompile it.</p>"},{"location":"customization/#environment-setup","title":"Environment setup","text":"<p>In order to start development on Material for MkDocs, a Node.js version of at least 14 is required. First, clone the repository:</p> <pre><code>git clone https://github.com/squidfunk/mkdocs-material\n</code></pre> <p>Next, all dependencies need to be installed, which is done with:</p> <pre><code>cd mkdocs-material\npip install -e .\npip install mkdocs-minify-plugin\npip install mkdocs-redirects\nnpm install\n</code></pre>"},{"location":"customization/#development-mode","title":"Development mode","text":"<p>Start the watcher with:</p> <pre><code>npm start\n</code></pre> <p>Then, in a second terminal window, start the MkDocs live preview server with:</p> <pre><code>mkdocs serve --watch-theme\n</code></pre> <p>Point your browser to localhost:8000 and you should see this very documentation in front of you.</p> <p>Automatically generated files</p> <p>Never make any changes in the <code>material</code> directory, as the contents of this directory are automatically generated from the <code>src</code> directory and will be overwritten when the theme is built.</p>"},{"location":"customization/#building-the-theme","title":"Building the theme","text":"<p>When you're finished making your changes, you can build the theme by invoking:</p> <pre><code>npm run build # (1)!\n</code></pre> <ol> <li> <p>While this command will build all theme files, it will skip the overrides     used in Material for MkDocs' own documentation which are not distributed     with the theme. If you forked the theme and want to build the overrides     as well, use:</p> <pre><code>npm run build:all\n</code></pre> <p>This will take longer, as now the icon search index, schema files, as well as additional style sheet and JavaScript files are built.</p> </li> </ol> <p>This triggers the production-level compilation and minification of all style sheets and JavaScript files. After the command exits, the compiled files are located in the <code>material</code> directory. When running <code>mkdocs build</code>, you should now see your changes to the original theme.</p> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>Prior to  7.0.0 the build was based on Webpack, resulting in occasional broken builds due to incompatibilities with loaders and plugins. Therefore, we decided to swap Webpack for a leaner solution which is now based on RxJS as the application itself. This allowed for the pruning of more than 500 dependencies (~30% less).\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/","title":"Getting started","text":"<p>Material for MkDocs is a powerful documentation framework on top of MkDocs, a static site generator for project documentation.1 If you're familiar with  Python, you can install Material for MkDocs with <code>pip</code>, the Python package manager. If not, we recommend using <code>docker</code>.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#with-pip","title":"with pip recommended","text":"<p>Material for MkDocs is published as a Python package and can be installed with <code>pip</code>, ideally by using a virtual environment. Open up a terminal and install Material for MkDocs with:</p> Latest9.x <pre><code>pip install mkdocs-material\n</code></pre> <pre><code>pip install mkdocs-material==\"9.*\" # (1)!\n</code></pre> <ol> <li> <p>Material for MkDocs uses semantic versioning2, which is why it's a     good idea to limit upgrades to the current major version.</p> <p>This will make sure that you don't accidentally upgrade to the next major version, which may include breaking changes that silently corrupt your site. Additionally, you can use <code>pip freeze</code> to create a lockfile, so builds are reproducible at all times:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>Now, the lockfile can be used for installation:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> </ol> <p>This will automatically install compatible versions of all dependencies: MkDocs, Markdown, Pygments and Python Markdown Extensions. Material for MkDocs always strives to support the latest versions, so there's no need to install those packages separately.</p> <p> How to set up Material for MkDocs by @james-willett \u2013  15m \u2013 Learn how to create and host a documentation site using Material for  MkDocs on GitHub Pages in a step-by-step guide.</p> <p>Tip: If you don't have prior experience with Python, we recommend reading  Using Python's pip to Manage Your Projects' Dependencies, which is a really good introduction on the mechanics of Python package management and helps you troubleshoot if you run into errors.</p>"},{"location":"getting-started/#with-docker","title":"with docker","text":"<p>The official Docker image is a great way to get up and running in a few minutes, as it comes with all dependencies pre-installed. Open up a terminal and pull the image with:</p> Latest9.x <pre><code>docker pull squidfunk/mkdocs-material\n</code></pre> <pre><code>docker pull squidfunk/mkdocs-material:9\n</code></pre> <p>The <code>mkdocs</code> executable is provided as an entry point and <code>serve</code> is the  default command. If you're not familiar with Docker don't worry, we have you covered in the following sections.</p> <p>The following plugins are bundled with the Docker image:</p> <ul> <li>mkdocs-minify-plugin</li> <li>mkdocs-redirects</li> </ul> How to add plugins to the Docker image? <p>Material for MkDocs only bundles selected plugins in order to keep the size of the official image small. If the plugin you want to use is not included, you can add them easily:</p> Material for MkDocsInsiders <p>Create a <code>Dockerfile</code> and extend the official image:</p> Dockerfile<pre><code>FROM squidfunk/mkdocs-material\nRUN pip install mkdocs-macros-plugin\nRUN pip install mkdocs-glightbox\n</code></pre> <p>Clone or fork the Insiders repository, and create a file called <code>user-requirements.txt</code> in the root of the repository. Then, add the plugins that should be installed to the file, e.g.:</p> user-requirements.txt<pre><code>mkdocs-macros-plugin\nmkdocs-glightbox\n</code></pre> <p>Next, build the image with the following command:</p> <pre><code>docker build -t squidfunk/mkdocs-material .\n</code></pre> <p>The new image will have additional packages installed and can be used exactly like the official image.</p>"},{"location":"getting-started/#with-git","title":"with git","text":"<p>Material for MkDocs can be directly used from GitHub by cloning the repository into a subfolder of your project root which might be useful if you want to use the very latest version:</p> <pre><code>git clone https://github.com/squidfunk/mkdocs-material.git\n</code></pre> <p>The theme will reside in the folder <code>mkdocs-material/material</code>. After cloning from <code>git</code>, you must install all required dependencies with:</p> <pre><code>pip install -e mkdocs-material\n</code></pre> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>In 2016, Material for MkDocs started out as a simple theme for MkDocs, but over the course of several years, it's now much more than that \u2013 with the many built-in plugins, settings, and countless customization abilities, Material for MkDocs is now one of the simplest and most powerful frameworks for creating documentation for your project.\u00a0\u21a9</p> </li> <li> <p>Note that improvements of existing features are sometimes released as patch releases, like for example improved rendering of content tabs, as they're not considered to be new features.\u00a0\u21a9</p> </li> </ol>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2016-2023 Martin Donath</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"philosophy/","title":"Philosophy","text":"<p>Before settling for Material for MkDocs, it's a good idea to understand the philosophy behind the project, in order to make sure it aligns with your goals. This page explains the design principles anchored in Material for MkDocs, and discusses the conventions used in this documentation.</p>"},{"location":"philosophy/#design-principles","title":"Design principles","text":"<ul> <li> <p>It's just Markdown: Focus on the content of your documentation and create   a professional static site in minutes. No need to know HTML,CSS or JavaScript   \u2013 let Material for MkDocs do the heavy lifting for you.</p> </li> <li> <p>Works on all devices: Serve your documentation with confidence \u2013 the    underlying layout automatically adapts to perfectly fit the available screen    estate, no matter the type or size of the viewing device.</p> </li> <li> <p>Made to measure: Change the colors, fonts, language, icons, logo and much   more with a few lines of configuration. Material for MkDocs can be easily    extended and provides tons of options to alter appearance and behavior.</p> </li> <li> <p>Fast and lightweight: Don't let your users wait \u2013 get incredible value   with a small footprint, by using one of the fastest themes around with   excellent performance, yielding great search engine rankings and happy   users that return.</p> </li> <li> <p>Accessible: Make accessibility a priority \u2013 users can navigate your   documentation with touch devices, keyboard, and screen readers. Semantic   markup ensures that your documentation works for everyone.</p> </li> <li> <p>Open Source: Trust 20,000+ users \u2013 choose a mature and well-funded   solution built with state-of-the-art Open Source technologies. Keep ownership   of your content without fear of vendor lock-in. Licensed under MIT.</p> </li> </ul>"},{"location":"philosophy/#conventions","title":"Conventions","text":""},{"location":"philosophy/#symbols","title":"Symbols","text":"<p>This documentation use some symbols for illustration purposes. Before you read on, please make sure you've made yourself familiar with the following list of conventions:</p>  \u00a0 Insiders <p>Some features are not yet available in the community edition, but only as part of the Insiders build of Material for MkDocs. Please consult the  Insiders guide to learn how to get access.</p> {x.x.x} <p>The tag icon in conjunction with a version number denotes when a specific  feature or behavior was added. Make sure you're at least on this version if you want to use it.</p> {file.ext} <p>The source file icon together with a file name is sometimes used in code examples which span multiple files. The file name (or path) always starts from the location of <code>mkdocs.yml</code>.</p> Default: value <p>Some properties in <code>mkdocs.yml</code> have default values for when the author does not explicitly define them. The default value of the property is always included.</p> Feature flag <p>Most of the features are hidden behind feature flags, which means they must be explicitly enabled via <code>mkdocs.yml</code>. This allows for the existence of potentially orthogonal features.</p> Experimental <p>Some newer features are still considered experimental, which means they might (although rarely) change at any time, including their complete removal  (which hasn't happened yet).</p> Plugin <p>Several features are implemented through MkDocs excellent plugin architecture, some of which are built-in and distributed with Material for MkDocs, so no installation is required.</p> Utility <p>Besides plugins, there are some utilities that build on top of MkDocs in order to provide extended functionality, like for example support for versioning.</p>"},{"location":"publishing-your-site/","title":"Publishing your site","text":"<p>The great thing about hosting project documentation in a <code>git</code> repository is the ability to deploy it automatically when new changes are pushed. MkDocs makes this ridiculously simple.</p>"},{"location":"publishing-your-site/#github-pages","title":"GitHub Pages","text":"<p>If you're already hosting your code on GitHub, GitHub Pages is certainly the most convenient way to publish your project documentation. It's free of charge and pretty easy to set up.</p>"},{"location":"publishing-your-site/#with-github-actions","title":"with GitHub Actions","text":"<p>Using GitHub Actions you can automate the deployment of your project documentation. At the root of your repository, create a new GitHub Actions workflow, e.g. <code>.github/workflows/ci.yml</code>, and copy and paste the following contents:</p> Material for MkDocsInsiders <pre><code>name: ci # (1)!\non:\npush:\nbranches:\n- master # (2)!\n- main\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV # (3)!\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: pip install mkdocs-material # (4)!\n- run: mkdocs gh-deploy --force\n</code></pre> <ol> <li> <p>You can change the name to your liking. </p> </li> <li> <p>At some point, GitHub renamed <code>master</code> to <code>main</code>. If your default branch     is named <code>master</code>, you can safely remove <code>main</code>, vice versa.</p> </li> <li> <p>Store the <code>cache_id</code> environmental variable to access it later during cache     <code>key</code> creation. The name is case-sensitive, so be sure to align it with <code>${{ env.cache_id }}</code>.</p> <ul> <li>The <code>--utc</code> option makes sure that each workflow runner uses the same time zone.</li> <li>The <code>%V</code> format assures a cache update once a week. </li> <li>You can change the format to <code>%F</code> to have daily cache updates. </li> </ul> <p>You can read the manual page to learn more about the formatting options of the <code>date</code> command.</p> </li> <li> <p>This is the place to install further MkDocs plugins or Markdown     extensions with <code>pip</code> to be used during the build:</p> <pre><code>pip install \\\nmkdocs-material \\\nmkdocs-awesome-pages-plugin \\\n...\n</code></pre> </li> </ol> <pre><code>name: ci\non:\npush:\nbranches:\n- master\n- main\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nif: github.event.repository.fork == false\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: apt-get install pngquant # (1)!\n- run: pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n- run: mkdocs gh-deploy --force\nenv:\nGH_TOKEN: ${{ secrets.GH_TOKEN }} # (2)!\n</code></pre> <ol> <li> <p>This step is only necessary if you want to use the     built-in optimize plugin to automatically compress images.</p> </li> <li> <p>Remember to set the <code>GH_TOKEN</code> environment variable to the value of your     personal access token when deploying Insiders, which can be done     using GitHub secrets.</p> </li> </ol> <p>Now, when a new commit is pushed to either the <code>master</code> or <code>main</code> branches, the static site is automatically built and deployed. Push your changes to see the workflow in action.</p> <p>If the GitHub Page doesn't show up after a few minutes, go to the settings of your repository and ensure that the publishing source branch for your GitHub Page is set to <code>gh-pages</code>.</p> <p>Your documentation should shortly appear at <code>&lt;username&gt;.github.io/&lt;repository&gt;</code>.</p>"},{"location":"publishing-your-site/#with-mkdocs","title":"with MkDocs","text":"<p>If you prefer to deploy your project documentation manually, you can just invoke the following command from the directory containing the <code>mkdocs.yml</code> file:</p> <pre><code>mkdocs gh-deploy --force\n</code></pre>"},{"location":"publishing-your-site/#gitlab-pages","title":"GitLab Pages","text":"<p>If you're hosting your code on GitLab, deploying to GitLab Pages can be done by using the GitLab CI task runner. At the root of your repository, create a task definition named <code>.gitlab-ci.yml</code> and copy and paste the following contents:</p> Material for MkDocsInsiders <pre><code>image: python:latest\npages:\nstage: deploy\nscript:\n- pip install mkdocs-material\n- mkdocs build --site-dir public\nartifacts:\npaths:\n- public\nrules:\n- if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'\n</code></pre> <pre><code>image: python:latest\npages:\nstage: deploy\nscript: # (1)!\n- pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n- mkdocs build --site-dir public\nartifacts:\npaths:\n- public\nrules:\n- if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'\n</code></pre> <ol> <li>Remember to set the <code>GH_TOKEN</code> environment variable to the value of your     personal access token when deploying Insiders, which can be done     using masked custom variables.</li> </ol> <p>Now, when a new commit is pushed to <code>master</code>, the static site is automatically built and deployed. Commit and push the file to your repository to see the workflow in action.</p> <p>Your documentation should shortly appear at <code>&lt;username&gt;.gitlab.io/&lt;repository&gt;</code>.</p>"},{"location":"publishing-your-site/#other","title":"Other","text":"<p>Since we can't cover all possible platforms, we rely on community contributed guides that explain how to deploy websites built with Material for MkDocs to other providers:</p> <ul> <li> Azure</li> <li> Cloudflare Pages</li> <li> DigitalOcean</li> <li> Netlify</li> <li> Vercel</li> </ul> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p>"},{"location":"upgrade/","title":"How to upgrade","text":"<p>Upgrade to the latest version with:</p> <pre><code>pip install --upgrade --force-reinstall mkdocs-material\n</code></pre> <p>Show the currently installed version with:</p> <pre><code>pip show mkdocs-material\n</code></pre>"},{"location":"upgrade/#upgrading-from-8x-to-9x","title":"Upgrading from 8.x to 9.x","text":"<p>This major release includes a brand new search implementation that is faster and allows for rich previews, advanced tokenization and better highlighting. It was available as part of Insiders for over a year, and now that the funding goal was hit, makes its way into the community edition.</p>"},{"location":"upgrade/#changes-to-mkdocsyml","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"upgrade/#contentcodecopy","title":"<code>content.code.copy</code>","text":"<p>The copy-to-clipboard buttons are now opt-in and can be enabled or disabled per block. If you wish to enable them for all code blocks, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.code.copy\n</code></pre>"},{"location":"upgrade/#contentaction","title":"<code>content.action.*</code>","text":"<p>A \"view source\" button can be shown next to the \"edit this page\" button, both of which must now be explicitly enabled. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.action.edit\n- content.action.view\n</code></pre>"},{"location":"upgrade/#navigationfooter","title":"<code>navigation.footer</code>","text":"<p>The previous and next buttons in the footer are now opt-in. If you wish to keep them for your documentation, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.footer\n</code></pre>"},{"location":"upgrade/#themelanguage","title":"<code>theme.language</code>","text":"<p>The Korean and Norwegian language codes were renamed, as they were non-standard:</p> <ul> <li><code>kr</code> to <code>ko</code></li> <li><code>no</code> to <code>nb</code></li> </ul>"},{"location":"upgrade/#feedbackratings","title":"<code>feedback.ratings</code>","text":"<p>The old, nameless placeholders were removed (after being deprecated for several months). Make sure to switch to the new named placeholders <code>{title}</code> and <code>{url}</code>:</p> <pre><code>https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url}\n</code></pre>"},{"location":"upgrade/#changes-to-html-files","title":"Changes to <code>*.html</code> files","text":"<p>The templates have undergone a series of changes. If you have customized Material for MkDocs with theme extension, be sure to incorporate the latest changes into your templates. A good starting point is to inspect the diff.</p> <p>Built-in plugins not working after upgrade?</p> <p>If one of the built-in plugins (search or tags) doesn't work anymore without any apparent error or cause, it is very likely related to custom overrides. MkDocs 1.4.1 and above allow themes to namespace built-in plugins, which Material for MkDocs 9 now does in order to allow authors to use third-party plugins with the same name as built-in plugins. Search your overrides for <code>\"in config.plugins\"</code> and add the <code>material/</code> namespace. Affected partials:</p> <ul> <li><code>content.html</code></li> <li><code>header.html</code></li> </ul>"},{"location":"upgrade/#upgrading-from-7x-to-8x","title":"Upgrading from 7.x to 8.x","text":""},{"location":"upgrade/#whats-new","title":"What's new?","text":"<ul> <li>Added support for code annotations</li> <li>Added support for anchor tracking</li> <li>Added support for version warning</li> <li>Added <code>copyright</code> partial for easier override</li> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integration \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"upgrade/#changes-to-mkdocsyml_1","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"upgrade/#pymdownxtabbed","title":"<code>pymdownx.tabbed</code>","text":"<p>Support for the legacy style of the Tabbed extension was dropped in favor of the new, alternate implementation which has better behavior on mobile  viewports:</p> 8.x7.x <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true </code></pre> <pre><code>markdown_extensions:\n- pymdownx.tabbed\n</code></pre>"},{"location":"upgrade/#pymdownxsuperfences","title":"<code>pymdownx.superfences</code>","text":"<p>The <code>*-experimental</code> suffix must be removed from the custom fence class property, which is used to target code blocks to be rendered as diagrams using Mermaid.js:</p> 8.x7.x <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid-experimental\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre>"},{"location":"upgrade/#google_analytics","title":"<code>google_analytics</code>","text":"<p>This option was deprecated in MkDocs 1.2.0, as the implementation of a JavaScript-based analytics integration is the responsibility of a theme. The following lines must be changed:</p> 8.x7.x <pre><code>extra:\nanalytics:\nprovider: google\nproperty: UA-XXXXXXXX-X\n</code></pre> <pre><code>google_analytics:\n- UA-XXXXXXXX-X\n- auto\n</code></pre>"},{"location":"upgrade/#upgrading-from-6x-to-7x","title":"Upgrading from 6.x to 7.x","text":""},{"location":"upgrade/#whats-new_1","title":"What's new?","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Added support for integrating a language selector</li> <li>Added support for rendering admonitions as inline blocks</li> <li>Rewrite of the underlying reactive architecture</li> <li>Removed Webpack in favor of reactive build strategy (\u2013480 dependencies)</li> <li>Fixed keyboard navigation for code blocks after content tabs switch</li> </ul>"},{"location":"upgrade/#changes-to-mkdocsyml_2","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"upgrade/#extraversionmethod","title":"<code>extra.version.method</code>","text":"<p>The versioning method configuration was renamed to <code>extra.version.provider</code> to allow for different versioning strategies in the future:</p> 7.x6.x <pre><code>extra:\nversion:\nprovider: mike\n</code></pre> <pre><code>extra:\nversion:\nmethod: mike\n</code></pre>"},{"location":"upgrade/#upgrading-from-5x-to-6x","title":"Upgrading from 5.x to 6.x","text":""},{"location":"upgrade/#whats-new_2","title":"What's new?","text":"<ul> <li>Improved search result look and feel</li> <li>Improved search result stability while typing</li> <li>Improved search result grouping (pages + headings)</li> <li>Improved search result relevance and scoring</li> <li>Added display of missing query terms to search results</li> <li>Reduced size of vendor bundle by 25% (84kb \u2192 67kb)</li> <li>Reduced size of the Docker image to improve CI build performance</li> <li>Removed hero partial in favor of custom implementation</li> <li>Removed deprecated front matter features</li> </ul>"},{"location":"upgrade/#changes-to-mkdocsyml_3","title":"Changes to <code>mkdocs.yml</code>","text":"<p>Following is a list of changes that need to be made to <code>mkdocs.yml</code>. Note that you only have to adjust the value if you defined it, so if your configuration does not contain the key, you can skip it.</p>"},{"location":"upgrade/#themefeatures","title":"<code>theme.features</code>","text":"<p>All feature flags that can be set from <code>mkdocs.yml</code>, like tabs and instant loading, are now prefixed with the name of the component or function they apply to, e.g. <code>navigation.*</code>:</p> 6.x5.x <pre><code>theme:\nfeatures:\n- navigation.tabs\n- navigation.instant\n</code></pre> <pre><code>theme:\nfeatures:\n- tabs\n- instant\n</code></pre>"},{"location":"upgrade/#upgrading-from-4x-to-5x","title":"Upgrading from 4.x to 5.x","text":""},{"location":"upgrade/#whats-new_3","title":"What's new?","text":"<ul> <li>Reactive architecture \u2013 try <code>app.dialog$.next(\"Hi!\")</code> in the console</li> <li>Instant loading \u2013 make Material behave like a Single Page Application</li> <li>Improved CSS customization with CSS variables \u2013 set your brand's colors</li> <li>Improved CSS resilience, e.g. proper sidebar locking for customized headers</li> <li>Improved icon integration and configuration \u2013 now including over 5k icons</li> <li>Added possibility to use any icon for logo, repository and social links</li> <li>Search UI does not freeze anymore (moved to web worker)</li> <li>Search index built only once when using instant loading</li> <li>Improved extensible keyboard handling</li> <li>Support for prebuilt search indexes</li> <li>Support for displaying stars and forks for GitLab repositories</li> <li>Support for scroll snapping of sidebars and search results</li> <li>Reduced HTML and CSS footprint due to deprecation of Internet Explorer support</li> <li>Slight facelifting of some UI elements (admonitions, tables, ...)</li> </ul>"},{"location":"upgrade/#changes-to-mkdocsyml_4","title":"Changes to <code>mkdocs.yml</code>","text":"<p>Following is a list of changes that need to be made to <code>mkdocs.yml</code>. Note that you only have to adjust the value if you defined it, so if your configuration does not contain the key, you can skip it.</p>"},{"location":"upgrade/#themefeature","title":"<code>theme.feature</code>","text":"<p>Optional features like tabs and instant loading are now implemented as flags and can be enabled by listing them in <code>mkdocs.yml</code> under <code>theme.features</code>:</p> 5.x4.x <pre><code>theme:\nfeatures:\n- tabs\n- instant\n</code></pre> <pre><code>theme:\nfeature:\ntabs: true\n</code></pre>"},{"location":"upgrade/#themelogoicon","title":"<code>theme.logo.icon</code>","text":"<p>The logo icon configuration was centralized under <code>theme.icon.logo</code> and can now be set to any of the icons bundled with the theme:</p> 5.x4.x <pre><code>theme:\nicon:\nlogo: material/cloud\n</code></pre> <pre><code>theme:\nlogo:\nicon: cloud\n</code></pre>"},{"location":"upgrade/#extrarepo_icon","title":"<code>extra.repo_icon</code>","text":"<p>The repo icon configuration was centralized under <code>theme.icon.repo</code> and can now be set to any of the icons bundled with the theme:</p> 5.x4.x <pre><code>theme:\nicon:\nrepo: fontawesome/brands/gitlab\n</code></pre> <pre><code>extra:\nrepo_icon: gitlab\n</code></pre>"},{"location":"upgrade/#extrasearch","title":"<code>extra.search.*</code>","text":"<p>Search is now configured as part of the plugin options. Note that the search languages must now be listed as an array of strings and the <code>tokenizer</code> was renamed to <code>separator</code>:</p> 5.x4.x <pre><code>plugins:\n- search:\nseparator: '[\\s\\-\\.]+'\nlang:\n- en\n- de\n- ru\n</code></pre> <pre><code>extra:\nsearch:\nlanguage: en, de, ru\ntokenizer: '[\\s\\-\\.]+'\n</code></pre>"},{"location":"upgrade/#extrasocial","title":"<code>extra.social.*</code>","text":"<p>Social links stayed in the same place, but the <code>type</code> key was renamed to <code>icon</code> in order to match the new way of specifying which icon to be used:</p> 5.x4.x <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/github-alt\nlink: https://github.com/squidfunk\n</code></pre> <pre><code>extra:\nsocial:\n- type: github\nlink: https://github.com/squidfunk\n</code></pre>"},{"location":"upgrade/#upgrading-from-3x-to-4x","title":"Upgrading from 3.x to 4.x","text":""},{"location":"upgrade/#whats-new_4","title":"What's new?","text":"<p>Material for MkDocs 4 fixes incorrect layout on Chinese systems. The fix includes a mandatory change of the base font-size from <code>10px</code> to <code>20px</code> which means all <code>rem</code> values needed to be updated. Within the theme, <code>px</code> to <code>rem</code>  calculation is now encapsulated in a new function called <code>px2rem</code> which is part of the SASS code base.</p> <p>If you use Material for MkDocs with custom CSS that is based on <code>rem</code> values, note that those values must now be divided by 2. Now, <code>1.0rem</code> doesn't map to <code>10px</code>, but <code>20px</code>. To learn more about the problem and implications, please refer to #911 in which the problem was discovered and fixed.</p>"},{"location":"upgrade/#changes-to-mkdocsyml_5","title":"Changes to <code>mkdocs.yml</code>","text":"<p>None.</p>"},{"location":"upgrade/#changes-to-html-files_5","title":"Changes to <code>*.html</code> files","text":"<p>None.</p>"},{"location":"virtual-assistants-overview/","title":"Virtual Assistants Overview","text":""},{"location":"virtual-assistants-overview/#introduction","title":"Introduction","text":"<p>Communication has been the essence of life from the beginning of time. Traditionally, conversations were restricted to verbal and textual interaction between humans. These interactions were usually guided by emotions, context, and awareness of previous conversations.</p> <p>With the advent of computers, interactions have expanded to include machines i.e. human-machine interactions. The transitions from a command-based interface to a Graphical User Interface (GUI) to a Conversational User Interface (CUI) became natural and need-based, making communication easier.</p> <p>Further enhancements facilitated the emergence of Artificial Intelligence (AI) that can process natural language (NLP). In turn, AI has contributed to Conversational Virtual Assistants that understand human communication, derive a task from this understanding and extract the information they require in order to execute this task.</p> <p>AI-driven, NLP-based chat, and voice Conversational Virtual Assistants are the latest in technology and a must for contemporary enterprises.</p> <p></p>"},{"location":"virtual-assistants-overview/#what-are-conversational-assistants","title":"What are Conversational Assistants?","text":"<p>A Conversational Virtual Assistant (VA) acts as an intelligent intermediary between people, digital systems, and internet-enabled things. It replaces the traditional Graphical User Interfaces (GUIs) of an application or website with a Conversational User Interface (CUI). It is a paradigm shift from the earlier communications achieved either by entering syntax-specific commands or clicking icons.</p> <p>These Virtual Assistants are designed to converse with users through a combination of natural language-based conversations. Responses can come in the form of text, links, buttons, calendars, or other widgets that accelerate the speed with which a user can respond.</p> <p></p> <p>AI-powered messaging solutions or Conversational Virtual Assistants serve as the stepping stone to the future. They communicate with intelligent virtual agents, organization apps, websites, social media platforms, and messenger platforms. Users can interact with such assistants using voice or text to access information, complete tasks, and execute transactions.</p>"},{"location":"virtual-assistants-overview/#why-add-a-conversational-virtual-assistant-to-your-business","title":"Why Add a Conversational Virtual Assistant to Your Business?","text":"<p>In a nutshell, such an assistant can significantly reduce the amount of time and labor required to maintain specific business processes. Here is what a Conversational VA can achieve:</p> <ul> <li>Talk to people, systems, and internet-enabled things,</li> <li>Perform omnichannel communication through voice and text, using natural language,</li> <li>Understand natural language, including domain-specific,</li> <li>Learn from its interactions and apply this learning in future conversations,</li> <li>Handle multi-turn conversations,</li> <li>Apply context to improve communication,</li> <li>Handle task interruptions and accomplish what users want.</li> </ul> <p></p>"},{"location":"virtual-assistants-overview/#how-do-conversational-virtual-assistants-work","title":"How Do Conversational Virtual Assistants Work?","text":"<p>A Conversational Virtual Assistant works by analyzing what users say, to detect their goals and extract the information required in order to achieve that goal.</p> <p>Let\u2019s take a look at the key components and the core process that enable a Virtual Assistant to fulfill its functions.</p>"},{"location":"virtual-assistants-overview/#the-key-components","title":"The Key Components","text":"<p>Whatever the user says is considered an Utterance. The main task of the Conversational VA is to analyze the utterance and extract the intent, and entities essential to carry a conversation. </p> <p>An Intent is the user\u2019s intention and usually comes in the form of a verb or noun within the user's utterance.</p> <p>Entities are a collection of data or information that the VA requires to complete the task which is identified in the user intent. They can be fields, data or words that the developer designates as necessary for the VA to complete a task. Entities can either be part of a user utterance, but the VA might also need to prompt the user to provide them. An Entity can be of any type; for instance: name, location, date, time, etc.</p> <p>For example, let us consider the following message that a user sends to the Virtual Assistant: </p> <p>I want to fly to London this weekend.</p> <ul> <li>The entire sentence represents the Utterance;</li> <li>\u201cI want to fly\u201d is the Intent;</li> <li>\u201cLondon\u201d and \u201cthis weekend\u201d form the values for the Entities representing \u201cDestination\u201d and \u201cTravel Date\u201d respectively. As you can notice, the \u201cSource\u201d entity value is missing and in such a case, the VA needs to ask the user where they want to fly from.</li> </ul>"},{"location":"virtual-assistants-overview/#the-core-process","title":"The Core Process","text":"<p>In order for a Conversational Virtual Assistant to work as intended, it has to simultaneously perform the following three processes:</p> <ul> <li>Detect the user\u2019s Intent: Understand what the user wants</li> <li>Extract Entities: Obtain specific information from the user, in order to accomplish what the user wants;</li> <li>Execute the Dialog Task: Participate in the conversation process in order to accomplish what the user wants.</li> </ul>"},{"location":"virtual-assistants-overview/#building-intelligent-conversational-virtual-assistants","title":"Building Intelligent Conversational Virtual Assistants","text":"<p>Virtual Assistants are not smart by default. They are designed to show some level of artificial intelligence by leveraging technologies such as machine learning, big data, natural language processing, etc. However, a Virtual Assistant is only intelligent when it can understand user needs, perspectives, or context, and responds according to the user\u2019s mood or emotion. This is only achievable through training and interaction with users, over a period of time. Below are a few suggestions that may help you increase your VA\u2019s level of intelligence.</p>"},{"location":"virtual-assistants-overview/#build-a-rich-collection-of-intents-and-entities","title":"Build a Rich Collection of Intents and Entities","text":"<p>The key for a Conversational Virtual Assistant to understand humans is its ability to identify human intentions (Intents), extract relevant information Entities) from utterances and map the relevant action/task against those utterances (Dialog Task execution). This is achievable using Natural Language Processing (NLP), which you can train according to your organization\u2019s needs.</p>"},{"location":"virtual-assistants-overview/#develop-conversations","title":"Develop Conversations","text":"<p>Managing dialogs to keep track of multiple conversation threads, remember the context, and respond to the user's tone or sentiment provides the much-needed humane touch to the conversation. At the same time, this serves the user with accurate and appropriate responses, ensuring a positive experience.</p>"},{"location":"virtual-assistants-overview/#build-a-knowledge-graph","title":"Build a Knowledge Graph","text":"<p>In addition, having a Knowledge Graph gives the VA the ability to respond to frequently asked questions that return static responses. Building such knowledge collections is an attempt to represent entities, ideas, and events with all their interdependent properties and relations according to a system of categories. This structured categorization of data helps the VA to answer user queries effectively and with ease.</p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/","title":"Web &amp; Mobile SDK: Message Formatting and Templates","text":"<p>Kore.ai SDK allows you to override the default message formatting using markdown and apply templates to display custom formatted bot messages to users. \\ This topic describes the following:</p> <ul> <li>Supported template types</li> <li>Template implementation details</li> <li>The default formatting for the Web SDK</li> <li>Supported markdown to customize messages</li> </ul>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#template-types","title":"Template Types","text":"<p>The SDKs support the following message template types. Depending on the SDK, the JavaScript implementation may vary.</p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#button-template","title":"Button Template","text":"<p>Shows one of the following button choices for the end user for each option:</p> <ul> <li>URL button: Opens a webpage in the application browser.</li> <li>Postback button: Sends the payload defined by the developer to the XO Platform to initiate action, for example, opens a chat window to a live agent.</li> </ul> <p>Required Parameters</p> <ul> <li>text: Enter the text consisting of up to 640 characters</li> <li>buttons: Enter a maximum of 3 array items</li> </ul> <p>Example</p> <pre><code>var message={\n  \"type\": \"template\",\n  \"payload\":\n    {\n     \"template_type\": \"button\",\n     \"text\": \"What do you want to do next?\",\n     \"buttons\":\n       [{\n         \"type\": \"web_url\",\n         \"title\": \"Show Website\",\n         \"url\": \"https://petersapparel.parseapp.com\"\n        },\n        {\n         \"type\": \"postback\",\n         \"title\": \"Start Chatting\",\n         \"payload\": \"USER_DEFINED_PAYLOAD\"\n        }\n       ]\n    }\n  }\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_1","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image1.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#quick-replies-template-text","title":"Quick Replies Template \u2013 Text","text":"<p>Shows a formatted text message to the user with clickable text choices. \\ Required Parameters</p> <ul> <li>text: Enter text consisting of up to 640 characters</li> <li>title: Enter a title for each option</li> </ul> <p>Example</p> <pre><code>var message=\n  {\n  \"type\":\"template\",\n  \"payload\":\n    {\n     \"template_type\":\"quick_replies\",\n     \"text\":\"Pick a color:\",\n     \"quick_replies\":\n       [\n        {\n         \"content_type\":\"text\",\n         \"title\":\"Red\",\n         \"payload\":\"DEVELOPER_DEFINED_PAYLOAD_FOR_PICKING_RED\"\n        },\n        {\n         \"content_type\":\"text\",\n         \"title\":\"Green\",\n         \"payload\":\"DEVELOPER_DEFINED_PAYLOAD_FOR_PICKING_GREEN\"\n        }\n       ]\n    }\n  }\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_2","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image2.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#quick-replies-template-text-and-image","title":"Quick Replies Template \u2013 Text and Image","text":"<p>Shows formatted text to the user with clickable text and images as choices. \\ Required Parameters</p> <ul> <li>text: Enter text consisting of up to 640 characters</li> <li>title: Enter a title for each option</li> </ul> <p>Example</p> <pre><code>var message =\n {\n  \"type\":\"template\",\n  \"payload\":\n    {\n     \"text\":\"Pick a color:\",\n     \"template_type\":\"quick_replies\",\n     \"quick_replies\":\n       [\n        {\n         \"content_type\":\"text\",\n         \"title\":\"Red\",\n         \"payload\":\"DEVELOPER_DEFINED_PAYLOAD_FOR_PICKING_RED\",\n         \"image_url\": \"https://cdn1.iconfinder.com/data/icons/brown-monsters/1024/Brown_Monsters_16-01.png\",\n        },\n        {\n         \"content_type\":\"text\",\n         \"title\":\"Green\",\n         \"payload\":\"DEVELOPER_DEFINED_PAYLOAD_FOR_PICKING_GREEN\",\n         \"image_url\": \"https://cdn3.iconfinder.com/data/icons/spring-2-1/30/Tree-128.png\",\n        }\n       ]\n    }\n  }\n  print(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#feedback-survey-templates","title":"Feedback Survey Templates","text":"<p>The Kore.ai XO Platform supports three new templates for the web/mobile client as part of the feedback module. These include NPS, CSAT, and Like/Dislike.</p> <p>While configuring the feedback survey, when the user selects a template, it\u2019s available as an override for the web/mobile client in the dialog. The system presents the selected template configured for the survey when collecting feedback from the customer on the web/mobile client. These templates are available as generic templates during feedback survey configuration in the channel template override section.</p> <p>NPS**Displays a dialog with a scoring scale from 0-10 for the customer to select. Each score icon appears in a different color, with **0 being the lowest and 10 being the highest rating. This template allows only one score selection by the customer.</p> <p>Required Parameters</p> <ul> <li>message</li> <li>template_type</li> <li>displayValues</li> <li>colors</li> </ul> <p>Example</p> <pre><code>var message =\n{\n  \"type\":\"template\",\n  \"payload\":\n      {\n       \"text\":\"On a scale of 0-10, how likely are you to recommend our product to your friends/family?\",\n       \"template_type\":\"feedbackTemplate\",\n       \"view\":\"NPS\",\"sliderView\":false,\"starArrays\":[],\n       \"messageTodisplay\":\"Glad you liked the experience. Thanks!\"\n      }\n };\n   message.payload.numbersArrays= [];\n   var displayValues = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"];\n   var colors = [\"#EF9AA3\",\"#EF9AA3\",\"#EF9AA3\",\"#EF9AA3\",\"#EF9AA3\",\"#EF9AA3\",\"#FB8460\",\"#FB8460\",\"#FB8460\",\"#28A745\",\"#28A745\"];\n    for(var i=0;i&lt;=10;i++)\n      {\n       var numberArray =\n          {\n            \"numberId\":i,\n            \"value\": displayValues[i],\n            \"color\":colors[i]\n          };\n          message.payload.numbersArrays.push(numberArray);\n      }\n    print(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image3.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>CSAT</p> <p>Displays a dialog with the feedback survey question and five smiley icons, each with a different expression to capture the customer\u2019s response. When the customer clicks an icon, it corresponds to a relevant survey score and response, which include \"Highly unsatisfied,\u201d \"Unsatisfied,\u201d \"Average,\u201d \"Satisfied,\u201d and \"Highly satisfied.\u201d Except for \u201cSatisfied\u201d and \u201cHighly Satisfied,\u201d the other responses prompt a follow-up question to the customer.</p> <p>Required Parameters</p> <ul> <li>payload: text</li> <li>template_type</li> <li>displayValues</li> <li>smileyArray</li> </ul> <p>Example</p> <pre><code>var message =\n {\n   \"type\":\"template\",\n   \"payload\":\n             {\n              \"text\":\"Are you satisfied with our product?\",\n              \"template_type\":\"feedbackTemplate\",\n              \"view\":\"CSAT\",\n              \"sliderView\":false,\n              \"starArrays\":[],\n              \"messageTodisplay\":\"Glad you liked the experience. Thanks!\"\n             }\n  };\n   var displayValues = [\"Highly Unsatisfied\",\"Unsatisfied\",\"Average\",\"Satisfied\",\"Highly satisfied\"];\n   message.payload.smileyArrays = [];\n     for(var i=1;i&lt;=5;i++)\n       {\n         var smileyArray =\n           {\n            \"smileyId\":i,\n            \"value\": displayValues[i-1],\n            \"reviewText\": displayValues[i-1]\n           };\n        message.payload.smileyArrays.push(smileyArray);\n       }\n      print(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image4.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Like/Dislike</p> <p>Displays a dialog with the feedback survey question and two icons to capture the customer\u2019s response. One is the Like icon, and the other is the Dislike icon. When the customer clicks the former, a response message is displayed. When the customer clicks the latter, a prompt displays the follow-up survey question to capture the customer\u2019s response.</p> <p>Required Parameters</p> <ul> <li>payload: text</li> <li>template_type</li> <li>messageTodisplay</li> <li>displayValues</li> <li>thumpsUpDownArray</li> </ul> <p>Example</p> <pre><code>var message =\n  {\n    \"type\":\"template\",\n    \"payload\":\n              {\n                \"text\":\"Would you recommend our product?\",\n                \"template_type\":\"feedbackTemplate\",\n                \"view\":\"ThumbsUpDown\",\n                \"sliderView\":false,\n                \"starArrays\":[],\n                \"messageTodisplay\":\"Glad you liked the experience. Thanks!\"\n              }\n   };\n    var displayValues = [\"Extremely Unlikely\",\"Extremely likely\"];\n    message.payload.thumpsUpDownArrays = [];\n      for(var i=0;i&lt;=1;i++)\n      {\n        var thumpsUpDownArray =\n              {\n                \"thumpUpId\":i,\n                \"value\": displayValues[i],\n                \"reviewText\": displayValues[i]\n              };\n       message.payload.thumpsUpDownArrays.push(thumpsUpDownArray);\n     }\n     print(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image5.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#list-template","title":"List Template","text":"<p>Shows a formatted list of choices to the user as clickable text and images as choices. List template has the following limitations:</p> <ul> <li>Maximum of four elements</li> <li>One optional button per element</li> <li>One optional global button</li> </ul> <p>Required Parameters</p> <ul> <li>AlwaysShowGlobalButtons: set to true if the global button needs to be displayed always, by default it is set to false ensuring that the global buttons are displayed only when the number of entries in the list exceeds 3,</li> <li>title: Enter a title for each option</li> <li>elements</li> </ul> <p>Example</p> <pre><code>var message =\n{\n        \"type\": \"template\",\n        \"AlwaysShowGlobalButtons\":false,\n        \"payload\": {\n            \"template_type\": \"list\",\n            \"elements\": [\n                {\n                    \"title\": \"Classic T-Shirt Collection\",\n                    \"image_url\": \"https://peterssendreceiveapp.ngrok.io/img/collection.png\",\n                    \"subtitle\": \"See all our colors\",\n                    \"default_action\": {\n                        \"type\": \"web_url\",\n                        \"url\": \"https://peterssendreceiveapp.ngrok.io/shop_collection\",\n                        \"messenger_extensions\": true,\n                        \"webview_height_ratio\": \"tall\",\n                        \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                    },\n                    \"buttons\": [\n                        {\n                            \"title\": \"View\",\n                            \"type\": \"web_url\",\n                            \"url\": \"https://peterssendreceiveapp.ngrok.io/collection\",\n                            \"messenger_extensions\": true,\n                            \"webview_height_ratio\": \"tall\",\n                            \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                        }\n                    ]\n                },\n                {\n                    \"title\": \"Classic White T-Shirt\",\n                    \"image_url\": \"https://peterssendreceiveapp.ngrok.io/img/white-t-shirt.png\",\n                    \"subtitle\": \"100% Cotton, 200% Comfortable\",\n                    \"default_action\": {\n                        \"type\": \"web_url\",\n                        \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=100\",\n                        \"messenger_extensions\": true,\n                        \"webview_height_ratio\": \"tall\",\n                        \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                    },\n                    \"buttons\": [\n                        {\n                            \"title\": \"Shop Now\",\n                            \"type\": \"web_url\",\n                            \"url\": \"https://peterssendreceiveapp.ngrok.io/shop?item=100\",\n                            \"messenger_extensions\": true,\n                            \"webview_height_ratio\": \"tall\",\n                            \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                        }\n                    ]\n                },\n                {\n                    \"title\": \"Classic Blue T-Shirt\",\n                    \"image_url\": \"https://peterssendreceiveapp.ngrok.io/img/blue-t-shirt.png\",\n                    \"subtitle\": \"100% Cotton, 200% Comfortable\",\n                    \"default_action\": {\n                        \"type\": \"web_url\",\n                        \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=101\",\n                        \"messenger_extensions\": true,\n                        \"webview_height_ratio\": \"tall\",\n                        \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                    },\n                    \"buttons\": [\n                        {\n                            \"title\": \"Shop Now\",\n                            \"type\": \"web_url\",\n                            \"url\": \"https://peterssendreceiveapp.ngrok.io/shop?item=101\",\n                            \"messenger_extensions\": true,\n                            \"webview_height_ratio\": \"tall\",\n                            \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                        }\n                    ]\n                },\n                {\n                    \"title\": \"Classic Black T-Shirt\",\n                    \"image_url\": \"https://peterssendreceiveapp.ngrok.io/img/black-t-shirt.png\",\n                    \"subtitle\": \"100% Cotton, 200% Comfortable\",\n                    \"default_action\": {\n                        \"type\": \"web_url\",\n                        \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=102\",\n                        \"messenger_extensions\": true,\n                        \"webview_height_ratio\": \"tall\",\n                        \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                    },\n                    \"buttons\": [\n                        {\n                            \"title\": \"Shop Now\",\n                            \"type\": \"web_url\",\n                            \"url\": \"https://peterssendreceiveapp.ngrok.io/shop?item=102\",\n                            \"messenger_extensions\": true,\n                            \"webview_height_ratio\": \"tall\",\n                            \"fallback_url\": \"https://peterssendreceiveapp.ngrok.io/\"\n                        }\n                    ]\n                }\n            ],\n             \"buttons\": [\n                {\n                    \"title\": \"View More\",\n                    \"type\": \"postback\",\n                    \"payload\": \"payload\"\n                }\n            ]\n        }\n}\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_3","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image6.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#error-template","title":"Error Template","text":"<p>Shows formatted messages to an end user for validation, errors and warning messages. \\ Example</p> <pre><code>var message={\n   \"type\":\"error\",\n   \"payload\":{\n      \"color\":\"#F35A00\",\n      \"text\":\"sample for error template\"\n   }\n}\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_4","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image7.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#attachment-template","title":"Attachment Template","text":"<p>Provides support to display images, render videos, links and play audio files to a user based on specified URL links.</p> <p>The following formats are supported for attachment template:</p> <ul> <li>audio = ['m4a', 'amr', 'wav', 'aac', 'mp3']</li> <li>video = ['mp4', 'mov', '3gp', 'flv']</li> <li>image = ['png', 'jpg', 'jpeg', '.GIF']</li> </ul> <p>Note: To display images in the attachment template use the \"url\" of the image.</p> <p>Examples</p> <p>Audio Template:</p> <pre><code>var message ={\n        \"type\": \"message\",\n         \"payload\": {\n          \"text\": \"\",\n          \"audioUrl\": \"https://file-examples-com.github.io/uploads/2017/11/file_example_MP3_700KB.mp3\"\n      }\n}\nprint(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image8.jpg). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Image Template</p> <p>To view image, use the following JS script:</p> <pre><code>var message = {\n    \"type\": \"image\",\n    \"payload\": {\n    \"url\": \" https://i.mdel.net/i/db/2017/12/822869/822869-800w.jpg\"\n    }\n    }\n    print(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image9.jpg). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Video Template</p> <p>You can either download or watch the video directly in the assistant window.</p> <p>To download and watch the video, use this JS script:</p> <pre><code>var message =\n   {\n      \"type\": \"video\",\n      \"payload\": {\n     \"url\": \" https://www.youtube.com/watch?v=a3aobWbIOj8\"\n    }\n  }\n    print(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image10.jpg). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>To play the video within the assistant window, use this JS script:</p> <pre><code>var message =\n   {\n       \"type\": \"message\",\n      \"payload\": {\n      \"text\": \"\",\n      \"videoUrl\": \"https://demo.kore.ai/barefoot/sites/default/files/demo_uploads/videoplayback.mp4\"\n    }\n}\nprint(JSON.stringify(message));\n</code></pre> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image11.jpg). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#text-template","title":"Text Template","text":"<p>Shows messages to the user using XO Platform defined default formatting. \\ Example</p> <pre><code>var message=\n {\n   \"text\" : \"message\"\n  }\nprint(JSON.stringify(message);\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#carousel-template","title":"Carousel Template","text":"<p>Shows a horizontal scrollable carousel of items, each composed of an image attachment, a short description, and buttons to request user input. \\ Required Parameters:</p> <ul> <li>title</li> <li>image_url</li> <li>elements</li> <li>buttons (only up to three items)</li> </ul> <p>Example</p> <pre><code>var message = {\n  \"type\": 'template',\n  \"payload\":\n    {\n     \"template_type\": 'carousel',\n     \"elements\":\n      [{\n        \"title\": \"Welcome to Peter\\'s Hats1\",\n        \"image_url\": \"https://previews.123rf.com/images/rez_art/rez_art1405/rez_art140500072/28632615-three-beef-tacos-with-cheese-lettuce-and-tomatos-Stock-Photo-taco.jpg\",\n        \"subtitle\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n        \"default_action\":\n         {\n           \"type\": \"web_url\",\n           \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=103\"\n           //or\n           //\"type\": \"postback\",\n           //\"title\": \"discard\",\n           //\"payload\":\"clear payload\"\n         },\n        \"buttons\":\n          [{\n            \"type\": \" postback\",\n            \"title\": \"Buy now\",\n            \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_0\"\n           },\n           {\n            \"type\": \"postback\",\n            \"title\": \"Show more like this\",\n            \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_1\"\n           }]\n       },\n       {\n        \"title\": \"Welcome to Peter\\'s Hats2\",\n        \"image_url\": \"https://static.pexels.com/photos/46239/salmon-dish-food-meal-46239.jpeg\",\n        \"subtitle\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n        \"default_action\":\n         {\n           \"type\": \"web_url\",\n           \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=103\"\n          },\n         \"buttons\":\n           [{\n             \"type\": \"postback\",\n             \"title\": \"Buy now\",\n             \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_0\"\n            },\n            {\n             \"type\": \"postback\",\n             \"title\": \"Show more like this\",\n             \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_1\"\n            }]\n       },\n       {\n        \"title\": \"Welcome to Peter\\'s Hats3\",\n        \"image_url\": \"https://previews.123rf.com/images/rez_art/rez_art1405/rez_art140500072/28632615-three-beef-tacos-with-cheese-lettuce-and-tomatos-Stock-Photo-taco.jpg\",\n        \"subtitle\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n        \"default_action\":\n         {\n           \"type\": \"web_url\",\n           \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=103\"\n         },\n        \"buttons\":\n          [{\n            \"type\": \"postback\",\n            \"title\": \"Buy now\",\n            \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_0\"\n           },\n           {\n            \"type\": \"postback\",\n            \"title\": \"Show more like this\",\n            \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_1\"\n            }]\n       },\n       {\n        \"title\": \"Welcome to Peter\\'s Hats4\",\n        \"image_url\": \"https://static.pexels.com/photos/416458/pexels-photo-416458.jpeg\",\n        \"subtitle\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\",\n        \"default_action\":\n          {\n           \"type\": \"web_url\",\n           \"url\": \"https://peterssendreceiveapp.ngrok.io/view?item=103\"\n          },\n         \"buttons\":\n           [{\n             \"type\": \"postback\",\n             \"title\": \"Buy now\",\n             \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_0\"\n            },\n            {\n             \"type\": \"postback\",\n             \"title\": \"Show more like this\",\n             \"payload\": \"DEVELOPER_DEFINED_PAYLOAD_1\"\n            }]\n     }]\n  }\n }\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_5","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image12.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#piechart-template","title":"Piechart Template","text":"<p>This template is supported only for Web SDK; doesn't apply for Mobile SDK.</p> <p>Shows the data in a Pie chart in one of these three variations - regular full pie, donut pie, and donut pie with legend table. If you do not specify a type, \u201cregular\u2019 will be considered by default \\ Required Parameters</p> <ul> <li>template_type</li> <li>elements</li> </ul> <pre><code>var message = {\n  \"type\": \"template\",\n  \"payload\":\n    {\n     \"text\": \"Travelling expenses report chart\",\n     \"template_type\": \"piechart\",\n     \"pie_type\": \"regular\",\n     \"elements\":\n       [{\n         \"title\": \"Airlines\",\n         \"value\": \"1264.0\",\n         \"displayValue\": \"$ 1,234\"\n        },\n        {\n         \"title\": \"Hotels\",\n         \"value\": \"568.10\",\n         \"displayValue\": \"$ 568\"\n        },\n       {\n        \"title\": \"Food\",\n        \"value\": \"324.50\",\n        \"displayValue\": \"$ 324\"\n       }],\n     speech_hint: \"You spent $2855.71 from your account. Here is the breakup.\"\n    }\n  }\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_6","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image13.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#line-chart-template","title":"Line Chart Template","text":"<p>This template is supported only for Web SDK; doesn't apply for Mobile SDK.</p> <p>Shows the data in a line chart. \\ Required Parameters</p> <ul> <li>template_type</li> <li>x_axis</li> <li>elements</li> </ul> <p>Example</p> <pre><code>var message =\n {\n  \"type\": \"template\",\n  \"payload\":\n   {\n    \"text\":\"Peter Sam Report\",\n    \"template_type\": \"linechart\",\n    \"X_axis\": [\"15-Jan-2017\", \"20-Jan-2017\", \"25-Jan-2017\", \"30-Jan-2017\"],\n    \"Auto_adjust_X_axis\": \"yes\",\n    \"elements\":\n      [\n       {\n        \"title\":  \"Peter\",\n        \"values\": [10,5,15,20],\n        \"displayValues\": [\"10ml\",\"5ml\",\"15ml\",\"20ml\"]\n       },\n       {\n        \"title\": \"Sam\",\n        \"values\": [30,15,12,60],\n        \"displayValues\": [\"30 mins\",\"15 mns\",\"12 mins\",\"1 hour\"]\n       }\n      ],\n    speech_hint:\"Here is your report\"\n   }\n  }\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_7","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image14.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#bar-chart-template","title":"Bar Chart Template","text":"<p>This template is supported only for Web SDK; doesn't apply for Mobile SDK.</p> <p>Shows the data in a bar graph in one of these variants: a single data series simple bar graphs, multiple data series bar graphs, or stacked multiple data series bar graphs. \\ Required Parameters</p> <ul> <li>template_type</li> <li>x_axis</li> <li>elements</li> </ul> <p>Example</p> <pre><code>var message =\n {\n   \"type\": \"template\",\n   \"pay load\":\n     {\n       \"text\":\"Peter Sam Report\",\n       \"template_type\": \"barchart\",\n       \"direction\":\"vertical\",\n       \"auto_adjust_X_axis\" : \"no\",\n       \"stacked\":false,\n       \"X_axis\": [\"15-Jan-2017\", \"20-Jan-2017\", \"25-Jan-2017\", \"30-Jan-2017\"],\n       \"Auto_adjust_X_axis\": \"yes\",\n       \"elements\":\n          [\n           {\n            \"title\":  \"Peter\",\n            \"values\": [10,5,15,20],\n            \"displayValues\": [\"10ml\",\"5ml\",\"15ml\",\"20ml\"]\n           },\n           {\n            \"title\": \"Sam\",\n            \"values\": [30,15,12,60],\n            \"displayValues\": [\"30 mins\",\"15 mns\",\"12 mins\",\"1 hour\"]\n           }\n          ],\n       speech_hint:\"Here is your report\"\n    }}\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_8","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image15.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#regular-table-template","title":"Regular Table Template","text":"<p>This template is supported only for Web SDK; doesn't apply for Mobile SDK.</p> <p>Shows the data in a regular or responsive table format. \\ Required Parameters</p> <ul> <li>template_type</li> <li>columns: Array of column names in the table</li> </ul> <pre><code>var m  essage =\n{\n  \"type\": \"template\",\n  \"payload\":\n    {\n     \"template_type\": \"table\",\n     \"text\":\"Account details\",\n     \"columns\":\n       [\n        [\"Sl\",\"center\"],[\"Name\"],[\"Designation\"],[\"Salary\",\"right\"]\n       ],\n     \"table_design\": \"regular\",\n     \"elements\":\n       [\n        {\n          \"Values\": [\"1\",\"Peter\",\"Producer\",\"1,000\"]\n        },\n        {\n          \"Values\": [\"2\",\"Sam\",\"Director\",\"2,000\"]\n        },\n        {\n          \"Values\": [\"3\",\"Nick\",\"DoP\",\"1,500\"]\n        }\n       ],\n     speech_hint:\"Here is your account details\"\n    }}\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_9","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image16.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#mini-table-template","title":"Mini Table Template","text":"<p>This template is supported only for Web SDK; doesn't apply for Mobile SDK.</p> <p>For each row header in a table, this template shows column data as separate cards. This is ideally suitable for data with 3-4 columns and 4-5 rows. \\ Required Parameters</p> <ul> <li>template_type</li> <li>elements</li> </ul> <p>Example</p> <pre><code>var message = {\n  \"type\": \"template\",\n  \"payload\": {\n     \"template_type\": \"mini_table\",\n     \"layout\": \"horizontal\",\n     \"text\":\"Account details\",\n     \"elements\": [\n        {\n         \"primary\":[[\"Current Accounts\"],[\"300\",\"right\"]],\n         \"additional\":[[\"CA00001\",\"150\"],[\"CA00123\",\"50\"],[\"CA23423\",\"100\"]]\n        },\n        {\n         \"primary\":[[\"Savings Accounts\"],[\"200\",\"right\"]],\n         \"additional\":[[\"SA33001\",\"75\"],[\"SA67345\",\"125\"]]\n        }\n       ],\n     speech_hint:\"Here is your account details\"\n    }\n  };\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#_10","title":"Web & Mobile SDK Message Formatting and Templates","text":"<p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image17.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#botkit-sdk-message-formatting-with-templates","title":"BotKit SDK Message Formatting with Templates","text":"<p>You can also apply message templates in the BotKit SDK using the sendUserMessage function by setting the <code>isTemplate</code> parameter to <code>true</code> in the payload object as shown in the following example.</p> <pre><code>on_user_message: function(requestId, data, callback) {\n console.log(\"User Message -----&gt;\", data.message);\n //console.log(JSON.stringify(data));\n if (data.message === \"Hi\") {\n    {\n      var overrideMessagePayload =\n         {\n           body : JSON.stringify({\n             \"type\": \"template\",\n             \"payload\":\n               {\n                 \"template_type\": \"button\",\n                 \"text\": \"This is an example to demonstrate message templates sent from bot kit\",\n                 \"buttons\":\n                    [{\n                       \"type\": \"postback\",\n                       \"title\": \"Yes\",\n                       \"payload\": \"Yes\"\n                     },\n                     {\n                       \"type\": \"postback\",\n                       \"title\": \"No\",\n                       \"payload\": \"No\"\n                     }]\n               }\n             }),\n           isTemplate :true\n          }\n    data.overrideMessagePayload= overrideMessagePayload;}\n   return sdk.sendUserMessage(data, callback);\n }\n</code></pre>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#standard-markdown-support","title":"Standard Markdown Support","text":"<p>You can apply your formatting directly in JavaScript using Kore.ai markdown as described.</p> <ul> <li>Bold - text to be bolded Do not add spaces after or before the \" * \" symbol. For example, <code>Here is *bold*.</code></li> <li>Italic - ~test to be italicized~ Do not add spaces after or before the \" ~ \" symbol. For example, <code>Here is ~italics~.</code> Preceeding and succeeding _ will also italicise the enclosed text, i.e. <code>Here is _italics_.</code></li> <li>Link - Text for the link here For example, <code>Here is a link to [Kore.ai.com](https://kore.ai/).</code></li> <li>New Line - \\n One line indention.</li> <li>Multi Line - \\n\\n\\n Three line indentions.</li> <li>Image -  For example, <code>![My image](http://d1hqmx8kqvpnpa.cloudfront.net/f-eeca5df3-7580-5a09-9aa3-09f809b44ac4.png)</code></li> <li>List -<ul> <li>Unordered Bulleted List - * Text for the list time  Add a space after the \" * \" symbol.<ul> <li><code>* This is an example of an unordered list Bullet 1.</code></li> <li><code>* This is an example of an unordered list Bullet 2.</code></li> <li><code>* This is an example of an unordered list Bullet 3.</code></li> </ul> </li> <li>Ordered List -<ul> <li><code>1. This is an example of an ordered list Bullet 1.</code></li> <li><code>2. This is an example of an ordered list Bullet 2.</code></li> <li><code>3. This is an example of an ordered list Bullet 3.</code></li> </ul> </li> </ul> </li> <li>Preformatted Text - <code>text</code> The text between the \" <code>\" symbols is formatted. For example, `Here is an example of</code>preformatting<code>``.</code>&gt;</li> <li>Paragraph Indent - &gt;&gt; For example, <code>&gt;&gt;This is indented once.</code></li> <li>Multi Indent - &gt;&gt;&gt;&gt; For example, <code>&gt;&gt;&gt;&gt;This is indented twice.</code></li> <li>Heading - #h1, #h2, #h3, #h4, #h5, #h6 For example,<ul> <li><code>Here is an example of #h1Heading1.</code></li> <li><code>Here is an example of #h2Heading2.</code></li> <li><code>Here is an example of #h3Heading3.</code></li> <li><code>Here is an example of #h4Heading4.</code></li> <li><code>Here is an example of #h5Heading5.</code></li> <li><code>Here is an example of #h6Heading6.</code></li> </ul> </li> <li>Horizontal Rule - ___ Three underscores inserts a horizontal line. For example, <code>This is a horizontal rule line, added three times. _________</code> *</li> </ul>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#default-message-templates-for-web-sdk","title":"Default Message Templates for Web SDK","text":"<p>When custom formatting is not defined, the following default message formatting types apply to the Web SDK.</p> <ul> <li>Choice Message<ul> <li>If the number of options is 3 or less, the Button Template is used.</li> <li>If the number of options is between 3  and 10, the Quick Replies Template is used.</li> <li>If the number of options is greater than 10, the Quick Replies Template is used. The 9th option is displayed as Show more which when clicked opens the next set of options.</li> <li>If the button title &gt; 20 characters, 18 characters and two periods get displayed. When the user clicks the title, the full title gets displayed.</li> </ul> </li> <li>Confirmation Message<ul> <li>Quick Replies Template is used with Yes and No options.</li> </ul> </li> <li>Question Message<ul> <li>Plain text.</li> </ul> </li> <li>Error Message<ul> <li>Text with red font color is sent as an attachment</li> </ul> </li> <li>Warning Message<ul> <li>Text with orange font color is sent as an attachment</li> </ul> </li> <li>Validation Message<ul> <li>Text with yellow font color is sent as an attachment</li> </ul> </li> <li>Info, Statement, Greeting, Chit Chat Messages<ul> <li>Plain text</li> </ul> </li> </ul>"},{"location":"web-mobile-SDK-message-formatting-and-templates/#custom-templates","title":"Custom Templates","text":"<p>Apart from using the above templates, you can build your own custom template.</p> <p>The following are the custom templates provided for you at webSDK for reference to build your own templates.</p> <p>Drop down template \\ <code>var message =  {</code></p> <pre><code>        \"type\": \"template\",\n        \"payload\": {\n            \"template_type\": \"dropdown_template\",\n            \"heading\":\"please select : \",\n            \"elements\": [\n                {\n                    \"title\": \"United Arab Emirates Dirham\",\n                    \"value\":\"AED\"\n                },\n                {\n                    \"title\": \"Australian Dollar\",\n                    \"value\":\"AUD\"\n                },\n                {\n                    \"title\": \"Canadian Dollar\",\n                    \"value\":\"CAD\"\n                },\n                {\n                    \"title\": \"Swiss Franc\",\n                    \"value\":\"CHF\"\n                },\n                {\n                    \"title\": \"Chinese Yuanr\",\n                    \"value\":\"CNY\"\n                },\n                {\n                    \"title\": \"Czech Koruna\",\n                    \"value\":\"CZK\"\n                }\n\n            ],\n        }\n};\n</code></pre> <ol> <li><code>print(JSON.stringify(message)); \\</code></li> </ol> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image18.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Like-dislike template: \\ <code>var message = {</code></p> <pre><code>  \"type\": \"template\",\n  \"payload\": {\n     \"template_type\": \"like_dislike\"\n     }\n  };\n</code></pre> <ol> <li><code>print(JSON.stringify(message)) \\</code></li> </ol> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image19.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Multi-select Template: \\ <code>var message = {</code></p> <pre><code>  \"type\": \"template\",\n  \"payload\": {\n      \"template_type\": \"multi_select\",\n      \"elements\": [\n         {\n           \"title\": \"Classic T-Shirt Collection\",\n           \"value\":\"tShirt\"\n          },{\n           \"title\": \"Classic Shirt Collection\",\n           \"value\":\"shirts\"\n          },\n          {\n           \"title\": \"Classic shorts Collection\",\n           \"value\":\"shorts\"\n          }\n        ],\n  \"buttons\": [\n     {\n       \"title\": \"Done\",\n       \"type\": \"postback\",\n       \"payload\": \"payload\"\n     }\n    ]\n  }\n};\n</code></pre> <ol> <li><code>print(JSON.stringify(message)) \\</code></li> </ol> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image20.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>To understand customized JavaScript responses and channel-specific templates, refer to Customize JavaScript Responses in User Prompts.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/","title":"Real-time Agent Coaching","text":""},{"location":"agentassist/agent-experience/agent-realtime-coaching/#introduction","title":"Introduction","text":"<p>Contact center agents are often under pressure to provide better customer experiences. Dealing with high call volumes and complex conversations can make it challenging for agents to meet or exceed customer expectations without sufficient support, guidance, and tools.</p> <p>The Real-time Agent Coaching feature enables real-time coaching based on the analysis of agent utterances and speech. You can set up specific utterances and speech patterns for AgentAssist to take relevant actions, such as providing hints and nudges or emailing the manager when those patterns occur.</p> <p>As a contact center supervisor, you can view triggered utterances, including the frequency of their occurrence, and evaluate how well agents follow the recommended actions within a specific time frame. You can also review speech patterns such as cross talks, dead air, and speech speed to help agents optimize their communication style.</p> <p>This document is meant for the contact center supervisors and explains everything about the Real-time Agent Coaching feature, including rules, associated triggers, and actions.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#rules","title":"Rules","text":"<p>Rules are a combination of triggers and actions to solve an issue. Each rule is an independent entity that you can edit, delete, tag, untag, enable, or disable. For easy identification, you can tag all relevant rules with the same tag. You can use multiple tags for one rule and one tag for multiple rules. Real-time Agent Coaching has two types of rules:</p> <ul> <li>Pre-built: These are pre-existing coaching options that come with Agent Coaching.</li> <li>New rules: These are new rules you can create based on your requirements.</li> </ul> <p>Currently, the pre-built rules section has two rules - None Intent and Price Objection.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#none-intent","title":"None Intent","text":"<p>The None Intent rule contains utterances that are used to prevent false positives during intent identification. By using these utterances, you can train the system to differentiate between a positive (trained) and a false-positive (wrong, untrained, ambiguous) utterance. For example, an utterance \u201cI need help with my account\u201d is a positive intent and the system has to act accordingly, but an utterance \u201cIt is too expensive\u201d is a false-positive intent wherein the system should not take any action.</p> <p>This rule is enabled by-default, and you can\u2019t disable or delete it. You can, however, add more utterances to make this rule more effective.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#adding-none-intent-utterances","title":"Adding None Intent Utterances","text":"<p>You can add utterances in two ways:</p> <ul> <li>AI Assist: You can take assistance from AI to generate and add more none intent utterances, based on the utterances of your selected rules.</li> <li>Input Utterances Manually: You can manually enter and save none intent utterances.</li> </ul> <p>Steps to add none intent utterances:</p> <ol> <li>Log in to Agentassist {:target=\"_blank\"}.</li> <li>Click Configuration&gt; Agent Coaching.</li> <li>Click the edit button under Actions. </li> <li>Click Add Utterance(s). </li> <li>Select AI Assist or Input Utterances Manually.</li> </ol> <p>Follow these steps if you select AI Assist:     1. Select AI Assist.      2. Select rules, as required, from the Add Rules list and click Add.      3. All added rules are displayed on the left, and the AI starts searching for more utterances that are similar in meaning to the utterances of your selected rules..       4. Select utterances, as required, and then click Add Selected.      5. Click Save to complete the process. </p> <pre><code>**Follow these steps if you select Input Utterances Manually:**\n\n1. Select **Input Utterances Manually**.\n![Alt text](./images/option-to-manually-enter-utterances-image_8.png)\n2. Enter your utterance in the **Utterances** field and press the **Enter** key.\n![Alt text](./images/entering-utterances-manually-image_9.png)\n</code></pre> <p>Following this step, you can add multiple utterances.     3. Click Save . </p> <pre><code>    * The new utterance gets added to the list of utterances.\n</code></pre> <p></p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#price-objection","title":"Price Objection","text":"<p>This is a predefined rule with conditions and actions that come with Agent Coaching. You can customize the conditions and actions, but can\u2019t edit or delete the rule name. However, you can disable this rule, if needed. It contains a customer\u2019s price objection utterance and defines the actions agents should take in response. The predefined conditions and actions are:</p> <ul> <li>Condition (When): Price objection utterance by customer</li> <li>Actions (Then do):<ul> <li>Alert Type: Hint Agent</li> <li>Alert Title: Price Objection identified</li> <li>Alert Body: Please reassure the customer and offer discounts</li> <li>Alert Display: Doesn\u2019t auto close</li> <li>Alert Adherence: \u201cOk, Got it\u201d</li> </ul> </li> <li>Assigned to: All Agents</li> </ul> <p>The following screenshot displays the Price Objection rule:</p> <p> For information on rule functionalities, refer to the section Create, Publish, Edit, Delete, and Disable Rules</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#create-publish-edit-delete-and-disable-rules","title":"Create, Publish, Edit, Delete, and Disable Rules","text":"<p>This section explains how to create, tag, publish, edit, delete, and disable rules.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#creating-a-new-rule","title":"Creating a New Rule","text":"<p>From time to time, depending on newer or different situations, you can create new rules to help agents with newer issues. This section explains the steps to create a new rule.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-create-a-new-rule","title":"Steps to create a new rule:","text":"<ol> <li>Log in to https://agentassist.kore.ai/koreagentassist.</li> <li>Click Configuration&gt;Agent Coaching. </li> <li>Click +New Rule. </li> <li>Enter a name for the new rule in the Name field. </li> <li> <p>Enter a short description about the rule in the Description field. To read how to form a rule description, hover over the \u201ci\u201d button beside the Description field. </p> <p>The rule description should be concise and include keywords and conditions. It trains our AI for real-time assistance. 6. Enter a tag in the Tag field and then press the Enter key to add the tag. 7. Click Voice or Live Chat or both in the Channels field. * Voice: Choose Voice if you want this rule to take input utterance only through the voice (voice calls) medium. * Live Chat: Choose Live Chat if you want this rule to take input utterance only through the live chat (text messages) medium. * Both: Choose both Voice and Live Chat if you want this rule to take input utterance through both these mediums. 8. Click Apply to complete the rule creation process:  A message shows up to confirm new rule creation. 9. Click +Add a trigger under When\u2026 to add a trigger condition for the rule. For more information, refer to the Agent Coaching Rule Triggers section. 10. Click +Add an action under Then do\u2026 to add an action for the rule. For more info, refer to the Agent Coaching Actions section. 11. Click Add agents, groups under Assign this to\u2026 to add agents or groups you want to assign this rule to. For more info, refer to the Assign this to section. 12. Click Save.</p> </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#publishing-a-rule","title":"Publishing a Rule","text":"<p>After creating a new rule, you need to publish it to be available in the system. You can either publish a rule after it\u2019s created or wait and publish multiple new rules at once.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-publish-a-rule","title":"Steps to publish a rule","text":"<ol> <li>Log in to https://agentassist.kore.ai/koreagentassist.</li> <li>Click Configuration&gt; Agent Coaching.</li> <li>Click the Publish button on the top right corner of the page.  <ul> <li>The Published Successfully confirmation message appears on the screen. </li> </ul> </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#editing-a-rule","title":"Editing a Rule","text":"<p>You can add to or change an existing rule, from time to time based on the requirements.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-edit-a-rule","title":"Steps to edit a rule","text":"<ol> <li>Log in to https://agentassist.kore.ai/koreagentassist.</li> <li>Click Configuration&gt;Agent Coaching.</li> <li>Locate the rule you want to edit\u2013either from the displayed list or by partially entering the rule name in the Search box.<ul> <li>As you start entering the rule name, matching rule names appear on the screen. </li> </ul> </li> <li>Click the edit button beside a rule name that you want to edit. \\ </li> </ol> <p>Note: Co-editing a rule is not allowed\u2013if you edit a rule, it's locked, and no one else can edit or delete it simultaneously. AgentAssist will notify you if you attempt to co-edit a rule. If a rule is locked for editing, but the user has not performed any editing for 15 minutes or left the Rules Configuration screen, AgentAssist unlocks the rule for editing by another user.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#deleting-a-rule","title":"Deleting a Rule","text":"<p>You can delete a rule due to irrelevance or other reasons. AgentAssist lets you delete an existing rule with the click of a button.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-delete-a-rule","title":"Steps to delete a rule","text":"<ol> <li>Go to the Configuration &gt; Agent Coaching main page.</li> <li>Click the delete button beside a rule name that you want to delete. </li> <li>Click the Yes button in the confirmation popup window. \\ </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#disabling-a-rule","title":"Disabling a Rule","text":"<p>If you don\u2019t want to use a rule temporarily, you can disable it.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-disable-a-rule","title":"Steps to disable a rule","text":"<ol> <li>Go to the Configuration &gt; Agent Coaching main page.</li> <li>In the Enabled column, click the disable   button corresponding to the rule you want to disable. <ul> <li>The Configuration has been saved message appears on the screen. </li> </ul> </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#agent-coaching-rule-triggers-when","title":"Agent Coaching Rule Triggers (When\u2026)","text":"<p>Trigger setting is essential to rule creation. You can\u2019t have a rule without a trigger. Triggers define the conditions for a rule to come into effect. This section explains how to set up triggers for new rules. The available triggers are:</p> <ul> <li>Utterance Triggers</li> <li>Speech Analysis Triggers</li> </ul>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#utterance-triggers","title":"Utterance Triggers","text":"<p>Utterances are inputs from either the customers or the agents. In Utterance Triggers, you set up conditions like input from customer or agent, the number of times the input came, and the time frame within which the input came to set off the trigger.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-set-up-utterance-triggers","title":"Steps to set up Utterance Triggers:","text":"<ol> <li>Go to the rule trigger creation page. For help, refer to Steps to create a new rule.</li> <li>Under When, click the + Add a trigger button. </li> <li>Select Utterance. </li> <li>Click {select person}. </li> <li>Select either Agent or Customer.</li> <li>Click set utterances. </li> <li>Enter an utterance that the user (customer or agent) may use in the Utterances box.</li> <li> <p>Select the utterance you have entered. </p> <ul> <li>There may be other matching utterances the AI suggests: </li> <li>Select the AI-suggested utterances, as required.  Note: AI suggests utterances that match with what you have entered based on conversation history. It also shows the appearance percentage of utterances.  </li> <li>Click Add. (The appearance of this button is based on the number of utterances entered by you plus the number of AI-suggested utterances you have selected. In this example, it\u2019s 1+3. So, it\u2019s displayed as Add 4.) </li> <li>Click Okay. </li> <li>Click Save.   Note: Before clicking the Save button, you can delete any utterance that you either would have added by mistake or think is not relevant.</li> <li>The following screen appears: </li> <li>Click 1 time to select the number of times any of these utterances appear. The default selection is 1 time. For example, a customer may use any of these utterances once by mistake and to be sure, you want the customer to use them twice or thrice. You need to select 2 times or 3 times for such situations. </li> <li>Click the default time frame, in conversation, to change it if you want to select other options. </li> <li>If you select Anytime in conversation, the following screen appears: </li> <li>If you select By time, the following screen appears:  From the dropdown, select first or within and enter the time in seconds.</li> <li>If you select By number of messages, the following screen appears: </li> </ul> </li> </ol> <p>From the dropdown, select first or within and enter a number in the messages field. 15. Press the Enter key to complete the process.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#speech-analysis-triggers","title":"Speech Analysis Triggers","text":"<p>This feature analyzes the speech pattern or event of both the customer and the agent and provides real-time feedback and coaching to improve customer-agent conversation quality. This section explains the steps to set up the Speech Analysis Triggers feature.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-set-up-speech-analysis-triggers","title":"Steps to set up Speech Analysis Triggers","text":"<ol> <li>Select Speech Analysis after clicking When &gt; +Add a trigger. </li> <li>Click {speech type} and select a type for analysis. <ul> <li>If you select Cross Talk, the following screen appears: <ol> <li>Click 30 to enter the duration in seconds\u201330 seconds is the default value.</li> <li>Enter the duration in seconds and then press the Enter key. </li> <li>Click 1 time to update the number of times crosstalk happened in a conversation. </li> <li>Click to select the number of times, as required.</li> <li>Click in conversation to update when crosstalk happened\u2013in conversation is the default value. <ol> <li>If you select Anytime in conversation, the following screen appears: </li> <li>If you select By time, the following screen appears: <ol> <li>From the dropdown, select first or within and enter the time in seconds.</li> <li>Press the Enter key to save the new values. Note: A validation error is displayed, as highlighted in the screenshot, either if the configured crosstalk time duration is lesser than the selected conversation time period or if the trigger setup is incomplete.</li> </ol> </li> </ol> </li> </ol> </li> <li>If you select Dead Air, the following screen appears: <ol> <li>Click 30 to enter the duration in seconds, and then press the Enter key to save it. </li> <li>Click {select person} to select the user. </li> <li>Click 1 time to select the frequency.</li> <li>Click In conversation to select a time frame. <ol> <li>From the dropdown, select first or within and enter the time in seconds.</li> <li>Press the Enter key to save the new values. Note: A validation error is displayed, as highlighted in the screenshot, either if the configured Dead Air duration is lesser than the selected conversation time period or if the trigger setup is incomplete.</li> </ol> </li> </ol> </li> <li>If you select Speech Speed, the following screen appears: <ol> <li>Click {select person} to select either Agent or Customer. </li> <li>Click 180 to enter words per minute\u2013180 words per minute is the default value.</li> <li>Enter the number of words per minute and then press the Enter key to save it.</li> <li>Click 1 time to select the frequency.</li> <li>Click In conversation to select a time frame.</li> </ol> </li> <li>If you select Talk Ratio, the following screen appears: <ol> <li>Click {Comparator} to select a value comparison. <ol> <li>If you select Less than **or Greater than**, a screen similar to the following appears: </li> <li>If you select In between, the following screen appears: </li> </ol> </li> <li>Click {Value} to enter a percentage value.  If you have selected In between, you have to enter the values twice, and click the tick mark, as highlighted in the following screenshot: </li> <li>Click in conversation to select a time duration. By default, Anytime in conversation is selected. <ol> <li>Click By time to indicate a selected time frame for talk ratio measurement.</li> <li>Enter time in minutes and press the Enter key. </li> </ol> </li> </ol> </li> </ul> </li> </ol> <p>Coaching Rule:</p> Field Description Rule Name     The name of the new rule and the users it has been assigned to.     Actions     Edit or delete a rule.     Description     A short description of the rule.     Tags     Name of the tags a rule has been tagged with.     Channels     Communication channels through which rules are applied. Valid values are: <ul> <li>Voice  <li>Chat </li> Last Updated     Time and date when a rule was last updated.     Status     Current status of a rule. Valid values are: <ul> <li>Enable  <li>Disable </li> <p>Speech Type:</p> Field Description Cross Talk     When the talks between the agent and the customer cross each other.     Dead Air     No talk/silence either by the customer or the agent. <p> Valid values to choose from: <ul> <li>Anytime in conversation: Select it to configure the dead air period as anytime during a conversation.  <li>By time: Select it to choose the exact time frame when dead air was noticed. Valid values are:  <ul> <li>First: Select and enter the time frame as first (variable) seconds of conversation.  <li>Within: Select and enter the time frame as within (variable) seconds anytime during the conversation.  </li> </li> </ul> Speech Speed     Number of words per minute during a session - either by the agent or the customer.     Talk Ratio     Agent to customer talk ratio - proportion of speaking time by an agent compared to a customer. By default, it can be identified only once. Here is a list of different scenarios for different talk ratio ranges: <ul> <li>Equal to 50% for 1 Time in Conversation: Both the agent and the customer contribute equally to the conversation. A balanced conversation where both parties are actively engaged and sharing information, questions, and responses.  <li>&lt;20% for 4 Times By Time in the first 30 seconds: The agent speaks less than the customer for four instances within the first 30 seconds of the conversation. It could be due to the agent allowing the customer to express their concerns or issues before providing assistance or solutions.  <li>Less than or equal to 60% for 1 Time By Time within 30 seconds: The agent's speaking time is limited to 60% or less of the conversation time within the first 30 seconds. This might occur when the agent is actively listening to the customer's initial query or complaint, gathering relevant information, and demonstrating empathy before engaging in a more detailed conversation.  <li>Between 20% and 40% for 1 Time Any Time in Conversation: A balanced conversation, where the agent speaks for a moderate portion of the conversation (20% to 40%) while allowing the customer to express their needs and concerns.  <li>Between 20% and 40% for 4 Times By Time in the first 30 seconds: For four instances within the first 30 seconds, the agent maintains a talk ratio of 20% to 40%, giving the customer ample space to explain their issue or query before responding.  <li>Between 20% and 40% for 1 Time By Time within 30 seconds: The agent maintains a balanced talk ratio (20% to 40%) within the first 30 seconds of the conversation, showing attentiveness and understanding of the customer's initial statements. </li>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#andor-condition","title":"And/Or Condition","text":"<p>AgentAssist allows you to add multiple rule triggers. It lets you set different conditions like combining multiple rules or choosing one or a set of rules against another or a different set of rules. You can even choose or combine rules from different trigger types like Utterance and Speech Analysis triggers.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-select-andor-condition","title":"Steps to select And/Or condition","text":"<ol> <li>Click +Add a trigger in the rule trigger creation page to create a new trigger.</li> <li>Click +Add a trigger again to create a new rule trigger.</li> <li>Select And or Or.  Note: For creating multiple rule triggers, it is mandatory to choose And or Or. When you choose \u201cAnd,\u201d the rule triggers add up. When you choose \u201cOr,\u201d the rule triggers set to either of the rules. Here\u2019s an example of this functionality: </li> </ol> <p>The And condition ensures that rule triggers 1 and 2 are combined, and the Or condition ensures that either the combination of the first two rule triggers (1+2) or the third rule trigger (3) becomes applicable.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#agent-coaching-actions-then-do","title":"Agent Coaching Actions (Then do\u2026)","text":"<p>After setting up rule triggers, you need to set up actions for those triggers. Here, you configure what actions Agent Coaching should take if the conditions you set up are met. You can set up three different actions:</p> <ul> <li>Nudge Agent</li> <li>Hint Agent</li> <li>Email Manager</li> </ul> <p>You can also set up adherence, which is like an acknowledgment, to ensure the agent has followed the instructions.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#add-adherence","title":"Add Adherence","text":"<p>The Add Adherence feature lets you know the agent\u2019s adherence to the instructions in the form of nudges and hints. Later, you can use this acknowledgement to measure agent performance in the Dashboard. This feature is applicable only for the Nudge and Hint Agent actions. </p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#add-adherence-types","title":"Add Adherence Types","text":"<p>You have two types of adherences to choose from:</p> <ul> <li>Acknowledge Pressed: Choosing this option sends an acknowledgement that the agent understood your instructions. The agent doesn\u2019t need to take any other action except acknowledging your message. An example would be a compliment to the agent for a job well done. The following screenshot is displayed when this option is used:  </li> <li>Utterance: Choosing this option sends an acknowledgement that the agent will take further action within a specified time frame during a session. An example would be when you ask the agent to offer a discount to the customer, and the agent acknowledges that they will perform this action within the next few messages, few minutes, or anytime during the session. The following screenshot is displayed when this option is selected:  For practical examples of this feature, refer to steps 7-8 of Steps to set up the Nudge Agent actions.</li> </ul>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#nudge-agent","title":"Nudge Agent","text":"<p>The Nudge Agent actions are the small messages that pop up on the agent\u2019s screen while communicating with the customers. They are disappearing messages, which stay on the agent\u2019s screen for 5 seconds. Through these messages, you either compliment the agents for a good job or direct them to take other appropriate actions to serve the customers in the best way possible. Here are the following four nudges that you can choose from:</p> <ul> <li>Positive</li> <li>Neutral</li> <li>Alert</li> <li>Critical</li> </ul>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-set-up-the-nudge-agent-actions","title":"Steps to set up the Nudge Agent actions:","text":"<ol> <li>Go to the rule action setup page.</li> <li>Click + Add an action under the section, Then do\u2026 </li> <li>Click the Nudge Agent option in the Choose an Action window. </li> <li>Click {Choose} to select one of the sentiment messages. </li> <li>Click {Choose} to enter a message, as displayed in the following screen: </li> <li>Enter a message in the Nudge Message box, and then click the tick mark to save it. </li> <li>Click +Add Adherence to set an adherence for the agent. </li> <li>Select Utterance in the Choose a Trigger window. </li> <li>Click {set utterances} to enter the agent\u2019s utterance. </li> <li>Type and select the utterance. You can select similar utterances from the  utterances list. </li> <li>Click Add, and then click Save. </li> <li>Click Anytime in the next screen to select one of the options. <ul> <li>If you select Within next (n) messages, the following screen appears:  You can change the number of messages, as required, by clicking the highlighted area.</li> <li>If you select Within next (n) minutes, the following screen appears:  You can change the time in minutes, as required, by clicking the highlighted area.</li> </ul> </li> </ol> <p>The agent gets screens similar to the following on their system for:         1. Positive Nudges</p> <pre><code>    ![Alt text](./images/positive-nudge-image_81.png)\n\n    2. Neutral Nudges\n\n    ![Alt text](./images/neutral-nudge-image_82.png)\n\n    3. Warning Nudges\n\n    ![Alt text](./images/warning-nudge-image_83.png)\n\n    4. Critical Nudges\n\n    ![Alt text](./images/critical-nudge-image_84.png)\n</code></pre>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#hint-agent","title":"Hint Agent","text":"<p>The Hint Agent actions are small pop-up messages that advise agents to take further action. They appear on the agent\u2019s screen while communicating with the customers and may or may not auto-close, based on how you set them. Through these messages, you also compliment the agents for a good job. Here are the four hint types that you can choose from:</p> <ul> <li>Positive</li> <li>Neutral</li> <li>Alert</li> <li>Critical</li> </ul>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-set-up-the-hint-agent-actions","title":"Steps to set up the Hint Agent actions:","text":"<ol> <li>Go to the rule action setup page.</li> <li>Click + Add an action under section, Then do\u2026 </li> <li>Click the Hint Agent option in the Choose an Action window. </li> <li>Click {Choose} and select one of the message types, as highlighted in the following screenshot: </li> <li>Click {Choose} to enter the title of your message, as highlighted in the following screenshot: </li> <li>Click the tick mark after entering the title. \\ </li> <li>Click {Choose} to enter the body of your message, as highlighted in the following screenshot: </li> <li>Click the tick mark after entering the body of your message. </li> <li>Click {Choose} to select the display option of your message, as highlighted in the following screenshot: <ol> <li>If you select Auto Close, the following screen displays:  Click the default value of 5 seconds to update it, as required. After entering the value, press the Enter key to update the new entry.</li> <li>If you select Does not auto close, the following screen displays: </li> </ol> </li> <li>Click +Add Adherence to set up agent adherence of the rule action. </li> <li> <p>Select an adherence trigger: </p> <ol> <li>If you select Acknowledge Pressed, the following screen is displayed: </li> <li>If you select Utterance, follow steps 9-12 of Steps to set up the Nudge Agent actions to complete the process.</li> </ol> <p>The agent gets screens similar to the following on their system for:</p> </li> <li> <p>Positive Hints </p> </li> <li>Neutral Hints </li> <li>Warning Hints </li> <li>Critical Hints </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#email-manager","title":"Email Manager","text":"<p>This feature lets you set a push notification alert to the manager\u2019s desktop. You can set who should receive this notification and customize the title and the body of the message. It applies to the customer\u2019s actions, such as using profanity or too many crosstalks. Instead of nudges and hints, the system can send an alert notification to the manager in these situations.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-set-up-the-email-manager-action","title":"Steps to set up the Email Manager action:","text":"<ol> <li>Go to the rule action setup page.</li> <li>Click + Add an action under section, Then do\u2026 </li> <li>Click the Email Manager option in the Choose an Action window. </li> <li>Click {select people} to enter the email address of one or multiple managers who should receive the notification. </li> <li>Enter the email addresses, and then click the tick mark to save them.  Note: Use commas to separate multiple email addresses.</li> <li>Click {set subject} to enter a subject for your notification. </li> <li>Click the tick mark to save it. </li> <li>Click {set body} to enter the body of the notification. </li> <li>Enter the notification content and then click the tick mark to save it. </li> </ol>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#assign-this-to","title":"Assign This To","text":"<p>This feature lets you assign the rule to the intended agents or groups. Currently, by default, this feature is assigned to all agents.</p>"},{"location":"agentassist/agent-experience/agent-realtime-coaching/#steps-to-assign-rules-to-agents-or-groups","title":"Steps to assign rules to agents or groups","text":"<ol> <li>Go to the rule action setup page. For help, refer to Steps to create a new rule.</li> <li> <p>Click +Add agents, groups under the section Assign this to... </p> <ul> <li>The following screen shows the default selection of All Agents: </li> </ul> </li> <li> <p>Click Save from the top right corner of the screen. </p> <ul> <li>The new rule appears at the bottom of the list of all new rules. </li> </ul> </li> </ol>"},{"location":"agentassist/welcome-events/configure-welcome-events/","title":"Welcome Events","text":"<p>Welcome Events are pre-configured messages or prompts that are automatically triggered when a conversation is assigned to an agent in the AgentAssist platform. Welcome Events guide agents to handle inquiries effectively by streamlining workflows, lowering their Average Handle Times (AHT), reducing repetition, and contributing to enhanced customer satisfaction.</p> <p>Managers can configure Welcome Events to provide consistent and relevant information to agents at the start of a conversation. These events can be used for both chat and voice interactions.</p> <p>You can configure Welcome Events for AgentAssist using Standard/Non-Universal Bots or a Universal Bot (UB). To learn more about the types of bots, see Universal Bots.</p>"},{"location":"agentassist/welcome-events/configure-welcome-events/#configure-welcome-events-for-a-non-universal-bot","title":"Configure Welcome Events for a Non-Universal Bot","text":"<p>Steps to configure Welcome Events for Non-Universal Bots:</p> <ol> <li> <p>Go to CONFIGURATION &gt; Welcome Event &gt; Configure Welcome Event. </p> <p>Note: The bot-level settings for Welcome Event are not applicable for AgentAssist. If the same bot is used for automation (prior to agent transfer), the bot-level event settings are honored.</p> </li> <li> <p>Click Select Dialog and select the appropriate event from the Automation dropdown. </p> </li> <li> <p>Click Save to configure the welcome event. </p> </li> </ol>"},{"location":"agentassist/welcome-events/configure-welcome-events/#configure-welcome-events-for-a-universal-bot","title":"Configure Welcome Events for a Universal Bot","text":"<p>If a Universal Bot is selected on the main bot selector, two dropdowns appear for Event Dialogue task selection.</p> <p></p> <p></p> <p>Steps to configure Welcome Events for a Universal Bot:</p> <ol> <li> <p>Click the Select Bot dropdown to select the child bot (only child bots of the selected UB appear). </p> </li> <li> <p>Click the Automation dropdown to select dialog tasks associated with the selected bot. </p> </li> <li> <p>Click Save to configure the welcome event. </p> </li> </ol>"},{"location":"analytics/automations/conversation-flows/","title":"Conversation Flows","text":"<p>Conversation Flows is a visual representation of the user journey. The user interactions with the virtual assistants are analyzed by the platform to provide insights into the commonly used intents, paths traversed, and drop-off points.</p> <p>Note</p> <p>The Conversation Flow feature is available only for the Published Bots.</p> <p>The Conversation Flows provides the following views:</p> <ul> <li>Intents Flow: This view provides an aggregated view of how each of the virtual assistant\u2019s intents is executed. The intents are rolled up to the top level, irrespective of what stage of a conversation they were initiated by the users. For example, intents invoked at the beginning of a conversation as well as any other stage during the conversation are all rolled up to the top level. This is the default view when you navigate to Conversation Flows. The View tasks by sessions toggle should be turned OFF to access this view.</li> <li>Session Flow: This view provides the user journey across the different intents in the order they were executed during a conversation session. Every flow starts with the intent used to initiate a conversation session and is followed by the other intents invoked in that session. You must turn ON the View Tasks by sessions toggle to access this view.</li> </ul> <p>To view the Conversation Flows dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click the Conversation Flows dashboard under the Automation section of the Analytics panel. The Conversation Flows dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>By default, the Intents Flow is presented along with the intents. Selecting any node will expand the flow to present the subsequent nodes in that path.</p> <p></p> <p>You can select session-wise view by toggling the View tasks by sessions option.</p> <p></p>"},{"location":"analytics/automations/conversation-flows/#purpose","title":"Purpose","text":"<p>The Conversation Flows can be used to identify the following:</p> <ul> <li>Popular utterances \u2013 Utterances that are used to invoke the virtual assistant\u2019s intents. Utterances are automatically grouped by similarity to provide a simplified view. </li> <li>False Positives \u2013 A quick review of the utterance groups will help you in identifying utterances going to an incorrect intent. You can analyze these utterances and make the necessary training updates. </li> <li>False Negatives \u2013 Utterances that did not result in any intent identification are presented as \u2018Not Handled Utterances\u2019. You can analyze these utterances and add them to the training corpus if required. </li> <li>Popular Intents and Flows \u2013 Helps in understanding the popular intents of your users and the flows used to execute these intents</li> <li>Drop-off Points \u2013 Analyze the specific areas of the conversations that are resulting in drop-offs. A conversation is marked as a drop-off if the user has abandoned it without providing a valid input. </li> <li>Agent Hand-offs \u2013 View the flows that are leading to agent hand-offs. Agent Hand-offs are conversations that result in navigating to the Agent Node from any of the Dialog Tasks.</li> </ul>"},{"location":"analytics/automations/conversation-flows/#key-features","title":"Key Features","text":"<p>The following are the details presented along with the flows:</p> <p></p> <ul> <li>Utterance Groups: Every flow starts with an utterance from the user that initiated the conversation and expands to show further interactions. These utterances are grouped based on their similarity, ignoring the stop words and values for entities. These utterance nodes lead to one of the following intents:<ul> <li>Individual task intents,</li> <li>FAQs,</li> <li>Small Talk,</li> <li>Help and</li> <li>Not Handled utterances</li> </ul> </li> <li>Nodes: are the individual points plotted on the conversation flow across various levels. Only the nodes that need input from the user are plotted on the graph. Following are the nodes that are plotted on the graph:<ul> <li>Intent Nodes: Includes Dialog as well as FAQ intents</li> <li>Entity Nodes </li> <li>Confirmation Nodes </li> <li>User Input Nodes (using on_intent transition) </li> <li>Message Nodes </li> </ul> </li> <li>Node Details: The following details are presented for each node:<ul> <li>Percentage of total utterances leading to this Node. Click on percentage to display the list of user utterances that triggered this Node;</li> <li>Node Name will be the task/entity name with the following details displayed on hover over the Node:<ul> <li>Conversation and Drop-offs details,</li> <li>See Responses shows the User\u2019s response, where applicable, to this Node;</li> </ul> </li> <li>Percentage of Drop-offs where applicable</li> <li>Path Indicators are visible on the path between two nodes, where applicable, indicating:<ul> <li>any Script/Service Nodes visited during the transition between the nodes;</li> <li>any Tasks executed as part of the Hold and Resume scenarios.</li> </ul> </li> </ul> </li> <li>Chat History is viewed by clicking the utterance from the User Utterance window for either input (percentage) or response information.</li> </ul>"},{"location":"analytics/automations/conversation-flows/#filters","title":"Filters","text":"<p>The Conversation Flows can be filtered using one or more of the following criteria:</p> <ul> <li>Date Period \u2013 Default is set to Last 7 days. You can change it to 24 Hrs. You can also set the start and end dates using the Custom option and by selecting the dates from the calendar.</li> <li>Languages  \u2013 In the case of multi-lang bots, you can filter the conversation flows by selecting one or more languages from the presented drop-down list. The default is All Languages.</li> <li>Channels \u2013 Selecting one or more channels the bot was published on, you can filter the flow based upon the channel used by the user. The default is All Channels.</li> <li>Custom Tags \u2013 In case you have added any meta/custom tags to your bot, you can filter based on the same. This requires the selecting of the Tag Name and the value for the tag you want to filter the conversations. By default, no tag is selected.</li> </ul> <p></p>"},{"location":"analytics/automations/conversation-insights/","title":"Conversation Insights","text":"<p>Once a virtual assistant is published, it is important to understand and analyze its performance. Kore.ai XO platform provides various dashboards; one of them being NLP Insights that captures details like Intent Found, Intent Not Found, Unhandled Utterances, and so on. However, to categorize the utterances as True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN), you need to go through all the utterances across multiple tabs in NLP Insights. There could be millions of utterances that a bot designer needs to review, which could be tedious and time-consuming.</p> <p>To view the Conversation Insights dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click the Conversation Insights dashboard under the Automation section of the Analytics panel. The Conversation Insights dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>The Conversation Insights in the Kore.ai XO Platform groups the utterances in a cluster, based on their semantic meaning and provides a name to each of these groups, which avoids the need to analyze all the utterances of the cluster. Based on the utterances that are identified or unidentified, these cluster groups can be part of one or more intents. Below is a snapshot of where intents and utterance groups are plotted in a treemap. For more information on TP, TN, FP, and FN scenarios, see Appendix.</p> <p></p> <p>Note</p> <p>The Kore.ai platform groups together all the similar utterances to form a cluster and gives a name to each created cluster. Conversation Insights allows the bot designers to identify FPs, and FNs, create new intents, and perform many more actions. Cluster labeling is crucial in decision-making in such scenarios.</p> <p>The utterances in the platform are grouped using an algorithm to create clusters. The most frequently occurring subject-verb-object is identified to create a label for the cluster.</p> <p>For example, In the utterance \u201cWhen will I get my ATM Card?\u201d verb = get: subject = card; object = atm, and the cluster label is created accordingly.</p>"},{"location":"analytics/automations/conversation-insights/#clustering-views","title":"Clustering Views","text":"<p>In Conversation Insights, the relationship between intents and clusters is represented visually in two different ways:</p> <ul> <li>Treemap View</li> <li>Grid View</li> </ul>"},{"location":"analytics/automations/conversation-insights/#treemap-view","title":"Treemap View","text":"<p>The default view of Conversation Insights is the treemap view. A treemap is a visual method for displaying hierarchical data that uses nested rectangles that represent the branches of a tree diagram. It shows the relationship between intents and clusters.</p> <p></p> <p>Using the Maximize icon you can view the insights in full-screen mode if required. The toggle next to it can be used to choose the cluster view either as a treemap or grid.</p> <p>Each rectangle that represents an intent with clusters has an area proportional to the count of utterances it contains and the Expand icon provides the ability to view the widget on a full screen with Zoom in and Zoom out capabilities.</p> <p></p> <p>All the Identified and Unidentified intents are displayed as rectangles. In a treemap, the intents form the outer rectangle. In this example card not working, get a physical card, and so on are the intents displayed as outer rectangles. Each intent consists of one or more clusters, also represented as rectangles.</p> <p>Note</p> <p>Hovering on an individual cluster highlights the cluster wherever it is available in all intents. In the following screenshot, you can see the tooltip displaying the information and the cluster working_card_time is highlighted in all the intents.</p> <p></p> <p>The tooltip displays the following information:</p> <ul> <li>Total utterances of the cluster</li> <li>Utterances count of the cluster across various intents</li> </ul> <p>On clicking any cluster, you navigate to the Cluster View page and view all the intents and utterances the cluster is a part of. To understand more about the actions that can be performed here, see Utterance Validation. </p> <p></p>"},{"location":"analytics/automations/conversation-insights/#display-more-intents-and-clusters","title":"Display More Intents and Clusters","text":"<p>On the Conversation Insights page, the number of intents to be displayed is adjusted using pagination,  in the Intents per page drop-down in the treemap view. You can select the intents that can be viewed per page here as per the requirement. Click Next to view the intents on the next page.</p> <p>Note</p> <p>If you select 10 'Intents per page' in the navigation bar, then the top 10 intents are displayed on the first page. Users can click the Next button to view the next set of 10 intents. The platform also shows the total number of pages in the navigation bar.</p> <p></p>"},{"location":"analytics/automations/conversation-insights/#grid-view","title":"Grid View","text":"<p>In the grid view, you can view all the intent and cluster details in a tabular format. This view is helpful when there is a large number of intents in the VA, and you can easily navigate through different intents and clusters.</p> <p>The details Intent Name, Cluster Count, and Utterance Count are displayed as shown in the following screenshot.</p> <p></p> <p>Expand the Intent Name to see more details as follows:</p> <ul> <li>Clusters: The clusters available for the specific intent.</li> <li>Utterance Count: The utterance count of each cluster.</li> <li>Details: The availability of the cluster in other intents of the VA.</li> </ul> <p></p> <p>Note</p> <p>You can click the toggle to go back to the treemap view.</p> <p></p> <p>On clicking the Available in #other intents link under Details, a pop-up is displayed with all the Intent details the cluster is a part of, and the number of utterances across each intent, for that cluster.</p>"},{"location":"analytics/automations/conversation-insights/#cluster-view","title":"Cluster View","text":"<ul> <li>Click the View Details link corresponding to the cluster name to go to the Cluster View page.</li> </ul> <p>The Cluster View page displays all the intents and utterances for that cluster. By default, the platform displays the utterances for the intent selected on the Conversation Insights page. To understand more about the actions that can be performed here, see Utterance Validation.</p> <p></p>"},{"location":"analytics/automations/conversation-insights/#intent-view","title":"Intent View","text":"<ul> <li>Click the View Details link corresponding to each intent, to go to the Intent View page.</li> </ul> <p>The Intent View page displays all the available clusters, utterances, and other details as shown in the following image. By default, the platform displays all the utterances for the cluster with the maximum number of utterances. You can select any cluster within an intent to view the utterances and take necessary actions.</p> <p></p> <p>Note</p> <p>The number across the Intent Name and Cluster Names represents the number of utterances.</p>"},{"location":"analytics/automations/conversation-insights/#utterance-validation","title":"Utterance Validation","text":"<p>The utterances grouped in the clusters can be validated and trained for an existing intent or a new intent, based on the requirements. Training the utterances and discovering new intents improves the performance of your virtual assistant.</p> <ul> <li>Click any Utterance displayed in the grid on the Intent View or Cluster View pages.</li> </ul> <p>The utterance details, NLP Analysis, and Chat History with user profile and conversation sessions are displayed the same as in NLP Insights.</p> <p></p>"},{"location":"analytics/automations/conversation-insights/#train-the-utterances","title":"Train the Utterances","text":"<p>This section describes the steps to be followed, to train the utterances grouped in a cluster.</p> <ul> <li>Click the cluster in the treemap view or the grid view, to display all the intents and utterances the cluster is a part of.</li> </ul> <p>Note</p> <p>All the utterances that are part of the clicked Cluster-Intent pair are displayed. You can select one or all the utterances of the cluster, to initiate the training. You can also go to the intent view by clicking View Details across the intent name from the grid view of the clusters. See Grid View for more information.</p> <p></p> <p>The identified utterances belong to any of the following categories:</p> <ul> <li>Identified as Incorrect Intents (False Positives)</li> <li>Unidentified due to insufficient training (False Negatives)</li> <li>Unidentified since the intent was not created (You can add a new intent here)</li> </ul> <p>See Appendix to understand more about FP, FN, TP, TN scenarios.</p> <p>Note</p> <p>The utterances that are categorized as Identified as Incorrect Intents or Unidentified due to insufficient training are mainly due to insufficient or incorrect training.</p> <p>The following steps explain how to train a single utterance or bulk utterances.</p> <ol> <li>Click the Train button available across the utterance to initiate the training.</li> <li> <p>You may also select multiple utterances for bulk training and choose an option from the Train drop-down as shown in the following screenshot. </p> <p></p> <p>Note</p> <p>NLP Analysis and the Utterance testing panels are displayed the same as in the NLP Insights. The training process is the same as the utterance training in the NLP insights.</p> <p></p> </li> <li> <p>Select a matching intent from the Selected Intent drop-down and click Save to initiate the training. You can also add Intent synonyms, patterns, and traits as required. The following message is displayed if the task is already published. Click Upgrade to change the task status to Development, to make the changes.</p> <p></p> </li> </ol> <p>A message, Utterance Uploaded Successfully is displayed.</p> <pre><code>!!! note\nYou can also click Re-Run Utterance if you want to train the utterance again.\n</code></pre> <p></p> <p>Note</p> <p>In the bulk utterance training, you select multiple utterances from the displayed list and train them for the existing intents by selecting an option from the Train drop-down or add new intents by selecting an option from the Add Intent drop-down. The steps followed are the same as in single utterance training.</p> <p>Add Existing Intent</p> <p>The following steps explain how to add an existing intent to an utterance or multiple utterances using the Train drop-down.</p> <ol> <li>To map an existing Dialog Task or FAQ, click the Train drop-down. (See step 2 under Train the Utterances).</li> <li> <p>Click the Dialog Task option to choose the matching intent for the selected utterance.</p> <p></p> </li> <li> <p>Click the button Add Utterances to add the intent for the utterances. Click Yes, Mark as Reviewed if you want to change the status of the trained utterances to Reviewed, or else click No. </p> <p></p> </li> <li> <p>Click the FAQ option from the Train drop-down to add the matching FAQ for the selected utterance. </p> <p></p> </li> <li> <p>Upon adding the FAQ successfully, a message is displayed as shown below. Click Yes, Mark as Reviewed if you want to change the status of the trained utterances to Reviewed, or else click No.</p> </li> </ol> <p>Add New Intent </p> <p>In a scenario where the utterances cannot be mapped to any of the existing intents, you have to create a new intent. </p> <p>Follow these steps to add a new intent for the utterance:</p> <ol> <li> <p>To create a new Dialog Task or FAQ for that utterance, click the Add Intent drop-down.</p> <p></p> </li> <li> <p>Click the Dialog Task option to create a new intent for the selected utterance.</p> </li> <li> <p>The Create Dialog panel is displayed. Enter the required details and click Proceed to add the new intent for the utterance.</p> <p></p> </li> <li> <p>Click Yes, Mark as Reviewed if you want to change the status of the trained utterances to Reviewed, or else click No.</p> <p></p> </li> <li> <p>Click the FAQ option listed in the Add Intent drop-down to add a new FAQ for the selected utterance.</p> <p></p> </li> <li> <p>Click Yes, Mark as Reviewed if you want to change the status of the trained utterances to Reviewed, or else click No.</p> <p></p> </li> </ol> <p>Status Review</p> <p>The status of all the utterances is Yet to review by default. You can change the status of an individual utterance from Yet to Review to Reviewed and vice versa.</p> <p>Note</p> <p>You can also use the Status drop-down provided in the top right corner of the page to change the status of one or more selected utterances.</p> <p></p> <ul> <li>Click any utterance from the list to display the Details, NLP Analysis, and Chat History panel shown in the following screenshot.</li> </ul> <p></p> <p>Dataset Filters</p> <p>Once a VA is published, the Kore.ai XO platform provides an option to filter the datasets on the Conversation Insights dashboard, to analyze the data of the multiple conversations. On the dashboard, various filter criteria like Date, Conversation Type, Conversation Status, and in More Filters drop-down Intent Type, Utterance Status, and so on are available for filtering.</p> <p></p> <p>To Know more about the filter criteria, their descriptions, and the availability matrix, see Analytics Dashboard Filters.</p> <p>Appendix</p> <p>This section provides more details about TP, TN, FP, and FN scenarios with examples:</p> <p>True Positive</p> <p>True Positives (TP) refer to instances where the virtual assistant correctly identifies the intent of an utterance. For example, if the user says \u201cWhat\u2019s the weather today?\u201d, and the virtual assistant correctly identifies the intent as \u201cget_weather\u201d, this would be a True Positive. In this example the intent is correctly mapped to Check Balance, hence it is a true positive.</p> <p></p> <p>True Negative</p> <p>True Negatives (TN) refer to instances where the virtual assistant correctly identifies that an utterance did not match any of the defined intents. For example, if the user says \u201cI\u2019m not sure what you mean\u201d, and the virtual assistant correctly identifies that this does not match any of the defined intents, this would be a True Negative. In the following example, the user utterance \u201cExtremely Likely\u201d did not match with any defined intent and is categorized as Unidentified intent.</p> <p></p> <p>False Positive</p> <p>False Positives (FP) refer to instances where the virtual assistant incorrectly identifies the intent of an utterance. For example, if the user provides his bank account name, and the virtual assistant incorrectly identifies the intent as \u201cClose Account\u201d, this would be a False Positive.</p> <p></p> <p>False Negative</p> <p>False Negatives (FN) refer to instances where the virtual assistant incorrectly identifies that an utterance did not match any of the defined intents. For example, if the user says \u201cWhat\u2019s the weather today?\u201d, and the virtual assistant incorrectly identifies that this does not match any of the defined intents, this would be a False Negative. In this example, the \u201ccreate account\u201d utterance is wrongly mapped as an Unidentified intent and hence would be False Negative.</p> <p></p>"},{"location":"analytics/automations/conversations-dashboard/","title":"Conversations Dashboard","text":"<p>The Conversations Dashboard provides insights into how conversations are handled by your virtual assistant (VA). It shows how many conversations were successfully answered by the VA, how many were transferred to agents, and how many were incomplete. You can also view other metrics, such as the trend of conversation sessions, the conversation path analysis, the session distribution by channel, and the VA\u2019s engagement grouped by self-service, drop-off, and agent transfer sessions.</p> <p>Note</p> <p>The Conversations Dashboard is available only post 9.2 release, i.e. post April 09, 2022.</p> <p>To view the Conversations dashboard, follow the steps:</p> <ol> <li>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</li> <li>Click Conversations Dashboard under the Automation section of the Analytics panel. The Overview dashboard is displayed on the right side of the page.</li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p> </p> <p>The Conversations Dashboard is organized into four categories based on the conversation behavior, explained below.</p>"},{"location":"analytics/automations/conversations-dashboard/#conversation-sessions","title":"Conversation Sessions","text":"<p>Conversation Sessions display the total number of conversations between the virtual assistant and a user in a specific period of time. The session starts when a user sends a message and ends when the user indicates that the problem is solved, abandons the chat, or reaches the agent transfer node. For details on the metrics used in each widget/category, see the Metrics Table section in this document.</p> <p></p>"},{"location":"analytics/automations/conversations-dashboard/#self-service-rate","title":"Self-service Rate","text":"<p>Self-service sessions refer to the conversations that the virtual assistant contains. The Self-service Rate widget displays the percentage and total number of self-service conversations. It also shows the percentage increase or decrease in the self-service conversations from the last selected period. For example, if you select the past 24 hours\u2019 data, the widget displays the percentage and total conversation sessions contained in the past 24 hours. Based on your selection, the widget can also display the rise or drop in the percentage of conversation sessions from the previous 24 hours. Any ongoing conversation is classified under Self-service conversation.</p> <p>If a dialog task reaches the End Of Dialog node, the task is considered as completed and categorized as a self-service. There could be a scenario where a virtual assistant is configured with either a Welcome event or an On-Connect event, and there are multiple messages sent by the virtual assistant without any user interaction. In this case, the platform considers this task as contained and increases the self-service count. For details on the metrics used in each widget/category, see the Metrics Table section in this document.</p> <p></p>"},{"location":"analytics/automations/conversations-dashboard/#drop-off-rate","title":"Drop-off Rate","text":"<p>A drop-off is a conversation session where the user abandons the conversation without completing the task. Below are a few scenarios where the conversations can lead to a drop-off:</p> <ul> <li>A user left the conversation midway without completing any task.</li> <li>The task ended as a failure.</li> <li>The last interaction/message resulted in an \u2018intent not identified\u2019 scenario.</li> <li>No response from the assistant.</li> <li>The user abandons the assistant during a live conversation.</li> </ul> <p>The Drop-off Rate widget displays the percentage and the total number of drop-offs within a selected period. It also shows the percentage increase or decrease in the drop-off sessions from the last selected period. For details on the metrics used in each widget/category, see the Metrics Table section in this document.</p> <p></p>"},{"location":"analytics/automations/conversations-dashboard/#agent-transfer-rate","title":"Agent Transfer Rate","text":"<p>Some conversations may require human assistance as the users can\u2019t finish the tasks using the virtual assistant. In such cases, the session is handed over to a human agent for help. When the conversation reaches the point where it\u2019s transferred to an agent \u2013 the dialog reaches the agent transfer node, the platform considers this as an Agent Transfer session.</p> <p>The Agent Transfer Rate widget displays the percentage and total number of agent transfers within the selected period. It also shows the percentage increase or decrease in the agent transfer sessions from the last selected period. For details on the metrics used in each widget/category, see the Metrics Table section in this document.as</p> <p></p> <p>Note</p> <p>Unblu and IVR channels don\u2019t need any Agent Transfer node to transfer the conversation to Agents.</p>"},{"location":"analytics/automations/conversations-dashboard/#metrics-table","title":"Metrics Table","text":"<p>Refer to the table below for the list of widgets present across each category on the Conversations Dashboard.</p> <p>Note</p> <p>For a trend line chart, if the period is 24 hours, the X-axis shows hourly intervals. Otherwise, the axis shows daily intervals. The Y-axis shows the total number of sessions.</p> Metric Description Conversation Session Trend     A line chart that displays the conversation session over a period of time. <p> Conversation Sessions: Displays the total conversations, self-service, drop-off, and agent transfer sessions over a period of time. <p> Self-Service: Displays self-service versus total conversation line chart over a period of time. <p> Drop-Off: Displays drop-off versus total conversation line chart over a period of time. <p> Agent Transfer: Displays agent transfer versus total conversation line chart over a period of time.     Message Trend     A line chart that displays the total number of messages sent by the virtual assistant versus the total number of messages received in the VA over a time period.  <p> This metric is available only for the Conversation Session.     Session Distributed by Channel     Displays the number of sessions distributed across all the channels in a timeframe. <p> This metric is available only for the Conversation Session.     Most Active Hours     A bar chart that displays the most active hours in a day based on the number of conversations and number of messages. <p> Conversation Sessions: Displays the total number of hours for self-service, drop-off, and agent transfer sessions over a period of time. <p> Self-Service: Displays the total number of hours for self-service sessions distributed hourly.  <p> Drop-off: Displays the total number of hours for drop-off sessions distributed hourly.  <p> Agent Transfer: Displays the total number of hours for agent transfer sessions distributed hourly.      Conversation Path Analysis     A table showing every unique conversation path between the VA and the users that has been executed over a period of time. <p> Conversation Session: Displays the most popular conversation path. <p> Self-Service: Displays the conversation path that leads to self-service. <p> Drop-off: Displays the conversation path that leads to self-service. <p> Agent Transfer: Displays the conversation path that leads to agent transfer.     Engagement Analysis     An interactive bar chart that allows you to analyze the VA\u2019s engagement based on the number of messages exchanged, conversation duration, and task completion.     Avg. Conversation per Day     A scorecard that displays the average number of conversation sessions per day and comparison analysis for the selected period. <p> Formula <p> Avg Conversation Per Day = Total Number of conversations / Number of days. <p> Comparison Analysis in % (Increase/Decrease) <p> This metric is available only for the Conversation Session.     Average Conversation Per User     A scorecard that displays the average number of conversations by user. <p> Formula <p> Average Conversation Per User = Total number of conversations / Total number of users. <p> This metric is available only for the Conversation Session.     Average Conversation Length     A scorecard that displays the average duration of a conversation (in Minutes).  <p> Formula <p> Average Conversation Length = Total conversation length / Total number of conversations. <p> Users may apply a filter on Session Status, and in such cases, the calculation is mentioned as below: <p> Conversation Length (for completed conversations) = Conversation End timestamp \u2013 Conversation Start timestamp. <p> Conversation Length (for ongoing conversations) = Dashboard Load timestamp \u2013 Conversation Start timestamp. <p> This metric is available only for the Conversation Session.     Total  Messages     A scorecard that displays the total number of messages received from the user and sent by the VA.  <p> This metric is available only for the Conversation Session.     Average Messages Per Session     A scorecard that displays the average number of messages per session. <p> Formula <p> Average Message Per Session = Total number of messages / Total number of sessions during the timeframe. <p> This metric is available only for the Conversation Session."},{"location":"analytics/automations/conversations-dashboard/#filter-criteria","title":"Filter Criteria","text":"<p>The Conversations data can be viewed based on specific filter criteria that can be selected. Learn more.</p> Widget Type Session Tags User Tags Message Tags Successful Tasks     Applicable     Applicable     Not Applicable     Sessions     Applicable     Applicable     Not Applicable     Messages &amp; Conversation Sessions     Applicable     Applicable     Applicable for Chats     Intent Recognized vs. Failed     Applicable     Applicable     Not Applicable     Top Tasks     Applicable     Applicable     Not Applicable     Top Channels     Applicable     Applicable     Not Applicable     Agent Transfer     Applicable     Applicable     Not Applicable"},{"location":"analytics/automations/conversations-history/","title":"Conversations History","text":"<p>The Conversation History dashboard allows you to review the transcripts of past conversations and label certain conversations for follow-up or further action.</p> <p>The Advanced Conversation Analytics feature provides a more detailed view of the conversation, including events and custom tags, which can help you better understand the interaction between the customer and the virtual assistant. Custom Tags can be reused across conversations for training purposes and for identifying areas where the virtual assistant could improve.</p> <p>Note</p> <p>The Conversations History Dashboard is available only post the 9.3 release, i.e. post-July 24, 2022.</p> <p>To view the Conversations History dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics.The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click the Conversations History dashboard under the Automation section of the Analytics panel. The Conversations History dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol>"},{"location":"analytics/automations/conversations-history/#filter-views-page","title":"Filter Views Page","text":"<p>The Filter Views page is the preface or landing page displayed when you click the Conversations History left menu item. You can create and view prebuilt and custom filters, filter configurations, and descriptions on this page in addition to the following:</p> <ul> <li>View the available conversation filters and their configurations.</li> <li>Create a custom filter to view only the required data.</li> <li>Access the Conversations History Dashboard for the selected preset.</li> </ul> <p></p>"},{"location":"analytics/automations/conversations-history/#prebuilt-filters-for-conversations-history","title":"Prebuilt Filters for Conversations History","text":"<p>As an analyst, you may need a customized view of the conversation\u2019s history data based on specific conditional filters. This helps analyze conversations based on priority/criticality.</p> <p>The Platform now supports Prebuilt Filters or Presets for the most common use-case scenarios. Presets reduce the developer\u2019s efforts in skimming through each conversation to understand and tag them for a specific use case.</p> <p>How it works</p> <ol> <li>The system checks the configuration parameters and the filter conditions for a conversation session.</li> <li>The conversation session is mapped to the respective filter automatically.</li> <li>Based on the date range selected on the Conversations History Dashboard, the system fetches and displays the conversations that meet the Prebuilt Filters\u2019 criteria.</li> </ol>"},{"location":"analytics/automations/conversations-history/#types-of-prebuilt-filters","title":"Types of Prebuilt Filters","text":"<p>The following table displays each preset\u2019s filter name, predefined configuration parameters, and description. For more information on the configuration parameters, please click here.</p> Filter Name     Configuration     Description     All Conversations (default)     <ul> <li>Conversation Status: CLOSED  <li>Containment Type: SELF-SERVICE  <li>Is Developer: INCLUDE  <li>Session Type: INTERACTIVE </li> Shows all the conversations made during the specified dates irrespective of the filter criteria selected on the dashboard. <p> Note: The user cannot edit the \u201cAll Conversations\u201d view.     Conversations with Multiple Intent Identification Failures <ul> <li>Conversation Status: CLOSED  <li>Containment Type: SELF-SERVICE  <li>isDeveloper: EXCLUDE  <li>Session Type: INTERACTIVE  <li>Events: Greater than equals to 2 intent identification failures. </li> Shows all the conversations with intents unidentified in a given date range.     Conversations with Multiple Entity Retries <ul> <li>Conversation Status: CLOSED  <li>Containment Type: SELF-SERVICE  <li>isDeveloper: EXCLUDE  <li>Session Type: INTERACTIVE  <li>Events: Greater than equals to 2 entity retries. </li> Shows all the conversations with entity retries in a given date range.     Conversations with Multiple Confirmation Retries <ul> <li>Conversation Status: CLOSED  <li>Containment Type: SELF-SERVICE  <li>isDeveloper: EXCLUDE  <li>Session Type: INTERACTIVE  <li>Events: Greater than equals to 2 confirmation retries. </li> Shows all the conversations with confirmation retries in a given date range.     Short Conversations resulting in User-Drop off <ul> <li>Conversation Status: CLOSED  <li>Containment Type: USER DROP-OFF  <li>isDeveloper: EXCLUDE  <li>Session Type: INTERACTIVE  <li>Events: Greater than or equals to 2 confirmation retries.  <li>Conversation Duration: Less than 30. </li> Shows all the conversations where users got dropped off and conversations that are less than 30 seconds."},{"location":"analytics/automations/conversations-history/#feedback-prebuilt-filter","title":"Feedback Prebuilt Filter","text":"<p>The Platform supports the Feedback filter on the Filter Views panel to create custom feedback filters. Based on the filter criteria, the system groups and displays the conversations for the following parameters:</p> <ul> <li>Feedback Survey Template Type: Indicates if the selected type is NPS, CSAT, or Thumbs-up / Thumbs-down. Learn more.</li> <li>Operator: The conditional/logical operator that applies to the Feedback filter evaluation which includes one of the following:<ul> <li>Equals to</li> <li>Less than or equals to</li> <li>Greater than equals to</li> <li>Greater than</li> <li>Less than</li> </ul> </li> <li>Value: The feedback survey score used for the conditional logic evaluation.</li> </ul> <p>Note</p> <p>The conversations with different survey types can be grouped using the <code>OR</code> operator to satisfy multiple conditions.</p>"},{"location":"analytics/automations/conversations-history/#view-prebuilt-filters","title":"View Prebuilt Filters","text":"<p>To view the prebuilt filters, follow the steps:</p> <ol> <li> <p>On the Conversations History dashboard page, the prebuilt filters are categorized and listed under the Filter Views section.</p> <p></p> </li> <li> <p>Click the Read More link corresponding to the name of the filter type to see the configuration details of each conversation filter type. </p> <p></p> </li> <li> <p>Click any prebuilt filter name to access the Conversations History panel where relevant data is displayed.</p> <p></p> </li> </ol>"},{"location":"analytics/automations/conversations-history/#create-a-custom-conversation-filter","title":"Create a Custom Conversation Filter","text":"<p>A Conversation Filter helps group and display selective conversation history data based on a specific criterion on the dashboard. </p> <p>To add a custom filter, follow these steps:</p> <ol> <li> <p>On the Conversations History page, click + Create Filter.</p> <p></p> </li> <li> <p>On the Create Conversation Filter panel, provide inputs for the following fields:           ld          Configuration          Description     View Name      N/A          Enter the name of the filter that will be displayed on the dashboard.     Description      N/A          Enter the description for the filter that will be displayed on the dashboard.     Conversation Status      The available options include: <ol> <li>All  <li>Active  <li>Closed </li>      Select All to view all conversations, Active to view ongoing conversations, and Closed to view conversations that have ended.     Containment Type      The available options include: <ol> <li>Self-service  <li>User Drop-off  <li>Agent Transfer </li>      Select one of the following: <ol> <li>Self-service to view only customer self-service conversations  <li>User Drop-off to view only conversations where the user dropped off.  <li>Agent Transfer to filter conversations with the agent transfer flow. </li> Channels      The available selection options include: <ol> <li>All Channels  <li>Web/Mobile Client  <li>Webhook  <li>Other configured channels. </li>      Filters conversations using the enabled channels.     Languages      The available selection options include: <ol> <li>All Languages  <li>English (default)  <li>Other configured languages </li>      Filters conversations using the enabled languages.     Session Type      The available selection options include: <ol> <li>All  <li>Interactive  <li>Non-interactive </li>      Filters conversations for conversations across all channels, only interactive channels, or only non-interactive channels based on the selected option.     User ID      The available selection options include: <ol> <li>Include  <li>Exclude </li>      Filters conversations using the Platform user identities based on the inclusion or exclusion list.     Channel ID / Kore ID selection      Toggle between the options.          Filters conversations using either the Channel ID or Kore ID.     Task / Intent      Select either all intents or specific configured intents.          Filters conversations using all intents/tasks or specific tasks/intents identified during the conversation sessions.     Developer Interactions (IsDeveloper)      The available selection options include: <ol> <li>Include  <li>Exclude </li>      Filters conversations by including or excluding developer interactions based on the selected condition.     Time Zone      Select from different global time zones.          Filters conversations based on the time zone of the conversation session.     Conversation Duration      The Conditional Filter options include: <ol> <li>Less than  <li>Less than Equals to  <li>Greater than  <li>Greater than equals to  <li>Equals to <p>      The Time units options include: <ol> <li>Seconds  <li>Minutes </li> </li> </ol>      Filters conversations based on the conditional filters set for the conversation session duration in seconds/minutes.     Events      The Conditional Filter options include: <ol> <li>Less than  <li>Less than Equals to  <li>Greater than  <li>Greater than equals to  <li>Equals to <p>      The Event Name options include: <ol> <li>Intent Identified  <li>Intent not Identified  <li>Success Task  <li>Fail Task  <li>Sentiment Event  <li>User Sentiment Type  <li>Entity Retry  <li>Confirmation Retry  <li>On Connect  <li>End of Conversation  <li>Debug Log  <li>Welcome  <li>Welcome Telegram  <li>Welcome Facebook  <li>Welcome Telephone  <li>Standard Response Interruption  <li>Message Node Interruption  <li>Optional Entity  <li>Script Node Failure  <li>Service Node Failure  <li>Agent Transfer </li> </li>      Filters conversations based on the conditional filters set for the conversation session duration and the selected event.     Feedback      The Feedback Type options include: <ol> <li>NPS  <li>CSAT  <li>Thumbs-up/Down <p>      The Conditional Filter options include <ol> <li>Less than  <li>Less than Equals to  <li>Greater than  <li>Greater than equals to  <li>Equals to <p>      The options for Score include: <ol> <li>NPS: Select a value between 0 and 10.  <li>CSAT: Select a value between 0 and 5.  <li>Thumbs-up/Down: Select either 0 or 1. </li> </li> </li> </ol>      Filters conversations based on the feedback type, conditional filter, and feedback score selection.     Labels      Select either all conversation labels or a specific configured label.          Filters conversations based on the selected label(s).     Custom Tags      Select the key and type the value for the key to define the custom tag selection. You can combine multiple key-value pairs to define the custom tag selection.          Filters conversations using custom tags added to the conversation for a key-value pair and the AND logical operator.     <p> 3. Click Save.</p> <p></p> <p>The new custom filter is listed on the Filter Views page. The conversations are grouped and displayed Conversations History Dashboard based on the inputs provided on the Filter Views page.</p> <p>Edit a Conversation Filter</p> <p>You can edit one or more fields for an existing conversation filter. </p> <p>To edit a conversation filter, follow the steps:</p> <ol> <li>Click the custom filter on the Filter Views page.</li> <li> <p>Click the More Filters dropdown list on the Conversations History panel.</p> <p></p> </li> <li> <p>Modify the required fields on the Edit Conversation Filter window.</p> </li> <li> <p>Click Apply.</p> <p> </p> </li> </ol>"},{"location":"analytics/automations/conversations-history/#filter-criteria","title":"Filter Criteria","text":"<p>You can customize the Conversations History data view by selecting the Filter Criteria on the dashboard. Please click to view the available filters.</p>"},{"location":"analytics/automations/conversations-history/#conversations-history-dashboard","title":"Conversations History Dashboard","text":"<p>The Conversations History Dashboard displays the following information for each conversation session that meets the defined filter condition(s) for the selected date range.</p> <p>Containment Type</p> <p>The following containment types affect the conversation flow and are displayed on top of the individual Conversations History details panel:</p> <ul> <li>Self-service: Indicates that the conversation (initiated by the user) with a VA was successfully completed.</li> <li>Agent Transfer: Indicates that the conversation was transferred to a live agent using the Agent Transfer node in the Dialog Flow.</li> <li> <p>User Drop-off: Indicates that the user stopped participating in the conversation before it was completed, either due to an error in the flow or some other reason.</p> <p></p> </li> </ul> <p>Label</p> <p>A custom label helps identify conversations that require follow-up or indicate an action item for an analyst during the review.</p> <p></p> <p>Add a Custom Label</p> <p>To add a custom label in addition to the default label for a conversation, follow the steps below:</p> <ol> <li> <p>Click the + Label button on the Conversations History panel for the required conversation session.</p> <p></p> </li> <li> <p>In the Labels window, scroll down and click + Add.</p> </li> <li> <p>Enter the label name, and click the confirm icon.</p> <p>Note</p> <p>You can select a different label color by clicking the color icon and using the color palette.</p> <p> 4. Click Save.</p> </li> </ol> <p>Manage a Custom Label</p> <p>Edit</p> <p>You can edit or delete an existing custom label while adding a new label.</p> <p>To edit a label, follow the steps:</p> <ul> <li>Click the + Label button on the Conversations History panel for the required conversation session.</li> <li>In the Labels window, click the edit icon for the label you want to modify.</li> <li>Make the changes and click the confirm icon.</li> <li>Click Save.</li> </ul> <p>Delete</p> <p>To delete a label, follow the steps:</p> <ul> <li>Click the + Label button on the Conversations History panel for the required conversation session.</li> <li>In the Labels window, click the delete icon for the label you want to remove.</li> <li>Click Save.</li> </ul> <p>Other Conversation Parameters</p> <p>The Channel, Language, Date, and conversation duration are displayed at the top of the Conversation History analytics panel.</p> <p></p>"},{"location":"analytics/automations/conversations-history/#conversation-summary","title":"Conversation Summary","text":"<ul> <li>User Messages: The number of messages sent by the user to the virtual assistant.</li> <li>Bot Messages: The number of messages sent by the bot/virtual assistant to the user.</li> <li>Intents Identified: The number of user intents identified by the virtual assistant during the conversation.</li> <li>Intent Unidentified: The number of utterances that did not result in any intent identification during the conversation.</li> <li>Tasks Completed: The number of tasks successfully completed by the virtual assistant.</li> <li>Failed Tasks: The number of tasks that failed during the conversation.</li> </ul>"},{"location":"analytics/automations/conversations-history/#conversation-events","title":"Conversation Events","text":"<p>Conversation Events indicate the sequence of occurrences during a conversation triggered by customer inputs and responses while interacting with a bot. Each event can be categorized into regular and error-based occurrences. When analyzing a conversation flow, the user can identify the event type based on the following icons that are displayed for the relevant event.</p> <p></p> <p>The list of events triggered during a conversation is displayed below.</p> <p>Intent Found: Triggered when the virtual assistant understands the user\u2019s intent. The intent name identified is displayed.</p> EVENT DESCRIPTION Intent Not Found Triggered when the virtual assistant is unable to understand the user\u2019s intent.     Agent Transfer Triggered when a live agent transfer is initiated during the conversation.     Entity Retry Triggered when the input provided by the user is not identified by the virtual assistant and an input retry request to the customer.     Confirmation Retry Triggered when a confirmation request for a query or selection is generated from the virtual assistant to the customer.     On Connect Triggered every time a customer invokes Web/Mobile SDK (a conversation is initiated on the channel).     Sentiment Event Triggered when a customer\u2019s sentiment is identified during the conversation. The user sentiment type identified is displayed.     Welcome Triggered on receiving a message from the user when channel specific event is not configured.     Welcome Event Telegram Triggered on receiving a welcome event from Telegram.     Welcome Event Facebook Triggered on receiving a welcome event from Facebook Messenger.     Welcome Event Telephone Triggered on receiving a Telephone Call from any voice channel.     End Triggered on the closing of a conversation.     Debug Log Triggered when a debug log script runs for a script failure or service failure event.     Script Failure Triggered when a Script node failure occurs.     Service Failure Triggered when a service node failure occurs.     RCS Opt In Triggered on receiving Opt-In from the user for Rich Communication Services.     RCS Opt Out Triggered on receiving Opt-out from the user for Rich Communication Services.     User Message Triggered when a customer sends a message to the virtual assistant on the channel."},{"location":"analytics/automations/conversations-history/#enriched-chat-transcript","title":"Enriched Chat Transcript","text":"<p>The Enriched Chat Transcript feature provides a more detailed view of the conversation, with all the events associated with each message displayed in the chat transcript slider. This can be useful for understanding the conversation at a granular level and identifying any issues that may have arisen. It can also help train the virtual assistant and improve its performance.</p> <p>To view the Enriched Chat Transcript, enable the Show Events option (default setting) in the Chat History panel.</p> <p>Note</p> <p>Disabling the Show Events option will display only the chat transcript without the events.</p> <p></p> <p>The Event labels that appear under Conversation Events are displayed against each chat text in the chat transcript slider. Click here to learn more about Conversational Events.</p> <p></p> <p></p> <p>Feedback User Type Label</p> <p>For conversations with the customer response to a feedback survey, the feedback user type label is added automatically based on the analytics data. This label indicates if a customer is a promote or a detractor.</p> <p>Hovering the mouse on the label displays the following data:</p> <ul> <li>Number of feedback responses collected.</li> <li>Type of feedback survey.</li> <li>Customer type (result generated internally after the feedback is submitted).</li> <li>Feedback score.</li> </ul> <p></p>"},{"location":"analytics/automations/conversations-history/#user-details","title":"User Details","text":"<p>To view the details of the agent that handled a conversation session, follow the steps below:</p> <ol> <li>Click either Conversation Summary or Conversation Event on the dashboard.</li> <li> <p>On the landing page, click the User Details tab to view the following information:</p> <ol> <li>User ID: The unique ID assigned to the agent.</li> <li>Channel Data: The conversational channel where the interaction occurred.</li> <li>Total Conversation Sessions: The total number of conversations the agent has handled for the selected period.</li> <li>Sessions in the Last 30 Days: The number of conversations the agent handled in the date period that the used has selected within the last 30 days.</li> <li>Last Interaction Date: The date of the agent\u2019s most recent customer interaction.</li> <li>User Meta tags: Used to identify important keywords in the conversation.</li> </ol> <p></p> </li> </ol>"},{"location":"analytics/automations/conversations-history/#chat-history","title":"Chat History","text":"<p>The chat conversation flow between the virtual assistant and the customer is displayed in the Chat History panel, including events, actions, input requests, queries, and intent-based responses. Any failed tasks or exceptions that occurred during the conversation will also be displayed here.</p> <p>The Enriched Chat Transcript is visible on the Chat History panel.</p> <p>To view Chat History, follow these steps:</p> <ul> <li>Click an entry under Conversation Summary or an event under Conversation Events on the Conversation History dashboard.</li> <li> <p>The Chat History window displays the conversation flow. In addition, the following information is displayed on the side pane:</p> <ul> <li> <p>Date Filter dropdown to select the period of Chat History.</p> <p></p> </li> <li> <p>The date-wise information summary on the following:</p> <ul> <li>Conversation channel.</li> <li>Chat initiation event.</li> <li>Chat Duration</li> <li>Chat Start time and End time.</li> <li>Conversation summary of the following metrics:<ul> <li>User messages</li> <li>Bot messages</li> <li>Intents identified</li> <li>Intents Unidentified</li> <li>Tasks completed</li> <li>Failed Tasks</li> </ul> </li> <li>Language (of interaction)</li> <li>Event labels tagged to the conversation history.</li> </ul> <p></p> <ul> <li>Trace ID \u2013 A unique ID assigned to each incoming message. The ID is also included in all the logs maintained by the Platform. When you hover over the message, the info icon appears. Click the Info icon to view the Message ID associated with the message.</li> </ul> <p></p> <ul> <li>Click the Message Id to view the Trace ID associated with a message in the Chat History.</li> </ul> <p></p> </li> </ul> </li> </ul> <p>Note</p> <p>The Trace ID is retained in the logs for 30 days. Once the Trace ID is expired, you see a tooltip message as \u2018<code>Trace Id: Trace records for this message are not available</code>\u2018.</p>"},{"location":"analytics/automations/conversations-history/#message-tags","title":"Message Tags","text":"<p>Message Tags help identify and categorize messages in the chat transcript. They add clarity and context to the conversation and can be reused across related conversations. System-defined message tags are provided by default, but users can create custom tags by defining a key-value pair. The key is used as an identifier for the specific message, and the value is the expected customer response to that message.</p> <p>Important</p> <ul> <li>You cannot add the same key to a message again.</li> <li>A custom message tag can only be added and detached from a message and not edited.</li> </ul> <p>To add a custom message tag, follow the steps:</p> <ol> <li>Hover over the message transcript in the conversation where you wish to add the message tag.</li> <li> <p>Click +Message Tag.</p> <p></p> </li> <li> <p>In the Add Message Tag window, enter the Key and Value in their respective text fields.</p> <p></p> </li> <li> <p>Click Save. The new message tag is displayed below the message in the transcript slider.</p> <p></p> </li> </ol> <p>Note</p> <p>The custom message tag you create is available in the Custom Tags Filters section as one of the filtering criteria.</p> <p>The Feedback Survey feature allows customers to provide feedback on their conversations with the virtual assistant.</p> <p>If enabled, the customer\u2019s response to the survey will be displayed in the chat transcript under Chat History.</p> <p>The system captures and displays a feedback event label <code>\"End of Conversation: Survey Type\"</code> on the chat transcript, indicating the end of the conversation and the survey type.</p> <p>The response will be mapped to a key-value pair for the conversation timeline, which can be useful for analyzing the conversation and customer experience at a granular level. This information is useful to improve the virtual assistant\u2019s performance and enhance the customer experience.</p> <p></p> <p>The Conversation Summary displays the following information on the Feedback event:</p> <ol> <li> <p>The Start Time and End Time, along with the real-time counts for the following:</p> <ol> <li>User Messages</li> <li>Bot Messages</li> <li>Intents Identified</li> <li>Intents Unidentified</li> <li>Tasks Completed</li> <li>Failed Tasks</li> </ol> <p></p> </li> <li> <p>The Feedback Event is based on the event timeline with Key and Value.</p> </li> <li>The total number of feedback responses collected for the session and the following:<ul> <li>Type of Feedback</li> <li>Feedback response</li> <li>Score</li> </ul> </li> </ol>"},{"location":"analytics/automations/dashboard-filters/","title":"Dashboard Filters","text":"<p>The dashboard filters are used to filter and view the analytics data for virtual assistants (VAs) on the following dashboards in the ANALYTICS section based on the user\u2019s selection(s):</p> <ul> <li>Overview Dashboard</li> <li>Conversations Dashboard</li> <li>Users Dashboard</li> <li>Performance Dashboard</li> <li>NLP Insights</li> <li>Conversation Insights</li> <li>Conversations History</li> <li>Conversation Flows</li> <li>Task Execution Logs</li> <li>Feedback Dashboard</li> </ul> <p></p> <p>To understand the filter criteria availability on different dashboards, see the Filter Criteria Matrix.</p> <p>Note</p> <p>By default, the VA dashboard displays data for the past 24 hours.</p>"},{"location":"analytics/automations/dashboard-filters/#filter-criteria-descriptions","title":"Filter Criteria Descriptions","text":"<p>The following table describes all the filter criteria available on the Kore.ai XO platform:</p> FILTER DESCRIPTION Date Select a specific period to display all the conversations that occurred during the period. The date format is MM-DD-YYYY. The following filter criteria are available for the date filter: <ul> <li>24 Hours \u2013 Data aggregated immediately preceding 24 hours is displayed. This is the default setting.  <li>7 Days \u2013 Data aggregated over the past seven days is displayed. The start date is the day you select from which this filter is applied. By default, the current day is set as the start date, which you can change.  <li>Custom \u2013 You can choose a custom date range to filter the records. Choose the start date and end date in the calendar and click the Select button to filter the records. The Platform stores only the latest six months of data, and you can apply the date filter only for this date range. </li> Conversation Type The data on the relevant dashboard is displayed based on the interactive or non-interactive conversation type. Learn more.    <p> The Developer Interactions are not included in the Conversation Type filter.     Conversation Status The dashboard data is displayed based on the following conversation statuses: <ul> <li>Active Conversations: These are the ongoing conversations where the users interact with the VA.  <li>Closed Conversations: These are the conversations where an active session between the VA and the customer has ended. Learn more. </li> UserID The UserID of the end-user related to the conversation. The following filter options are available: <ul> <li>Kore User ID \u2013 This User ID is generated by the platform when the user registers; or  <li>Channel User ID \u2013 Email address of the user as received from the channels. Developer interactions are available under Channel User ID. \\ For \u2018Enterprise Bots\u2019, the email address (kore registered email address) is available under Channel ID.  <p> You can select the user ID from the populate drop-down after you enter the first three alphabets of the user ID. <p> You can choose to either Include or Exclude the selected user ID. <p> Channel-specific ids are shown only for the users who have interacted with the VA during the selected period.  Languages If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default. <p> This criterion is not available for the Performance tab of NLP Insights.     Channels When the VA is published in multiple channels, select this filter to view the data for various channels enabled for the VA. <p> The conversations that occurred in all enabled channels are displayed by default.     Task/Intent Select specific tasks or intents to filter the conversation related to those tasks or intents. The page shows the conversations related to all tasks or intents by default. <p> This criterion is not available for the Intent Not Found tab of NLP Insights.     Utterance Type Select the Trained option to filter the conversations that only contain trained utterances to the VA. <p> To view the conversations that contain untrained utterances, click Not Trained. By default, this filter shows the conversations\u2019 data related to both Trained and Not Trained utterances. <p> This criterion is available only for the Intent Found tab of NLP Insights.     Utterance Status The dashboard data is filtered based on the utterance status, Reviewed or Yet to be Reviewed.     Intent Type The dashboard data is filtered based on the conversation skill \u2013 Dialog Tasks, FAQs, or Small Talks. Dialog Tasks The dashboard data is filtered based on the selection of available Dialog Tasks in the Dialog Tasks drop-down.     Ambiguous Select the Show Ambiguous option to filter the conversations that identify multiple tasks or intents and the user is asked to choose from the presented options. <p> This criterion is available only for the Intent Not Found tab of NLP Insights.     Developer Interactions Select \u2018Include Developer Interactions\u2019, to include developer interactions in the results. By default, the developer interactions aren\u2019t included.  <p> Developers include both the VA owners and shared developers.     Custom Tags Select the specific custom tags to filter the records based on the meta-information, session data, and filter criteria. You can add these tags at three levels: <ul> <li>User Level: These tags can be added to the user information.  <li>Message Level: These tags can be added to the message of the current node. If the current node is not associated with a message, then the tag gets added to the immediate previous node that has a message associated with it.  <li>Session Level: These tags can be added at the current session of the user.  <p> You can set the criterion as either Contain or Does Not Contain the specified value. <p> This criterion is not available for the Debug Logs tab of NLP Insights. <p> You can define Tags as key-value pairs from Script written anywhere in the application like Script node, Message, Entity, Confirmation prompts, Error prompts, Knowledge Graph responses, BotKit SDK, etc. <p> The following script can be used for adding meta tags: <ul> <li>To add a User level tag: \\ tags.addUserLevelTag(\u201ctagname\u201d,\u201dtagvalue\u201d)  <li>To add a Session level tag: \\ tags.addSessionLevelTag(\u201ctagname\u201d,\u201dtagvalue\u201d)  <li>To add the Message level tag: \\ tags.addMessageLevelTag(\u201ctagname\u201d,\u201dtagvalue\u201d) </li> </li> <p>Note</p> <p>To see the filter criteria from UserID till Custom Tags listed in the preceding table, click the More Filters drop-down.</p> <p></p>"},{"location":"analytics/automations/dashboard-filters/#filter-criteria-matrix","title":"Filter Criteria Matrix","text":"<p>The following matrix shows the availability of filter criteria on different dashboards and their default values:</p> FILTER TYPE OVERVIEW <p> DASHBOARD CONVERSATION <p> DASHBOARD USERS <p> DASHBOARD PERFORMANCE <p> DASHBOARD CONVERSATIONS HISTORY DASHBOARD NLP INSIGHTS CONVERSATIONAL INSIGHTS DEFAULT <p> VALUE Date Period     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     24 Hours     Conversation Type     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     Interactive     Conversation Status     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     Closed     Channels     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     ALL     Custom Tags     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     None     Language     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     \u2714     ALL     UserID     X     X     X     X     X     \u2714     X     None     Task / Intent     X     X     X     X     X     \u2714     \u2714     None     Utterance Type     X     X     X     X     X     \u2714     X     Both     Developer Interactions     X     X     X     X     X     \u2714     X     Checked     Utterance Status     X     X     X     X     X     X     \u2714     Both     Intent Type     X     X     X     X     X     X     \u2714     Dialog Tasks"},{"location":"analytics/automations/feedback-dashboard/","title":"Feedback Dashboard","text":"<p>Once you\u2019ve created a Feedback Survey for your conversations based on a survey type (NPS, CSAT, or Like/Dislike), it\u2019s important to constantly monitor and analyze the customer responses, feedback survey scores, and trends over a given period.</p> <p>Thus, knowing the survey type scores and the key metrics for respondents, responses, trends, and users helps gain actionable insights into the customer experience your business is delivering. The new Feedback Analytics Dashboard provides prebuilt dashboards to view the survey results and insights based on the duration, survey name, and type you select.</p> <p>This dashboard displays graphs and charts derived from real-time feedback data for the following:</p> <ul> <li>Distribution trends of feedback scores.</li> <li>The overall score for the given period and its trend.</li> <li>The comprehensive feedback results with an option to export the results for review.</li> </ul> <p>Note</p> <p>The Feedback Dashboard is available in Release 10.0.0 (January 2023).</p> <p>To view the Feedback dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click the Feedback Dashboard under the Automation section of the Analytics panel. The Feedback Dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol>"},{"location":"analytics/automations/feedback-dashboard/#dashboard-filters","title":"Dashboard Filters","text":"<p>The Feedback Dashboard displays analytics data on the Feedback Survey responses from customers based on the following filters:</p> <ul> <li>Date: Indicates the date range to filter the conversation sessions and capture the survey feedback responses.</li> </ul> <p>Note</p> <p>The session start time filters the sessions based on when they were initiated.</p> <p></p> <p>The filter options include the following:</p> <ul> <li>24 Hours: Captures feedback survey responses from conversations in the past 24 hours.</li> <li>Last 7 Days: Captures feedback survey responses from conversations that happened in the last seven days.</li> <li>Last Month: Captures feedback survey responses from conversations in the last month.</li> <li>Last 3 Months Captures feedback survey responses from conversations in the last three months.</li> <li> <p>Custom: Select the start and end date range on the calendar widget to capture the feedback survey data.</p> <p> </p> </li> <li> <p>Survey Type: The type of survey including CSAT, NPS, or Like/Dislike. Learn more.     </p> </li> <li> <p>Survey Name: This is the feedback survey name provided when creating a feedback survey under Build &gt; Configurations &gt; Feedback Survey. You can either select All Surveys to capture the Feedback Survey analytics data of all the surveys configured for the virtual assistant or a specific survey name from the dropdown list.</p> <p></p> </li> </ul>"},{"location":"analytics/automations/feedback-dashboard/#dashboard-sections","title":"Dashboard Sections","text":"<p>The Feedback Survey Dashboard is categorized into five sections that display analytics-driven graphs and charts for the selected feedback survey name, survey type, and date based on the captured feedback survey responses. These include:</p>"},{"location":"analytics/automations/feedback-dashboard/#percentage-and-number-of-respondents","title":"Percentage and Number of Respondents","text":"<p>This widget displays the percentage and the number of respondents for a specific feedback survey response. In addition, it displays the percentage of increase or decrease in the individual response type over the given period.</p> <p>For the NPS survey type, it captures the data for the following responders:</p> <ul> <li>Promoters: Respondents who gave a score of 9 or above.</li> <li>Passives: Respondents who gave a score between 6 and 8.</li> <li>Detractors: Respondents who gave a score between 0 and 5.</li> </ul> <p></p> <p>For the CSAT survey type, it captures the data for the following responses:</p> <ul> <li>Very Satisfied: Respondents who gave a score of 5.</li> <li>Satisfied: Respondents who gave a score of 4.</li> <li>Neutral: Respondents who gave a score of 3.</li> <li>Unsatisfied: Respondents who gave a score of 2.</li> <li>Very Unsatisfied: Respondents who gave a score of 1.</li> </ul> <p></p> <p>For the Like/Dislike survey type, it captures the data for the following responses:</p> <ul> <li>Extremely Likely: Respondents who gave a score of 1.</li> <li>Extremely Unlikely: Respondents who gave a score of 0.</li> </ul> <p></p>"},{"location":"analytics/automations/feedback-dashboard/#score-break-up-respondent-wise-survey-score-over-time","title":"Score Break up \u2013 Respondent-wise Survey Score over Time","text":"<p>This section displays the bar chart widget representing the percentage of each response type for Like/Dislike and CSAT surveys and the respondent type for NPS surveys over a time period.</p> <p>Note</p> <p>Hover your mouse over the Survey Score chart to see the number of respondents, the response type scores, and the percentage of respondents for each response type at the granular level.</p> <p>For the NPS survey type, the number of promoters, passives, and detractors is displayed in different colors over the selected period on the days they responded.</p> <p></p> <p>For the CSAT survey type, the number of very satisfied, satisfied, neutral, unsatisfied, and very unsatisfied responses received over the selected date range is displayed in different colors.</p> <p></p> <p>For the Like/Dislike survey type, the number of extremely likely and extremely unlikely responses captured over the selected date range is displayed in different colors</p> <p></p>"},{"location":"analytics/automations/feedback-dashboard/#survey-score","title":"Survey Score","text":"<p>This section displays the meter graph (from 0 to 100) widget for the survey score based on the actual customer feedback survey responses for a specific survey type. Each score graph is generated based on an internal formula mapped to a survey type as follows:</p> <ul> <li> <p>NPS Score: Displays a whole number between -100 and 100 based on the formula <code>(Percentage of Promoters - Percentage of Detractors)</code>.</p> <p></p> </li> <li> <p>CSAT: Displays the percentage value based on the formula <code>(Number of very satisfied/satisfied Respondents / Total Number of Respondents) * 100</code>.</p> <p></p> </li> <li> <p>Like/Dislike: Displays the percentage value based on the formula <code>(Number of extremely likely Respondents / Total Number of Respondents) * 100</code>.</p> <p></p> </li> </ul>"},{"location":"analytics/automations/feedback-dashboard/#survey-trendline","title":"Survey Trendline","text":"<p>This section displays the widget with the line graph capturing the date-wise response score trend for the total number of positive respondents over the selected date range.</p> <p>Note</p> <p>Hover your mouse over the trend chart to see the number of respondents and the response scores on a specific date at the granular level.</p> <p>For the NPS survey type, the line graph displays the Promoters score trend changes for the total number of promoters over the selected period.</p> <p></p> <p>For the CSAT survey type, the line graph displays the Respondents Score trend changes for the total number of very satisfied and satisfied respondents over the selected period.</p> <p></p> <p>For the Like/Dislike survey type, the line graph displays the respondents\u2019 score trend changes for the total number of extremely likely respondents over the selected period.</p> <p></p>"},{"location":"analytics/automations/feedback-dashboard/#user-level-feedback","title":"User-level Feedback","text":"<p>This information grid represents the metadata for the Total number of conversations for every unique conversation path between the virtual assistant and the user. This grid summarizes and lists the data of all the feedback surveys mapped to the selected survey type filter. The fields for which data is displayed are:</p> FIELD NAME DESCRIPTION Survey Name The name of the feedback survey for the selected survey type.     Kore User ID The internal ID of the user who responded to the survey.     Channel ID The channel ID of the conversation session channel.     Session ID The identifier of the conversation session.     Channel The conversation channel of the user and virtual assistant interaction. This can be a web/mobile client or a messaging platform.     Language The language used to communicate during the conversation session.     Score The feedback survey score.     Date &amp; Time The date and time of the interaction.     Descriptive Feedback The user\u2019s response to the follow-up question was triggered during the feedback survey. <p> Note: This value appears only if a follow-up question is configured for a survey. <p></p> <p>Note</p> <p>The values for Score and Survey Name will change based on the selected Survey Type.</p>"},{"location":"analytics/automations/feedback-dashboard/#download-the-feedback-analytics-report","title":"Download the Feedback Analytics Report","text":"<p>To download the User-level feedback report, click the Export to CSV icon as shown below:</p> <p></p>"},{"location":"analytics/automations/introduction/","title":"Analyzing Your Bot","text":"<p>The Kore.ai XO Platform provides various dashboards to analyze the real-time data generated by the virtual assistant through its interaction. This data can be useful and provide value for your business.</p> <p>These dashboards are available within the Analytics section of the Platform and are as follows:</p> <ul> <li>Overview Dashboard: This page summarizes the Conversations Dashboard, Users Dashboard, and Performance Dashboard.</li> <li>Conversations Dashboard: This page provides insights into the usage and containment of conversation sessions. It focuses on whether requests were successfully answered by the virtual assistant (VA), landed with agents, or were incomplete. You can view many metrics like the conversation session trend, conversation path analysis, session distribution by channel, VA\u2019s engagement, and so on with the breakup of self-service, drop-off, and agent transfer sessions.</li> <li>Users Dashboard: This page is a central place for information on new and returning user trends. It also provides insights like total unique users count, returning users count, new users count, and weekly or daily user retention cohort.</li> <li>Performance Dashboard: This page helps you understand the performance of a virtual assistant. A VA designer needs insights into how many intents were identified, how many tasks were successfully completed using the virtual assistant, how many services or scripts failed during the interactions, and so on. The performance dashboard provides this essential information.</li> <li>Custom Dashboard: This page allows you to design your own reports and dashboards.</li> <li>NLP Insights: This page helps you achieve the following:<ul> <li>Gain in-depth insights into your VA\u2019s performance in identifying and executing tasks.</li> <li>Get a summarized view of VA conversations, intents detected, and drop-offs with the complete VA-user conversation presented as a flow diagram.</li> </ul> </li> <li>Task execution logs: This page helps you gain in-depth insights into the task execution-related data and assess your virtual assistant\u2019s performance in executing the tasks.</li> <li>Conversations History: This page helps you analyze the user interactions by summarizing the key events identified during the conversation. Intent identifications, entity or confirmation retries, task execution failures, and so on are some of the key events tracked.</li> <li>Conversation Flows: This page can be used to visualize the journey of various VA-user interactions across conversation sessions in a given time period. This helps developers understand their assistant\u2019s most frequently used tasks, how users invoke them, popular task execution paths, dropout points, and so on.</li> <li>Conversation Insights: This page provides a visual user utterances map to easily discover false positives and negatives and identify opportunities to train new intents. The dashboard aims to provide a structured approach for analysts to review and improve the NLU performance regularly. Utterance clusters are formed using deep neural models, and each cluster is assigned a name representative of the underlying utterances. You can also switch to the tabular view to see the list of all intents and the corresponding clusters under these intents. You can categorize the utterances as True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) and train them for existing or new intents.</li> <li>Feedback Dashboard: The Feedback Dashboard uses the Feedback Survey feature to help you capture user feedback about your products, services, and overall experience with the virtual assistant. The in-built analytics help you get valuable insights using NPS, CSAT, or any other metrics of your choice. The Feedback Dashboard provides survey results and insights. You can see the distribution trend of feedback scores and the overall score for a given period. You can also review the full feedback results with an option to export them.</li> <li>Usage Metrics: This page provides the VA activity and bot user overview. It includes both interactive and non-interactive sessions.</li> <li>Containment Metrics: This page provides insights on whether queries are successfully answered by the Virtual assistant or handled by agents.</li> </ul>"},{"location":"analytics/automations/nlp-insights/","title":"NLP Insights","text":"<p>The NLP Insights feature helps you gain in-depth insights into the analytics data and assess your virtual assistant\u2019s performance in identifying and executing tasks. You can improve your VA\u2019s performance based on the insights. </p> <p>To view the NLP Insights dashboard, follow the steps: </p> <ol> <li>Click the three dots on the left navigation pane and then click Analytics.The Analytics panel is displayed with the list of reports.</li> </ol> <p> </p> <ol> <li>Click the NLP Insights under the Automation section of the Analytics panel. The NLP Insights dashboard is displayed on the right side of the page.</li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>The NLP Insights page shows the specific information in the following sections:</p> <ul> <li>Intent Found: Number of identified intents</li> <li>Intent Not Found: Number of unidentified intents</li> <li>Unhandled Utterances: Number of unhandled utterances</li> <li>Pinned: Pinned NLP Insight records. Specific records are pinned to highlight them for easy access and viewing.</li> </ul> <p>In the latest version of the XO Platform, the NLP Insights section retains only the NLP-related analytics data for task identification. The new Task Execution Logs section displays the analytics data related to a VA\u2019s task execution.</p>"},{"location":"analytics/automations/nlp-insights/#nlp-analytics-fields","title":"NLP Analytics Fields","text":"<p>The following fields are available for NLP Analytics:</p>"},{"location":"analytics/automations/nlp-insights/#intent-found","title":"Intent Found","text":"<p>An intent refers to the goal the customer has in mind when typing in a question or comment. The  phrases used to express the intent are called user utterances. The Intent Found tab includes all the user utterances identified by the platform. </p> <p>Note</p> <p>You need to check for false positives in scenarios where the utterance is wrongly identified for an intent.</p> <p>See the following table and features section to know more:</p> <p></p> <p>The following is an example of Intent Found:</p> <p>User: I want to know my order confirmation</p> <p>VA: Would you like to switch to Track Order</p> <p>User: Yes</p> <p>VA: Let\u2019s log you in. \\       How would you like to go ahead \u2013 Log in or Guest?</p> <p>In the above conversation, the user utterance of \u2018knowing the order confirmation status\u2019 is recognized by the VA and successfully mapped to the Track Order intent.</p> <p>Description of the Intent Found Fields</p> <p>The following table lists the fields on the Intent Fount tab with descriptions:</p> FIELDS DESCRIPTION Utterances     The utterances that are identified by the VA. The details on the tab are grouped by utterances based on similarity by default. To turn off grouping by utterance, click the Utterances header and disable the Group by Utterances option.     Intent     The intent/task that is identified. The details on the tab can be grouped by intent. By default, the  Group by Intent option is turned off. To turn it on, click the Intent header and enable the Group by Intent option. <p> If the intent has been identified through a Dialog Task, this column displays the task\u2019s name. If the intent is answered using the Answer from Document feature, this column mentions Answer from Documents.     Traits     All the traits that are identified for the listed utterances. The details on the tab can be grouped by traits. By default, the  Group by Traits option is turned off. To turn it ON, click the Traits header and enable the Group by Traits option. <p> This information is available for the data generated after June 1, 2021.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User ID or Channel User ID. <p> Channel-specific IDs are shown only for the users who have interacted with the VA during the selected period.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/nlp-insights/#intent-not-found","title":"Intent Not Found","text":"<p>Intent Not Found includes all the user utterances that the platform is not able to identify with a dialog task or FAQ either due to invalid training, less training data, or the intent unavailability in the virtual assistant.</p> <p>See the following table and Features section to know more:</p> <p></p> <p>Example of Intent Not Found: </p> <p>User: I want to know my account statement</p> <p>VA: I\u2019m sorry, I did not recognize the value you have entered. Please select a value from the list.</p> <p>In the above conversation, the VA does not recognize the user utterance of \u2018knowing the account statement\u2019. It could be due to invalid training, less training, or unavailability of intents in the virtual assistant.</p> <p>Description of Intent Not Found Fields</p> <p>The following table lists the fields on the Intent Not Found tab with descriptions:</p> FIELDS DESCRIPTION Utterances     The utterances that are not identified by the VA. The details on the tab are grouped by utterances based on similarity by default. To turn off grouping by utterance, click the Utterances header and disable the Group by Utterances option.     Traits     All the traits that are identified for the listed utterances. The details on the tab can be grouped by traits. By default, the  Group by Traits option is turned off. To turn it on, click the Traits header and enable the Group by Traits option. <p> This information is available for data generated after June 1, 2021.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User id or Channel User Id. <p> Channel-specific ids are shown only for the users who have interacted with the VA during the selected period.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/nlp-insights/#unhandled-utterances","title":"Unhandled Utterances","text":"<p>The Unhandled Utterances help analyze the unidentified inputs received from the users during a task execution at an entity node, message node, or confirmation node. These insights allow you to identify the need for additional training or new intents and enhance the existing NLU model of the VAs.</p> <p>In an unhandled utterance, the following new fields are available:</p> <ul> <li>Prompt Type \u2013 A prompt type could be either an Entity node, Message node, or a Confirmation node.</li> <li>Node Name\u2013 Name of the node in which the utterance is not handled</li> <li>Task Name \u2013 Name of the task in which the utterances are unidentified on an entity, message, or confirmation nodes.</li> </ul> <p></p> <ul> <li>Group by functionality is available for Utterances, Traits, Prompt Type, Task Name, and Node Name</li> </ul> <p>Note</p> <p>The unhandled utterances are available for all conversations with product version 9.3 or higher.</p> <p>See the following table and Features section to know more.</p> <p>Unhandled Utterance Examples</p> <p>The following examples show the conversations between the VA and user, with unhandled utterances captured at Entity, Message, and Confirmation nodes.</p> <p>At an Entity Node:</p> <p>For example, when the user provides an invalid input at entity or confirmation nodes as follows:</p> <p>User: I want my account statement</p> <p>VA: Please enter your Customer Id</p> <p>User: Where do I find it?</p> <p>VA: Sorry, that is an incorrect input. Please enter your Customer Id</p> <p>In the above conversation, if the VA doesn\u2019t recognize \u201cwhere to find customer id\u201d as an intent or entity, then this utterance is  categorized under Unhandled Utterances.</p> <p>At a Message Node:</p> <p>For example, when the user provides an invalid input at a message node as follows:</p> <p>User: I want to book a flight for today</p> <p>VA: Enter the flight number User: 12434 VA: Enter number of seats required User: 3  VA: Your flight is booked. Would you like to: 1. Book a Hotel  2. Book a sightseeing tour User: I want to Cancel the Flight VA: I\u2019m sorry, I don\u2019t understand. Please enter again.</p> <p>In the above conversation, if the VA doesn\u2019t recognize the intent name \u201ccancel flight\u201d as an input at the message node. The intent identification fails and the utterance is categorized under Unhandled Utterances.</p> <p>At Confirmation Node:</p> <p>For example, when the user provides an invalid input at a confirmation node as follows:</p> <p>VA: How may I help you</p> <p>User: I want to book a flight</p> <p>VA: Enter the number of seats</p> <p>User: 2</p> <p>VA: Please confirm if you want two seats</p> <p>User: I want to hire a cab</p> <p>VA: I cannot understand it, can you rephrase it</p> <p>In the preceding conversation, when a user enters \u2018I want to hire a cab\u2019 at the confirmation node, it is not recognized and logged under Unhandled Utterances.</p> <p>Description of Unhandled Utterances Fields</p> <p>The following table lists the fields on the Unhandled Utterances tab with descriptions:</p> FIELDS DESCRIPTION Utterances     The unhandled utterances for which the inputs received are unidentified. The details in the tab are grouped by utterances based on similarity by default. To turn off grouping by utterance, click the Utterances header and disable the Group by Utterances option.     Traits     All the traits that are identified for the listed utterances. The details in the tab can be grouped by traits. By default, the  Group by Traits option is turned off. To turn it on, click the Traits header and enable the Group by Traits option. <p> This information is available for analytics generated after June 1, 2021.     Prompt Type     A prompt type could be either an Entity node, Message node, or a Confirmation node. To turn on grouping by Prompt Type, click the Prompt Type header and enable the Group by Prompt Type option.     Task Name     The task that is identified for the user utterance. To turn on grouping by task name, click the Task Name header and enable the Group by Task option.     Node Name     The name of the service or script or WebHook within the task that got executed in response to the user utterance. To turn on grouping by node names to which these scripts or services belong, click the Node Name header and turn on the Group by NodeName option.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User id or Channel User Id. <p> Channel-specific ids are shown only for the users who have interacted with the VA during the selected period.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/nlp-insights/#pinned","title":"Pinned","text":"<p>Any records from Identified and Unidentified Intents, or Unhandled Utterances tabs that are pinned are displayed in the Pinned tab. </p> <p>Description of Pinned Fields</p> <p>The following table lists the fields on the Pinned tab with descriptions:</p> FIELDS DESCRIPTION Utterances     The pinned utterances are displayed here. The details in the tab are grouped by utterances based on similarity by default. To turn off grouping by utterance, click the Utterances header and disable the Group by Utterances option.     Intent     The intent associated with the pinned utterance. The details in the tab can be grouped by Intents. By default, the  Group by Intent option is turned off. To turn it on, click the Intent header and enable the Group by Intent option.     Type of Issue     Shows the reason for failure in case of Task Failure records. <p> To know the usual type of issues, see Failed Task \u2013 Type of Issues.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User id or Channel User Id. <p> Channel-specific ids are shown only for the users who have interacted with the VA during the selected period.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/nlp-insights/#nlp-insights-analysis","title":"NLP Insights Analysis","text":"<p>The following sections describe more about the options available on NLP Insights page and the analysis of the records captured here.</p>"},{"location":"analytics/automations/nlp-insights/#features","title":"Features","text":"<p>The following list details the features available in NLP Insights for Intent Found, Intent Not Found, and Unhandled Utterances.</p> <ul> <li>You can filter the information based on various criteria such as User Utterances, Intent, user id (Kore user id or channel-specific unique id), date-period, the channel of use, language, etc. You can also filter records based on multiple custom tags. See Filter Criteria to know more.</li> <li>Complete meta-information is stored for later analysis, including the original user utterance, the channel of communication, entities extracted (if any), custom tags applied, detailed NLP analysis with scores returned from each engine, and the ranking and resolver scores.</li> <li>Ability to view the chat transcript to the point of the user utterance. This also gives the option to view the user profile and the details of that user\u2019s conversation sessions.</li> <li>You have an option to train the utterance.  The utterance will be marked once trained.</li> <li>Any important record you want to mark, track later, or both can be pinned. They appear on  the Pinned tab.</li> <li>Sorting feature is available for Date and Time (Oldest to Newest, Newest to Oldest). You can export the insights data as a CSV file.</li> </ul> <p></p> <p>Note</p> <p>The NLP Insights page shows the conversations from the last 24 hours by default. You can filter the insights for a selected period \u2013 use the Date drop-down to select 24 hours, the last 7 days, or a custom period.</p>"},{"location":"analytics/automations/nlp-insights/#fields-matrix","title":"Fields Matrix","text":"<p>The following matrix shows the availability of fields on each tab of NLP Insights:</p> FIELDS INTENT FOUND INTENT NOT FOUND UNHANDLED UTTERANCES PINNED Utterances     \u2714     \u2714     \u2714     \u2714     Intent     \u2714     X     X     \u2714     Traits     \u2714     \u2714     \u2714     X     UserID     \u2714     \u2714     \u2714     \u2714     Language     \u2714     \u2714     \u2714     \u2714     Date &amp; Time     \u2714     \u2714     \u2714     \u2714     Prompt Type     X     X     \u2714     X     Task Name     X     X     \u2714     X     Node Name     X     X     \u2714     X     Failure Point     X     X     X     X     Type of Issue     X     X     X     \u2714     Type     X     X     X     X     Total Runs     X     X     X     X     Success%     X     X     X     X     2XX Responses     X     X     X     X     Non 2XX Responses     X     X     X     X     Avg Response Time     X     X     X     X     Log     X     X     X     X     Debug Point     X     X     X     X     Channel     X     X     X     X"},{"location":"analytics/automations/nlp-insights/#filter-criteria","title":"Filter Criteria","text":"<p>You can filter the information on the Insights page using various filters. You can save the entered filter criteria and set it as the default filter using Save as Default Filter.</p> <p>The filter criteria differ slightly between different tabs. The relevant filters are applied when you switch between the tabs on the Insights Page. See Dashboard Filter Criteria to know more details.</p>"},{"location":"analytics/automations/nlp-insights/#detailed-view","title":"Detailed View","text":"<p>For all the user utterances listed on the various tabs such as Intent Found, Intent Not Found, Unhandled Utterances, etc., you can open more details of the user session by clicking the respective record. The record shows the information on the following sub-tabs: Details, NLP Analysis, and Chat History.</p>"},{"location":"analytics/automations/nlp-insights/#details","title":"Details","text":"<p>The Details tab shows the basic details of the session along with a JSON file that includes the NLP analysis for the conversation.</p> <p></p> <p>If the intent has been answered from a document, this section provides the following details:</p> <ul> <li>Information on the Intent not being identified by the ML, FM, and KG engines. Hence, the user utterance is answered directly from the document.</li> <li>The answer presented to the user.</li> <li>The document from which the answer was provided.</li> <li>A Similarity Score for how similar the user query is to the document content.</li> <li>An option to add the query to the Knowledge Graph as an FAQ.</li> </ul> <p></p>"},{"location":"analytics/automations/nlp-insights/#nlp-analysis","title":"NLP Analysis","text":"<p>This tab provides a visual representation of the NLP Analysis, including intent scoring and selection.  See Testing and Training a Virtual Assistant and Ranking and Resolver for more information.</p> <p></p>"},{"location":"analytics/automations/nlp-insights/#chat-history","title":"Chat History","text":"<p>On the Chat History tab, you can access the exact message or conversation for which the record is logged. It shows the entire chat history of the user session.</p> <p></p> <p>Chat History provides visibility into the user information by capturing the following details:</p> <ul> <li>User Profile: Provides a 360-degree view of the user and their usage metrics.</li> <li>User Conversation Sessions: Lists all the sessions of the user in the given period with the selected utterance section expanded.</li> <li>Go to Selected Utterance: When you click this icon, the selected utterance is highlighted in orange (see the preceding screenshot).</li> <li>Trace ID\u2013 A unique ID assigned to each incoming message. The Id is also included in all the logs maintained by the Platform.. When you hover over the message, the info icon appears. Click the Info icon to view the Message Id associated with the message.</li> </ul> <p></p> <ul> <li>Click the Message Id to view the Trace ID associated with a message in the Chat History.</li> </ul> <p></p> <p>Note</p> <p>The Trace ID is retained in the logs for 30 days. Once the Trace ID is expired, you see a tooltip message as \u2018<code>Trace Id: Trace records for this message are not available</code>\u2018.</p> <p>The following user information details are displayed on the** Chat History **tab:</p> FUNCTIONALITY ATTRIBUTE DESCRIPTION User Profile     Kore User ID     User id assigned by the platform     Channel Data     Data received from the channel, that is the information available in the User Context.     User Meta Tags     The total number of meta tags associated with the user and key-value pairs for the most recent ones.     Latest Interaction     Last time the user interacted with the VA.     Total Conversation Sessions     The total number of interactive and non-interactive sessions registered by the user from the beginning of time.     Total Conversation Sessions in the Last 30 Days     The total number of interactive and non-interactive sessions registered by the user in the last 30 days.     *The next few attributes are not displayed if there is no interaction by the user in the last 30 days Last 30 Days\u2019 Intent Detection Rate     (Total identified intents / (Total identified intents + unidentified utterances)) * 100 for the utterances over the last 30 days     Intents Requested     Total identified intents + unidentified utterances     Intents Identified     Total intents identified     Last 30 Days Goal Completion Rate     (Tasks success tasks / (Total success tasks + total failed tasks) ) * 100 for the tasks over the last 30 days     Tasks Initiated     Total success tasks + total failed tasks     Tasks Completed     Tasks successfully completed     Recent Conversation Flows     Top 10 popular conversation flows executed by the user in the last 30 days. Popular flows are determined by the number of instances, for which the conversation flow is executed.     User Conversation Sessions     Session Attributes Session Start     Session start date and time.     Session End     Session end date and time.     Channel     Channel in which the session is initiated.     Agent Transfer Tag     The session where the user is transferred to an agent. Sessions should be considered even if the user returns to the VA.     Drop Off Tag     The session where the user dropped off.     Total Success Tasks     Count of tasks successfully completed in the session.     Total Failed Tasks     Count of tasks failed in the session.     Intents Identified     Count of intents successfully identified in the session.     Intents Unidentified     Count of intents unidentified in the session and list of unidentified intents.     Conversation Path     The series of tasks initiated by the user in the session.     Session Meta Tags     Count of the session meta tags used with the details of the most recent custom meta tags displayed.     Conversation Transcript Message Meta Tags     The chat transcript is annotated with message tags for messages with meta-tags associated with them.     Agent Transfer     Indicates the point of agent transfer at the last message before transfer.     Drop Off     Indicate the point of drop off at the last message before dropping off.     <p>Advanced Performance Details</p> <p>Clicking a service or script or WebHook name opens the advanced details dialog for the service, which lists each instance of its run along with separate tabs for successful and failed runs. Analyzing the average response time of different runs gives you insights into any aberrations in the service or script execution. Click any row to open the JSON response associated with the service or script run.</p>"},{"location":"analytics/automations/nlp-insights/#train-the-virtual-assistant","title":"Train the Virtual Assistant","text":"<p>You can train the specific intents and utterances from the Intent Found, Intent Not Found, and Unhandled Utterances tabs. To do so, hover over a row in any of these tabs, and click the **Train **icon. It opens the Test &amp; Train page, where you can train the Virtual Assistant. For more information, see  Testing and Training a Virtual Assistant.</p>"},{"location":"analytics/automations/nlp-insights/#data-export","title":"Data Export","text":"<p>You can export the data present on the NLP Insights page to a CSV file, by clicking the Export icon on the top right corner of the page.</p> <p></p> <p>Once you click the icon, the export process starts, and you can see the progress in the Status Tracker dock. The export file is downloaded to your local Downloads folder. The downloaded file has the information specific to the selected tab and a detailed analysis based on the selected filters.</p> <p>These records also include the Meta Tag information.</p>"},{"location":"analytics/automations/overview-dashboard/","title":"Overview Dashboard","text":"<p>The Overview dashboard gives a snapshot of the Virtual Assistant\u2019s conversations, user analytics, and performance over time. You can filter the information by date, conversation type (interactive and non-interactive), conversation status, and more.</p> <p>To view the Overview dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click Overview under the Automation section of the Analytics panel. The Overview dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>Note</p> <p>The Overview dashboard is available only post-9.3 release, i.e. post-July 24, 2022.</p>"},{"location":"analytics/automations/overview-dashboard/#overview-dashboard-components","title":"Overview Dashboard Components","text":"<p>Once users start interacting with your assistant, you can view the following details in the Overview dashboard:</p> <ul> <li>Conversations Dashboard: Displays the key virtual assistant metrics and insights into the usage and containment of the conversations. You can view the conversations\u2019 trend with the breakup of self-service, drop-off, and agent transfers. Learn more.</li> <li>Users Dashboard: Displays trend-based analytics data on new and returning users. Learn more.</li> <li>Performance Dashboard: Provides insights on the NLP and execution performance of the virtual assistants including intent identification rate, goal completion rate, service, and script execution rates. Learn more.</li> </ul>"},{"location":"analytics/automations/overview-dashboard/#filter-criteria","title":"Filter Criteria","text":"<p>The Virtual Assistants Overview data can be viewed based on specific filter criteria that can be selected. Learn more.</p>"},{"location":"analytics/automations/performance-dashboard/","title":"Performance Dashboard","text":"<p>After you publish a Virtual Assistant (VA), you can monitor its performance using the Performance dashboard. This dashboard provides insights into metrics such as the number of intents identified, tasks completed successfully, and any service or script failures that occur during interactions. You can use these insights to identify areas where your virtual assistant needs improvement. For example, if you see that many intents are not identified, you can train the virtual assistant for those unidentified intents.</p> <p>To view the Performance dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click Performance Dashboard under the Automation section of the Analytics panel. The Performance Dashboard is displayed on the right side of the page.</p> </li> <li> <p>Select appropriate filters on the dashboard and click Apply.</p> <p></p> </li> </ol> <p>Note</p> <p>The Performance dashboard is available only post-9.2 release, i.e. post April 09, 2022.</p>"},{"location":"analytics/automations/performance-dashboard/#performance-dashboard-metrics","title":"Performance Dashboard Metrics","text":"<p>The Performance Dashboard provides insights to understand the virtual assistant\u2019s NLP performance and integration metrics. The Performance Dashboard is categorized into four categories to identify how a virtual assistant performs. These categories are mentioned below:</p>"},{"location":"analytics/automations/performance-dashboard/#intent-identification-rate","title":"Intent Identification Rate","text":"<p>This section of the dashboard provides information on the number of intents that were classified and unclassified. An intent refers to the goal the customer has in mind when typing in a question or comment. While entity refers to the modifier the customer uses to describe an issue, intent is \u201cWhat they really mean\u201d. To know more about intents refer here.</p> <p>Below are the widgets that are used to provide insights:</p> Metric Description Intent Identification Rate     A scorecard that displays the percentage and the number of intents that were identified in a duration. It also displays the percentage increase or decrease in identifying intents from the last selected period.     Intent Identification Trend     A line chart that displays the total number of intents that were classified by the virtual assistant versus the total number of intents that were unclassified by the virtual assistant over a period of time.     Popular Intents     Displays a table with data insights on the number of times the virtual assistant identified the given intent from the user utterances in active and closed conversations. <p> The following fields are displayed: <ul> <li>Intent Name: Name of the identified intent.  <li>Utterance Group: The cluster name where similar utterances are grouped to which the identified intent is mapped.  <li>Count: The count of identified utterances.  <p> Note: Clicking an intent name row displays a drill-down view of the relevant utterances, channel, user ID, Date and time, and chat history.  Popular Unidentified Utterances     A table that displays the number of utterances that did not identify an intent. The utterances are grouped by their similarity."},{"location":"analytics/automations/performance-dashboard/#goal-completion-rate","title":"Goal Completion Rate","text":"<p>The goal completion metrics provide insights as to how many tasks were completed in a period by a virtual assistant. This metric shows all types of tasks which include completed tasks, abandoned tasks, incomplete tasks, and failed tasks.</p> <p>Listed below are the widgets that could help in providing information about these details:</p> Metric Description Goal Completion Rate     A scorecard that displays the percentage and the number of task executions that were successfully completed in a duration. It also displays the percentage increase or decrease in completing tasks from the last selected period.     Goal Completion Trend     A line chart that plots the successful and failed task executions over a period of time.     Task Performance     A table that provides insights into the number of successful and failed task executions per task for a selected duration.     Failure Point Analysis     A table that displays the number of times a task has failed at various nodes."},{"location":"analytics/automations/performance-dashboard/#api-execution-rate","title":"API Execution Rate","text":"<p>This section of the dashboard provides information on the number of APIs that were successfully executed and failed. While configuring a dialog task often there are needs to use a Service node that is used to make REST or SOAP requests to a third party web-services. To know more about service nodes refer here.</p> <p>Below are the widgets that are used to provide information about API performance:</p> Metric Description API Performance Rate     A scorecard that displays the percentage and the number of service calls that were executed successfully. It also displays the percentage increase or decrease of APIs that were executed successfully from the last selected period.     Service Execution Trend     A line chart that plots the trend of successful and failed service execution over a period of time.     Service Performance     A table that displays the number of times a service node is executed, its status, and the average response time of executing the API."},{"location":"analytics/automations/performance-dashboard/#script-execution-rate","title":"Script Execution Rate","text":"<p>This section of the dashboard provides information on the number of Scripts that were successfully executed and failed. A Script allows you to write JavaScript code in a dialog task. To know more about script nodes please refer here.</p> <p>Below are the widgets that are used to provide information about Script performance.</p> Metric Description Script Performance Rate     A scorecard that displays the percentage and the number of scripts that were executed successfully. It also displays the percentage increase or decrease of Scripts that were executed successfully from the last selected period.     Script Execution Trend     A line chart that plots the trend of successful and failed script execution over a period of time.     Script Performance     A table that displays the number of times a script node is executed, its status, and the average response time executing the script."},{"location":"analytics/automations/performance-dashboard/#filter-criteria","title":"Filter Criteria","text":"<p>The Performance Analytics Dashboard data can be viewed based on specific filter criteria that can be selected. Learn more.</p>"},{"location":"analytics/automations/task-execution-logs/","title":"Task Execution Logs","text":"<p>The Task Execution Logs feature helps you gain in-depth insights into the task execution-related data and assess your virtual assistant\u2019s performance in executing tasks. </p> <p>To view the Task Execution Logs dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics.The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click the Task Execution Logs under the Automation section of the Analytics panel. The Task Execution Logs dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>The Task Execution Logs page shows information specific to task execution in the following sections:</p> <ul> <li>Failed Task: Indicates the number of unsuccessful tasks.</li> <li>API Calls: Displays all the Service node and Webhook node executions-related data, and the number of failed services during Bot interactions.</li> <li>Script Execution: Displays analytics data for all the script node executions and the number of failed scripts during Bot interactions.</li> <li>Debug Log: Custom Debug logs include user conversations from across all channels for analyzing your VA.</li> <li>Pinned: Pinned Task Execution Logs records. Specific records are pinned to highlight them for easy access and viewing.</li> </ul>"},{"location":"analytics/automations/task-execution-logs/#task-execution-logs-fields","title":"Task Execution Logs Fields","text":"<p>The Task Execution Logs page displays the following fields specific to task execution:</p>"},{"location":"analytics/automations/task-execution-logs/#failed-task","title":"Failed Task","text":"<p>In a scenario where all the user utterances are successfully mapped to an intent, but the task cannot be completed for some reason, then such utterances are listed under this tab. You can group them based on task and failure types to analyze and solve issues with the VA.</p> <p>See the following table and the Features section to know more:</p> <p></p>"},{"location":"analytics/automations/task-execution-logs/#failed-task-type-of-issues","title":"Failed Task \u2013 Type of Issues","text":"<p>Different types of issues that occur during a Failed Task are listed as follows:</p> <ul> <li>Task aborted by user</li> <li>Alternate task initiated</li> <li>Chat Interface refreshed</li> <li>Human-agent transfer</li> <li>Authorization attempt failure \u2013 Max attempts reached</li> <li>Incorrect entity failure \u2013 Max attempts reached</li> <li>Script failure</li> <li>Service failure</li> <li>Inactivity or External Events (from ver8.0) \u2013 when the conversation session and as a result, the in-progress task is closed due to inactivity or external events.</li> </ul> <p>Description of Failed Task Fields</p> <p>The following table lists the fields on the Failed Task tab with descriptions:</p> FIELDS DESCRIPTION Utterances     The utterances are successfully mapped to an intent, but still, the task failed due to some issue. The details in the tab are grouped by utterances based on similarity by default. To turn off grouping by utterance, click the Utterances header and turn off the Group by Utterances option.     Task Name     The task that is identified for the user utterance. To turn on grouping by task name, click the Task Name header and enable the Group by Task option.     Failure Point     Nodes or points in the task execution journey where the failure occurred, resulting in the task cancellation or user drop. Click an entry to view the complete conversation for that session with markers to identify the intent detection utterance and the failure/drop-out point. Depending on the task type, clicking Failure Point shows more details.     Type of Issue     Shows the reason for failure in case of Task Failure records.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User ID or Channel User ID. <p> Channel-specific IDs are shown only for the users who have interacted with the VA during the selected period.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/task-execution-logs/#performance","title":"Performance","text":"<p>Developers can monitor all the scripts and API services across the VA\u2019s tasks from a single window. The performance tab displays information related to the backend performance of the VA in two sections, namely API Calls and Script Execution. The platform stores the following meta-information:</p>"},{"location":"analytics/automations/task-execution-logs/#api-calls","title":"API Calls","text":"<p>The API Calls section provides information on the API calls execution performance based on the following metrics:</p> <ul> <li>Node name, type, and task name</li> <li>Success %</li> <li>The total number of calls with 200 responses and the total number of calls with a non-200 response. You can view the actual response code from the details page that opens when you click the service row.</li> <li>Average Response times</li> </ul> <p>Description of the API Calls Fields</p> <p>The following table lists the fields in the API Calls section with their descriptions:</p> FIELDS DESCRIPTION Node Name     The name of the service or script or Webhook within the task that was executed in response to the user utterance. To turn on grouping by components to which these scripts or services belong, click the Node Name header and turn on the Group by NodeName option.     Type     Shows whether it is a script or service or Webhook. <p> Webhook details are included from ver 7.0.     Task Name     The task that is identified for the user utterance. To turn on grouping by task name, click the Task Name header and enable the Group by Task option.     Success%     The percentage of the service or script runs that got executed successfully.     2XX Responses     The percentage of the service or script runs that returned a 2xx response.     Non 2XX Responses     The percentage of the service or script runs that returned a non-2xx response.     Avg Response Time     The average response time of the script or service in the total number of runs. <p> This can be sorted from High to Low or Low to High under the Performance tab.     Status Code     Filter service executions based on the status codes. From the More Filters drop-down menu &gt; Status Code, you can choose one or more status codes: <ul> <li>Success status code: 200   <li>Non-success status code: 304, 400, 401, 403, 404, 408, 409, 500, 502, 503, and 504  <p>"},{"location":"analytics/automations/task-execution-logs/#script-execution","title":"Script Execution","text":"<p>The Script Execution section provides information on the VA\u2019s script execution performance based on the following metrics:</p> <ul> <li>Node name and task name</li> <li>Success %</li> <li>Average Response times</li> <li>Appropriate alerts if a script or a service is failing consecutively</li> </ul> <p>Description of the Script Execution Fields</p> <p>The following table lists the fields in the Script Execution section with their descriptions:</p> FIELDS DESCRIPTION Node Name     The name of the service or script or Webhook within the task that was executed in response to the user utterance. To turn on grouping by components to which these scripts or services belong, click the Node Name header and turn on the Group by NodeName option.     Task Name     The task that is identified for the user utterance. To turn on grouping by task name, click the Task Name header and enable the Group by Task option.     Success%     The percentage of the service or script runs that got executed successfully.     Avg Response Time     The average response time of the script or service in the total number of runs. <p> This can be sorted from High to Low or Low to High under the Performance tab."},{"location":"analytics/automations/task-execution-logs/#debug-log","title":"Debug Log","text":"<p>Any custom debug statements that you entered in the Script node using the script <code>koreDebugger.log(\"&amp;lt;debug statement&gt;\")</code>are displayed on this tab. Debug statements should be in a string format. See the following table to know more:</p> <p>The logs include the user conversation from across all channels. You can use them for bot analysis, especially in case of failures during user interaction.</p> <p>The details include the following:</p> <ul> <li>The actual statement that you have defined at the time of Bot definition.</li> <li>Date and time of logging</li> <li>Channel</li> <li>User ID (along with channel-specific ID)</li> <li>Language of interaction</li> <li>Task name, if available</li> </ul> <p>You can also view the details of the chat history associated with the session. </p> <p>To view more details, follow the steps:</p> <ol> <li>Click a logged record.</li> <li>On the corresponding window, you can find the Details and Chat History tabs.</li> <li>Under the Details tab, you can find the task name, channel, language, and flow.</li> <li>Click the Chat History tab. You can find the chat transcript where the log is recorded.<ol> <li>If the debug log is generated from a VA message, you are navigated to that specific message in the chat transcript.</li> <li>If the debug log is not part of the VA message, you are navigated to the latest message added before the debug statement.</li> </ol> </li> </ol> <p>For universal VAs, the debug statements from the universal and linked assistants are included in the logs. The debug logs also include the error messages related to BotKit, for example, when the platform could not reach the BotKit or when the BotKit did not acknowledge the message sent by the platform. The message includes details like the <code>&lt;endpoint&gt;, &lt;error code&gt;,</code> and <code>&lt;response time&gt;.</code></p> <p>Description of Debug Log Fields</p> <p>The following table lists the fields on the Debug Log tab with descriptions:</p> FIELDS DESCRIPTION Log     Description of the debug log. For example, getIndex is not defined.     Task Name     The task that is identified for the user utterance. To turn on grouping by task name, click the Task Name header and enable the Group by Task option.     Debug Point      The point or node in the conversation where the error is identified. For example, buildDataForCarousel     Channel     A specific channel where the conversation occurred.     Language     The language in which the conversation occurred. <p> If it is a multi-lingual VA, you can select specific languages to filter the conversations that occurred in those languages. The page shows the conversations that occurred in all enabled languages by default.     UserID     The UserID of the end user related to the conversation. You can view the metrics based on either Kore User ID or Channel User ID. <p> Channel-specific IDs are shown only for the users who have interacted with the VA during the selected period.     Date &amp; Time     The date and time of the chat. You can sort the data by either Newest to Oldest or Oldest to Newest."},{"location":"analytics/automations/task-execution-logs/#pinned","title":"Pinned","text":"<p>Any records from the Failed Tasks, API Calls, and Script Execution sections that are pinned are displayed here. The fields available in the Pinned section under Task Execution Logs are listed here as well. However, they pertain to Task Execution Logs. Learn more.</p>"},{"location":"analytics/automations/task-execution-logs/#storage-limitations","title":"Storage Limitations","text":"<p>The platform imposes restrictions on the number of log statements retained per VA. The limit is a combination of volume and period:</p> <ul> <li>Only the latest 700 statements per VA are stored.</li> <li>Statements older than 7 days are removed.</li> </ul>"},{"location":"analytics/automations/task-execution-logs/#task-execution-logs-analysis","title":"Task Execution Logs Analysis","text":"<p>The following sections describe more about the options available on the Task Execution Logs page and the analysis of the records captured here.</p>"},{"location":"analytics/automations/task-execution-logs/#features","title":"Features","text":"<p>The following list details the features available for Task Execution Logs including Failed Tasks, API Calls, Script Execution, and Debug Log.</p> <ul> <li>You can filter the information based on various criteria such as User Utterances, Intent, user ID (Kore user ID or channel-specific unique ID), date period, channel of use, language, and so on. You can also filter records based on multiple custom tags. See Filter Criteria to know more.</li> <li>Complete meta-information is stored for later analysis, including the original user utterance, the channel of communication, entities extracted (if any), custom tags applied, and detailed Task Execution Logs.</li> <li>Any important record you want to mark, track later, or both can be pinned which appears on the Pinned tab.</li> <li>The sorting feature is available for Date and Time (Oldest to Newest, Newest to Oldest). You can export the insights data as a CSV file.</li> </ul>"},{"location":"analytics/automations/task-execution-logs/#fields-matrix","title":"Fields Matrix","text":"<p>The following matrix shows the availability of fields on each tab of the Task Execution Log dashboard:</p> FIELD FAILED TASKS API CALLS SCRIPT EXECUTION PINNED DEBUG LOG Utterances     \u2714     X     X     \u2714     X     Intent     X     X     X     \u2714     X     Traits     X     X     X     X     X     UserID     \u2714     X     X     \u2714     \u2714     Language     \u2714     X     X     \u2714     \u2714     Date &amp; Time     \u2714     X     X     \u2714     \u2714     Prompt Type     X     X     X     X     X     Task Name     \u2714     \u2714     \u2714     X     \u2714     Node Name     X     \u2714     \u2714     X     X     Failure Point     \u2714     X     X     X     X     Type of Issue     \u2714     X     X     \u2714     X     Type     X     \u2714     \u2714     X     X     Total Runs     X     \u2714     \u2714     X     X     Success%     X     \u2714     \u2714     X     X     2XX Responses     X     \u2714     \u2714     X     X     Non 2XX Responses     X     \u2714     \u2714     X     X     Avg Response Time     X     \u2714     \u2714     X     X     Log     X     X     X     X     \u2714     Debug Point     X     X     X     X     \u2714     Channel     X     X     X     X     \u2714"},{"location":"analytics/automations/users-dashboard/","title":"Users Dashboard","text":"<p>Once you have implemented a virtual assistant, you can gain actionable insights on the type of users it handles, including unique, new, and returning users, and the user trends for a given period for different conversation types, conversation statuses, channels, languages, and custom conversational tags on the Users Dashboard.</p> <p>This dashboard displays the trends of total users interacting with the virtual assistant, with a breakup of new and returning users, which helps understand user trends and the user retention status of your business.</p> <p>For example, an e-Commerce company requiring insights on user trend-based data for their mobile app can use the Users Dashboard to determine the following:</p> <ul> <li>The new users, existing users, and returning users of their app.</li> <li>The active users over a specific period.</li> <li>The new and returning users on a specific day, week, or month.</li> <li>The total inactive users registered on the app.</li> <li>The percentage of users who return and use the app \u201cN\u201d days after they start using it.</li> </ul> <p>To view the Users dashboard, follow the steps: </p> <ol> <li> <p>Click the three dots on the left navigation pane and then click Analytics. The Analytics panel is displayed with the list of reports.</p> <p></p> </li> <li> <p>Click Users Dashboard under the Automation section of the Analytics panel. The Users Dashboard is displayed on the right side of the page.</p> </li> <li>Select appropriate filters on the dashboard and click Apply.</li> </ol> <p>Note</p> <p>The Users dashboard is available only post-9.3 release, i.e. post-July 24, 2022.</p>"},{"location":"analytics/automations/users-dashboard/#user-trends-considerations","title":"User Trends Considerations","text":"<ul> <li>If User-A has interacted with the bot on 25-Jan-2022 for the first time and the dashboard is viewed between 23-Jan-2022 to 26-Jan-2022 then this user is considered a new user.</li> <li>If User-B has interacted with the bot on 25-Jan-2022 for the first time and again interacted with the bot on 26-Jan-2022, and if the dashboard is viewed between 23-Jan-2022 to 26-Jan-2022, then this user is considered as:<ul> <li>A new user on 25-Jan-2022</li> <li>A returning user on 26-Jan-2022</li> </ul> </li> <li>If User-C has interacted with the bot on 21-Jan-2022 for the first time and again interacted with the bot on 26-Jan-2022, and the dashboard is viewed between 23-Jan-2022 to 26-Jan-2022, then, this user is considered as a returning user.</li> </ul> <p>The Users Dashboard provides insights on the following user trend metrics:</p> <ul> <li>Total Unique Users: The total number of unique users who interacted with the virtual assistant.</li> <li>New Users: The total number of users who have interacted with the virtual assistant for the first time in the selected period.</li> <li>Returning Users: The total number of users who have already interacted with the virtual assistant earlier and have initiated another session in the selected period.</li> <li>Avg. Total Unique Users Per Day: The total number of unique users who interacted with the virtual assistant in the selected period divided by the number of days in the selected period.</li> <li>Avg. New Users Per Day: The total number of new users who interacted with the virtual assistant in the selected period divided by the number of days in the selected period.</li> </ul> <p>The key components of the Users Dashboard are:</p> <ul> <li>Users Trend: The users\u2019 trend shows the distribution of New Users, Returning Users, and Total Unique Users who have interacted with the virtual assistant over a period. This helps determine User Engagement for the selected period. </li> </ul> <p>Graph- Users\u2019 Trend for the Selected Period</p> <p></p> <p>Users Trend Summary: This panel displays the real-time counts of the Total Unique Users, New Users, Avg. Total Unique Users Per Day, and Avg. New Users Per Day.</p> <p>The increment/decrement of the above user metrics\u2019 counts is displayed as percentage values.</p> <ul> <li>Returning Users: Displays the graph for the day-wise returning users (in percentage) for the selected dates and other filters. Here, Day 0 is the first time a user interacts with the virtual assistant. The returning users % is calculated for the consecutive days for the selected period. For example, in the following image, the number of users is 100% on Day 0 (first interaction) and 0% on Day 1 since none of the users who have already interacted with the virtual assistant have initiated a conversation on the same channel/browser. </li> </ul> <p>Graph- Returning Users Trend for the Selected Period</p> <p></p> <ul> <li>Cohort Analysis: This data visualization chart plots the weekly new users and the percentage of returning users based on the formula (Returning Users/New Users)*100 on consecutive days to determine the retention rate. The Users Dashboard displays the Day N retention of daily, weekly, or monthly cohorts, within a customizable range of dates. For example, if you\u2019re looking at the retention of daily cohorts acquired from July 13 to July 20, 2022, based on the filters selected, and the actual users returning on Day 2, the following Cohort Analysis Chart is displayed:</li> </ul> <p></p>"},{"location":"analytics/automations/users-dashboard/#filter-criteria","title":"Filter Criteria","text":"<p>The Users Dashboard data can be viewed based on specific filter criteria that can be selected. Learn more.</p>"},{"location":"apis/add-enable-new-language/","title":"Add and Enable a New Language API","text":"<p>To initiate the addition and enablement of a new language for a virtual assistant.</p> Method POST     Endpoint <code>https://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Language Configuration  <li>Admin Console: Language Settings &gt; Language Management </li>"},{"location":"apis/add-enable-new-language/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION host     The environment URL. For example, <code>https://bots.kore.ai</code>."},{"location":"apis/add-enable-new-language/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language \\\n-H 'Content-Type: application/json' \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-d '[\n{\n\"enableLanguage\" : \"\",\n\"langDefinitionMode\": {\n\"baseLanguage\": \"language_code\",\n\"Type\": \"advancedConfig/fileUpload\",\n\"fileId\":\"\",\n\"preferredData\":{\n\"Training\": true/false,\n\"Faqs\": true/false,\n\"ontology\": true/false,\n\"smalltalk\": true/false,\n\"traits\": true/false\n}\n},\n\"multiLingualConfigurations\":{\n\"nluLanguage\": \"language_code\",\n\"inputTranslation\": true/false,\n\"responseTranslation\": true/false\n}\n}]'\n</code></pre>"},{"location":"apis/add-enable-new-language/#body-parameters","title":"Body Parameters","text":"PARAMETER SUB-PARAMETER DESCRIPTION MANDATE enableLanguage     The language to be enabled based on the language code.     Required     langDefinitionMode     Required     langDefinitionMode.baseLanguage     Base language of the Virtual Assistant.     Optional     langDefinitionMode.type     Type of language enablement Basic, advancedConfig, or fileUpload.     Optional     langDefinitionMode.fileId     The file ID for handling the file upload if the fileUpload language enablement is selected.     Optional     langDefinitionMode.preferredData     If the advancedConfig language enablement is selected, the True/False configuration setting for \u201ctraining\u201d, \u201cfaqs\u201d, \u201contology\u201d, \u201cSmalltalk\u201d and \u201ctraits\u201d keys should be included.     Optional     multiLingualConfigurations     Required     multiLingualConfigurations.nluLanguage     Refers to the language code of the bot language.     Required     multiLingualConfigurations.inputTranslation     Refers to True/False setting for the input language translation to English.     Required     multiLingualConfigurations.responseTranslation     Refers to the True/False setting for the response language translation to English.     Required"},{"location":"apis/add-enable-new-language/#sample-response","title":"Sample Response","text":"<p>For success case:</p> <p>```json [{ \"message\": \"Enabled language successfully\", \"configurationDetails\": { \"dialogs\":3, \"alerts\":0, \"actions\":0, \"knowledgetTasks\":0, \"smallTalk\":1, \"panels\":0, \"widgets\":0 } }]</p>"},{"location":"apis/add-enable-new-language/#test","title":"Test","text":"<p>How to generate the JWT Token.</p>"},{"location":"apis/add-questions-to-knowledgegraph/","title":"Add Questions from Extract \u2013 KG","text":"<p>To add specific questions to the Knowledge graph.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{botId}}/faqs/bulk?language=en</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/add-questions-to-knowledgegraph/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/add-questions-to-knowledgegraph/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required"},{"location":"apis/add-questions-to-knowledgegraph/#sample-request","title":"Sample Request","text":"<pre><code>curl --location 'https://bots.kore.ai/api/public/bot/botID/faqs/bulk?language=en' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'content-type: application/json' \\\n--data-raw '{\n\"faqs\": [\n{\n\"questionPayload\": {\n\"question\": \"question\", //question - GET EXTRACTION QUESTION(https://developer.kore.ai/docs/bots/api-guide/get-extraction-questions-kg/)\n\"tagsPayload\": []\n},\n\"answerPayload\": [{\n\"text\": \"\", //answer - GET EXTRACTION QUESTION(https://developer.kore.ai/docs/bots/api-guide/get-extraction-questions-kg/)\n\"type\": \"basic\",\n\"channel\": \"default\"\n}],\n\"knowledgeTaskId\": \"645e0aab1ee65252a433d457\", // \"_id\" - GET KNOWLEDGE TASKS(https: //developer.kore.ai/docs/bots/api-guide/get-knowledgetasks-kg/)\n\"subQuestions\": [],\n\"responseType\": \"message\",\n\"subAnswers\": [],\n\"streamId\": \"botId\",\n\"parent\": \"f1324935-341d-5b0e-8551-c705a2eb58b9\", //\"parent\" - GET KNOWLEDGE TASKS(https: //developer.kore.ai/docs/bots/api-guide/get-knowledgetasks-kg/)\n\"leafterm\": \"Botname\", \"qsId\": \"qna-f6014fd0-f8e8-5cb1-b952-cf9e57091ffc\" // \"_id\" -  GET EXTRACTION QUESTION(https://developer.kore.ai/docs/bots/api-guide/get-extraction-questions-kg/)\n}'\n</code></pre>"},{"location":"apis/add-questions-to-knowledgegraph/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE faqs An array with the following parameter values: <ul> <li>questionPayload  <ul> <li>question </li> </ul> <li>answerPayload  <ul> <li>text  <li>type  <li>channel </li> <li>knowledgeTaskId  <li>subQuestions  <li>responseType  <li>subAnswers  <li>streamId  <li>parent  <li>leafterm  <li>qsId </li> Required"},{"location":"apis/add-questions-to-knowledgegraph/#sample-response","title":"Sample Response","text":"<p>```json {        \"status\": \"success\" }</p>"},{"location":"apis/batch-test-execution-status/","title":"Batch Test Execution Status API","text":"<p>To get the status of the Batch Test Execution request against a unique \u2018Request Id\u2019 and provide the download link for the results file after the test execution is complete. Please refer to the Batch Test Execution API to learn more.</p> Method GET     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}/{testRunId}/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Execution  <li>Admin Console: Not Applicable </li>"},{"location":"apis/batch-test-execution-status/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL, for example,<code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName Name of the test suite as created in the Bot\u2019s platform that is being executed     Required     testRunId The unique \u2018Request ID\u2019 returned by the Batch Test Execution API to track the progress     Required"},{"location":"apis/batch-test-execution-status/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request GET \\\n'https://{host}/api/public/stream/{streamId}/testsuite/{testSuiteName}/{testRunId}/status' \\\n--header 'auth: {jwt-token}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/batch-test-execution-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/batch-test-execution-status/#sample-response","title":"Sample Response","text":"<p>When the test execution is completed \\</p> <pre><code>{\n\"_id\": \"tr-74d94321-35f8-5066-bdc8-a0863e7axxxx\",\n\"streamId\": \"st-83a4989c-7f57-59e7-85b8-d6547a91xxxx\",\n\"testSuiteId\": \"ts-cf304560-7e39-5876-ad22-8c114743xxxx\",\n\"status\": \"completed\",\n\"utterance_count\": 1,\n\"result\": {\n\"_id\": \"tr-74d94321-35f8-5066-bdc8-a0863e7axxxx\",\n\"isPartialFailure\": false,\n\"status\": \"completed\",\n\"isAvailable\": true,\n\"testSuiteId\": \"ts-cf304560-7e39-5876-ad22-8c114743893d\",\n\"triggeredBy\": \"u-b6cd832d-d3c0-501f-9d94-9e4c76667e9e\",\n\"streamId\": \"st-83a4989c-7f57-59e7-85b8-d6547a91xxxx\",\n\"botLanguage\": \"en\",\n\"runType\": \"inDevelopment\",\n\"utterance_count\": 1,\n\"startTime\": \"2023-06-26T12:07:38.405Z\",\n\"__v\": 0,\n\"endTime\": \"2023-06-26T12:09:39.518Z\",\n\"f1_score\": \"0.00\",\n\"fileId\": \"649980035ebd2d3b2d5c6df5\",\n\"precision\": \"0.00\",\n\"recall\": \"0.00\",\n\"results\": {\n\"TP\": 0,\n\"TN\": 0,\n\"FP\": 0,\n\"FN\": 0,\n\"success\": 0,\n\"failure\": 1,\n\"traitSuccess\": 0,\n\"traitFailure\": 0,\n\"totalEntitiesCount\": 0,\n\"matchedEntitiesCount\": 0,\n\"totalTraitsCount\": 0,\n\"matchedTraitsCount\": 0,\n\"failedUtteranceCount\": 1,\n\"failedEntitiesCount\": 0\n},\n\"fileUrl\": \"http://hostname/api/getMediaStream/media/f-c6071507-a603-59ed-8d2b-5ec344be3696.csv?e=1689769306&amp;n=2501205681&amp;s=IkxtTVdUdTd4c3J6WTFaSWp0MUZHWHlaNjR5bEdmaEJPczNrdU42RHB6TWc9Ig$$&amp;clientfilename=test1-26-06-23.csv&amp;batchtesting=true\"\n}\n}\n</code></pre> <p>When the test execution is in progress \\</p> <pre><code>{\n\"_id\": \"tr-beaadxxb-xxxx-xxxe-axfb-xxxxcxbexdxa\",\n\"streamId\": \"st-xxxxxxxx-cxxd-xcaf-xxax-dxxxxxxffxdxb\",\n\"testSuiteId\": \"ts-deaxxxxc-xxxx-xxxe-axbx-bxxcxxxxfxxx\",\n\"status\": \"running\",\n\"utterance_count\": 10,\n\"result\": {\n\"_id\": \"tr-beaadxxb-xxxx-xxxe-axfb-xxxxcxbexdxa\",\n\"isPartialFailure\": false,\n\"status\": \"running\",\n\"testSuiteId\": \"ts-deaxxxxc-xxxx-xxxe-axbx-bxxcxxxxfxxx\",\n\"triggeredBy\": \"u-xxbdxecd-xxdx-xxex-xxxd-xxdxxxxdxxea\",\n\"streamId\": \"st-xxxxxxxx-cxxd-xcaf-xxax-dxxxxxxffxdxb\",\n\"botLanguage\": \"en\",\n\"runType\": \"inDevelopment\",\n\"utterance_count\": 10,\n\"startTime\": \"2021-01-07T17:05:34.509Z\",\n\"__v\": 0\n},\n\"totalUtterances\": 10,\n\"utterance_ran\": 5,\n\"percentage\": 50\n}\n</code></pre>"},{"location":"apis/batch-test-execution/","title":"Batch Test Execution API","text":"<p>To execute Batch Test Suites and get results. This API only initiates the test process. Please look at the Batch Test Execution Status API for the results of the batch test.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/testsuite/{testSuiteName}/run</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Execution  <li>Admin Console: Not Applicable </li>"},{"location":"apis/batch-test-execution/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName Name of the test suite on the Bot Builder.     Required"},{"location":"apis/batch-test-execution/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request POST \\\n'https://{host}/api/public/stream/{streamId}/testsuite/{testSuiteName}/run' \\\n--header 'auth: {jwt-token}' \\\n--header 'bot-language: {language-code}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"version\":\"inDevelopment\" }'\n</code></pre>"},{"location":"apis/batch-test-execution/#body-parameters","title":"Body Parameters","text":"PARAMETER     DESCRIPTION     MANDATE version The version of the bot against which the execution is required <ul> <li>published for Published version  <li>inDevelopment for the Configured version </li> Required"},{"location":"apis/batch-test-execution/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"accepted\",     \"requestId\": \"tr-acfxxbff-xxxf-xaxx-bbbx-exxxabaxxcxx\" }</p>"},{"location":"apis/bot-export-status/","title":"Bot Export \u2013 Status API","text":"<p>Gets the status of Bot Export request and also provides the download link of the bot export copy after the export is completed. Refer here for initiating Bot Export API.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/export/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Bot Export  <li>Admin Console: Bot Definition &gt; Bot Export </li>"},{"location":"apis/bot-export-status/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example,<code>https://bots.kore.ai</code> Required     BotID Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/bot-export-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\ https://{{host}}/api/public/bot/{{BotID}}/export/status \\\n-H 'auth:  {{YOUR_JWT_ACCESS_TOKEN}}' \\\n</code></pre>"},{"location":"apis/bot-export-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/bot-export-status/#sample-response","title":"Sample Response","text":"<p>```json {     \"_id\": \"ber-xxxxx-xxx-xxx-xxx-xxxxx\",     \"botId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",     \"createdBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",     \"exportType\": \"published\",     \"requestType\": \"Botexport\",     \"status\": \"success\",     \"createdOn\": \"2018-12-05T07:18:40.028Z\",     \"__v\": 0,     \"downloadURL\": \"{{url}}\",     \"fileId\": \"{{file-id}\",     \"store\": {         \"urlParams\": \"url-params\"     },     \"fileSize\": \"947\" }</p>"},{"location":"apis/bot-export/","title":"Bot Export API","text":"<p>To export the bot definition and all the associated components.</p> <p>Note</p> <p>This API only initiates the export process. Please use the Export Status API to view the export progress status and obtain a link to download the file once the export completes.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/export</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Bot Export  <li>Admin Console: Bot Definition &gt; Bot Export </li>"},{"location":"apis/bot-export/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID     Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/bot-export/#sample-request","title":"Sample Request","text":"<pre><code>curl --location 'https://{host}/api/public/bot/{BotID}/export' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'content-type: application/json' \\\n--data '{\n\"exportType\": \"published\",\n\"exportOptions\": {\n\"settings\": [\n\"botSettings\",\n\"botVariables\",\n\"ivrSettings\"\n],\n\"tasks\": [\n\"botTask\",\n\"knowledgeGraph\",\n\"smallTalk\"\n],\n\"nlpData\": [\n\"nlpSettings\",\n\"utterances\",\n\"patterns\",\n\"standardResponses\"\n]\n},\n\"subTasks\": {\n\"alerts\": [],\n\"actions\": [],\n\"dialogs\": []\n},\n\"allTasks\": true,\n\"customDashboards\": true,\n\"IncludeDependentTasks\": true\n}'\n</code></pre>"},{"location":"apis/bot-export/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE exportType     Bot type \u2013 <ul> <li>\u2018latest\u2018 or  <li>\u2018published\u2018 </li> Required     exportOptions     All the bot components are exported by default. If required, you may specify the components to be included for the export. <p> Usage: <p> <code>\"exportOptions\": {</code> <p> <code>      \"tasks\": [</code> <p> <code>             \"botTask\",</code> <p> <code>             \"knowledgeGraph\"</code> <p> <code>           ],</code> <p> <code>      \"nlpData\": [</code> <p> <code>             \"nlpSettings\",</code> <p> <code>             \"utterances\",</code> <p> <code>             \"standardResponses\"</code> <p> <code>           ],</code> <p> <code>      \"settings\": [</code> <p> <code>             \"botSettings\",</code> <p> <code>             \"botVariables\",</code> <p> <code>             \"ivrSettings\"</code> <p> <code>           ]</code> <p> <code>   },</code> Optional     subTasks     For partial export mention the tasks to be exported. <p> Usage: <p> <code>   \"subTasks\": {</code> <p> <code>        \"dialogs\": [\"&lt;dialog Name 1&gt;\",\"&lt;dialog Name 2&gt;\"],</code> <p> <code>        \"alerts\": [\"&lt;alert name 1&gt;\",\"&lt;alert name 2&gt;\"],</code> <p> <code>        \"actions\": [\"&lt;action name 1&gt;\",\"&lt;action name 2&gt;\"]</code> <p> <code>    }</code> Optional     IncludeDependentTasks     To include dependent tasks for export. <p> Usage: <p> <code>\"IncludeDependentTasks\": true</code> Optional     customDashboards     To include custom dashboards for export. <p> Usage: <p> <code>\"customDashboards\": true</code> Optional     allTasks     To include all tasks for export, will be ignored if subTasks is present. <p> Usage: <p> <code>\"allTasks\": true</code> Optional     <p>To learn more about the optional parameters for partial import and dependent tasks, please click here.</p>"},{"location":"apis/bot-export/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"status\": \"pending\",\n\"streamId\": \"st-57af1576-bbdc-5ded-a608-5cfbc00c6415\",\n\"createdBy\": \"u-f8708c55-de2c-5690-8821-ac90624779b5\",\n\"exportType\": \"published\",\n\"requestType\": \"Botexport\",\n\"_id\": \"ber-dd746d3c-1631-53af-81ca-03a1d01f0487\",\n\"createdOn\": \"2023-03-31T13:06:16.309Z\",\n\"__v\": 0\n}\n</code></pre>"},{"location":"apis/bot-import-status/","title":"Bot Import Status API","text":"<p>To get the status of the bot import request initiated using the Import Bot API for a new bot or an existing bot.</p> <p>Note</p> <p>This API requires the JWT generated by an application created on the Bot Admin Console.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/import/status/{{BotImportBIR}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Definition &gt; Bot Import </li>"},{"location":"apis/bot-import-status/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, https://bots.kore.ai     Required     BotImportBIR bir-xxxxxxx-xxx-xxxx-xxxxx-xxxxxxxxxx. The BIR ID is found in the response of the Import Bot as a New Bot API endpoint.     Required"},{"location":"apis/bot-import-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{{host}}/api/public/bot/import/status/bir-xxxxxxx-xxx-xxxx-xxxxx-xxxxxxxxxx \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n</code></pre>"},{"location":"apis/bot-import-status/#body-parameters","title":"Body Parameters","text":"<p>No Body Parameters passed.</p>"},{"location":"apis/bot-import-status/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"_id\": \"bir-5fxxxxxx-a0xx-52xx-axxf-f3xxxxxxxxxx\",\n\"status\": \"success\",\n\"streamRefId\": \"d1xxxxxx-bxx7-5cxx-axx7-a8xxxxxxxxxx\",\n\"statusLogs\": [\n{\n\"taskType\": \"importRequest\",\n\"taskName\": \"SampleBot\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Bot Definition\",\n\"taskName\": \"SampleBot\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"IdpConfigurations\",\n\"taskName\": \"IdpConfigurations\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"CustomTemplates\",\n\"taskName\": \"CustomTemplates\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"BotFunctions\",\n\"taskName\": \"Bot Functions\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Widget\",\n\"taskName\": \"UnderwritingExplanation\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Dialog\",\n\"taskName\": \"Test Firebase Service\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Form\",\n\"taskName\": \"BloodPressure\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Widget\",\n\"taskName\": \"WidgetPhysique\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Dialog\",\n\"taskName\": \"ShowDiseaseList\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Event\",\n\"taskName\": \"TASK_FAILURE_EVENT\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Event\",\n\"taskName\": \"WELCOME_MESSAGE_EVENT\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Event\",\n\"taskName\": \"INTENT_UNIDENTIFIED\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Event\",\n\"taskName\": \"CONVERSATION_END\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"KnowledgeTasks\",\n\"taskName\": \"KnowledgeTasks\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Utterences\",\n\"taskName\": \"Utterences\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"Patterns\",\n\"taskName\": \"Patterns\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"BotVariables\",\n\"taskName\": \"BotVariables\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"SmallTalk\",\n\"taskName\": \"SmallTalk\",\n\"status\": \"success\"\n},\n{\n\"taskType\": \"importBot\",\n\"taskName\": \"SampleBot\",\n\"status\": \"success\"\n}\n],\n\"createdBy\": \"u-adxxxxxx-e9xx-5xxd-axxc-21xxxxxxxxxx\",\n\"requestType\": \"Botimport\",\n\"createdOn\": \"2022-07-29T07:24:17.496Z\",\n\"__v\": 0,\n\"streamId\": \"st-8axxxxxx-0xxb-5axx-9xx2-97xxxxxxxxxx\"\n}\n</code></pre>"},{"location":"apis/bot-publish-status/","title":"Bot Publish Status \u2013 API","text":"<p>To fetch the publish status of the current bot or the last completed status request for the bot. To initiate the Publish API, refer here.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/publish/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Publish &gt; Publish Status </li>"},{"location":"apis/bot-publish-status/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder. <p> Note: This is required only for Bot Builder API scope of Proactive Messages.     Required"},{"location":"apis/bot-publish-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{{host}}/api/1.1/public/bot/{{BotID}}/publish/status/ \\\n-H 'Auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n</code></pre>"},{"location":"apis/bot-publish-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/bot-publish-status/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"_id\": \"ds-4a1b3e3d-7f55-5d80-acc6-7066e5cc6a6f\",\n\"action\": \"RUN\",\n\"jobType\": \"PUBLISH_BOT\",\n\"streamId\": \"st-a86a6717-340b-5830-a8b6-13b4aeb6b865\",\n\"__v\": 0,\n\"countOfDockStatuses\": 1,\n\"createdBy\": \"u-adb7cfc7-e9d1-55dd-acfc-214b82dc51d8\",\n\"percentageComplete\": 100,\n\"requestedTime\": \"2022-07-29T08:04:48.731Z\",\n\"status\": \"successful\",\n\"lastModifiedOn\": \"2022-07-29T08:04:50.083Z\",\n\"initiatedOn\": \"2022-07-29T08:04:48.828Z\",\n\"statusSummary\": [\n{\n\"resourceId\": \"SETTINGS\",\n\"resourceType\": \"SETTINGS\",\n\"name\": \"Settings\",\n\"modules\": [\n\"general\",\n\"bot_variables\",\n\"pii\",\n\"ivr\",\n\"hold_resume\",\n\"custom_script\",\n\"advanced\"\n],\n\"result\": {\n\"resourceId\": \"SETTINGS\",\n\"resourceType\": \"SETTINGS\",\n\"name\": \"Settings\",\n\"modules\": [\n\"general\",\n\"bot_variables\",\n\"pii\",\n\"ivr\",\n\"hold_resume\",\n\"custom_script\",\n\"advanced\"\n]\n},\n\"status\": \"SUCCESS\"\n},\n{\n\"resourceId\": \"CHANNELS\",\n\"resourceType\": \"CHANNELS\",\n\"name\": \"Channels\",\n\"modules\": [\n\"rtm\"\n],\n\"result\": {\n\"resourceId\": \"CHANNELS\",\n\"resourceType\": \"CHANNELS\",\n\"name\": \"Channels\",\n\"modules\": [\n\"rtm\"\n]\n},\n\"status\": \"SUCCESS\"\n},\n{\n\"resourceId\": \"EXTENSIONS\",\n\"resourceType\": \"EXTENSIONS\",\n\"name\": \"Extensions\",\n\"modules\": [\n\"botkit\",\n\"agent_transfer\",\n\"websdk\",\n\"events\"\n],\n\"result\": {\n\"resourceId\": \"EXTENSIONS\",\n\"resourceType\": \"EXTENSIONS\",\n\"name\": \"Extensions\",\n\"modules\": [\n\"botkit\",\n\"agent_transfer\",\n\"websdk\",\n\"events\"\n]\n},\n\"status\": \"SUCCESS\"\n},\n{\n\"resourceId\": \"BOTLANGUAGES\",\n\"resourceType\": \"BOTLANGUAGES\",\n\"name\": \"BotLanguages\",\n\"modules\": {\n\"enabledLanguages\": [\n\"en\"\n]\n},\n\"result\": {\n\"resourceId\": \"BOTLANGUAGES\",\n\"resourceType\": \"BOTLANGUAGES\",\n\"name\": \"BotLanguages\",\n\"modules\": {\n\"enabledLanguages\": [\n\"en\"\n]\n}\n},\n\"status\": \"SUCCESS\"\n},\n{\n\"resourceId\": \"NL\",\n\"resourceType\": \"NL\",\n\"name\": \"Natural Language\",\n\"modules\": [\n\"nl_model\",\n\"settings\"\n],\n\"result\": {\n\"resourceId\": \"NL\",\n\"resourceType\": \"NL\",\n\"name\": \"Natural Language\",\n\"modules\": [\n\"nl_model\",\n\"settings\"\n]\n},\n\"status\": \"SUCCESS\"\n},\n{\n\"resourceId\": \"dg-ebdce1a1-d912-52b7-b66e-5ad1eda304a6\",\n\"resourceVersion\": \"1.0\",\n\"resourceType\": \"dialog\",\n\"approvalRequestedLanguages\": [\n\"en\"\n],\n\"name\": \"Find Keyword\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"visibility\": {\n\"namespace\": \"enterprise\",\n\"namespaceIds\": [\n\"o-12f4144a-f85a-5cc3-8ba3-baec6a9602c4\"\n]\n},\n\"contextLifeTime\": {\n\"options\": \"close\"\n},\n\"version\": \"1.0\",\n\"isPublishedVersion\": false,\n\"idp\": \"none\",\n\"state\": \"published\",\n\"languages\": [],\n\"compatibility\": [],\n\"adminTaskStatus\": \"active\",\n\"editable\": true,\n\"isHidden\": false,\n\"approvedLanguages\": [\n\"en\"\n],\n\"approvalRequestedLanguages\": [\n\"en\"\n],\n\"isFollowUp\": false,\n\"interruptOptions\": {\n\"priority\": \"bot\"\n},\n\"amendConfig\": {\n\"priority\": \"bot\"\n},\n\"vNameSpace\": [\n\"5f9d4653e2bd8b32e8a58042\"\n],\n\"_id\": \"dg-4f8e44e9-111b-59c8-bc15-32652cd571dd\",\n\"__v\": 0,\n\"createdBy\": \"u-adb7cfc7-e9d1-55dd-acfc-214b82dc51d8\",\n\"createdOn\": \"2022-07-29T08:04:49.188Z\",\n\"followupTaskOptions\": {\n\"isFollowUp\": false,\n\"message\": \"\"\n},\n\"lMod\": \"2022-07-29T08:04:49.000Z\",\n\"lModBy\": \"u-adb7cfc7-e9d1-55dd-acfc-214b82dc51d8\",\n\"lname\": \"find keyword\",\n\"nodes\": [\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"intent0\",\n\"type\": \"intent\",\n\"transitions\": [\n{\n\"default\": \"service15\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy0\"\n}\n}\n],\n\"metadata\": {\n\"left\": 8,\n\"top\": 121\n},\n\"componentId\": \"dc-23b2efe4-3d4e-5d00-9b21-53e03583179b\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"script2\",\n\"type\": \"script\",\n\"transitions\": [\n{\n\"if\": {\n\"context\": \"questionsFound\",\n\"op\": \"eq\",\n\"value\": \"0\"\n},\n\"then\": \"message4\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy5\"\n}\n},\n{\n\"default\": \"message14\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy3\"\n}\n}\n],\n\"metadata\": {\n\"left\": 673,\n\"top\": 422\n},\n\"componentId\": \"dc-c7835a66-b6bc-5d55-860c-5679cfa055fb\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"type\": {\n\"option\": \"developer\"\n},\n\"interruptsEnabled\": false,\n\"priority\": \"node\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"message4\",\n\"type\": \"message\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy4\"\n}\n}\n],\n\"metadata\": {\n\"left\": 745,\n\"top\": 564\n},\n\"componentId\": \"dc-2ada27bb-dc14-5cad-8ef6-0b92413b5972\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"script8\",\n\"type\": \"script\",\n\"transitions\": [\n{\n\"if\": {\n\"context\": \"questionSearchType\",\n\"op\": \"eq\",\n\"value\": \"keyword\"\n},\n\"then\": \"script2\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy17\"\n}\n},\n{\n\"default\": \"script10\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy12\"\n}\n}\n],\n\"metadata\": {\n\"left\": 342,\n\"top\": 185\n},\n\"componentId\": \"dc-aeee21d4-7eb3-59f8-985d-c30bb46d84d0\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"script10\",\n\"type\": \"script\",\n\"transitions\": [\n{\n\"default\": \"message13\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy16\"\n}\n}\n],\n\"metadata\": {\n\"left\": 656,\n\"top\": 197\n},\n\"componentId\": \"dc-e3d1a42a-a6b3-5ef4-ad34-eaf3852e488e\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\",\n\"type\": {\n\"option\": \"doNotAllowHoldResume\"\n}\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"message11\",\n\"type\": \"message\",\n\"transitions\": [\n{\n\"default\": \"message12\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy18\"\n}\n}\n],\n\"metadata\": {\n\"left\": 973,\n\"top\": 182\n},\n\"componentId\": \"dc-b88bfdb3-274e-5d82-ace7-0b8a19b1f6de\"\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"message12\",\n\"type\": \"message\",\n\"componentId\": \"dc-9008c640-fe4a-554e-b941-a3835620bedb\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy25\"\n}\n}\n],\n\"metadata\": {\n\"left\": 1371,\n\"top\": 155\n}\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"message13\",\n\"type\": \"message\",\n\"componentId\": \"dc-0817f38b-26b7-525c-b6a8-8f358e5398ba\",\n\"transitions\": [\n{\n\"default\": \"message11\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy27\"\n}\n}\n],\n\"metadata\": {\n\"left\": 806,\n\"top\": 30\n}\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"message14\",\n\"type\": \"message\",\n\"componentId\": \"dc-443d8c26-06f7-58fa-ab60-5edcbeaa7918\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy27\"\n}\n}\n],\n\"metadata\": {\n\"left\": 1084,\n\"top\": 425\n}\n},\n{\n\"nodeOptions\": {\n\"customTags\": {\n\"session\": [],\n\"message\": [],\n\"user\": []\n},\n\"transitionType\": \"auto\",\n\"isRetriesExceeded\": false,\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"userInputCorrection\": true,\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"contextTags\": [],\n\"message\": [],\n\"errorMessage\": []\n},\n\"vNameSpace\": [],\n\"preConditions\": [],\n\"useTaskLevelNs\": true,\n\"nodeId\": \"service15\",\n\"type\": \"service\",\n\"componentId\": \"dc-80557e8a-e14a-510d-9609-b6bb6b845d96\",\n\"transitions\": [\n{\n\"default\": \"script8\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy28\"\n}\n}\n],\n\"metadata\": {\n\"left\": 8,\n\"top\": 272\n}\n}\n],\n\"publishedOn\": \"2022-07-29T08:04:48.678Z\",\n\"refId\": \"e2135e58-6f62-5071-9c35-0d1cb395031b\",\n\"streamId\": \"st-a86a6717-340b-5830-a8b6-13b4aeb6b865\",\n\"versionComment\": \"check Publish\",\n\"groups\": [],\n\"resourceid\": null,\n\"traceId\": null,\n\"spanId\": null,\n\"name\": \"Find Keyword\",\n\"shortDesc\": \"\"\n},\n\"deployedTo\": \"enterprise\"\n},\n{\n\"resourceId\": \"5ecd12358bfeeb59851d90a0\",\n\"resourceVersion\": \"1.0\",\n\"resourceType\": \"knowledge\",\n\"name\": \"10241aaa\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"state\": \"published\",\n\"editable\": true,\n\"nodesToPublish\": [],\n\"deletedNodesToPublish\": [],\n\"publishRoot\": true,\n\"version\": \"1.0\",\n\"adminTaskStatus\": \"active\",\n\"ontologyReport\": false,\n\"vNameSpace\": [\n\"5f9d4653e2bd8b32e8a58042\"\n],\n\"_id\": \"62e394a00238910393277e11\",\n\"name\": \"10241aaa\",\n\"description\": \"This is used to make ontology\",\n\"refId\": \"0d599ce6-dc05-527f-a04c-d57059c9eefd\",\n\"isGraph\": true,\n\"taxonomy\": [\n{\n\"parent\": [],\n\"synonyms\": [],\n\"preConditions\": [],\n\"contextTags\": [],\n\"enableContext\": false,\n\"traitRule\": [],\n\"isDummy\": true,\n\"editLocked\": false,\n\"termStatus\": true,\n\"label\": \"Internal Audit Chatbot\",\n\"nodeId\": \"rootNodeId000000001\",\n\"level\": \"LR\"\n}\n],\n\"language\": \"en\",\n\"visibility\": {\n\"namespace\": \"enterprise\",\n\"namespaceIds\": [\n\"o-12f4144a-f85a-5cc3-8ba3-baec6a9602c4\"\n]\n},\n\"streamId\": \"st-a86a6717-340b-5830-a8b6-13b4aeb6b865\",\n\"botName\": \"10241aaa\",\n\"createdBy\": \"u-adb7cfc7-e9d1-55dd-acfc-214b82dc51d8\",\n\"lastModifiedBy\": \"u-adb7cfc7-e9d1-55dd-acfc-214b82dc51d8\",\n\"createdOn\": \"2022-07-29T08:04:48.913Z\",\n\"modifiedOn\": \"2022-07-29T08:04:48.927Z\",\n\"__v\": 0,\n\"publishedOn\": \"2022-07-29T08:04:48.927Z\",\n\"versionComment\": null\n},\n\"deployedTo\": \"enterprise\"\n},\n{\n\"resourceId\": \"AUTOVERSIONING\",\n\"resourceType\": \"AUTOVERSIONING\",\n\"name\": \"Creating New Version\",\n\"status\": \"SUCCESS\"\n}\n]\n}\n</code></pre> <p>Note</p> <p>The possible values for the \u2018status\u2019 field are \u2013 SUCCESSFUL, FAILED or INPROGRESS.</p>"},{"location":"apis/bot-variables-import/","title":"Bot Variables Import API","text":"<p>To import global and content variables into the bot.</p> Method POST     Endpoint <code>https://{{host}}/api/{{version}}/public/builder/bot/{{BotID}}/variables/import</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Import Variables  <li>Admin Console: Not Applicable </li>"},{"location":"apis/bot-variables-import/#query-parameters","title":"Query Parameters","text":"PARAMETER REQUIRED DESCRIPTION host     Required     The environment URL. For example, <code>https://bots.kore.ai</code> BotID     Required     The identifier can be accessed under General Settings on the Bot Builder."},{"location":"apis/bot-variables-import/#body-parameters","title":"Body Parameters","text":"PARAMETER REQUIRED DESCRIPTION key     Required     Name of the variable.     value     Required     Value for the variable.     hint     Required     Description of the variable.     variableType     Required     The type of variable can be as follows: <ul> <li>env for global variable or  <li>locale for content variable </li> scope     Required     The scope of the variable corresponds to the Setup Option at the time of variable declaration and can be one of the following: <ul> <li>prePopulated  <li>askOnInstall  <li>hidden </li> localeData     Required     For the variables of type locale, additional language data needs to be passed in the following format for each language: <p> <code>{</code> <p> <code>      \"en\": {</code> <p> <code>        \"value\": \"english language prompt\",</code> <p> <code>        \"hint\": \"\"</code> <p> <code>      }</code> <p> <code> }</code>"},{"location":"apis/bot-variables-import/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/1.1/public/builder/bot/{{BotId}}/variables/import \\\n-H 'Content-Type: application/json' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-d '[\n{\n\"key\": \"Global\",\n\"value\": \"Globalkey-prePopulated\",\n\"hint\": \"\",\n\"variableType\": \"env\",\n\"scope\": \"prePopulated\"\n},\n{\n\"key\": \"Lang\",\n\"variableType\": \"locale\",\n\"scope\": \"prePopulated\",\n\"localeData\": {\n\"en\": {\n\"value\": \"english language prompt\",\n\"hint\": \"\"\n}\n}\n}\n]'\n</code></pre>"},{"location":"apis/bot-variables-import/#sample-request-when-collections-are-enabled","title":"Sample Request when Collections are enabled","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/1.1/public/builder/bot/{{BotId}}/variables/import \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"botVariables\": [\n{\n\"key\": \"CVar\",\n\"value\": \"Cvar1\",\n\"hint\": \"\",\n\"audioTag\": \"\",\n\"variableType\": \"locale\",\n\"scope\": \"prePopulated\",\n\"localeData\": {\n\"en\": {\n\"value\": \"Cvar1\",\n\"hint\": \"\",\n\"audioTag\": \"\"\n}\n},\n\"group\": \"\",\n\"propagateValue\": false,\n\"vNameSpace\": [\n{\n\"name\": \"default\",\n\"refId\": \"10xxxxxx-4xxb-50xx-bxx9-3axxxxxxxxxx\"\n}\n]\n},\n{\n\"key\": \"GKey1\",\n\"value\": \"GValue1-C\",\n\"hint\": \"GNotes1\",\n\"audioTag\": \"\",\n\"variableType\": \"env\",\n\"scope\": \"prePopulated\",\n\"group\": \"\",\n\"propagateValue\": false,\n\"vNameSpace\": [\n{\n\"name\": \"default\",\n\"refId\": \"10xxxxxx-4xxb-50xx-bxx9-3axxxxxxxxxx\"\n}\n]\n},\n{\n\"key\": \"GKey2\",\n\"value\": \"Gkey2Stag\",\n\"hint\": \"GNotes2\",\n\"audioTag\": \"\",\n\"variableType\": \"env\",\n\"scope\": \"prePopulated\",\n\"group\": \"\",\n\"propagateValue\": false,\n\"vNameSpace\": [\n{\n\"name\": \"default\",\n\"refId\": \"10xxxxxx-4xxb-50xx-bxx9-3axxxxxxxxxx\"\n}\n]\n},\n{\n\"key\": \"GKey55\",\n\"value\": \"GKey55-Staging\",\n\"hint\": \"GNotes2\",\n\"audioTag\": \"\",\n\"variableType\": \"env\",\n\"scope\": \"prePopulated\",\n\"propagateValue\": false,\n\"vNameSpace\": [\n{\n\"name\": \"default\",\n\"refId\": \"10xxxxxx-4xxb-50xx-bxx9-3axxxxxxxxxx\"\n}\n]\n},\n{\n\"key\": \"contentvar\",\n\"value\": \"contvarvalue\",\n\"hint\": \"This is content variable\",\n\"audioTag\": \"\",\n\"variableType\": \"locale\",\n\"scope\": \"prePopulated\",\n\"localeData\": {\n\"en\": {\n\"value\": \"contvarvalue\",\n\"hint\": \"This is content variable\",\n\"audioTag\": \"\"\n}\n},\n\"group\": \"\",\n\"propagateValue\": false,\n\"vNameSpace\": [\n{\n\"name\": \"default\",\n\"refId\": \"10xxxxxx-4xxb-50xx-bxx9-3axxxxxxxxxx\"\n}\n]\n}\n],\n\"botCollections\": [\n{\n\"name\": \"Default\",\n\"description\": \"Default Collection\",\n\"refId\": \"8xxxxxxa-exxc-5xx1-bxxd-56xxxxxxxxxx\"\n},\n{\n\"name\": \"Staging\",\n\"description\": \"Staging Environment\",\n\"refId\": \"0cxxxxx1-3xx8-52xx-bxxc-02xxxxxxxxxx\"\n}\n],\n\"botCollectionVariables\": [\n{\n\"key\": \"GKey1\",\n\"value\": \"GValue1-C\",\n\"audioTag\": \"\",\n\"refId\": \"0cxxxxx1-3xx8-52xx-bxxc-02xxxxxxxxxx\"\n},\n{\n\"key\": \"GKey1\",\n\"value\": \"GValue1-C\",\n\"audioTag\": \"\",\n\"refId\": \"8xxxxxxa-exxc-5xx1-bxxd-56xxxxxxxxxx\"\n},\n{\n\"key\": \"GKey2\",\n\"value\": \"Gkey2Stag\",\n\"audioTag\": \"\",\n\"refId\": \"0cxxxxx1-3xx8-52xx-bxxc-02xxxxxxxxxx\"\n},\n{\n\"key\": \"GKey2\",\n\"value\": \"Gkey2Diff\",\n\"audioTag\": \"\",\n\"refId\": \"8xxxxxxa-exxc-5xx1-bxxd-56xxxxxxxxxx\"\n},\n{\n\"key\": \"GKey55\",\n\"value\": \"GKey55-Staging\",\n\"audioTag\": \"\",\n\"refId\": \"0cxxxxx1-3xx8-52xx-bxxc-02xxxxxxxxxx\"\n},\n{\n\"key\": \"GKey55\",\n\"value\": \"GKey55-Default\",\n\"audioTag\": \"testaudioTag\",\n\"refId\": \"8xxxxxxa-exxc-5xx1-bxxd-56xxxxxxxxxx\"\n}\n]\n}'\n</code></pre>"},{"location":"apis/bot-variables-import/#body-parameters_1","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/bot-variables-import/#sample-response","title":"Sample Response","text":"<p>```json {   \"message\": \"2 Variables imported/updated successfully.\" }</p>"},{"location":"apis/channel-enablement/","title":"Channel Enablement API","text":"<p>To initiate enable a channel for a virtual assistant.</p> Method POST     Endpoint <code>https://{{host}}/api/public/channels</code> <p> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Channel Management </li>"},{"location":"apis/channel-enablement/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, https://bots.kore.ai     Required"},{"location":"apis/channel-enablement/#sample-request","title":"Sample Request","text":"<p>Sample Request for Web/Mobile channel:</p> <pre><code>curl --location --request POST 'https://{{host}}/api/public/channels' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"streamId\": \"st-xxxxfxxx-edxx-xxxx-xxbb-fxxxexxfxfcx\",\n\"channelDetails\": {\n\"displayName\": \"Web / Mobile Client\",\n\"type\": \"rtm\",\n\"app\": {\n\"clientId\": \"cs-xexxdxxx-xbbc-xxex-xxef-xxxxxxxxfxfx\",\n\"appName\": \"app_name\"\n},\n\"enable\": true\n},\n\"type\": \"rtm\"\n}'\n</code></pre> <p>Sample Request for MS Teams channel:</p> <pre><code>curl --location --request POST 'https://{{host}}/api/public/channels' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"streamId\": \"st-4xx7ccxx-8xx5-5cxx-9xxf-5bxxxxxxxxxx\",\n\"channelDetails\": {\n\"botName\": \"Banking Bot\",\n\"enable\": true,\n\"type\": \"msteams\",\n\"appId\": \"cbabcxce-acxb-xxxx-axxf-xabxxxfexxxb\",\n\"appPassword\": \"\"\n},\n\"type\": \"msteams\"\n}'\n</code></pre> <p>Sample Request for WebHook channel:</p> <pre><code>curl --location --request POST 'https://{{host}}/api/public/channels' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"streamId\": \"st-cxfaxxax-xexx-xxex-axxe-xxdxexxxfxex\",\n\"channelDetails\": {\n\"app\": {\n\"clientId\": \"cs-dxxcxxxc-Xxxx-xxxx-axxx-xxxxcxbexeax\",\n\"appName\": \"Banking Bot\"\n},\n\"createInstance\": true,\n\"type\": \"ivr\",\n\"displayName\": \"webhook1\",\n\"enable\": true,\n\"enablePolling\": false,\n\"isAsync\": false,\n},\n\"type\": \"ivr\"\n}'\n</code></pre> <p>Sample Request for Slack channel:</p> <pre><code>curl --location --request POST 'https://{{host}}/api/public/channels' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"streamId\": \"st-1bxxxxxx-9xx0-5xxa-abxx-51xxxxxxxxxa\",\n\"channelDetails\": {\n\"displayName\": \"slack\",\n\"botName\":\"Banking Bot\",\n\"enable\": true,\n\"type\": \"slack\",\n\"accessToken\": \"xoxb-xxxxxxxx-xxxxxx-xxxxxxxxxxxxxxxxxxxxxZ\",\n\"clientId\": \"xxxxxx.xxxxxx\",\n\"clientSecret\": \"xxexxdxxxdxcxxbxacxxxdfxxxxxex\",\n\"verificationToken\": \"abcd\"\n},\n\"type\": \"slack\"\n}'\n</code></pre>"},{"location":"apis/channel-enablement/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE streamId     Stream or Bot ID \u2013 You can access it from the General Settings page of the bot.     Required     appName     The app associated with this Bot, you can obtain it from the Manage Apps page of the bot     Required     clientId     The client id for the app associated with this Bot, you can obtain it from the Manage Apps page of the bot     Required     type     Channel that you want to enable for this Bot. Following are the channel type details: <ul> <li>rtm \u2013 for Web/Mobile SDK  <li>slack \u2013 for Slack  <li>ivr \u2013 for WebHook  <li>msteams \u2013 for MS Teams </li> Required"},{"location":"apis/channel-enablement/#sample-response","title":"Sample Response","text":"<p>The response from the platform depends on the channel being enabled.</p> <p>Sample response for web/mobile SDK:</p> <pre><code>{\n\"displayName\": \"Web / Mobile Client\",\n\"type\": \"rtm\",\n\"enable\": true,\n\"notification\": {\n\"acl\": []\n},\n\"name\": \"Web/Mobile Client\",\n\"embedWebClientDetails\": {\n\"scriptTag\": \"\",\n\"cssTag\": \"     \",\n\"domains\": [],\n\"apiKey\": \"d3be215756d94803b0a548e594c0e1625b88e873cec9e48eb918add573d738f26stda\",\n\"testAPIKey\": \"7e203670dc4d41d5bcc0d58b4e02a164e0b6a0c9438b45c1971c6e703582c88estda\",\n\"chatURL\": \"https://preprod-bots.korebots.com/webclient/d3be215756d94803b0548e594c0e162a5b88e873cec9e48eb918add573d738f26stda\",\n\"isURLEnabled\": true\n}\n}\n</code></pre> <p>Sample response for webhook channel:</p> <pre><code>{\n\"streamId\": \"st-6f90cbdc-46c7-52f8-a388-8db39b0f4436\",\n\"channelDetails\": {\n\"app\": {\n\"clientId\": \"cs-ccaa5400-83b9-5a38-897d-0114d2aab521\",\n\"appName\": \"try\"\n},\n\"createInstance\": true,\n\"type\": \"ivr\",\n\"displayName\": \"webhook11\",\n\"enable\": true,\n\"isAsync\": false\n},\n\"type\": \"ivr\"\n}\n</code></pre> <p>Sample response for Slack channel:</p> <pre><code>{\n\"streamUserAccountId\": \"su-5d7c2d17-5fa2-58db-b2fc-83cfe259d14a\",\n\"type\": \"slack\",\n\"enable\": true,\n\"verificationToken\": \"a7365\",\n\"notification\": {\n\"acl\": []\n},\n\"name\": \"Slack\"\n}\n</code></pre> <p>Sample response for MS Teams channel:</p> <p>```json {     \"streamId\": \"st-6f90cbdc-46c7-52f8-a388-8db39b0f4436\",     \"channelDetails\": {        \"botName\": \"today\",        \"enable\": true,        \"type\": \"msteams\",        \"appId\": \"e51678c4-3c92-4053-8d0e-f9173ec1136e\",        \"appPassword\": \"DLu8Q~oB1BSUOpKcwUp.BWotfOqAagfPCOm4oaXz\"     },     \"type\": \"msteams\" }</p>"},{"location":"apis/conversation-history/","title":"Conversation History API","text":"<p>To fetch the conversational messages between the bot and user in reverse chronological order. This API supports pagination. You can provide offset/skip and limit to get a certain number of messages at a time.</p> Method GET and POST     Endpoint This API has two versions for GET and POST methods. The v1 of the API includes messages associated with all tasks, and it has a maximum limit of 100 messages per request. The v2 of the API does not include the messages related to Alert and Action tasks, and it has a maximum limit of 10,000 messages per request. <p> GET Method<p>Version 1: <p><code>https://{{host}}/api/public/bot/{{botId}}/getMessages?userId={{userId}}&amp;limit=10&amp;dateFrom=2023-05-20&amp;dateTo=2023-05-25</code><p>Version 2: <p><code>https://{{host}}/api/public/bot/{{botId}}/getMessagesV2?userId={{userId}}&amp;limit=10&amp;dateFrom=2023-05-20&amp;dateTo=2023-05-25</code> <p> Note: The GET method shows the RTM interactions by default. To get the channel-specific interaction, use the channelType parameter in the GET method. For the channelType parameter values, see Request Body Parameters section. <p> POST Method<p>Version 1:<p> <code>https://{{host}}/api/public/bot/{{botId}}/getMessages </code>and <code>https://{{host}}/api/public/getMessages</code> for Bot Admin Console. <p>Version 2:<p> <code>https://{{host}}/api/public/bot/{{botId}}/getMessagesV2</code> accept-encoding <code>gzip, deflate, br</code> <p> This allows the server to compress the response using any of these algorithms (gzip, deflate, or Brotli) before sending it back, which makes the response size smaller and faster to transmit over the network, thereby improving the overall performance of the API communication. <p> Note: We recommend using this header element in v2 of the GET and the POST methods.     Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token. API Scope <ul> <li>Bot Builder: Chat History \\ OR  <li>Admin Console: Bot Analytics &gt; Chat History </li>"},{"location":"apis/conversation-history/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION host     required     Environment URL, for example, https://bots.kore.ai     botId     optional     Bot ID or Stream ID. You can access it from the General Settings page of the bot."},{"location":"apis/conversation-history/#sample-request","title":"Sample Request","text":"<p>Sample Request for GET Method</p> <p>Version 1:</p> <pre><code>curl -X GET \\\n'https://{{host}}/api/public/bot/{{botId}}/getMessages?userId={{userId}}&amp;limit=10&amp;dateFrom=2023-05-20&amp;dateTo=2023-05-25' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}'\n</code></pre> <p>Version 2:</p> <pre><code>curl -X GET --compressed --location \\\n'https://{{host}}/api/public/bot/{{botId}}/getMessagesV2?userId={{userId}}&amp;limit=10&amp;dateFrom=2023-05-20&amp;dateTo=2023-05-25' \\\n--header 'accept-encoding: gzip, deflate, br' \\\n--header 'Content-Type: application/json' \\ --header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}'\n</code></pre> <p>Sample Request for POST method</p> <p>Version 1:</p> <pre><code>curl -X POST \\\n'https://{{host}}/api/public/bot/{{botId}}/getMessages' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data '{\n\"userId\"           : \"u-xxxx-xxxxx-xxxx\",\n\"skip\"             : 0,                           \"limit\"            : 100,                       \"dateFrom\"         : \"2019-04-01\",\n\"dateTo\"           : \"2019-04-01\",\n\"channelType\"      : \"rcs\",\n\"sessionId\"        : [\"5eadxxxxxxxxxxxxx\",\"5ebxxxxxxxxxxxxxxx\"],\n\"includeTraceId\"  : \"true\"\n\"tags\"         : {\n\"and\"    : [\n{\n\"name\"  : \"tagname\",\n\"values\"  : [\"tagvalue1\",\"tagvalue2\"],\n\"type\"    : \"tagtype\"\n},\n{\n\"name\"  : \"tagname\",\n\"values\"  : [\"tagvalue1\",\"tagvalue2\"],\n\"type\"    : \"tagtype\"  }\n]  }\n}'\n</code></pre> <p>Version 2:</p> <pre><code> curl -X POST --compressed --location \\\n'https://{{host}}/api/public/bot/{{botId}}/getMessagesV2' \\\n--header 'accept-encoding: gzip, deflate, br' \\\n--header 'Content-Type: application/json' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--data '{\n\"userId\"          : \"u-xxxx-xxxxx-xxxx\",\n\"skip\"            : 0,                           \"limit\"           : 100,                       \"dateFrom\"        : \"2019-04-01\",\n\"dateTo\"          : \"2019-04-01\",\n\"channelType\"     : \"rcs\",\n\"sessionId\"       : [\"5eadxxxxxxxxxxxxx\",\"5ebxxxxxxxxxxxxxxx\"],\n\"includeTraceId\"  : \"true\"\n\"tags\"        : {\n\"and\"   : [\n{\n\"name\"    : \"tagname\",\n\"values\"  : [\"tagvalue1\",\"tagvalue2\"],\n\"type\"    : \"tagtype\"\n},\n{\n\"name\"    : \"tagname\",\n\"values\"  : [\"tagvalue1\",\"tagvalue2\"],\n\"type\"    : \"tagtype\"     }\n] }\n}'\n</code></pre>"},{"location":"apis/conversation-history/#request-query-parameters","title":"Request Query Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION userId     required for GET <p> optional for POST     The ID of the user whose conversation history to access. Can be user email id or enterprise assigned unique id.     skip/offset     optional     The number of messages to be skipped.     limit     optional     The number of messages to be shown on each page.     channelType     optional     Channel type name for which you want to see the interactions; the default is \u201crtm\u201d . <p> Accepted channel types are: <ul> <li>\u201cskypeforbusiness\u201d,  <li>\u201cmsteams\u201d,  <li>\u201ctwitter\u201d,  <li>\u201cspark\u201d,  <li>\u201crtm\u201d,  <li>\u201cfacebook\u201d,  <li>\u201cslack\u201d,  <li>\u201cskype\u201d,  <li>\u201ckore\u201d,  <li>\u201cemail\u201d,  <li>\u201csms\u201d,  <li>\u201cwfacebook\u201d,  <li>\u201cringcentral\u201d,  <li>\u201cjabber\u201d,  <li>\u201cyammer\u201d,  <li>\u201calexa\u201d,  <li>\u201ctwiliovoice\u201d,  <li>\u201ctelegram\u201d,  <li>\u201civr\u201d,  <li>\u201civrVoice\u201d,  <li>\u201csmartassist\u201d,  <li>\u201cline\u201d,  <li>\u201cliveperson\u201d,  <li>\u201cgoogleactions\u201d,  <li>\u201changoutchat\u201d,  <li>\u201cmattermost\u201d,  <li>\u201crcs\u201d.  <p> Note: In case of multi-webhook channel configuration, \u201civr\u201d gives the conversations for the first WebHook instance. For other WebHoo instance, specify the<code>ivrInstID</code>, you can get it from the WebHook URL which is of the form: <code>{{host_url}}/chatbot/hooks/{{BotId}}/hookInstance/{{ivrInstID}}</code>)  dateFrom     optional     Accepts the yyyy-mm-dd date format. <p> (or) yyyy-mm-ddThh:mm:ss.msZ <p> eg:2019-04-01 (or) 2019-04-01T13:25:58.515ZIf not provided, calculated as 7 days behind dateTo. <p> Note: This field cannot be used in combination with msgId.     dateTo     optional     Accepts the yyyy-mm-dd date format. <p> (or) yyyy-mm-ddThh:mm:ss.msZ <p> eg:2019-04-01 (or) 2019-04-01 T13:26:05.598ZIf not provided, calculated as 7 days from dateFrom. If dateFrom is also not provided then set to Today. <p> Note: This field cannot be used in combination with msgId     getAgentsInfo     optional     Accepts true or false. If the value is true then the agent info is fetched and put in the author object of the agent. If the value is false or the field is not provided then agent info is not passed in the response.     <p>Note: The duration between dateTo and dateFrom should be less than 7 days, else an error will be thrown.</p>"},{"location":"apis/conversation-history/#request-body-parameters","title":"Request Body Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION skip/offset     optional     The number of messages to be skipped.     limit     optional     The number of messages to be shown on each page.     forward     optional     Takes boolean values true/false. Specifies the direction of the messages to be retrieved. <ul> <li>If the value is true, then the conversation history is retrieved in the order old to the most recent one.  <li>If the value is false, then the conversation history is retrieved in the reverse order i.e, the most recent to the oldest message </li> msgId     optional     A specific Message-Id if known. This would fetch the records starting from that message either forward or backward depending upon the direction (see below) requested. <p> In case only the specific conversation is required, set the limit to 1 <p> Note: This field cannot be used in combination with dateFrom and dateTo.     includeTraceId     optional     Whether to include the trace ID in the response. A trace ID is a unique ID assigned to each incoming message.  Possible values of the parameter: <ul> <li>true: Include the trace ID in the response.  <li>false: Default value, indicates not to include the trace ID in the response. </li> direction     optional when msgId is given     <ul> <li>&lt;0 reverse  <li>=0 bidirectional  <li>&gt;0 forward Default direction is forward. </li> sessionId     optional     A specific Session-Id if known. Refer here to obtain the session id tags     optional     Meta tags to filter the conversations.     getAgentsInfo     optional     Accepts true or false. If the value is true then the agent info is fetched and put in the author object of the agent. If the value is false or the field is not provided then agent info is not passed in the response."},{"location":"apis/conversation-history/#sample-response","title":"Sample Response","text":"<p>Sample response for the GET method</p> <pre><code>{\n\"total\": 1,\n\"moreAvailable\": false,\n\"icon\": \"https://dlnwzkim0wron.cloudfront.net/f-87c47629-7exxxxxxxx-a807ccfb1cf0.png\",\n\"messages\": [\n{\n\"_id\": \"ms-fee996b9-0485-55a3-bf42-417c1272aff4\",\n\"channels\": [\n{\n\"type\": \"rtm\",\n\"channelUId\": \"alan.walker@abc.com\"\n}\n],\n\"type\": \"incoming\",\n\"status\": \"received\",\n\"createdBy\": \"u-1bc0993f-e0d6-5589-973d-6fe2663de2d4\",\n\"lmodifiedBy\": \"u-1bc0993f-e0d6-5589-973d-6fe2663de2d4\",\n\"createdOn\": \"2023-07-18T09:46:46.925Z\",\n\"lmodifiedOn\": \"2023-07-18T09:46:46.925Z\",\n\"botId\": \"st-369f9021-2a85-5b32-9005-63139d57c2e5\",\n\"orgId\": \"o-f4b49c0a-f027-57bf-aef0-b68ad9b51ee2\",\n\"accountId\": \"6461f97ed43763474b34e56e\",\n\"isBB\": 1,\n\"ms\": 1,\n\"chnl\": \"rtm\",\n\"isD\": 1,\n\"components\": [\n{\n\"_id\": \"cp-ae11791d-118f-53f1-8905-9bc9f03fdece\",\n\"cT\": \"text\",\n\"data\": {\n\"text\": \"hi\"\n},\n\"thumbnails\": []\n}\n],\n\"timestampValue\": 1689673606939,\n\"__v\": 0,\n\"lang\": \"en\",\n\"sT\": 1,\n\"sessionId\": \"64b65f87277b464507f778c0\",\n\"cluster_id\": \"Others\",\n\"resourceid\": \"messagestore\",\n\"tags\": {\n\"messageTags\": [],\n\"userTags\": [\n{\n\"value\": \"Alan\",\n\"name\": \"Alan Walker\"\n}\n],\n\"sessionTags\": []\n},\n\"traceId\": \"5371b61d-b1bb-4432-80de-7430772b0cfb\"\n},\n{\n\"_id\": \"ms-5436a303-0d8c-58e8-8ad3-33bf5bcefcb7\",\n\"channels\": [\n{\n\"type\": \"rtm\",\n\"channelUId\": \"alan.walker@abc.com\"\n}\n],\n\"type\": \"outgoing\",\n\"status\": \"pending\",\n\"createdOn\": \"2023-07-18T09:46:47.497Z\",\n\"lmodifiedOn\": \"2023-07-18T09:46:47.497Z\",\n\"createdBy\": \"u-1bc0993f-e0d6-5589-973d-6fe2663de2d4\",\n\"components\": [\n{\n\"_id\": \"cp-c035b2f4-10f2-5294-b655-c2d6273e0154\",\n\"cT\": \"text\",\n\"data\": {\n\"text\": \"Hey :)\"\n},\n\"thumbnails\": []\n}\n],\n\"botId\": \"st-369f9021-2a85-5b32-9005-63139d57c2e5\",\n\"orgId\": \"o-f4b49c0a-f027-57bf-aef0-b68ad9b51ee2\",\n\"accountId\": \"6461f97ed43763474b34e56e\",\n\"isBB\": 1,\n\"ms\": 1,\n\"chnl\": \"rtm\",\n\"isD\": 1,\n\"lang\": \"en\",\n\"timestampValue\": 1689673607507,\n\"__v\": 0,\n\"sT\": 1,\n\"sessionId\": \"64b65f87277b464507f778c0\",\n\"resourceid\": \"messagestore\",\n\"tags\": {\n\"messageTags\": [],\n\"userTags\": [\n{\n\"value\": \"Alan\",\n\"name\": \"Alan Walker\"\n}\n],\n\"sessionTags\": []\n}\n},\n</code></pre> <p>Sample Response from POST method:</p> <pre><code>{\n\"total\": 1,\n\"moreAvailable\": false,\n\"messages\"  : [\n{\n\"_id\": \"ms-xxxxxxxxxxxxxxxxxxxx\",\n\"type\": \"incoming\",\n\"status\": \"sent to cs\",\n\"createdBy\":\"u-xxxxxxxxxxxxxxxxxxx\",\n\"lmodifiedBy\": u-xxxxxxxxxxxxxxxxxxx\",\n                  \"lmodifiedOn\": \"2019-04-10T10:21:45.103Z\",\n                  \"channels\": [\n                     {\n                      \"type\": \"rcs\"\n                        }\n                     ],\n                  \"botId\":\"st-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n                  \"orgId\": \"o-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n                  \"accountId\": \"5xxxxxxxxxxxxxxxxxxxxxxxx\",\n                  \"isBB\": 0,\n                  \"ms\": 1,\n                  \"channel\": \"rcs\",\n                  \"components\": [\n                    {\n                      \"_id\":\"cp-xxxxxxxxxxx\",\n                      \"cT\": \"text\",\n                      \"data\": {\n                          \"text\": \"23\"\n                           },\n                      \"thumbnails\": []\n                      }\n                    ],\n                    \"createdOn\": \"2019-04-10T10:21:45.106Z\",\n                    \"timestampValue\": 1554891705106,\n                    \"__v\": 0,\n                    \"sessionId\": \"5cadbefc6a81a71559f6bece\"\n               }\n             ]\n }\n</code></pre>"},{"location":"apis/conversation-history/#response-body-parameters","title":"Response Body Parameters","text":"PARAMETER DESCRIPTION total     The total number of records identified as per the API request parameters. The response will include a maximum of X records. If more than X records are identified, then the \u2018moreAvailable\u2019 field in the response will have the value as \u2018True\u2019. <p> It is recommended to programmatically iterate the request by dynamically updating the values of the \u2018skip\u2019 and \u2018limit\u2019 parameters in the request.     moreAvailable     Indicates if the API has returned all the records or if more are available, based on the pagination criteria. <p> True if more records are available. False if there are no more records to be retrieved.     icon     The URL of the bot logo.     messages     Contains complete information about the message.     messages._id     The unique identifier for the message record.     messages.traceId     A unique identifier associated with each incoming message. <p> Note: The Trace ID is retained in the logs for 30 days. Once the Trace ID is expired, you see a tooltip message as \u2018<code>Trace Id: Trace records for this message are not available</code>\u2018.     messages.type     The message type \u2013 incoming (user input) or outgoing (bot response).     messages.status     Processing status of the message: received, queued, in progress, delivered, or pending.     messages.lmodifiedOn     The last modified time for the record.     messages.createdBy     The user ID of the end user who was chatting with the bot.     messages.channels     The channels object provides additional information about the channel through which the conversation was initiated.     messages.channels.type     Name of the channel through which the conversation is initiated. The default is \u2018rtm\u2019.     messages.channels.channelUId     The end-user\u2019s identity provided by the channel.     messages.components     Additional information about the message record.     messages.components._id     The unique id of the component.     messages.components.cT     Type of the user input (component type): text, audio, video, image, attachment, contact, task, filelink, location, email, alert, action, timeline, meeting, error, upgrade, NLResponse, or contextUpdate.     messages.components.data     The data object.     messages.components.data.text     The message shown to the user or the bot, depending on the message type.     messages.components.thumbnails     The thumbnails object.     messages.components.thumbnails._id     The unique id of the thumbnails.     messages.components.thumbnails.width     The width of the thumbnails.     messages.components.thumbnails.height     The height of the thumbnails.     messages.components.thumbnails.size     The size of the thumbnails.     messages.components.thumbnails.url     The URL of the thumbnails.     messages.botId     Bot ID or Stream ID.     messages.orgId     The organization ID to which the bot belongs to.     messages.accountId     The account id to which the bot belongs to.     messages.isBB     Informs whether the conversation was initiated from the Bot Builder; 1 for Yes, 0 for No.     messages.isD     Informs whether the conversation was initiated by a developer; 1 for Yes, 0 for No.     messages.lang     The conversation\u2019s language.     messages.ms     Message source; enum[0,1,2,3]; 0-task alert, 1-text, 2-task(action), and 3-others.     messages.chnl     The end user\u2019s conversation channel.     messages.createdOn     The record creation date.     messages.timestampValue     The creation date converted into the timestamp format.     messages.__v     The field is used for internal purposes. No specific significance.     messages.resourceid     The field is used for internal purposes. No specific significance.     messages.tags     Meta tags to filter the conversations.     messages.tags.messageTags     Message tags object; custom tags added to the message in the conversation.     messages.tags.messageTags.value     Tag\u2019s value.     messages.tags.messageTags.name     Tag\u2019s name.     messages.tags.userTags     User tags object; custom tags added to the user\u2019s profile information.     messages.tags.userTags.value     Tag\u2019s value.     messages.tags.userTags.name     Tag\u2019s name.     messages.tags.sessionTags     Session tags object; custom tags added to the conversation session.     messages.tags.sessionTags.value     Tag\u2019s value.     messages.tags.sessionTags.name     Tag\u2019s name."},{"location":"apis/conversation-summary/","title":"Conversation Summary API","text":"<p>The API summarizes the conversation between a user and an agent. The agent can be a virtual agent or a human agent. The API accepts the conversation Id or the transcripts as input and provides an auto-generated conversation summary. Currently, the API supports transcripts only in English (en) and is available only in our global deployment (https://bots.kore.ai).</p> <p>The API uses a fine-tuned Flan-T5 model, an open-source LLM hosted by Kore.ai. The Flan-T5 foundational model has been fine-tuned for summarizing conversations using a large number of sample conversation transcripts from various fields and industries.</p> Method POST     Endpoint <code>https://{{host}}/api/public/streams/{{streamId}}/conversationSummary</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token. API Scope Bot Builder: Conversation Summary"},{"location":"apis/conversation-summary/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION host     required     Environment URL, for example, https://bots.kore.ai     streamId     required     Stream ID or Bot ID. You can access it from the General Settings page of the bot."},{"location":"apis/conversation-summary/#sample-request","title":"Sample Request","text":"<p>With Conversation Id as Input Mode</p> <pre><code>curl -X POST \\ 'https://{{host}}/api/public/streams/{{streamId}}/conversationSummary' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data '{\n\"lang\": \"en\",\n\"inputMode\": {\n\"conversationId\": \"64808537ba90cb4b384157cf\"\n}\n}'\n</code></pre> <p>With Transcript as Input Mode</p> <pre><code>curl -X POST \\ 'https://{{host}}/api/public/streams/{{streamId}}/conversationSummary' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data '{\n\"lang\": \"en\",\n\"inputMode\": {\n\"transcript\": \"Agent: Thank you for calling spectrum community solutions. My name is Jeff I'\\''ll be glad to assist you? Consumer: I just. My name is Tom link LINK. Agent: . Alright. How are you doing today sir. Alright. What can I do to help you? Consumer: Good how are you the yeah that? I get it right. Is it is Jeff. Agent: Yes sir. Consumer: Good. Okay. Okay. Okay um. So I'\\''m was having a little I was having a DVD issue. I'\\''ve got two boxes. The TV part is fine. I can get the channels in and everything is fine. Consumer: And the DVD. I'\\''m. As a DVR. I guess DVR. Consumer: We'\\''ve got a DVR capability on on the problem I'\\''ll call at the primary box and then the secondary box upstairs the primary box is working. Consumer: Hundred percent. I can record channels. I can call them back up again. I can go forward and backwards. Everything is fully functional on the primary box for DVD the secondary box upstairs. Agent: Um-hum. Consumer: Um it it just doesn'\\''t respond at all to the. You know I'\\''m using the wand with the green button right in the middle the list button and it it just doesn'\\''t respond at all to that. I'\\''ve got full functionality on the TV channels in the guide. But but the list does not work at all. So I can'\\''t protect a penny taped shows. Agent: Alright I definitely understand your concern. Dear Sir up. Glad look into this for you. Agent: Okay. So the first thing I'\\''m gonna do is run a communication test if there'\\''s. Consumer: Okay. Agent: If there'\\''s any issues with the communication that would definitely cause problems with the DVR. Consumer: Okay. Agent: Because I need good communication going in and good communication. Going out for it. Deport that list up player programs etc. so I'\\''m looking into that right now for you. Consumer: Very good. Consumer: Hello. Agent: Alright. In question for you sir. Have you had any problems with your Internet the past couple of days. Also. Consumer: Know the Internet seems fine. Agent: Okay. Alright. Because I ran a test in very quickly. Your DVR. Consumer: Okay. Agent: And your modem or Agenth failing. Agent: Let'\\''s just waiting for the test to complete fully. Agent: Alright. So they'\\''re Agenth failing on different frequencies. So. Agent: One more than likely has nothing to do with the other just a coincidence. But they Agenth are failing. Consumer: And and by Agenth you mean that the DVR boxes. Agent: Yes I did the DVR box that you have is failing Consumer: . Okay. Agent: In your modem just failing. Also. Consumer: Okay. Well? Yes. So we'\\''ve got we'\\''ve got a we'\\''ve got an appointment scheduled for tomorrow at 3 o'\\''clock? Should I just keep that in have a tech come in and take a look at it. Consumer: Very good. We'\\''ll leave it in place then. Thank you. Agent: Absolutely. Alright you'\\''re welcome ma'\\''am, it'\\''s gonna place some notes on the account. Agent: DVR failed signal level check in modem. Modem failed. Also. Agent: Alright great. So yes I would definitely say keep the appointment and technician gets here he can go through everything test everything and make sure everything is working properly for you. Consumer: Super. Thank you so much. Agent: Alright. You'\\''re more than welcome sir. We do apologize for the inconvenience but we look forward to getting a technician out there and resolve an issue for you sir.\"\n}\n}'\n</code></pre>"},{"location":"apis/conversation-summary/#request-body-parameters","title":"Request Body Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION language     required     The language used for understanding the transcript and generating the summary. Currently, only the English language (en) is supported.     inputMode     required     One of the following modes in which the input can be provided to the API: <ul> <li>ConversationId: A valid conversation session Id of the current bot.  <li>transcript: The conversation transcript in a specific format; see the sample code above. </li>"},{"location":"apis/conversation-summary/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"ConversationSummary\": \"Consumer was having a DVD issue. He has two boxes. The TV part is fine. The DVD is a DVR. The list doesn't work at all. Consumer needs good communication going in and good communication going out for it.\",\n\"time\": \"2023-06-09T07:45:47.940Z\"\n}\n</code></pre>"},{"location":"apis/conversation-summary/#response-body-parameters","title":"Response Body Parameters","text":"PARAMETER DESCRIPTION ConversationSummary     The auto-generated summary of the conversation.     time     Date &amp; time of the summary generation."},{"location":"apis/create-conversation-test-suite/","title":"Create (Import) a Test Suite API","text":"<p>To create a conversation test suite by importing the test cases from a given file. This API returns dsId, the ID to check the import status.</p> Method POST     Endpoint <code>https://{{host}}/api/public/stream/:streamId/conversation/testsuite/import</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Conversation Tests Management  <li>Admin Console: Conversation Tests Management </li>"},{"location":"apis/create-conversation-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL. For example,<code>https://bots.kore.ai</code> Required     StreamID The  Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/create-conversation-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request POST \\     'https://{{host}}/api/public/stream/:streamId/conversation/testsuite/import' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"fileName\": \"64dxxxxxxxxxxxxxxxxxxxxc\", field(fileId)\n\"name\": \"newtestcase\", \"tags\" : [],\n\"description\" : \"\"\n}'\n</code></pre>"},{"location":"apis/create-conversation-test-suite/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE fileName File containing the conversation test suite details.     Required     name TestSuite Name     Required     tags Conversation test cases tags list.     Optional     description Test suite description     Optional"},{"location":"apis/create-conversation-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"IN_PROGRESS\",     \"dsId\": \"ds-f8xxxxx5-5xxa-5xx4-axx4-48xxxxxxxxx9\"  }</p>"},{"location":"apis/delete-batch-test-suite-execution/","title":"Delete Batch Test Suite Execution API","text":"<p>To delete a specific execution of a Batch Test Suite.</p> Method DELETE     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}/{testRunId}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Management  <li>Admin Console: Batch Tests Management </li>"},{"location":"apis/delete-batch-test-suite-execution/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName Name of the test suite on the Bot Builder.     Required     testRunId The unique identifier of an execution result obtained by running the test execution API.     Required"},{"location":"apis/delete-batch-test-suite-execution/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request DELETE \\\n'https://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}/{testRunId}' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/delete-batch-test-suite-execution/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/delete-batch-test-suite-execution/#sample-response","title":"Sample Response","text":"<p>```json {     \"message\": \"Test Result Removed Successfully\" }</p>"},{"location":"apis/delete-batch-test-suite/","title":"Delete Batch Test Suite API","text":"<p>To delete a Batch Test Suite.</p> Method DELETE     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Management  <li>Admin Console: Batch Tests Management </li>"},{"location":"apis/delete-batch-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName Name of the test suite on the Bot Builder. <p> Note: Only Custom Batch Test Suites can be deleted.     Required"},{"location":"apis/delete-batch-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request DELETE \\\n'https://{host}/api/public/stream/{streamId}/testsuite/{testSuiteName}' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/delete-batch-test-suite/#body-parameters","title":"Body Parameters","text":"<p>No Body parameters are passed.</p>"},{"location":"apis/delete-batch-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"message\": \"Test Suite removed successfully\" }</p>"},{"location":"apis/delete-test-suite/","title":"Delete a Test Suite API","text":"<p>To delete an existing conversation test suite.</p> Method DELETE     Endpoint <code>https://{{host}}/api/public/stream/:streamId/conversation/testsuite</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Conversation Tests Management  <li>Admin Console: Conversation Tests Management </li>"},{"location":"apis/delete-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL. For example,<code>https://bots.kore.ai</code> Required     StreamID The  Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/delete-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request DELETE \\\n'https://{{host}}/api/public/stream/:streamId/conversation/testsuite' \\\n--header 'auth: {jwt-token}' \\\n--header 'bot-language: {language-code}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"testSuiteNames\" : [\"newtestcaseconvtest\"] }'\n</code></pre>"},{"location":"apis/delete-test-suite/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE testSuiteNames Array containing test suite names.     Required"},{"location":"apis/delete-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"Success\" }</p>"},{"location":"apis/disable-existing-language/","title":"Disable an Existing Language API","text":"<p>To disable an existing language for a virtual assistant.</p> Method POST     Endpoint <code>https://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language/status</code> <p> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Language Configuration  <li>Admin Console: Language Settings &gt; Language Management </li>"},{"location":"apis/disable-existing-language/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required"},{"location":"apis/disable-existing-language/#sample-request","title":"Sample Request","text":"<pre><code>https://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language/status \\\n-H 'Content-Type: application/json' \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-d '[\n{\n\"language\" : ,\n\"enable\": false\n}]'\n</code></pre>"},{"location":"apis/disable-existing-language/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE language     The language code of the language to be disabled.     Required     enable     The enable configuration is set to False.     Required"},{"location":"apis/disable-existing-language/#sample-response","title":"Sample Response","text":"<pre><code>Disabled Spanish language successfully\n</code></pre>"},{"location":"apis/enable-existing-language/","title":"Enable an Existing Language API","text":"<p>To enable an existing language for a virtual assistant.</p> Method POST     Endpoint <code>https://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language/status</code> <p> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Language Configuration  <li>Admin Console: Language Settings &gt; Language Management </li>"},{"location":"apis/enable-existing-language/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required"},{"location":"apis/enable-existing-language/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language/status \\\n-H 'Content-Type: application/json' \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-d '[\n{\n\"language\" : ,\n\"enable\": true\n}]'\n</code></pre>"},{"location":"apis/enable-existing-language/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE language     The language code of the language to be enabled.     Required     enable     The enable configuration is set to True.     Required"},{"location":"apis/enable-existing-language/#sample-response","title":"Sample Response","text":"<pre><code>\"Enabled Spanish language successfully\"\n</code></pre>"},{"location":"apis/execute-test-suite/","title":"Execute a Test Suite API","text":"<p>To execute Conversation Test Suites and get results. This API only initiates the test process and returns the execution status and testRunId to track the execution status. Please look at the Conversation Test Suite Execution Status API for the results of the test.</p> Method POST     Endpoint <code>https://{{host}}/api/public/stream/:streamId/conversation/testsuite/:testSuiteName/run</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Conversation Tests Execution  <li>Admin Console: Conversation Tests Execution </li>"},{"location":"apis/execute-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL. For example,<code>https://bots.kore.ai</code> Required     StreamID The  Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName Name of the test suite on the Bot Builder.     Required"},{"location":"apis/execute-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request POST \\\n'https://{{host}}/api/public/stream/:streamId/conversation/testsuite/:testSuiteName/run' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"version\":\"inDevelopment\" }'\n</code></pre>"},{"location":"apis/execute-test-suite/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE version The version of the bot against which the execution is required. The following options are available: <ul> <li>published for the published version.  <li>inDevelopment for the configured version. </li> Required"},{"location":"apis/execute-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"IN_PROGRESS\",     \"testRunId\": \"ctr-80xxxx9a-bxx1-58xx-axx7-d5xxxxxxxxxx\" }</p>"},{"location":"apis/export-batch-test-suite/","title":"Export Batch Test Suite API","text":"<p>To export the test cases of a given Batch Test Suite and get a link to download the file once the export is completed.</p> Method POST     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}/export</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Management  <li>Admin Console: Batch Tests Management </li>"},{"location":"apis/export-batch-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName The name of the test suite created on the Bot Builder for the export. <p> Note: Only Custom Batch Test Suites can be exported.     Required"},{"location":"apis/export-batch-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{host}/api/public/bot/{botId}/testsuite/{testSuiteName}/export \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'bot-language: {language-code}' \\\n</code></pre>"},{"location":"apis/export-batch-test-suite/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/export-batch-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"downloadUrl\": {{downloadURL}},     \"name\": \"Batch Test Name\",     \"description\": \"Batch Test Description\" }</p>"},{"location":"apis/extract-kg-from-file-url/","title":"Extraction from file or URL \u2013 KG","text":"<p>To extract the Knowledge Graph from the imported file or URL.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{botId}}/qna/import?language=en</code> Content Type <code>application/json</code> Authorization <code>auth: {{YOUR_JWT_ACCESS_TOKEN}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/extract-kg-from-file-url/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED DESCRIPTION host     Required     The environment URL. For example, <code>https://bots.kore.ai</code> BotId     Required     Bot ID or Stream ID can be accessed under General Settings on the Bot Builder."},{"location":"apis/extract-kg-from-file-url/#query-parameters","title":"Query Parameters","text":"PARAMETER REQUIRED DESCRIPTION language     Required     The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot."},{"location":"apis/extract-kg-from-file-url/#sample-request-extraction-using-url","title":"Sample Request (Extraction using URL)","text":"<pre><code>curl --location 'https://bots.kore.ai/api/public/bot/st-2be3c498-d718-5160-853c-0166b82bc41c/qna/import?language=en' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'content-type: application/json' \\\n--data '{\n\"fileUrl\":\"https://www.icicibank.com/nri-banking/money_transfer/faq/m2i-rewards-program/loyalty-program.page%22, \n    \"name\":\"Test\"\n }'\n</code></pre>"},{"location":"apis/extract-kg-from-file-url/#sample-request-extraction-using-file","title":"Sample Request (Extraction using File)","text":"<pre><code>curl --location 'https://bots.kore.ai/api/public/bot/st-2be3c498-d718-5160-853c-0166b82bc41c/qna/import?language=en' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'content-type: application/json' \\\n--header 'Cookie: AWSALB=ywKTJVAcCplRMGaJXRvhZ4gUvOCrfYhOjeqvdYirqAyRQyP9WpTDeNwZI1tDwgoP/CiA6G6j2DxXGWIbCEWdjaiq1ehA2Xo/YxwOBDi02Ix9cbcGYum8P1bxBSq1; AWSALBCORS=ywKTJVAcCplRMGaJXRvhZ4gUvOCrfYhOjeqvdYirqAyRQyP9WpTDeNwZI1tDwgoP/CiA6G6j2DxXGWIbCEWdjaiq1ehA2Xo/YxwOBDi02Ix9cbcGYum8P1bxBSq1' \\\n--data '{\n\"fileId\":\"64c0facd1913a83c147847ca\",\n\"name\": \"Test2\"\n}'\n</code></pre>"},{"location":"apis/extract-kg-from-file-url/#body-parameters","title":"Body Parameters","text":"PARAMETER REQUIRED DESCRIPTION fileUrl     Required     The URL pointing to the location of the FAQs to be extracted.     fileId     Required     The File id pointing to the FAQ file\u2019s location.     name     Required     The name provided to the FAQ."},{"location":"apis/extract-kg-from-file-url/#sample-response","title":"Sample Response","text":"<p>```json {        \"_id\": ,        \"status\": \"success\" }"},{"location":"apis/faq-training-status/","title":"FAQ Training Status API","text":"<p>To get the status of the FAQ training.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/faqs/train/status?language={{Lang}}&amp;state={{state}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Train FAQ  <li>Admin Console: Test and Train &gt; Train FAQ </li>"},{"location":"apis/faq-training-status/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required     language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required     state The state of the bot \u2013 configured is set for the In-Development version and published for the Published version. The default setting is configured.     Optional"},{"location":"apis/faq-training-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\n'https://{{host}}/api/public/bot/{{bot_id}}/faqs/train/status?language=en' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n</code></pre>"},{"location":"apis/faq-training-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/faq-training-status/#sample-response","title":"Sample Response","text":"<p>For successful training</p> <pre><code>{\n\"_id\": \"5dxxxxxxxxxxxxxxxxxxxxxx\",\n\"message\": \"Success\",\n\"status\": \"success\",\n\"__v\": 0,\n\"modifiedOn\": \"2019-06-27T12:07:30.898Z\",\n\"lastModifiedBy\": \"u-5xxxxxxd-bxx1-5xx0-axx8-2exxxxxxxxxx\"\n}\n</code></pre> <p>For training in-progress</p> <pre><code>{\n\"_id\": \"5dxxxxxxxxxxxxxxxxxxxxxx\",\n\"message\": \"in-progress\",\n\"status\": \"in-progress\",\n\"__v\": 0,\n\"modifiedOn\": \"2019-06-27T12:07:30.898Z\",\n\"lastModifiedBy\": \"u-5xxxxxxd-bxx1-5xx0-axx8-2exxxxxxxxxx\"\n}\n</code></pre> <p>For failed training</p> <pre><code>{\n\"_id\": \"5dxxxxxxxxxxxxxxxxxxxxxx\",\n\"message\": \"failure\",\n\"status\": \"failure\",\n\"__v\": 0,\n\"modifiedOn\": \"2019-06-27T12:07:30.898Z\",\n\"lastModifiedBy\": \"u-5xxxxxxd-bxx1-5xx0-axx8-2exxxxxxxxxx\"\n}\n</code></pre>"},{"location":"apis/faq-training/","title":"FAQ Training API","text":"<p>To initiate the training of the knowledge graph.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/faqs/train</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Train FAQ  <li>Admin Console: Test and Train &gt; Train FAQ </li>"},{"location":"apis/faq-training/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/faq-training/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{bot_id}}/faqs/train \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n-d '{\n\"language\":\"en\"\n}'\n</code></pre>"},{"location":"apis/faq-training/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required"},{"location":"apis/faq-training/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"_id\": \"ds-1xxxxxxd-31xx-5xx1-83xx-0dxxxxxxxxxx\",\n\"message\": \"in-progress\",\n\"status\": \"in-progress\",\n\"__v\": 0,\n\"lastModifiedBy\": \"u-adxxxxxx-exx1-5xxd-axxc-21xxxxxxxxxx\",\n\"modifiedOn\": \"2022-07-29T08:20:31.569Z\"\n}\n</code></pre>"},{"location":"apis/fetch-feedback-survey-scores/","title":"Feedback Survey API","text":"<p>To fetch the feedback survey scores provided by the user in the conversation with a virtual assistant and push the data for visualization on the Feedback Analytics module using the Survey Type and Survey Name.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/saveFeedback</code> <p> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Metrics  <li>Admin Console: Bot Analytics &gt; Feedback Analytics </li>"},{"location":"apis/fetch-feedback-survey-scores/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION TYPE host The environment URL. For example, <code>https://bots.kore.ai</code> string, required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder. <p> Note: This is required only for Bot Builder API scope of Proactive Messages.     string, required"},{"location":"apis/fetch-feedback-survey-scores/#sample-request","title":"Sample Request","text":"<pre><code>curl --location 'https://{{host}}/api/1.1/public/bot/{{botId}}/saveFeedback' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"channelUId\":\"qatesting@vomoto.com\",\n\"name\":\"Thumb\",\n\"score\":0,\n\"channel\":\"rtm\",\n\"type\":\"THUMB\",\n\"language\":\"en\",\n\"message\":\"\"\n}'\n</code></pre>"},{"location":"apis/fetch-feedback-survey-scores/#request-body-parameters","title":"Request Body Parameters","text":"PARAMETER DESCRIPTION TYPE channelUId     The ID of the user on the channel where the feedback survey was triggered. Can be the user\u2019s email id or enterprise assigned unique id.     string, required     name     The name of the survey provided by the user.     string, required     score     The feedback survey score provided by the user as a response.     number, required     channel     The channel used for the feedback survey.     string, required     type     One of the feedback survey types THUMB, NPS, or CSAT.     string, required     language     The language in which the Feedback survey is triggered.     string, required     message     The message prompted to the user during the feedback survey.     string, required"},{"location":"apis/fetch-feedback-survey-scores/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"botId\": \"st-053cd130-f983-577a-8aad-2504aebd60b9\",\n\"channel\": \"rtm\",\n\"language\": \"en\",\n\"score\": 0,\n\"timestamp\": \"2023-03-23T07:07:43.538Z\",\n\"createdOn\": \"2023-03-23T07:07:43.538Z\",\n\"timestampValue\": 1679555263538,\n\"type\": \"THUMB\",\n\"name\": \"Thumb\",\n\"channelUId\": \"qatesting@vomoto.com\",\n\"orgId\": \"o-89b0abd5-19af-5017-a80a-6fc6bfc7a638\",\n\"accountId\": \"60dbef1bc2f5c25106cdb57d\",\n\"userId\": \"u-f5d97fb8-8767-5b6c-a28d-09e9ac281e12\",\n\"_id\": \"641bfabf0353f52d915f7a87\",\n\"__v\": 0\n}\n</code></pre>"},{"location":"apis/fetch-feedback-survey-scores/#response-body-parameters","title":"Response Body Parameters","text":"PARAMETER DESCRIPTION TYPE botId     The ID of the virtual assistant for which feedback was given. You can access it from the virtual assistant\u2019s General Settings page.     string, required     channel     The channel on which the user responds to the feedback survey.     string, required     language     The language in which the feedback survey is triggered.     string, required     score     The feedback score.     number, required     timestamp     Feedback response date converted into timestamp format.     date (ISO Date format YYYY-MM-DDThh:mm:ss.mmmZ), required     createdOn     Feedback creation date converted into timestamp format.     date (ISO Date format YYYY-MM-DDThh:mm:ss.mmmZ), required     timestampValue     Creation date converted into timestamp numeric format.     number, required     type     The feedback survey type.     string, required     name     The feedback survey name.     string, required     channelUId     The end-user\u2019s channel user identifier.     string, required     orgId     Organization id the bot belongs to.     string, required     accountId     Account id the bot belongs to.     string, required     userId     User id the bot belongs to.     string, required     _Id     Unique identifier for the message record.     string, required     __v     The value is always 0. Does not have any significance as of now.     integer, optional"},{"location":"apis/find-intent/","title":"Find Intent API","text":"<p>To fetch the intent recognition result and the scores from NLP and ML engines.</p> Method POST     Endpoint <code>https://{{host}}/api/v1.1/rest/bot/{{BotID}}/findIntent?fetchConfiguredTasks=false</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token. API Scope <ul> <li>Bot Builder: Intent and Entity Detection  <li>Admin Console: Intent Identification &gt; Intent and Entity Detection </li>"},{"location":"apis/find-intent/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION host     Required     Environment URL, for example, https://bots.kore.ai     BotID     Required     Bot ID or Stream ID. You can access it from the General Settings page of the bot.     fetchConfiguredTasks     Required     true if you want to fetch the intents from configured tasks in the bot and false if you want to fetch only for the published tasks"},{"location":"apis/find-intent/#bot-language","title":"Bot Language","text":"<p>Optionally, if multi-language is enabled for the Bot, you need to pass the bot-language header with the language code such as en, zh_cn etc. If the language code is not passed for a multi-lingual Bot, then the default language of the Bot will be considered.</p> <pre><code>bot-header: {{lang-code}}\n</code></pre>"},{"location":"apis/find-intent/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\n'https://{{host}}/api/v1.1/rest/bot/{{BotID}}/findIntent?fetchConfiguredTasks=false' \\\n-H \"Content-Type:application/json\" \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}'\\ -H \"bot-language:{{lang-code}}\" \\\n-d '{\n\"parentIntent\": \"{{parent intent}}\",\n\"input\": \"{{user utterance}}\",\n\"streamName\": \"{{bot name}}\"\n}'\n</code></pre>"},{"location":"apis/find-intent/#body-parameters","title":"Body Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION parentIntent     Optional     To detect a sub-intent in the context of another intent     input     Required     The user utterance to find the matching intents <p> Example: Create a task     streamName     Required     The name of the bot <p> Example: JIRA Bot     bot-language     Optional     The bot language, for example, \u201cen\u201d for English and \u201cde\u201d for German."},{"location":"apis/find-intent/#sample-response","title":"Sample Response","text":"<pre><code>{\n    \"request\": {\n        \"input\": \"book a ticket\",\n        \"streamName\": \"Public APIs\"\n    },\n    \"response\": {\n        \"usedtime\": 313,\n        \"debugTitle\": \"Intent Match Successful: 'Book a ticket'\",\n        \"result\": \"successintent\",\n        \"messageStoreId\": \"xxx\",\n        \"bot\": \"Public APIs\",\n        \"botid\": \"st-6ecb5ba2-5e31-5a40-b918-8cbee40f3fdb\",\n        \"task\": \"Book a ticket\",\n        \"taskId\": \"dg-18219164-c11c-5605-9c29-d2e632ec3646\",\n        \"intentStatus\": \"published\",\n        \"subType\": \"dialog\",\n        \"input\": [\n            \"book a ticket\"\n        ],\n        \"identifiedVia\": \"cs em\",\n        \"language\": \"en\",\n        \"userId\": \"u-5dad2ccd-b271-5c00-a338-2e6e25e1ec91\",\n        \"time\": \"2019-06-27T11:48:28.250Z\",\n        \"_id\": \"f-19f149a6-25e3-5c85-8793-679bfd26acf5\",\n        \"traits\": {},\n        \"toneAnalysis\": {},\n        \"nlProcessing\": {\n            \"originalInput\": \"book a ticket\",\n            \"canonical\": \"book a ticket\",\n            \"wordAnalysis\": [\n                {\n                    \"word\": \"book\",\n                    \"ignored\": false,\n                    \"pos\": \"Verb_infinitive \",\n                    \"role\": \"MAINVERB \",\n                    \"original\": \"book\",\n                    \"processedWord\": \"book\"\n                },\n                {\n                    \"word\": \"a\",\n                    \"ignored\": true,\n                    \"pos\": \"Determiner \",\n                    \"original\": \"a\",\n                    \"processedWord\": \"a\"\n                },\n                {\n                    \"word\": \"ticket\",\n                    \"ignored\": false,\n                    \"pos\": \"Noun_singular \",\n                    \"role\": \"MAINOBJECT \",\n                    \"original\": \"ticket\",\n                    \"processedWord\": \"ticket\"\n                }\n            ]\n        },\n        \"ml\": {\n            \"namedEntityRecognition\": []\n        },\n        \"fm\": {\n            \"definitive\": [\n                {\n                    \"count\": 2,\n                    \"score\": 11643.33,\n                    \"botid\": \"st-6ecb5ba2-5e31-5a40-b918-8cbee40f3fdb\",\n                    \"botname\": \"Public APIs\",\n                    \"activity\": \"Book a ticket\",\n                    \"activityType\": 1,\n                    \"exactcount\": 2,\n                    \"labelsize\": 2,\n                    \"ignorewords\": 1,\n                    \"mask\": 66306,\n                    \"words\": {\n                        \"book\": [\n                            \"0-1\"\n                        ],\n                        \"ticket\": [\n                            \"0-3\"\n                        ]\n                    },\n                    \"priority\": 2,\n                    \"tense\": 8192,\n                    \"mainRoles\": 10,\n                    \"sentencelength\": 3,\n                    \"ignorewordlist\": {\n                        \"a\": 1\n                    },\n                    \"maskEntity\": 66306,\n                    \"firstwordmatch\": \"book\",\n                    \"details\": {\n                        \"0\": {\n                            \"1\": {\n                                \"labelword\": \"book\",\n                                \"inputwords\": {\n                                    \"1\": \"book\"\n                                },\n                                \"wordindex\": [\n                                    1\n                                ],\n                                \"foundexact\": true,\n                                \"bestwordindex\": 1,\n                                \"role\": 2,\n                                \"pos\": 2200096997376,\n                                \"tense\": 8192,\n                                \"ageLevel\": 1,\n                                \"commonness\": 6\n                            },\n                            \"2\": {\n                                \"labelword\": \"ticket\",\n                                \"inputwords\": {\n                                    \"3\": \"ticket\"\n                                },\n                                \"wordindex\": [\n                                    3\n                                ],\n                                \"foundexact\": true,\n                                \"bestwordindex\": 3,\n                                \"role\": 8,\n                                \"pos\": 2147483680,\n                                \"tense\": 8192,\n                                \"ageLevel\": 1,\n                                \"commonness\": 5\n                            }\n                        }\n                    },\n                    \"hasNoun\": true,\n                    \"hasVerb\": true,\n                    \"ageLevel\": 1,\n                    \"foundFmEngine\": true,\n                    \"scoreBreakdown\": {\n                        \"wordMatch\": 500,\n                        \"exactWords\": 60,\n                        \"coverage\": 2000,\n                        \"sentenceBonus\": 4000,\n                        \"positionBonus\": 733.33,\n                        \"orderBonus\": 100,\n                        \"spreadBonus\": 800,\n                        \"roleBonus\": 2900,\n                        \"faqQuestionBonus\": 0,\n                        \"mlMatchBonus\": 0,\n                        \"tasktypeBonus\": 50,\n                        \"matchBonus\": 500,\n                        \"phraseJoinPenalty\": 0\n                    },\n                    \"matchType\": \"definite\",\n                    \"task\": \"Book a ticket\",\n                    \"state\": \"published\",\n                    \"foundVia\": \"wordMatch\"\n                }\n            ]\n        },\n        \"finalResolver\": {\n            \"ranking\": [\n                {\n                    \"taskId\": \"dg-18219164-c11c-5605-9c29-d2e632ec3646\",\n                    \"intent\": \"Book a ticket\",\n                    \"activityType\": \"dialog\",\n                    \"state\": \"published\",\n                    \"totalScore\": 11643.33,\n                    \"scoring\": {\n                        \"count\": 2,\n                        \"score\": 11643.33,\n                        \"botid\": \"st-6ecb5ba2-5e31-5a40-b918-8cbee40f3fdb\",\n                        \"botname\": \"Public APIs\",\n                        \"activity\": \"Book a ticket\",\n                        \"activityType\": 1,\n                        \"exactcount\": 2,\n                        \"labelsize\": 2,\n                        \"ignorewords\": 1,\n                        \"mask\": 66306,\n                        \"words\": {\n                            \"book\": [\n                                \"0-1\"\n                            ],\n                            \"ticket\": [\n                                \"0-3\"\n                            ]\n                        },\n                        \"priority\": 10,\n                        \"tense\": 8192,\n                        \"mainRoles\": 10,\n                        \"sentencelength\": 3,\n                        \"ignorewordlist\": {\n                            \"a\": 1\n                        },\n                        \"maskEntity\": 66306,\n                        \"firstwordmatch\": \"book\",\n                        \"details\": {\n                            \"0\": {\n                                \"1\": {\n                                    \"labelword\": \"book\",\n                                    \"inputwords\": {\n                                        \"1\": \"book\"\n                                    },\n                                    \"wordindex\": [\n                                        1\n                                    ],\n                                    \"foundexact\": true,\n                                    \"bestwordindex\": 1,\n                                    \"role\": 2,\n                                    \"pos\": 2200096997376,\n                                    \"tense\": 8192,\n                                    \"ageLevel\": 1,\n                                    \"commonness\": 6\n                                },\n                                \"2\": {\n                                    \"labelword\": \"ticket\",\n                                    \"inputwords\": {\n                                        \"3\": \"ticket\"\n                                    },\n                                    \"wordindex\": [\n                                        3\n                                    ],\n                                    \"foundexact\": true,\n                                    \"bestwordindex\": 3,\n                                    \"role\": 8,\n                                    \"pos\": 2147483680,\n                                    \"tense\": 8192,\n                                    \"ageLevel\": 1,\n                                    \"commonness\": 5\n                                }\n                            }\n                        },\n                        \"hasNoun\": true,\n                        \"hasVerb\": true,\n                        \"ageLevel\": 1,\n                        \"foundFmEngine\": true,\n                        \"scoreBreakdown\": {\n                            \"wordMatch\": 500,\n                            \"exactWords\": 60,\n                            \"coverage\": 2000,\n                            \"sentenceBonus\": 4000,\n                            \"positionBonus\": 733.33,\n                            \"orderBonus\": 100,\n                            \"spreadBonus\": 800,\n                            \"roleBonus\": 2900,\n                            \"faqQuestionBonus\": 0,\n                            \"mlMatchBonus\": 0,\n                            \"tasktypeBonus\": 50,\n                            \"matchBonus\": 500,\n                            \"phraseJoinPenalty\": 0\n                        },\n                        \"matchType\": \"definite\",\n                        \"csMatch\": true\n                    },\n                    \"identifyingEngines\": {\n                        \"fm\": true\n                    },\n                    \"csMatch\": true,\n                    \"intentMatchVia\": \"wordMatch\"\n                }\n            ],\n            \"userInput\": \"book a ticket\",\n            \"winningIntent\": [\n                {\n                    \"intent\": \"Book a ticket\",\n                    \"taskId\": \"dg-18219164-c11c-5605-9c29-d2e632ec3646\",\n                    \"activityType\": \"dialog\",\n                    \"state\": \"published\",\n                    \"score\": 11643.33\n                }\n            ],\n            \"entities\": []\n        }\n    },\n    \"streamId\": \"st-6ecb5ba2-5e31-5a40-b918-8cbee40f3fdb\",\n    \"streamName\": \"Public APIs\",\n    \"seqLogId\": \"f-19f149a6-25e3-5c85-8793-679bfd26acf5\",\n    \"_id\": \"f-19f149a6-25e3-5c85-8793-679bfd26acf5\",\n    \"name\": \"Public APIs\",\n    \"input\": [\n        \"book a ticket\"\n    ]\n}\n</code></pre>"},{"location":"apis/get-batch-test-suites/","title":"Get Batch Test Suites API","text":"<p>To get the list of Batch Test Suites available for a bot.</p> Method GET     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite?skip={skip}&amp;limit={limit}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Management  <li>Admin Console: Batch Tests Management </li>"},{"location":"apis/get-batch-test-suites/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID Bot ID or Stream ID. You can access it from the General Settings page of the bot.     Required     skip Number of records to skip before fetching.     Optional     limit The number of records to fetch.     Optional"},{"location":"apis/get-batch-test-suites/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{host}/api/public/bot/{botId}/testsuite?skip={skip}&amp;limit={limit} \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/get-batch-test-suites/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-batch-test-suites/#sample-response","title":"Sample Response","text":"<p>```json {     \"count\": 36,     \"moreAvailable\": true,     \"ts-2xxxxxxc-exx0-5fxx-bxx2-3xxxxxxxxxxf\": {         \"testSuiteType\": \"custom\",         \"name\": \"sdsa\",         \"description\": \"dfgfd\",         \"results\": [             {                 \"_id\": \"ts-2xxxxxxc-exx0-5fxx-bxx2-3xxxxxxxxxxf\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 2,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 2,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-e1xxxxxx-8cxx-5xx4-8xx8-ecxxxxxxxxxd\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 2,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 2,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-0xxxxxx9-4xx9-5xxa-9xx5-c8xxxxxxxxxx\",                 \"version\": \"inDevelopment\"             },             {                 \"_id\": \"tx-a1xxxxxx-6xx3-5xx2-8xxa-35xxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 2,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 2,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-1axxxxxx-0axx-54xx-8xxc-8fxxxxxxxxb\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 2,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 2,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-8xxxxxxa-3xx2-5xxe-98xx-83xxxxxxxxxx\",                 \"version\": \"inDevelopment\"             },             {                 \"_id\": \"tx-2bxxxxxx-abxx-5xxb-9xx9-75xxxxxxxxxx\",                 \"version\": \"inDevelopment\"             },             {                 \"_id\": \"tx-7xxxxxx0-2xx5-5xx4-b3xx-8fxxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 1,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 1,                     \"success\": 1,                     \"failure\": 1,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.50\",                 \"precision\": \"1.00\",                 \"f1_score\": \"0.67\"             }         ]     },     \"Last100sentences\": {         \"testSuiteType\": \"prebuilt\",         \"results\": [             {                 \"_id\": \"tx-dbxxxxxx-4xx5-5xx2-8xxc-baxxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 3,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 3,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-8xxxxxx0-exxa-5xx6-8xx9-ddxxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 3,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 3,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-7xxxxxx6-6xxa-5xxa-axx8-7xxxxxxxxxxa\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 3,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 3,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-2xxxxxx5-1exx-5xx4-8xx7-2xxxxxxxxxx4\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 0,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 0,                     \"failure\": 3,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 3,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"0.00\",                 \"precision\": \"0.00\",                 \"f1_score\": \"0.00\"             },             {                 \"_id\": \"tx-4xxxxxx4-exx5-5xxf-8xx4-2xxxxxxxxxx9\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 3,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 3,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             },             {                 \"_id\": \"tx-0xxxxxxb-exx4-5xx9-bxx2-dxxxxxxxxxxa\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 2,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 2,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             }         ]     },     \"AllMlUtterances\": {         \"testSuiteType\": \"prebuilt\",         \"results\": [             {                 \"_id\": \"tx-exxxxxx5-1xx7-59xx-8xxa-c6xxxxxxxxxx\",                 \"version\": \"inDevelopment\"             },             {                 \"_id\": \"tx-2xxxxxx9-1xx2-5xxc-axx0-a8xxxxxxxxxx\",                 \"version\": \"inDevelopment\"             },             {                 \"_id\": \"tx-1xxxxxx2-8xxc-5xx4-bxx9-7xxxxxxxxxx7\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 2,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 2,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             },             {                 \"_id\": \"tx-c1xxxxxx-fexx-5axx-8xx8-79xxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 2,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 2,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             },             {                 \"_id\": \"tx-3xxxxxx6-9xx3-5xx9-8xxc-eexxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 2,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 2,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             },             {                 \"_id\": \"tx-8exxxxxx-cbxx-5xxb-axx0-15xxxxxxxxxx\",                 \"version\": \"inDevelopment\",                 \"results\": {                     \"TP\": 2,                     \"TN\": 0,                     \"FP\": 0,                     \"FN\": 0,                     \"success\": 2,                     \"failure\": 0,                     \"totalEntitiesCount\": 0,                     \"matchedEntitiesCount\": 0,                     \"failedUtteranceCount\": 0,                     \"failedEntitiesCount\": 0                 },                 \"recall\": \"1.00\",                 \"precision\": \"1.00\",                 \"f1_score\": \"1.00\"             }         ]     } }</p>"},{"location":"apis/get-conversation-test-suite-creation-status/","title":"Conversation Test Suite Creation Status API","text":"<p>To get the creation/import request status of the Conversation Test Suite against a unique Import ID and provide the download link for the results file after the test execution is complete. Please refer to Create (Import) a Test Suite API  to learn more.</p> Method GET     Endpoint <code>https://{{host}}/api/public/stream/:streamId/conversation/testsuite/import/:dsId/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Conversation Tests Management  <li>Admin Console: Conversation Tests Management </li>"},{"location":"apis/get-conversation-test-suite-creation-status/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL. For example,<code>https://bots.kore.ai</code> Required     StreamID The  Stream ID can be accessed under General Settings on the Bot Builder.     Required     dsId The unique ID to check the conversation test suite creation/import status.     Required"},{"location":"apis/get-conversation-test-suite-creation-status/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request GET \\\n'https://{{host}}/api/public/stream/:streamId/conversation/testsuite/import/:dsId/status' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/get-conversation-test-suite-creation-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-conversation-test-suite-creation-status/#sample-response","title":"Sample Response","text":"<ul> <li>When the test suite creation/import is in progress.</li> </ul> <pre><code>{\n\"_id\": \"ds-f8xxxxx5-5xxa-5xx4-axx4-48xxxxxxxxx9\",\n\"status\": \"IN_PROGRESS\",\n\"percentageComplete\": 85,\n\"streamId\": \"st-45xxxxx7-3xx4-5xxa-9xxa-d8xxxxxxxxx0\",\n\"jobType\": \"CONVERSATION_TESTING_VALIDATE\",\n\"action\": \"RUN\",\n\"countOfDockStatuses\": 1,\n\"createdBy\": \"u-7dxxxxxf-7xxd-5xx7-axx7-37xxxxxxxxx4\",\n\"testSuiteId\": \"ctc-a1xxxxxc-5xx3-5xx5-axx3-77xxxxxxxxxb\",\n\"expireAt\": \"2023-08-23T10:18:21.820Z\",\n\"statusLogs\": [],\n\"lMod\": \"2023-08-23T10:03:36.109Z\",\n\"createdOn\": \"2023-08-23T10:03:21.825Z\",\n\"requestedTime\": \"2023-08-23T10:03:21.825Z\",\n\"__v\": 0\n}\n</code></pre> <ul> <li>When the test suite creation/import is completed.</li> </ul> <pre><code>{\n\"_id\": \"ds-f8xxxxx5-5xxa-5xx4-axx4-48xxxxxxxxx9\",\n\"status\": \"SUCCESS\",\n\"percentageComplete\": 100,\n\"streamId\": \"st-45xxxxx7-3xx4-5xxa-9xxa-d8xxxxxxxxx0\",\n\"jobType\": \"CONVERSATION_TESTING_VALIDATE\",\n\"action\": \"RUN\",\n\"countOfDockStatuses\": 1,\n\"createdBy\": \"u-7dxxxxxf-7xxd-5xx7-axx7-37xxxxxxxxx4\",\n\"testSuiteId\": \"ctc-a1xxxxxc-5xx3-5xx5-axx3-77xxxxxxxxxb\",\n\"expireAt\": \"2023-08-23T10:18:21.820Z\",\n\"statusLogs\": [],\n\"lMod\": \"2023-08-23T10:04:24.972Z\",\n\"createdOn\": \"2023-08-23T10:03:21.825Z\",\n\"requestedTime\": \"2023-08-23T10:03:21.825Z\",\n\"__v\": 0,\n\"response\": {\n\"schedule\": {\n\"enableSchedule\": false\n},\n\"channel\": \"rtm\",\n\"tags\": [],\n\"recentTags\": [],\n\"metadataAvailable\": true,\n\"name\": \"newtestcaseconvtest1979asdxxxxxxxxx9\",\n\"description\": \"\",\n\"preprocessor\": \"\",\n\"serviceMap\": [],\n\"authProfiles\": [],\n\"streamId\": \"st-45xxxxx7-3xx4-5xxa-9xxa-d8xxxxxxxxx0\",\n\"accountId\": \"639xxxxxxxxxxxxxxxxxxxx3\",\n\"lModBy\": \"u-7dxxxxxf-7xxd-5xx7-axx7-37xxxxxxxxx4\",\n\"createdBy\": \"u-7dxxxxxf-7xxd-5xx7-axx7-37xxxxxxxxx4\",\n\"testSteps\": [\n{\n\"input\": \"Start_Flow\",\n\"outputs\": [\n{\n\"text\": \"asdasd\",\n\"nodeId\": \"\",\n\"componentType\": \"\",\n\"intentId\": \"\",\n\"nodeName\": \"\",\n\"intentType\": \"\",\n\"taskId\": \"\",\n\"dialogName\": \"\",\n\"transitions\": [],\n\"transitionNodeNames\": [],\n\"transitionNodeType\": [],\n\"assertions\": {\n\"flowLevel\": {\n\"enabled\": false,\n\"contains\": []\n},\n\"text\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"text\": \"asdasd\"\n}\n]\n},\n\"context\": {\n\"enabled\": false,\n\"contains\": []\n}\n}\n}\n],\n\"event\": \"Start_Flow\"\n}\n],\n\"_id\": \"ctc-f9xxxxxc-7xx1-5xxe-axx6-80xxxxxxxxxd\",\n\"createdOn\": \"2023-08-23T10:03:37.404Z\",\n\"lModOn\": \"2023-08-23T10:03:37.404Z\",\n\"__v\": 0\n}\n}\n</code></pre>"},{"location":"apis/get-faqs-from-knowledge-task/","title":"Get FAQs \u2013 KG","text":"<p>To get a list of questions and nodes under the Knowledge task.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{botId}}/faqs?ktId=&amp;limit=&amp;offset=&amp;parentId=&amp;withallchild=&amp;type=&amp;language=en</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/get-faqs-from-knowledge-task/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/get-faqs-from-knowledge-task/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE ktId The Knowledge task ID based on which the FAQs are listed. <p> You can retrieve the ktId from the request of the GetFAQs API call. Learn more. <p> Note: The ktId values are different for both in-development and published bots.     Required     limit The number of records to be fetched. The default count and the maximum limit is 50.     Optional     offset The number of records to be skipped. The default count is set 0.     Optional     parentId The ID of the nodes in the Knowledge tasks section. <p> You can retrieve the parentId from the response of the GetFAQs API call. Learn more.     Optional     withallchild Whether child nodes need to be included     Optional     type Type of FAQs to be fetched.     Optional     language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required     search Used to search the KG using the reference id or display name.     Optional"},{"location":"apis/get-faqs-from-knowledge-task/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\n'https://{{host}}/api/public/bot/{{bot_id}}/faqs?ktId=5afxxxxxf&amp;limit=30&amp;offset=0&amp;parentId=xxxxx-xxx-xxx-xxx-xxxxx&amp;withallchild=true&amp;type=all&amp;language=en' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json'  </code></pre>"},{"location":"apis/get-faqs-from-knowledge-task/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-faqs-from-knowledge-task/#sample-response","title":"Sample Response","text":"<p>```json {     \"faqs\": [         {             \"_id\": \"5exxxxxxxxxxxxxxxxxxxxxx\",             \"subAnswers\": [],             \"editLocked\": false,             \"isPublished\": true,             \"questionPayload\": {                 \"question\": \"What is Bank Internet Banking?\",                 \"tagsPayload\": []             },             \"answerPayload\": [                 {                     \"_id\": \"mt-95xxxxxx-9xxa-5xxe-97xx-56xxxxxxxxxx\",                     \"channel\": \"default\",                     \"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",                     \"lModBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",                     \"lMod\": \"Fri Jan 03 2020 13:11:03 GMT+0530 (India Standard Time)\",                     \"createdBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",                     \"createdOn\": \"Fri Jan 03 2020 13:11:03 GMT+0530 (India Standard Time)\",                     \"text\": \"Bank Internet banking is a convenient way to bank anytime, anywhere even from the comfort of your home using your PC or Tab.\",                     \"type\": \"basic\"                 }             ],             \"knowledgeTaskId\": \"5axxxxxxxxxxxxxxxxxxxxxx\",             \"subQuestions\": [],             \"responseType\": \"message\",             \"referenceId\" :\"12xxx32\",             \"label\" :\"displayname\",             \"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",             \"parent\": \"pa-xxxxx-xxx-xxx-xxx-xxxxx\",             \"leafterm\": \"yes\",             \"language\": \"en\",             \"createdBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",             \"lastModifiedBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",             \"createdOn\": \"2020-01-03T07:41:03.017Z\",             \"modifiedOn\": \"2020-01-03T07:41:03.017Z\",             \"sortId\": 1578037263017,             \"botName\": \"BankingBot\",             \"refId\": \"re-xxxxx-xxx-xxx-xxx-xxxxx\",             \"__v\": 0         }] }</p>"},{"location":"apis/get-kg-extraction-history/","title":"Get Extractions History \u2013 KG","text":"<p>To get the KG extractions\u2019 history as a list.</p> Method GET     Endpoint <code>https://{{host}}/api/public/stream/{{streamId}}/qna/history?language=en</code> Content Type <code>application/json</code> Authorization <code>auth: {{YOUR_JWT_ACCESS_TOKEN}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/get-kg-extraction-history/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     streamId The Stream ID that can be accessed under General Settings <p> on the Bot Builder.     Required"},{"location":"apis/get-kg-extraction-history/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required"},{"location":"apis/get-kg-extraction-history/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{{host}}/api/public/stream/{{streamId}}/qna/history?language=en \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json'\n</code></pre>"},{"location":"apis/get-kg-extraction-history/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-kg-extraction-history/#sample-response","title":"Sample Response","text":"<p>```json {     \"metaqnas\": [         {             \"_id\": \"ke-bxxxxxxb-bxx2-5xx8-bxx8-14xxxxxxxxxx\",             \"editable\": false,             \"status\": \"success\",             \"isVisited\": false,             \"fileId\": \"5e0xxxxxx8b\",             \"name\": \"KG_QuestionExtraction\",             \"extractionType\": \"faq\",             \"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",             \"createdBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",             \"language\": \"en\",             \"fileName\": \"KGCSVBotQuestionExtraction.csv\",             \"createdOn\": \"2020-01-03T06:17:50.416Z\",             \"modifiedOn\": \"2020-01-03T06:17:56.932Z\",             \"__v\": 0,             \"qnaAddedCount\": 0,             \"qnaExtractedCount\": 113,             \"qnaCount\": 113         }     ] }</p>"},{"location":"apis/get-kg-extraction-questions/","title":"Get Extraction Questions \u2013 KG","text":"<p>To get the list of KG Extraction Questions.</p> Method GET     Endpoint <code>https://{{host}}/api/public/stream/{{streamId}}/qna/{{ExtractionId}}/questions?limit=&amp;offset=</code> Content Type <code>application/json</code> Authorization <code>auth: {{YOUR_JWT_ACCESS_TOKEN}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/get-kg-extraction-questions/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     streamId The Stream ID that can be accessed under General Settings <p> on the Bot Builder.     Required     ExtractionId The ExtractionId used to identify the extraction of the questions.     Required"},{"location":"apis/get-kg-extraction-questions/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE limit The number of records to be fetched. The default count is 50.     Optional     offset The number of records to be skipped. The default count is 0.     Optional"},{"location":"apis/get-kg-extraction-questions/#sample-request","title":"Sample Request","text":"<pre><code>curl --location 'https://{{host}}/api/public/stream/{{streamId}}/qna/{{ExtractionId}}/questions?limit=20&amp;offset=0' \\\n--header 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n--header 'Content-Type: application/json'\n</code></pre>"},{"location":"apis/get-kg-extraction-questions/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-kg-extraction-questions/#sample-response","title":"Sample Response","text":"<p>```json {     \"extractions\": [         {             \"_id\": \"qna-64xxxxxx-axx5-5xx1-b2xx-exxxxxxxxxxa\",             \"status\": true,             \"question\": \"Am I going to be charged for this security feature?\",             \"answer\": \"As of now, this service is free of charge and is a security measure for your online account safety.\",             \"language\": \"en\",             \"kEId\": \"ke-xxxxx-xxx-xxx-xxx-xxxxx\",             \"createdBy\": \"u-xxxxx-xxx-xxxx-xxx-xxxxx\",             \"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",             \"createdOn\": \"2020-01-03T06:59:19.472Z\",             \"modifiedOn\": \"2020-01-03T06:59:19.472Z\",             \"__v\": 0         }     ] }</p>"},{"location":"apis/get-knowledge-tasks/","title":"Get KnowledgeTasks \u2013 KG","text":"<p>To get the list of knowledge Tasks along with the nodes.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{botId}}/knowledgeTasks?language=en</code> Content Type <code>application/json</code> Authorization <code>auth: {{YOUR_JWT_ACCESS_TOKEN}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Manage Knowledge Graph  <li>Admin Console: Manage Knowledge Graph </li>"},{"location":"apis/get-knowledge-tasks/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/get-knowledge-tasks/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE language The Bot language which is identified by the language acronym. For example, en for English and de for German. The user can set the default language of the bot.     Required"},{"location":"apis/get-knowledge-tasks/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{{host}}/api/public/bot/{{botId}}/knowledgeTasks?language=en \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json'\n</code></pre>"},{"location":"apis/get-knowledge-tasks/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/get-knowledge-tasks/#sample-response","title":"Sample Response","text":"<pre><code>    {\n\"_id\": \"5axxxxxxxxxxxxxxxxxxxxxx\",\n\"createdOn\": \"2018-05-15T06:08:35.732Z\",\n\"modifiedOn\": \"2020-01-03T07:54:13.583Z\",\n\"state\": \"configured\",\n\"editable\": true,\n\"taxonomy\": [\n{\n\"parent\": [],\n\"synonyms\": [],\n\"isDummy\": false,\n\"editLocked\": false,\n\"nodeId\": \"bxxxxxxa-3xx5-4xxc-9xxd-0axxxxxxxxxx\",\n\"label\": \"tarak\",\n\"level\": \"l0\",\n\"faqCount\": 5\n}\n],\n\"nodesToPublish\": [],\n\"publishRoot\": false,\n\"version\": \"1.0\",\n\"adminTaskStatus\": \"active\",\n\"name\": \"tarak\",\n\"description\": \"This is used to make ontology\",\n\"isGraph\": true,\n\"visibility\": {\n\"namespace\": \"private\",\n\"namespaceIds\": [\n\"u-99xxxxxx-1xx6-5xx8-bxxf-acxxxxxxxxxx\"\n]\n},\n\"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",\n\"metadata\": {\n\"taxonomy\": [\n{\n\"nodeId\": \"bxxxxxxa-3xx5-4xxc-9xxd-0axxxxxxxxxx\",\n\"label\": \"tarak\",\n\"class\": \"bgblack\",\n\"level\": \"l0\",\n\"parent\": [],\n\"synonyms\": [],\n\"nodes\": []\n}\n]\n},\n\"createdBy\": \"u-9xxxxxx6-1xx6-5xx8-bxxf-acxxxxxxxxxx\",\n\"lastModifiedBy\": \"u-9xxxxxx6-1xx6-5xx8-bxxf-axxxxxxxxxx9\",\n\"botName\": \"tarak\",\n\"language\": \"en\",\n\"refId\": \"1xxxxxx9-3xx6-5xxf-8xx1-3dxxxxxxxxxx\",\n\"__v\": 0,\n\"deletedNodesToPublish\": [],\n\"publishedOn\": \"2020-01-03T07:54:13.583Z\",\n\"versionComment\": null,\n\"parentId\": \"5exxxxxxxxxxxxxxxxxxxxx3\",\n\"_resolve\": [\n\"createdBy\"\n],\n\"lock\": {\n\"islocked\": \"false\"\n},\n\"traitCount\": 0,\n\"faqCount\": 5\n}\n</code></pre>"},{"location":"apis/get-test-suite-execution-status/","title":"Get the Execution Status and Summary of a Test Suite API","text":"<p>To get the status of the Conversation Test Suite Execution request against a unique testSuiteId if the request is in progress, and provide the download link for the results file after the test execution is complete.</p> Method GET     Endpoint <code>https://{{host}}/api/public/stream/:streamId/conversation/testsuite/:testSuiteName/:testRunId/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Conversation Tests Execution  <li>Admin Console: Conversation Tests Execution </li>"},{"location":"apis/get-test-suite-execution-status/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host Environment URL. For example,<code>https://bots.kore.ai</code> Required     StreamID The  Stream ID can be accessed under General Settings on the Bot Builder.     Required     testSuiteName The name of the Test Suite.     Required     testRunId The ID of the test run to track the execution status.     Required"},{"location":"apis/get-test-suite-execution-status/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request GET \\\n'https://{{host}}/api/public/stream/:streamId/conversation/testsuite/:testSuiteName/:testRunId/status' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}'\n</code></pre>"},{"location":"apis/get-test-suite-execution-status/#body-parameters","title":"Body Parameters","text":"<p>No Body parameters are passed.</p>"},{"location":"apis/get-test-suite-execution-status/#sample-response","title":"Sample Response","text":"<ul> <li>When the request in in progress.</li> </ul> <pre><code>{\n\"_id\": \"ctr-80xxxxxa-bxx1-5xx1-axx7-d5xxxxxxxxxb\",\n\"streamId\": \"st-4xxxxxx7-3xx4-5xxa-9xxa-d8xxxxxxxxx0\",\n\"testSuiteId\": \"ctc-3xxxxxx5-6xxf-5xxb-bxx8-04xxxxxxxxxc\",\n\"status\": \"inprogress\",\n\"totalTestStepsCount\": 13,\n\"result\": {\n\"nlpVersion\": [],\n\"startTime\": \"2023-08-23T10:14:13.330Z\",\n\"version\": \"configured\",\n\"status\": \"inprogress\"\n},\n\"percentageCompleted\": 85\n}\n</code></pre> <ul> <li>When the request is completed.</li> </ul> <pre><code>{\n\"_id\": \"ctr-8xxxxxxa-bxx1-5xx1-axx7-d5xxxxxxxxxb\",\n\"streamId\": \"st-4xxxxxx7-3xx4-5xxa-9xxa-d8xxxxxxxxx0\",\n\"testSuiteId\": \"ctc-3xxxxxx5-6xxf-5xxb-bxx8-04xxxxxxxxxc\",\n\"status\": \"passed\",\n\"totalTestStepsCount\": 13,\n\"result\": {\n\"nlpVersion\": [\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\",\n\"v3\"\n],\n\"startTime\": \"2023-08-23T10:14:13.330Z\",\n\"version\": \"configured\",\n\"status\": \"passed\",\n\"stepDetails\": {\n\"passed\": 13,\n\"failed\": 0,\n\"total\": 13\n},\n\"errorDetails\": null,\n\"executionResults\": [            {\n\"actualOutput\": [\n{\n\"text\": \"asdasd\",\n\"nodeId\": \"\",\n\"componentType\": \"\",\n\"intentId\": \"\",\n\"nodeName\": \"\",\n\"intentType\": \"\",\n\"taskId\": \"\",\n\"dialogName\": \"\",\n\"transitions\": [],\n\"transitionNodeNames\": [],\n\"transitionNodeType\": [],\n\"assertions\": {\n\"flowLevel\": {\n\"enabled\": false,\n\"contains\": []\n},\n\"text\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"text\": \"asdasd\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"context\": {\n\"enabled\": false,\n\"contains\": []\n}\n}\n}\n],\n\"intents\": [],\n\"faqs\": [],\n\"smalltalk\": [],\n\"input\": \"Start_Flow\",\n\"outputs\": [\n{\n\"text\": \"asdasd\",\n\"nodeId\": \"\",\n\"componentType\": \"\",\n\"intentId\": \"\",\n\"nodeName\": \"\",\n\"intentType\": \"\",\n\"taskId\": \"\",\n\"dialogName\": \"\",\n\"transitions\": [],\n\"transitionNodeNames\": [],\n\"transitionNodeType\": [],\n\"assertions\": {\n\"flowLevel\": {\n\"enabled\": false,\n\"contains\": []\n},\n\"text\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"text\": \"asdasd\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"context\": {\n\"enabled\": false,\n\"contains\": []\n}\n}\n}\n],\n\"event\": \"Start_Flow\",\n\"requestId\": \"ctr-8xxxxxxa-bxx1-5xx1-axx7-d5xxxxxxxxxx0\",\n\"nlpVersion\": \"v3\",\n\"status\": \"passed\"\n},\n{\n\"actualOutput\": [\n{\n\"text\": \"{\\\"type\\\":\\\"template\\\",\\\"payload\\\":{\\\"template_type\\\":\\\"quick_replies\\\",\\\"text\\\":\\\"Sorry! We are unable to detect the language. Please choose one of the below languages :\\\\n\\\",\\\"quick_replies\\\":[{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"English\\\",\\\"payload\\\":\\\"English\\\"},{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"Deutsch\\\",\\\"payload\\\":\\\"Deutsch\\\"}]}}\",\n\"category\": \"Confirmation\",\n\"isStandardResponse\": true,\n\"userPrompts\": [],\n\"assertions\": {\n\"flowLevel\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"nodeId\": \"Confirmation\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"text\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"text\": \"{\\\"type\\\":\\\"template\\\",\\\"payload\\\":{\\\"template_type\\\":\\\"quick_replies\\\",\\\"text\\\":\\\"Sorry! We are unable to detect the language. Please choose one of the below languages :\\\\n\\\",\\\"quick_replies\\\":[{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"English\\\",\\\"payload\\\":\\\"English\\\"},{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"Deutsch\\\",\\\"payload\\\":\\\"Deutsch\\\"}]}}\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"context\": {\n\"enabled\": false,\n\"contains\": []\n}\n}\n}\n],\n\"intents\": [],\n\"faqs\": [],\n\"smalltalk\": [],\n\"input\": \"help\",\n\"outputs\": [\n{\n\"text\": \"{\\\"type\\\":\\\"template\\\",\\\"payload\\\":{\\\"template_type\\\":\\\"quick_replies\\\",\\\"text\\\":\\\"Sorry! We are unable to detect the language. Please choose one of the below languages :\\\\n\\\",\\\"quick_replies\\\":[{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"English\\\",\\\"payload\\\":\\\"English\\\"},{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"Deutsch\\\",\\\"payload\\\":\\\"Deutsch\\\"}]}}\",\n\"category\": \"Confirmation\",\n\"isStandardResponse\": true,\n\"userPrompts\": [],\n\"assertions\": {\n\"flowLevel\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"nodeId\": \"Confirmation\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"text\": {\n\"enabled\": true,\n\"contains\": [\n{\n\"text\": \"{\\\"type\\\":\\\"template\\\",\\\"payload\\\":{\\\"template_type\\\":\\\"quick_replies\\\",\\\"text\\\":\\\"Sorry! We are unable to detect the language. Please choose one of the below languages :\\\\n\\\",\\\"quick_replies\\\":[{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"English\\\",\\\"payload\\\":\\\"English\\\"},{\\\"content_type\\\":\\\"text\\\",\\\"title\\\":\\\"Deutsch\\\",\\\"payload\\\":\\\"Deutsch\\\"}]}}\",\n\"status\": \"passed\"\n}\n],\n\"status\": \"passed\"\n},\n\"context\": {\n\"enabled\": false,\n\"contains\": []\n}\n},\n\"textMismatch\": true\n}\n],\n\"requestId\": \"ctr-8xxxxxxa-bxx1-5xx1-axx7-d5xxxxxxxxxx1\",\n\"nlpVersion\": \"v3\",\n\"status\": \"passed\"\n}\n......................................................................................\n],\n\"duration\": 14364\n},\n\"percentageCompleted\": 100\n}\n</code></pre>"},{"location":"apis/import-batch-test-suite/","title":"Import Batch Test Suite API","text":"<p>To import the test cases from a given Test Suite file.</p> Method POST     Endpoint <code>https://{host}/api/public/bot/{botId}/testsuite/import</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Batch Tests Management  <li>Admin Console: Batch Tests Management </li>"},{"location":"apis/import-batch-test-suite/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID that can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/import-batch-test-suite/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request POST \\\n'https://{host}/api/public/stream/{streamId}/testsuite/import' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'bot-language: {language-code}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"delimiter\": \",\",\n\"description\": \"fcgfddfg\",\n\"fileName\": \"5ff70b47a664d31999d9202c\",\n\"fileType\": \"json\",\n\"importType\": \"update\",\n\"name\": \"hgf\"\n}'\n</code></pre>"},{"location":"apis/import-batch-test-suite/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE fileName     File containing the Batch Test suite details.     Required     fileType     JSON.     importType     new/update     delimiter     Field delimiter in the file     Required     description     Test suite description     Required"},{"location":"apis/import-batch-test-suite/#sample-response","title":"Sample Response","text":"<p>```json {     \"_id\": \"ts-8304802f-6f85-5f67-8964-de04446c1c93\",     \"name\": \"hgf\",     \"description\": \"fcgfddfg\",     \"streamId\": \"st-15864388-c33d-5caf-86a6-d17951ff3d5b\",     \"language\": \"en\",     \"fileId\": \"5ff70b47a664d31999d9202c\",     \"createdBy\": \"u-49bd0ecd-18d1-53e1-988d-84d3004d79ea\",     \"createdOn\": \"2021-01-05T17:43:43.927Z\",     \"modifiedOn\": \"2021-01-07T13:48:14.169Z\",     \"__v\": 0,     \"fileName\": \"sampleBatchtesting (2) (copy) (1).json\" }</p>"},{"location":"apis/import-bot-as-new-bot/","title":"Import Bot as a New Bot API","text":"<p>To create a new bot in the account owner\u2019s Builder Tool using the File IDs generated when uploading the files to the local server.</p> <p>Please refer to the Upload File API for uploading and obtaining the File Id.</p> <p>Note</p> <p>The API requires the JWT generated by an application created only from the Bot Admin Console.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/import</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Definition &gt; Bot Import </li>"},{"location":"apis/import-bot-as-new-bot/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required"},{"location":"apis/import-bot-as-new-bot/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/import \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n-d '{\n\"botDefinition\" : \"5bxxxxxxxxxxx4f9\",\n\"configInfo\" : \"5bxxxxxxxxxxxxx4fa\",\n\"botFunctions\":[\"5bxxxxxxxxxxxxxea6\"],\n\"icon\":\"5bxxxxxxxxxxxxxxxx4fb\"\n}'\n</code></pre>"},{"location":"apis/import-bot-as-new-bot/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE botDefinition \u201cBot definition file id\u201d     Required     configInfo \u201cBot configuration file id\u201d     Required     botFunctions \u201cBot functions File id\u201d     Optional     icon \u201cBot icon File id\u201d     Required     name \u201cBot name\u201d <p> \u2013 If not provided, it is fetched from the existing bot\u2019s copy.     Optional     purpose \u201ccustomer\u201d/\u201demployee\u201d <p> \u2013 If not provided, it is fetched from the existing bot\u2019s copy.     Optional"},{"location":"apis/import-bot-as-new-bot/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"status\": \"pending\",\n\"\"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",\n    \"statusLogs\": [\n        {\n            \"taskType\": \"importRequest\",\n            \"taskName\": \"Welcome\",\n            \"status\": \"success\"\n        }\n    ],\n    \"createdBy\": \"u-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx\",\n    \"requestType\": \"Botimport\",\n    \"bir\": \"bir-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n    \"createdOn\": \"2022-07-29T07:24:17.496Z\",\n    \"__v\": 0\n}\n</code></pre>"},{"location":"apis/import-bot-into-an-existing-bot/","title":"Import Bot into an Existing Bot API","text":"<p>To import the bot definition file to an existing bot for a current version upgrade or previous version restoration.</p> <p>Note</p> <p>This API requires the JWT generated by an application created on the Bot Admin Console.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/import</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Definition &gt; Bot Import </li>"},{"location":"apis/import-bot-into-an-existing-bot/#query-parameters","title":"Query Parameters","text":"PARAMETER MANDATE DESCRIPTION host Required     The environment URL. For example, <code>https://bots.kore.ai</code> BotID Required     The Bot ID or Stream ID. You can access it under General Settings on the Bot Builder."},{"location":"apis/import-bot-into-an-existing-bot/#sample-request-for-the-universal-bot","title":"Sample Request for the Universal Bot","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{BotID}}/import \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-H 'content-type: application/json' \\\n-d '{\n\"botDefinition\" : \"5bxxxxxxxxxxxxxxxxxxxxxx\",\n\"configInfo\" : \"5bxxxxxxxxxxxxxxxxxxxxxx\",\n\"importOptions\": {\n\"nlpData\": [\n\"training_data\",\n\"bot_synonyms\",\n\"nlpSettings\",\n\"defaultDialog\",\n\"standardResponses\"\n],\n\"settings\": [\n\"botSettings\",\n\"ivrSettings\",\n\"botVariables\",\n\"ivrSettings\"\n],\n\"options\": {\n\"utterances\": {\n\"append\": true,\n\"replace\": false\n}\n},\n\"botComponents\": [\n\"linkedBots\",\n\"smallTalk\"\n],\n\"customDashboard\": true\n}\n}'\n</code></pre>"},{"location":"apis/import-bot-into-an-existing-bot/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{BotID}}/import \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-H 'content-type: application/json' \\\n-d '{\n\"botDefinition\" : \"5bxxxxxxxxxxxxxxxxxxxxxx\",\n\"configInfo\" : \"5bxxxxxxxxxxxxxxxxxxxxxx\",\n\"botFunctions\":[\"5bxxxxxxxxxxxxxxxxxxxxxx\"]\n}'\n</code></pre>"},{"location":"apis/import-bot-into-an-existing-bot/#body-parameters","title":"Body Parameters","text":"PARAMETER MANDATE DESCRIPTION botDefinition Required     \u201cBot Definition File id\u201d Learn more on obtaining the Definition file ID.     configInfo Required     \u201cBot Configuration File id\u201d Learn more on obtaining the Configuration file ID.     botFunctions Optional     \u201cFileid\u201d     importOptions Required     All bot components are imported by default. If needed, you may specify the components to be included in the import. <p> Usage: <p> <code>\"importOptions\": {</code> <p> <code>   \"tasks\": [</code> <p> <code>     \"botTask\",</code> <p> <code>     \"knowledgeGraph\"</code> <p> <code>     ],</code> <p> <code>   \"nlpData\": [</code> <p> <code>     \"nlpSettings\",</code> <p> <code>     \"utterances\",</code> <p> <code>     \"standardResponses\"</code> <p> <code>     ],</code> <p> <code>   \"settings\": [</code> <p> <code>     \"botSettings\",</code> <p> <code>     \"botVariables\",</code> <p> <code>     \"ivrSettings\"</code> <p> <code>     ]</code> <p> <code> },</code> options Optional     This will indicate incremental import options for the ML utterances, whether to replace or append. Learn more. <p> Usage: <p> <code>\"options\": {</code> <p> <code>     \"utterances\": {</code> <p> <code>        \"replace\": true</code> <p> <code>  \"append\":false</code> <p> <code>        }</code> <p>**Universal Bot \\ **For the Universal bot, the import the importOptions may differ as shown below:</p> <pre><code>\"importOptions\": {\n\"nlpData\": [\n\"training_data\",\n\"bot_synonyms\",\n\"nlpSettings\",\n\"defaultDialog\",\n\"standardResponses\"\n],\n\"settings\": [\n\"botSettings\",\n\"ivrSettings\",\n\"botVariables\",\n\"ivrSettings\"\n],\n\"options\": {\n\"utterances\": {\n\"append\": true,\n\"replace\": false\n}\n},\n\"botComponents\": [\n\"linkedBots\",\n\"smallTalk\"\n],\n\"customDashboard\": true\n}\n</code></pre>"},{"location":"apis/import-bot-into-an-existing-bot/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"streamRefId\": \"c685t327-xxxx-58xx-9xbx-33xxxxxxxxxx\",\n\"statusLogs\": [\n{\n\"taskType\": \"importRequest\",\n\"taskName\": \"Sample Task\",\n\"status\": \"success\"\n}\n],\n\"createdBy\": \"u-3xxxxxxx-axxe-5bxx-bxxb-8xxxxxxxxxxx\",\n\"requestType\": \"Botimport\",\n\"_id\": \"bir-00bxxxxx-7xx2-5xxx-bxxx-79xxxxxxxxxx\",\n\"status\": \"pending\",\n\"createdOn\": \"2018-12-05T07:40:51.956Z\",\n\"__v\": 0\n}\n</code></pre>"},{"location":"apis/import-ml-utterances/","title":"ML Utterances Import API","text":"<p>To import the ML Utterances into a bot.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/mlimport</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Utterances Import  <li>Admin Console: Test &gt; Utterances Import and Train </li>"},{"location":"apis/import-ml-utterances/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/import-ml-utterances/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{bot ID}}/mlimport \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n-d '{\n\"fileName\":\"MLUtterances.json\",\n\"fileId\": \"5beed4fd0b9a4b740c09dca2\"\n}'\n</code></pre>"},{"location":"apis/import-ml-utterances/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE fileName The full name of the ML Utterances file to be imported.     Required     fileID The ID of the imported file (provided by the cloud service where the file is uploaded).     Required"},{"location":"apis/import-ml-utterances/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"status\": \"pending\",\n\"streamId\": \"sx-6exxxxxx-5xx1-5xx0-b9xx-8cxxxxxxxxxx\",\n\"createdBy\": \"u-5dxxxxxxxxxxx-5xx0-a3xx-2exxxxxxxxxx\",\n\"requestType\": \"MLimport\",\n\"_id\": \"bxx-7exxxxxx-5xxb-51xx-bxx5-88xxxxxxxxxx\",\n\"statusLogs\": [],\n\"createdOn\": \"2019-06-27T12:03:30.748Z\",\n\"__v\": 0\n}\n</code></pre>"},{"location":"apis/install-sample-bot/","title":"Install a Sample Bot API","text":"<p>To install a sample bot.</p> Method POST     Endpoint <code>https://{{host}}/api/public/samplebots/{{botId}}/add</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> <code>AccountId: {{accountId}}</code> <p> <code>userId: {{userId}}</code> <p> <code>bot-language : en</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Definition &gt; Bot Create </li>"},{"location":"apis/install-sample-bot/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. for example, https://bots.kore.ai     Required     BotID Bot ID or Stream ID which can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/install-sample-bot/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\n'https://{{host}}/api/public/samplebots/{{bot_id}}/add' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n-H 'AccountId: xexxbaxxxbxbxxxxxxxxcxfb' \\\n-H 'userId: u-fbxxfxxx-axfd-xfcx-abxx-xcxxxxaxexxx' \\\n-H 'bot-language: en </code></pre>"},{"location":"apis/install-sample-bot/#body-parameters","title":"Body Parameters","text":"<p>No Body parameters are passed.</p>"},{"location":"apis/install-sample-bot/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"visibility\": {\n\"namespace\": \"private\",\n\"namespaceIds\": [\n\"u-fbxxxxxx-a5xx-5xx8-abxx-6cxxxxxxxxxx\"\n]\n},\n\"languages\": [],\n\"screenShots\": [],\n\"downloadCount\": 0,\n\"alerts\": [\n\"l-bexxxxxx-dxxe-5xx1-84xx-c0xxxxxxxxxx\"\n],\n\"actions\": [],\n\"dialogs\": [\n\"dg-cbxxxxxx-cxx4-5fxx-8xx6-b2xxxxxxxxxx\",\n\"dg-35xxxxxx-bxx7-58xx-bxxa-0bxxxxxxxxxx\"\n],\n\"widgets\": [],\n\"panels\": [],\n\"forms\": [],\n\"categoryIds\": [\n\"451xxxxxxxxxxxxxxxxxxxxx\"\n],\n\"class\": [],\n\"featured\": false,\n\"profileRequired\": true,\n\"sendVcf\": false,\n\"isNLEnabled\": true,\n\"interruptsEnabled\": true,\n\"state\": \"setup\",\n\"defaultLanguage\": \"en\",\n\"_id\": \"st-cxxxxxxe-exxe-5xx3-8xx0-2cxxxxxxxxxx\",\n\"modifiedOn\": \"2021-01-12T10:55:11.551Z\",\n\"sBannerColor\": \"#E44929\",\n\"bBannerColor\": \"#E44929\",\n\"createdOn\": \"2021-01-12T10:55:11.115Z\",\n\"createdBy\": \"u-fbxxxxxx-axxd-5xx8-axx4-6cxxxxxxxxxx\",\n\"lastModifiedBy\": \"u-fbxxxxxx-axxd-5fxx-axx4-6cxxxxxxxxxx\",\n\"accountId\": \"5e8xxxxxxxxxxxxxxxxxxxxx\",\n\"sharedBy\": [],\n\"__v\": 0,\n\"name\": \"Asana Sample_botowner@koreai.in_34\",\n\"keywords\": [],\n\"originalName\": \"Asana Sample\",\n\"icon\": \"58fxxxxxxxxxxxxxxxxxxxxx\",\n\"color\": \"#E44929\"\n}\n</code></pre>"},{"location":"apis/language-updation/","title":"Language Updation API","text":"<p>To update for an existing language\u2019s configuration for a virtual assistant.</p> Method PUT     Endpoint <code>https://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Language Configuration  <li>Admin Console: Language Settings &gt; Language Management </li>"},{"location":"apis/language-updation/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required"},{"location":"apis/language-updation/#sample-request","title":"Sample Request","text":"<pre><code>curl -X PUT \\\nhttps://{{host}}/api/{{version-Id}}/public/bot/{{botId}}/language \\\n-H 'Content-Type: application/json' \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-d '[\n{\n\"updateLanguage\" : \"\",\n\"fileId\":\"\",\n\"multiLingualConfigurations\":{\n\"nluLanguage\": \"language_code\",\n\"inputTranslation\": true/false,\n\"responseTranslation\": true/false\n}\n}\n]'\n</code></pre>"},{"location":"apis/language-updation/#body-parameters","title":"Body Parameters","text":"PARAMETER SUB-PARAMETER DESCRIPTION MANDATE updateLanguage     The language to be enabled based on the language code.     Required     field     The file ID for handling the file upload if the fileUpload <p> language enablement is selected.     Required     multiLingualConfigurations     Required     multiLingualConfigurations.nluLanguage     Refers to the language code of the bot language.     Required     multiLingualConfigurations.inputTranslation     Refers to True/False setting for the input language translation to English.     Required     multiLingualConfigurations.responseTranslation     Refers to the True/False setting for the response language translation to English.     Required"},{"location":"apis/language-updation/#sample-response","title":"Sample Response","text":"<pre><code>[\n{\n\"message\": \"Updated language successfully\",\n\"configurationDetails\": {\n\"dialogs\":3,\n\"alerts\":0,\n\"actions\":0,\n\"knowledgetTasks\":0,\n\"smallTalk\":1,\n\"panels\":0,\n\"widgets\":0 }\n}\n]\n</code></pre>"},{"location":"apis/ml-utterances-export-status/","title":"ML Utterances Export Status API","text":"<p>To get the download link of the ML Utterances export copy.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/mlexport/status</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Utterances Export  <li>Admin Console: Test &gt; Utterances Export and Train </li>"},{"location":"apis/ml-utterances-export-status/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED/OPTIONAL DESCRIPTION host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/ml-utterances-export-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\n'https://{{host}}/api/public/bot/{{bot ID}}/mlexport/status' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n</code></pre>"},{"location":"apis/ml-utterances-export-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/ml-utterances-export-status/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"_id\": \"dx-aaxxxxxx-bxxe-5xxc-bxxf-31xxxxxxxxxx\",\n\"status\": \"SUCCESS\",\n\"percentageComplete\": 100,\n\"streamId\": \"sx-6xxxxxx2-5xx1-5xx0-b9xx-8cxxxxxxxxxx\",\n\"createdBy\": \"u-5dxxxxxx-bxx1-5xx0-axx8-2exxxxxxxxxx\",\n\"jobType\": \"ML_UTTERANCE\",\n\"action\": \"EXPORT\",\n\"countOfDockStatuses\": 1,\n\"fileType\": \"CSV\",\n\"statusLogs\": [],\n\"lMod\": \"2019-06-27T06:49:15.726Z\",\n\"createdOn\": \"2019-06-27T06:49:15.572Z\",\n\"requestedTime\": \"2023-07-25T15:23:36.912Z\",\n\"__v\": 0,\n\"downloadUrl\": \"\"\n}\n</code></pre>"},{"location":"apis/ml-utterances-export/","title":"ML Utterances Export API","text":"<p>To export the ML utterances of a bot by creating a request ID to generate the download link of the bot using the ML Utterance Export Status API.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/mlexport</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Utterances Export  <li>Admin Console: Test &gt; Utterances Export and Train </li>"},{"location":"apis/ml-utterances-export/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/ml-utterances-export/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\ 'https://{{host}}/api/public/bot/{{bot_id}}/mlexport?state=configured&amp;=&amp;type=csv' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json'\n</code></pre>"},{"location":"apis/ml-utterances-export/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/ml-utterances-export/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"IN_PROGRESS\",     \"percentageComplete\": 0,     \"streamId\": \"st-22184e1f-e116-5ed4-8741-7aec3be466d7\",     \"jobType\": \"ML_UTTERANCE\",     \"action\": \"EXPORT\",     \"countOfDockStatuses\": 1,     \"createdBy\": \"u-8214dc3a-c749-5d23-b8ad-2a21bfa396ca\",     \"fileType\": \"CSV\",     \"statusLogs\": [],     \"_id\": \"ds-db32ec69-7f80-5873-890a-576fe585965f\",     \"lMod\": \"2023-07-26T13:15:04.000Z\",     \"createdOn\": \"2023-07-26T13:15:04.983Z\",     \"requestedTime\": \"2023-07-26T13:15:04.984Z\",     \"__v\": 0 }</p>"},{"location":"apis/ml-utterances-import-status/","title":"ML Utterances Import Status API","text":"<p>To get the status of the ML utterances import request made through Import ML Utterances API.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/mlimport/status/{{MLutteranceID}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Utterances Import  <li>Admin Console: Test and Train &gt; Utterances Import </li>"},{"location":"apis/ml-utterances-import-status/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Stream ID of the bot to import the ML Utterances.     Required     MLutteranceID The ID generated in the format Bir-xxxxxxx-xxx-xxxx-xxxxx-xxxxxxxxxx when calling the ML Utterances Import API.     Required"},{"location":"apis/ml-utterances-import-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\ https://{{host}}/api/public/bot/{{BotID}}/mlimport/status/{{MLutteranceID}} \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n-H 'content-type: application/json' \\\n</code></pre>"},{"location":"apis/ml-utterances-import-status/#body-parameters","title":"Body Parameters","text":"<p>No Body Parameters are passed.</p>"},{"location":"apis/ml-utterances-import-status/#sample-response","title":"Sample Response","text":"<p>```json {     \"_id\": \"bxx-7xxxxxxe-5xxb-5xx5-bxx5-88xxxxxxxxxx\",     \"status\": \"success\",     \"streamId\": \"sx-6exxxxxx-5xx1-5xx0-bxx8-8cxxxxxxxxxx\",     \"createdBy\": \"u-5dxxxxxx-bxx1-5xx0-axx8-2exxxxxxxxxx\",     \"requestType\": \"MLimport\",     \"statusLogs\": [],     \"createdOn\": \"2019-06-27T12:03:30.748Z\",     \"__v\": 0,     \"message\": \"File imported completed. 1 utterances copied successfully\" }</p>"},{"location":"apis/ml-utterances-train-status/","title":"ML Utterance Train Status API","text":"<p>To get the ML training status.</p> Method GET     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/ml/train/status?language={{lang}}&amp;state={{state}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Train ML  <li>Admin Console: Test and Train &gt; Train ML </li>"},{"location":"apis/ml-utterances-train-status/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID to be accessed under General Settings on the Bot Builder.     Required     language The Bot language which is identified by the language acronym. For example, en for English and de for German. <p> The user can set the default language of the bot.     Optional     state The state of the bot configured for the In-Development version and published for the published version. <p> Set by default to configured Optional"},{"location":"apis/ml-utterances-train-status/#sample-request","title":"Sample Request","text":"<pre><code>curl -X GET \\\nhttps://{{host}}/api/public/bot/{{BotId}}/ml/train/status \\\n-H 'Content-Type: application/json' \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n</code></pre>"},{"location":"apis/ml-utterances-train-status/#body-parameters","title":"Body Parameters","text":"<p>No Body Parameters are passed.</p>"},{"location":"apis/ml-utterances-train-status/#sample-response","title":"Sample Response","text":"<p>For successful training</p> <pre><code>{\n\"trainingStatus\": \"Finished\",\n\"isMlInSyncWithSentences\": true,\n\"isMlInSyncWithSynonyms\": true,\n\"isMlInSyncWithMlparams\": true,\n\"isMlInSyncWithTraits\": true,\n\"isMlInSyncWithSmallTalk\": true,\n\"isMlInSyncWithUBTraining\": true,\n\"isMlInSyncWithEntityNode\": true,\n\"isMlInSyncWithIntentNode\": true,\n\"isMlInSyncWithPatterns\": true,\n\"isMlInSyncWithBTUtterances\": true,\n\"trainDetails\": {\n\"nlpVersion\": 3,\n\"trainVersion\": 3\n}\n}\n</code></pre> <p>For training in-progress</p> <pre><code>{\n\"trainingStatus\": \"Inprogress\",\n\"isMlInSyncWithSentences\": true,\n\"isMlInSyncWithSynonyms\": true,\n\"isMlInSyncWithMlparams\": true,\n\"isMlInSyncWithTraits\": true,\n\"isMlInSyncWithSmallTalk\": true,\n\"isMlInSyncWithUBTraining\": true\n}\n</code></pre> <p>For failed training</p> <pre><code>{\n\"trainingStatus\": \"Failed\",\n\"isMlInSyncWithSentences\": true,\n\"isMlInSyncWithSynonyms\": true,\n\"isMlInSyncWithMlparams\": true,\n\"isMlInSyncWithTraits\": true,\n\"isMlInSyncWithSmallTalk\": true,\n\"isMlInSyncWithUBTraining\": true\n}\n</code></pre>"},{"location":"apis/ml-utterances-train/","title":"ML Utterances Train API","text":"<p>To initiate the ML training for a bot.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/ml/train</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Train ML  <li>Admin Console: Test and Train &gt; Train ML </li>"},{"location":"apis/ml-utterances-train/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID to be accessed under General Settings on the Bot Builder.     Required"},{"location":"apis/ml-utterances-train/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{BotId}}/ml/train \\\n-H 'auth: {{YOUR_JWT_ACCESS_TOKEN}}' \\\n</code></pre>"},{"location":"apis/ml-utterances-train/#body-parameters","title":"Body Parameters","text":"<p>No Body Parameters are passed.</p>"},{"location":"apis/ml-utterances-train/#sample-response","title":"Sample Response","text":"<p>```json [     {         \"message\": \"Training Queued.\",         \"Training_ID\": \"5dxxxxxxxxxxxxxxxxxxxxxx\"     } ]</p>"},{"location":"apis/proactive-notifications-status/","title":"Proactive Notification Status API","text":"<p>To fetch the status of Proactive Notifications API.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/notify/status/{{requestId}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Proactive Messages  <li>Admin Console: Channel Management &gt; Proactive Messages </li>"},{"location":"apis/proactive-notifications-status/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settingson the Bot Builder. <p> Note: This is required only for Bot Builder API scope of Proactive Messages.     Required     requestId The unique \u2018Request ID\u2019 returned by the Proactive Notifications API to track the progress.     Required"},{"location":"apis/proactive-notifications-status/#sample-request","title":"Sample Request","text":"<pre><code>curl --\nGET \\ 'https://{{host}}/api/public/bot/{{BotID}}/notify/status/{{requestId}}' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'Content-Type: application/json'\n</code></pre>"},{"location":"apis/proactive-notifications-status/#body-parameters","title":"Body Parameters","text":"<p>No body parameters are passed.</p>"},{"location":"apis/proactive-notifications-status/#sample-response","title":"Sample Response","text":"<pre><code>{\n\"_id\": \"ds-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"status\": \"PARTIAL_SUCCESS\", // can be \"SUCCESS\" / \"FAILURE\" / \"PARTIAL_SUCCESS\"\n\"percentageComplete\": 100,\n\"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",\n\"createdBy\": \"u-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"jobType\": \"PROACTIVE_NOTIFICATIONS_API\",\n\"action\": \"PROACTIVE_NOTIFICATIONS\",\n\"statusLogs\": [\n{\n\"_id\": \"nl-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"requestId\": \"ds-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"originalId\": \"john@abc.com\",\n\"status\": \"FAILURE\",\n\"createdBy\": \"u-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"comments\": \"'Identity is not associated with the channel'\",\n\"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",\n\"channel\": \"msteams\",\n\"createdOn\": \"2022-01-24T20:55:21.918Z\",\n\"__v\": 0\n},\n{\n\"_id\": \"nl-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"requestId\": \"ds-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"createdBy\": \"u-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"channel\": \"msteams\",\n\"comments\": \"Notification has been sent successfully\",\n\"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",\n\"koreId\": \"u-xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n\"channelId\": \"29:1964-sxxxxxxxxxxxx-1MxxxxxxxxxxxxxxLqSODuQ\",\n\"messagestoreId\": \"ms-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx\",\n\"originalId\": \"john@abc.com\",\n\"status\": \"SUCCESS\",\n\"createdOn\": \"2022-01-24T20:55:23.029Z\",\n\"__v\": 0\n}\n],\n\"lMod\": \"2022-01-24T20:55:23.000Z\",\n\"createdOn\": \"2022-01-24T20:55:21.254Z\",\n\"requestedTime\": \"2022-01-24T20:55:21.254Z\",\n\"__v\": 0,\n\"count\": 2\n}\n</code></pre>"},{"location":"apis/proactive-notifications/","title":"Proactive Notifications API","text":"<p>Proactive Notifications allow enterprises to engage with their end users (customers or employees) by providing relevant and timely updates.</p> <p>Proactive notification includes:</p> <ul> <li>Nudge the employees to reset their password before it expires in certain days</li> <li>Remind users to submit expense reports.</li> <li>Inform customers about their order status.</li> <li>Other reminders which are defined.</li> </ul> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/notify</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Proactive Messages  <li>Admin Console: Channel Management &gt; Proactive Messages </li>"},{"location":"apis/proactive-notifications/#path-parameters","title":"Path Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotId Bot ID or Stream ID can be accessed under General Settings on the Bot Builder. <p> Note: This is required only for Bot Builder API scope of Proactive Messages.     Required"},{"location":"apis/proactive-notifications/#sample-request","title":"Sample Request","text":"<pre><code>curl --location --request POST \\' https://{{host}}/api/public/bot/{{BotID}}/notify' \\\n--header 'auth: {YOUR_JWT_ACCESS_TOKEN}' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\n\"channel\": \"msteams\",\n\"userIdentityType\": \"resolve\",\n\"message\": {\n\"type\": \"text\",\n\"val\": \"hello\"\n},\n\"identities\": [\n\"john@kore.com\",\n\"jane@outlook.com\",\n\"sam@slack.com\"\n]\n}'\n</code></pre>"},{"location":"apis/proactive-notifications/#body-parameters","title":"Body Parameters","text":"PARAMETER DESCRIPTION MANDATE channel     Name of the channel for which notifications to be sent <p> Accepted channel types are:\u201cmsteams\u201d and \u201cslack\u201c.     Required     userIdentityType     Define whether to resolve the user identities provided in the API call to get the channel identities, or to directly use the user identities for delivering the messages <p> The values is resolve.     Required     message     It is an object and accepts two fields <ul> <li>type \u2192 Indicates the type of message. \u201ctext\u201d for sending plain text and \u201cscript\u201d for sending JavaScript templates as messages.  <li>val \u2192 value of the message to be sent to user.  <p> Example 1:Text: \\ <code>{ \\ \"type\": \"text\", \\ \"val\": \"Hi User\" \\ }</code> <p> Example 2: Script: <p> <code>{ \\ \"type\": \"script\", \\ \"val\": \"var envMsg = 'John'; var channel = context.session.BotUserSession.lastMessage.channel; print(JSON.stringify({text: 'Hi ' + envMsg + ' message is from ' + channel + ' channel'}));\" \\ }</code> Required     identities     It accepts the list of user identities for whom notifications need to be sent. <p> A maximum of 1000 identities are supported.     Required"},{"location":"apis/proactive-notifications/#sample-response","title":"Sample Response","text":"<p>```json {     \"status\": \"IN_PROGRESS\",     \"percentageComplete\": 0,     \"streamId\": \"st-xxxxx-xxx-xxx-xxx-xxxxx\",     \"createdBy\": \"u-xxxxx-xxx-xxx-xxx-xxxxx\",     \"jobType\": \"PROACTIVE_NOTIFICATIONS_API\",     \"action\": \"PROACTIVE_NOTIFICATIONS\",     \"statusLogs\": [],     \"_id\": \"ds-xxxxx-xxx-xxx-xxx-xxxxx\",     \"lMod\": \"2022-01-25T06:56:48.000Z\",     \"createdOn\": \"2022-01-25T06:56:48.891Z\",     \"requestedTime\": \"2022-01-25T06:56:48.891Z\",     \"__v\": 0 }</p>"},{"location":"apis/publish-bot/","title":"Publish Bot API","text":"<p>To initiate a publish request for a bot.</p> <p>Note</p> <p>Before calling the API, ensure that at least one channel is enabled for the bot.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/publish</code> <p> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Bot Publish &gt; Publish </li>"},{"location":"apis/publish-bot/#path-parameters","title":"Path Parameters","text":"PARAMETER REQUIRED DESCRIPTION host     Required     The environment URL. For example, <code>https://bots.kore.ai</code> BotId     Required     Bot ID or Stream ID can be accessed under General Settings on the Bot Builder. <p> Note: This is required only for Bot Builder API scope of Proactive Messages."},{"location":"apis/publish-bot/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/bot/{{BotID}}/publish \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-H 'content-type: application/json' \\\n-d '{\n\"versionComment\" : \"new update\",\n\"initiateTraining\": \"true\"\n}'\n</code></pre>"},{"location":"apis/publish-bot/#body-parameters","title":"Body Parameters","text":"PARAMETER REQUIRED DESCRIPTION versionComment     Required     Comments for your Publish request.     initiateTraining     Optional     Indicates whether to trigger or skip the training process when publishing the bot: <ul> <li>true: Initiate the training.  <li>false: Skip the training.  <p> Note: By default, the platform automatically initiates training upon bot publishing to ensure that the bot is trained with the latest ML and KG changes. Skipping the training can result in issues in intent detection and flow execution."},{"location":"apis/publish-bot/#sample-response","title":"Sample Response","text":"<pre><code>[\n{\n\"resourceType\": \"dialog\",\n\"resourceId\": \"dg-606c7f53-e94a-58ff-8b98-d83ce03e6360\",\n\"sbResourceId\": \"dg-606c7f53-e94a-58ff-8b98-d83ce03e6360\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"visibility\": {\n\"namespace\": \"enterprise\",\n\"namespaceIds\": [\n\"o-23b63f37-89e7-52e9-bc5d-8012cbda0d4a\"\n]\n},\n\"contextLifeTime\": {\n\"options\": \"close\"\n},\n\"version\": \"1.0\",\n\"nodes\": [\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false\n},\n\"nodeId\": \"intent0\",\n\"type\": \"intent\",\n\"transitions\": [\n{\n\"default\": \"entity1\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy0\"\n}\n}\n],\n\"metadata\": {\n\"left\": 19,\n\"top\": 142\n},\n\"componentId\": \"dc-4935f617-c82d-5c39-96d6-4df11f48bd99\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"precedence\": \"entityOverIntent\"\n},\n\"nodeId\": \"entity1\",\n\"type\": \"entity\",\n\"transitions\": [\n{\n\"metadata\": {\n\"connId\": \"dummy1\",\n\"color\": \"#299d8e\"\n},\n\"default\": \"entity2\"\n}\n],\n\"metadata\": {\n\"left\": 9,\n\"top\": 312\n},\n\"componentId\": \"dc-a62d7d10-3ed2-5fb8-afc1-1d75b12e0253\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"precedence\": \"entityOverIntent\"\n},\n\"nodeId\": \"entity2\",\n\"type\": \"entity\",\n\"transitions\": [\n{\n\"metadata\": {\n\"connId\": \"dummy6\",\n\"color\": \"#299d8e\"\n},\n\"then\": \"message3\",\n\"if\": {\n\"value\": \"15\",\n\"op\": \"eq\",\n\"field\": \"entity2\"\n}\n},\n{\n\"metadata\": {\n\"connId\": \"dummy7\",\n\"color\": \"#5ea8d3\"\n},\n\"then\": \"message4\",\n\"if\": {\n\"value\": \"30\",\n\"op\": \"eq\",\n\"field\": \"entity2\"\n}\n},\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy3\"\n}\n}\n],\n\"metadata\": {\n\"left\": 24,\n\"top\": 467\n},\n\"componentId\": \"dc-64fc56de-b475-5071-b839-7615d600bf9b\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false\n},\n\"nodeId\": \"message3\",\n\"type\": \"message\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy5\"\n}\n}\n],\n\"metadata\": {\n\"left\": 318,\n\"top\": 373\n},\n\"componentId\": \"dc-fb7bb786-8bd8-5f40-a2f9-92642c43ae5c\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false\n},\n\"nodeId\": \"message4\",\n\"type\": \"message\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy7\"\n}\n}\n],\n\"metadata\": {\n\"top\": 627,\n\"left\": 278\n},\n\"componentId\": \"dc-32f800ce-f457-545c-846f-8e0b64c6c58c\"\n}\n],\n\"isPublishedVersion\": false,\n\"idp\": \"none\",\n\"state\": \"awaitingApproval\",\n\"languages\": [],\n\"compatibility\": [],\n\"adminTaskStatus\": \"active\",\n\"editable\": true,\n\"isHidden\": false,\n\"approvedLanguages\": [],\n\"approvalRequestedLanguages\": [\n\"en\"\n],\n\"localeData\": {\n\"en\": {\n\"name\": \"mortgage\",\n\"shortDesc\": \"\"\n}\n},\n\"isFollowUp\": false,\n\"interruptOptions\": {\n\"type\": {\n\"option\": \"developer\",\n\"message\": \"\"\n},\n\"priority\": \"task\",\n\"interruptsEnabled\": true,\n\"holdUxOptions\": {\n\"option\": \"discardCurrTaskNoNotify\",\n\"message\": \"\"\n}\n},\n\"_id\": \"dg-606c7f53-e94a-58ff-8b98-d83ce03e6360\",\n\"refId\": \"682f9675-07a2-5505-aa75-52fd2c4d1a17\",\n\"followUpIntents\": [\n{\n\"refId\": \"19ad68d9-beb9-5670-ba73-47cf4e8cb1e7\",\n\"transitions\": [],\n\"interruptOptions\": {\n\"type\": {\n\"option\": \"developer\",\n\"message\": \"\"\n},\n\"interruptsEnabled\": true,\n\"holdUxOptions\": {\n\"option\": \"discardCurrTask\",\n\"message\": [\n\"Discarded current task to switch to new task\"\n]\n},\n\"parameterMap\": {\n\"preAssignments\": [\n{\n\"Place\": \"\",\n\"preDefined\": true,\n\"entityId\": \"dc-325a8628-ef8b-5411-853b-f6b51e6f43aa\"\n},\n{\n\"Day\": \"\",\n\"preDefined\": true,\n\"entityId\": \"dc-33d98b9a-f332-505b-b370-c63b7d22edc9\"\n},\n{\n\"Time\": \"\",\n\"preDefined\": true,\n\"entityId\": \"dc-d24a083d-e8e0-51c0-ba25-216ba5439ee2\"\n}\n],\n\"postAssignments\": [\n{\n\"mortType\": \"\",\n\"preDefined\": true,\n\"entityId\": \"dc-29155c38-86f4-5124-b704-e932f55b0623\"\n},\n{\n\"frType\": \"\",\n\"preDefined\": true,\n\"entityId\": \"dc-7af53bfd-eff5-5e0d-84c5-24d22d8fa150\"\n}\n]\n}\n}\n}\n],\n\"botId\": \"st-b4543a96-49ec-5d95-a120-c6244fc23777\",\n\"createdBy\": \"u-3ae8bd39-a65b-5b2c-b55b-85864a8202c3\",\n\"createdOn\": \"2018-12-05T07:45:19.391Z\",\n\"lModBy\": \"u-3ae8bd39-a65b-5b2c-b55b-85864a8202c3\",\n\"lMod\": \"2018-12-05T07:53:13.000Z\",\n\"lname\": \"mortgage\",\n\"__v\": 0,\n\"versionComment\": \"new update\",\n\"publishedOn\": \"2018-12-05T07:53:13.237Z\",\n\"name\": \"mortgage\"\n}\n},\n{\n\"resourceType\": \"dialog\",\n\"resourceId\": \"dg-b68f22ad-19b8-5894-857a-04156d391b44\",\n\"sbResourceId\": \"dg-b68f22ad-19b8-5894-857a-04156d391b44\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"visibility\": {\n\"namespace\": \"enterprise\",\n\"namespaceIds\": [\n\"o-23b63f37-89e7-52e9-bc5d-8012cbda0d4a\"\n]\n},\n\"contextLifeTime\": {\n\"options\": \"close\"\n},\n\"version\": \"1.0\",\n\"nodes\": [\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"message\": [],\n\"errorMessage\": []\n},\n\"nodeId\": \"intent0\",\n\"type\": \"intent\",\n\"transitions\": [\n{\n\"default\": \"entity2\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy0\"\n}\n}\n],\n\"metadata\": {\n\"left\": 175,\n\"top\": 64\n},\n\"componentId\": \"dc-4a22c00f-a5f8-5c2b-819b-db264a4a399b\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"isOptional\": false,\n\"message\": [],\n\"errorMessage\": [],\n\"precedence\": \"entityOverIntent\"\n},\n\"nodeId\": \"entity1\",\n\"type\": \"entity\",\n\"transitions\": [\n{\n\"default\": \"entity3\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy1\"\n}\n}\n],\n\"metadata\": {\n\"left\": 235,\n\"top\": 396\n},\n\"componentId\": \"dc-d2794a44-f565-5de3-8073-5321a773c044\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"node\",\n\"type\": {\n\"option\": \"developer\"\n},\n\"interruptsEnabled\": true,\n\"holdUxOptions\": {\n\"option\": \"discardCurrTaskNoNotify\",\n\"message\": \"\"\n}\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"message\": [],\n\"errorMessage\": [],\n\"isOptional\": false,\n\"precedence\": \"entityOverIntent\"\n},\n\"nodeId\": \"entity2\",\n\"type\": \"entity\",\n\"transitions\": [\n{\n\"default\": \"entity1\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy3\"\n}\n}\n],\n\"metadata\": {\n\"left\": 175,\n\"top\": 227\n},\n\"componentId\": \"dc-9f065640-c0b6-5e86-8de7-d19997adb487\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"message\": [],\n\"errorMessage\": [],\n\"precedence\": \"entityOverIntent\"\n},\n\"nodeId\": \"entity3\",\n\"type\": \"entity\",\n\"transitions\": [\n{\n\"default\": \"message4\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy5\"\n}\n}\n],\n\"metadata\": {\n\"left\": 768,\n\"top\": 404\n},\n\"componentId\": \"dc-8f9c6361-47f7-519b-950d-0b97b5b80ffb\"\n},\n{\n\"nodeOptions\": {\n\"transitionType\": \"auto\",\n\"promptOptions\": \"required\",\n\"reuseMarkedupPhrases\": false,\n\"interruptOptions\": {\n\"priority\": \"task\"\n},\n\"transitionMode\": \"initiateCurrentTask\",\n\"inputHandlingOptions\": \"useAsEntityValue\",\n\"reuseOptions\": \"1\",\n\"noAutoCorrection\": false,\n\"notForReuse\": false,\n\"message\": [],\n\"errorMessage\": []\n},\n\"nodeId\": \"message4\",\n\"type\": \"message\",\n\"transitions\": [\n{\n\"default\": \"end\",\n\"metadata\": {\n\"color\": \"#299d8e\",\n\"connId\": \"dummy7\"\n}\n}\n],\n\"metadata\": {\n\"left\": 786,\n\"top\": 58\n},\n\"componentId\": \"dc-45d51547-e374-5b90-ba1a-3fe620f9ab89\"\n}\n],\n\"isPublishedVersion\": false,\n\"idp\": \"none\",\n\"state\": \"awaitingApproval\",\n\"languages\": [],\n\"compatibility\": [],\n\"adminTaskStatus\": \"active\",\n\"editable\": true,\n\"isHidden\": false,\n\"approvedLanguages\": [],\n\"approvalRequestedLanguages\": [\n\"en\"\n],\n\"localeData\": {\n\"en\": {\n\"name\": \"Support\",\n\"shortDesc\": \"Schedule\"\n}\n},\n\"isFollowUp\": false,\n\"interruptOptions\": {\n\"priority\": \"bot\"\n},\n\"_id\": \"dg-b68f22ad-19b8-5894-857a-04156d391b44\",\n\"refId\": \"19ad68d9-beb9-5670-ba73-47cf4e8cb1e7\",\n\"botId\": \"st-b4543a96-49ec-5d95-a120-c6244fc23777\",\n\"createdBy\": \"u-3ae8bd39-a65b-5b2c-b55b-85864a8202c3\",\n\"createdOn\": \"2018-12-05T07:45:19.402Z\",\n\"lModBy\": \"u-3ae8bd39-a65b-5b2c-b55b-85864a8202c3\",\n\"lMod\": \"2018-12-05T07:53:13.000Z\",\n\"lname\": \"support\",\n\"__v\": 0,\n\"versionComment\": \"new update\",\n\"publishedOn\": \"2018-12-05T07:53:13.236Z\",\n\"name\": \"Support\"\n}\n},\n{\n\"resourceType\": \"NL\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"resourceId\": \"NL\",\n\"resourceType\": \"NL\",\n\"modules\": [\n\"nl_model\",\n\"settings\"\n],\n\"name\": \"Natural Language\"\n}\n},\n{\n\"resourceType\": \"CHANNELS\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"resourceId\": \"CHANNELS\",\n\"resourceType\": \"CHANNELS\",\n\"modules\": [\n\"alexa\"\n],\n\"name\": \"Channels\"\n}\n},\n{\n\"resourceType\": \"EXTENSIONS\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"resourceId\": \"EXTENSIONS\",\n\"resourceType\": \"EXTENSIONS\",\n\"modules\": [\n\"botkit\",\n\"agent_transfer\",\n\"websdk\",\n\"events\"\n],\n\"name\": \"Extensions\"\n}\n},\n{\n\"resourceType\": \"SETTINGS\",\n\"status\": \"SUCCESS\",\n\"result\": {\n\"resourceId\": \"SETTINGS\",\n\"resourceType\": \"SETTINGS\",\n\"modules\": [\n\"general\",\n\"bot_variables\",\n\"pii\",\n\"ivr\",\n\"hold_resume\",\n\"custom_script\",\n\"advanced\"\n],\n\"name\": \"Settings\"\n}\n}\n]\n</code></pre>"},{"location":"apis/update-nlp-configurations/","title":"Update NLP Configurations","text":"<p>To update the NLP thresholds and configurations.</p> Method POST     Endpoint <code>https://{{host}}/api/public/bot/{{BotID}}/configurations?language={{languageCode}}&amp;groupName={{groupName}}</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: NLP Configurations  <li>Admin Console: Test &gt; NLP Configurations &amp; Train </li>"},{"location":"apis/update-nlp-configurations/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host The environment URL. For example, <code>https://bots.kore.ai</code> Required     BotID The Bot ID or Stream ID that can be accessed under General Settings on the Bot Builder.     Required     languageCode The Bot language in which the configurations need to be updated.     Required     groupName The GroupName can be used to update the ML parameters of a specific group.  To update Bot level Intent Model Configurations, groupName should be set to \u201cBot Level Intent Model\u201c.     Required <p> for Multiple ML Model"},{"location":"apis/update-nlp-configurations/#sample-request","title":"Sample Request","text":"<pre><code>curl --location -g --request POST \\\n'https://{{host}}/api/public/bot/{{bot-id}}/configurations?language={{languageCode}}' \\\n--header 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n--header 'content-type: application/json' \\\n--data-raw '{\n\"advancedNLPSettings\": [\n{\n\"configurationKeyName\": \"NoneIntent\",\n\"configurationValue\": true,\n\"nlpEngine\": \"ML\"\n}\n],\n\"configurations\": [\n{\n\"mode\": \"ml\",\n\"exactMatchThreshold\": 85,\n\"useDependencyParser\": true,\n\"minThreshold\": 0.2\n},\n{\n\"mode\": \"faq\",\n\"useBotSynonyms\": true,\n\"searchInAnswer\": {\n\"enabled\": true,\n\"notifyUser\": false,\n\"responseType\": \"relevantWithReadMore\",\n\"customReadMoreURL\": \"aa\",\n\"useCustomReadMoreURL\": true\n}\n}\n],\n\"mlParams\": {\n\"intentParams\": {\n\"features\": \"skip_gram\",\n\"skip_gram\": {\n\"seqLength\": 3,\n\"maxSkipDistance\": 2\n}\n}\n},\n\"nlSettings\": {\n\"enableAutoUtteranceAddition\": false,\n\"enableNegativePatterns\": true\n}\n}'\n</code></pre>"},{"location":"apis/update-nlp-configurations/#body-parameters","title":"Body Parameters","text":"<p>The parameters depend on the threshold configuration that needs to be updated. The comprehensive list of the parameters for the various threshold configurations is given below:</p>"},{"location":"apis/update-nlp-configurations/#update-settings","title":"Update Settings","text":""},{"location":"apis/update-nlp-configurations/#machine-learning-engine","title":"Machine Learning Engine","text":"<p>This section refers to the configurations related to the Machine Learning engine. For details on the configurations, please click here.</p> <p>```json {     \"configurations\": [         {             \"mode\": \"ml\",               // Machine Learning Engine             \"exactMatchThreshold\": 90,  // ML Definitive Score - value in range [80-100]             \"minThreshold\": 0.4        // ML threshold - value in range [0-1]         }     ],     \"mlParams\": {         \"intentParams\": {             \"useSynonyms\": true,       // Bot Synonyms             \"useStopwords\": true,      // Stopwords             \"usePlaceholders\": true,   // Entity Placeholders             \"features\": \"skip_gram\",       // Feature Extraction - value in range [skip_gram, n_gram]             \"skip_gram\": {             // features should be 'skip_gram'                 \"seqLength\": 2,        // Sequence Length - value in range [2-4]                 \"maxSkipDistance\": 1   // Maximum Skip Distance - value in range [1-3]               }               // ngram Sequence Length - value in range [1-4]                                        // features should be 'n_gram'         },         \"nerParams\": {             \"type\": \"corenlp\"          // NER Model                                        // could be \"corenlp\" for  Conditional Random Field                                        //       or \"spacy\" -  Deep Neural Network          }     } }</p>"},{"location":"apis/upload-file/","title":"Upload File API","text":"<p>To upload the botdefinition, botconfig, and botfunction files (if any) and the bot icon to the local server. Additionally, the API fetches the file ID to be used in Import Bot API.</p> <p>Note</p> <p>You need to upload the files separately. You can upload a file by signing with any app created by the account administrator.</p> Method POST     Endpoint <code>https://{{host}}/api/public/uploadfile</code> Content Type <code>application/json</code> Authorization <code>auth: {{JWT}}</code> <p> See How to generate the JWT Token.     API Scope <ul> <li>Bot Builder: Not Applicable  <li>Admin Console: Not Applicable </li>"},{"location":"apis/upload-file/#query-parameters","title":"Query Parameters","text":"PARAMETER DESCRIPTION MANDATE host     The environment URL. For example, <code>https://bots.kore.ai</code> Required"},{"location":"apis/upload-file/#sample-request","title":"Sample Request","text":"<pre><code>curl -X POST \\\nhttps://{{host}}/api/public/uploadfile \\\n-H 'auth: YOUR_JWT_ACCESS_TOKEN' \\\n-H 'content-type: multipart/form-data' \\\n-F file=@botDefinition.json \\\n-F fileContext=bulkImport \\\n-F fileExtension=json\n</code></pre>"},{"location":"apis/upload-file/#body-parameters","title":"Body Parameters","text":"<p>The following parameters are Required and passed based on the file id.</p> <p>For Bot Definition File ID</p> PARAMETER DESCRIPTION file Upload the Botdefinition.json file.     fileContext bulkImport     fileExtension .json     <p>For Bot Config File ID</p> PARAMETER DESCRIPTION file Upload the Botconfig.json file.     fileContext bulkImport     fileExtension .json     <p>For Bot Function File ID</p> PARAMETER DESCRIPTION file Upload the Bot function file.     fileContext bulkImport     fileExtension .js     <p>For Bot icon File ID</p> PARAMETER DESCRIPTION file Upload the Bot icon file.     fileContext bulkImport     fileExtension .json     <p>For ML Utterances File ID</p> PARAMETER DESCRIPTION file Upload the ML Utterance file (.json or .csv)     fileContext bulkImport     fileExtension .json or .csv"},{"location":"app-settings/app-profile/","title":"General Settings","text":"<p>To modify the general settings of a bot:</p> <ol> <li>Select the Build tab from the top.</li> <li>Click Configuration &gt; General Settings. </li> </ol>"},{"location":"app-settings/app-profile/#general-bot-settings","title":"General Bot Settings","text":"<p>Modify one or more of the settings described in the following table.</p> FIELD DESCRIPTION Bot Name     The name of the Bot. When a Bot is published, the Name cannot be changed. This field is required.     Description     The description of the Bot. This field is required.     Icon     The icon image for the Bot displayed in Bot Builder, Bots Marketplace, and the end-user interface as shown in the previous illustration. The image format must be .png and best results are obtained using a 200 x 200-pixel image. This field is required.     Target Audience     <ul> <li>Select General Public if the bot is for public use for both managed and unmanaged users in your domain. Bot assignments are not required and when the Bots Admin deploys the bot, it is available for use by all domain users. Use this option to make a bot widely available for all user types.   <li>Select Enterprise Users if the bot is for managed users only in a domain, for example, for your employees or paid customers. After the Bots Admin approves and deploys this bot, it is not available to any managed users unless explicitly assigned by the Bots Admin. Use this option when you want to control which managed users in your domain can access and set up this bot on their devices. Once Target Audience is defined and saved, you cannot change them. </li> Default Bot Language     This is uneditable and is set at the time of Bot creation.     Bot Id     Non-editable, assigned by the platform. Can be copied for use in API calls etc..     Variable Namespaces     You can categorize variables using Namespaces and map them to various components. The XO Platform will load the variables only from the mapped namespaces while executing specific components. .     Subdomain (Tenancy)     Click Yes to enable the use of tenancy. When the tenancy is defined, the end-user is prompted to enter a tenant name as part of the URL for the Bot, for example, kore, for the www.kore.someWebService.com tenant-specific URL. When enabled define the following properties: <ul> <li>Help Hint \u2013 The text displayed to the end-user to prompt the user to enter a tenant-specific URL for the Bot.   <li>Base URL \u2013 The base URL for the Bot that the end-user must specify their company to complete the tenant-specific URL using the following syntax: https://{tenant}.someWebService.com where {tenant}, including the braces, represents the tenant name.  </li> Show link for task setup/execution     <ul> <li>Select Yes to display a link to enable the choice for a user to input information used to execute a task in a user interface form or input the data directly into the message input field, for example, Enter the title for new Asana task. To make edits, click here. where here is a link to a form with fields.   <li>When No is selected, the user can only input information for the task in the message input field. For example, Enter the title for a new Asana task. </li> Error Message(s)     Edit or add custom HTTP Status Codes and error messages for your Bot. For more information, see Customizing Error Messages.     <p>To save the Bot settings, click Save. The &lt; Bot Name &gt; updated successfully message is displayed.</p>"},{"location":"app-settings/app-profile/#customizing-error-messages","title":"Customizing Error Messages","text":"<p>In Bot Builder, each Bot and task contains a set of predefined error messages along with actions for standard HTTP Status codes returned for an HTTP Request method. In most cases, the default response and action are sufficient for an end-user response, however, you may need to handle other HTTP Status codes not defined by default, or customize the error message itself, or change the default response by Kore.ai in the event of an error. This topic describes how to customize and create error messages for Kore.ai Bots and tasks. When you create a Bot or a task, you can add or customize error messages for HTTP Status codes in the Error Messages section of the Bot or task settings. </p> <p></p>"},{"location":"app-settings/app-profile/#custom-status-codes","title":"Custom Status Codes","text":"<p>There are approximately 25 HTTP Status codes defined by default for a Bot or task. To customize an HTTP Status code</p> <ol> <li>Open the Bot or task in Bot Builder</li> <li>Select Build tab from top menu</li> <li>From the left menu click Configurations -&gt; General Settings</li> <li>Scroll down to locate the Error Messages section.</li> <li> <p>Click the Edit </p> </li> <li> <p>In the Message Type field, select one of:</p> <ol> <li>Custom \u2013 Displays a Custom Message field to define an error-specific message for the end-user.</li> <li>Source \u2013 Displays the Error Paths field where you can define the JSON path from the JSON response payload for HTTP Status codes other than those in the 2XX range (success messages).</li> </ol> </li> <li> <p>In the Action field, specify the action to take when the number of consecutive errors defined in the Error Recurrence field is reached. Select one of:</p> <ol> <li>Disable \u2013 The task is set to Inactive when the error occurs. The end-user can activate the task when needed.</li> <li>Reschedule \u2013 Displays the Retry Interval field used to define the elapsed time in minutes after which to retry the task when the error occurs.</li> <li>Disable Auth \u2013 When the error occurs, the authorization mechanism defined for the task is disabled. Any other task that uses the same authorization mechanism is also disabled.</li> <li>Notify \u2013 Displays the error message in the end-user interface. </li> </ol> </li> <li> <p>In the Message field (available only for the default messages), enter the text message displayed to the end-user.</p> </li> <li>In the Error Recurrence field, specify the number of consecutive error codes must be returned before the action is executed. By default, the Error Recurrence field is set to \u201d 1 \u201c.</li> <li>Click Add to save and close the Setup Error Message dialog for your custom error message.</li> </ol> <p>To create a new HTTP Status code, click Add Error Message, define the fields for your new code as described in the preceding section, and then click Add.</p>"},{"location":"app-settings/integrations/actions/actions/","title":"Actions","text":"<p>The Kore.ai XO Platform offers pre-built integrations with popular business applications to exchange data. You can configure and enable actions for Service Now, Salesforce, Zendesk, Hubspot, and others. Each of these integrations provides a full conversation flow definition, a low-code interface for API integration, and pre-built response mapping and create dialog tasks with pre-built templates without need to worry about developer assistance.</p> <p>Watch a Short Video on System Integrations</p> <p></p>"},{"location":"app-settings/integrations/actions/actions/#steps-to-use-the-actions-or-pre-built-integrations","title":"Steps to use the actions or pre-built integrations","text":"<ol> <li>Enable the Developer or a User to do a single-click authorization.</li> <li>Enable an integration to exchange data between two systems during the dialog task execution.</li> <li>Enable an integration and create the dialog tasks using the preconfigured templates supported by the integration.</li> </ol> <p>The Actions module is available under the Build &gt; Integrations menu.</p>"},{"location":"app-settings/integrations/actions/actions/#actions-enablement","title":"Actions Enablement","text":"<p>By default, your Virtual Assistant (VA) will not exchange data with any integration unless you authorize one or more actions through which it can communicate. You can enable an integration and perform actions in a third-party system. </p>"},{"location":"app-settings/integrations/actions/actions/#authorization-types","title":"Authorization Types","text":"<p>The Kore.ai XO Platform supports OAuth 2.0, Basic, and API key based authentication to allow an integration to exchange data.</p>"},{"location":"app-settings/integrations/actions/actions/#oauth-v2-authentication","title":"OAuth v2 Authentication","text":"<p>OAuth v2 is the new version of the open protocol to allow secure authorization via a standard method from web, mobile, and desktop applications. To learn how OAuth v2 authentication works, read the Setting Up Authorization using OAuth v2 article.</p>"},{"location":"app-settings/integrations/actions/actions/#basic-http-authentication","title":"Basic HTTP Authentication","text":"<p>HTTP Basic Auth is a simple method that creates a username and password style authentication for HTTP requests. This technique uses a header called Authorization, with a base64 encoded representation of the username and password. For more information, read the Bot Authorization Overview article.</p>"},{"location":"app-settings/integrations/actions/actions/#api-key","title":"API Key","text":"<p>Identification and authorization token generated or provided by a web application or web service used to identify the incoming application request, and in some cases, also provides authentication for secure access. For more information, read the Setting Up Authorization using an API Key article. </p> <p>Actions can be authorized based on the authorization profiles that are supported by the third-party  integrations.  Users can use pre-authorized credentials provided by the developer during the configuration process or their own authorization profile during the configuration process to let the end user authorize during the conversation.</p> <p>Note</p> <p>An email notification is sent to all the bot developers when the authorization token expires for any of the Prebuilt Action Integrations in the bot. The notification requests the bot developer to reauthorize. The integration moves to an error state as soon as the token expires. The service call fails during the run time, upon expiry of authorization token and an error message, \"Something went wrong\" is displayed to the end-user.</p> <p>The email template which is sent to the bot developer upon token expiry is as follows: </p>"},{"location":"app-settings/integrations/actions/actions/#available-actions-and-how-to-configure-them","title":"Available Actions and How to Configure Them","text":"<p>The available Actions/Integrations are listed in the table below. Go to Build &gt; Integrations &gt; Actions and click the Action you want to configure in the Kore.ai XO platform. The page with Instructions and Configuration settings will slide out. For step-by-step instructions on how to configure an action, click the Learn more link for the action in the table below.</p> Actions Descriptions Supported Templates  Authorization Type More Information Azure OpenAi     Integrates with Azure OpenAI instance to find answers to your general queries..     1     Basic Auth     Learn more BambooHR     Integrates with BambooHR software for small and medium businesses and those who work in them.     7     Basic Auth     Learn more DHL     Integrates with DHL system to find information regarding DHL Locations and Track Shipments.     2     Basic Auth     Learn more Freshdesk      Integrates with Freshdesk to create, view, update, search and delete tickets.     6     Basic Auth     Learn more Freshservice ITSM     Integrates with Freshservice ITSM to create, view, update, search and delete tickets.     6     Basic Auth     Learn more Google Maps     Integrates with Google Maps to find information regarding accurate Locations and places.     2     Basic Auth     Learn more HubSpot      Integrates with HubSpot CRM to customize the lead details through a virtual assistant.     10     Dev OAuth and OAuth     Learn more JIRA      Integrates with JIRA to create, view, update and delete issues.     5     Basic Auth     Learn more Microsoft Graph      Integrates with Microsoft Graph to create, view, and update events and to-do lists, and send emails to users.     5     Basic Auth     Learn more OpenAI     Integrates with OpenAI ChatGPT to generate answers from context and extract skills from the resume through a virtual assistant.     2     API Key OAuth     Learn more Salesforce CRM     Integrates with Salesforce CRM to power your conversations to create Leads / Opportunities and other functions.     7     Dev OAuth and OAuth     Learn more Shopify     Integrates with Shopify Shop instance to find information regarding Customers, Products, and Orders.     6     Basic OAuth     Learn more ServiceNow     Integrates with ServiceNow to build the digital workflows on a single, unified platform.     10     Basic OAuth     Learn more Stripe     Integrates with Stripe to accept payments, send payouts, and manage the payment to complete payment-related tasks.     5     Basic OAuth     Learn more Twilio Verify     Integrates with Twilio Verify to send SMS, start verification and check verification.     3     Basic OAuth     Learn more Zendesk     Integrates with Zendesk instance to create ticket, view all tickets, search tickets with IDs and search ticket with keywords.     5     Basic OAuth     Learn more"},{"location":"app-settings/integrations/actions/actions/#disabling-or-deleting-actionsintegrations","title":"Disabling or Deleting Actions/Integrations","text":"<p>You can disable or delete an external integration that you configured earlier. This is useful in case you want to switch to another integration and are no longer using the configured integration.</p>"},{"location":"app-settings/integrations/actions/actions/#disabling-an-integrationaction","title":"Disabling an Integration/Action","text":"<p>Disabling the integration action will change its status from enabled to disabled, but the authorization configurations associated with it will remain the same.</p> <p>Steps to disable an integration.</p> <ol> <li>To disable the integration, hover over it in the actions list and click the Settings icon in the top right corner.</li> <li> <p>If the action/integration is enabled, you will have the option to Disable it, and vice versa. </p> </li> <li> <p>Once you Disable an action, the authorization configurations related to that particular action are disabled with no changes.</p> </li> <li> <p>The service node status changes from Integration Service to Custom Service. </p> </li> <li> <p>If you need to enable a previously disabled action, you can do so by hovering over it in the actions list and clicking on the Settings icon located in the top right corner as shown in the figure below. </p> </li> <li> <p>You will be redirected to re-authorize the action with your external integration account credentials. For more information related to how to authorize an integration action, see Authorization article.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/actions/#deleting-an-integrationaction","title":"Deleting an Integration/Action","text":"<p>You can delete an external integration that is no longer in use.</p> <p>Steps to delete an integration:</p> <ol> <li>To delete the integration, hover over it in the actions list and click the Settings icon in the top right corner.</li> <li>Choose the option to Delete the action/integration. </li> </ol> <p>Warning: Deletion is permanent and cannot be undone. You are asked to confirm your choice, so make sure this is exactly what you want to do. Once an action is Deleted, all authorization configurations related to that particular integration are deleted.</p>"},{"location":"app-settings/integrations/actions/actions/#more-like-this","title":"More Like This","text":"<ul> <li>Kore.ai Integrations Framework Guide</li> <li>Configure Salesforce Integrations Actions (Video: 3m15s)</li> </ul>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/","title":"Configuring the Asana Action","text":"<p>The Kore.ai XO Platform lets you easily connect with your Asana instance to find information regarding projects, users, and tasks. Learn more about Asana.</p> <p>This document explains how to authorize and enable the Asana action and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication to allow Asana integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the Asana integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Asana app to access an access token at runtime. To learn more about Asana, see Asana Documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/#enable-the-asana-action","title":"Enable the Asana Action","text":"<p>Prerequisites:</p> <p>Before enabling the Asana action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have Asana account credentials, create an account in the Asana Developer console and note down the login credentials. See Asana Documentation for more information.</li> <li>Create a custom app on the Asana admin page.</li> <li>Copy your Asana account\u2019s personal access token and keep it for future use.</li> </ul>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with the preconfigured Kore.ai app with the Basic Auth option.</p> <p>Steps to authorize an Asana action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li> <p>Select the Asana from the list of Available actions. </p> </li> <li> <p>In the Configurations dialog, select the Authorization tab.</p> </li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>Personal Access Token \u2013 Enter the access token of your Asana account. </p> </li> </ol> </li> <li> <p>Click Save. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> <p>Note: The Asana action is moved from Available to Configured region.</p> </li> <li> <p>You can also click the Skip for Now button to install the Dialog Task templates later. To learn how to use action templates, read the Using the Asana Action Templates article. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/#allow-end-users-to-authorize","title":"Allow End Users to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Asana app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize an Asana action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Asana action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.</li> <li> <p>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Asana app for authorization. To create a profile, click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the API Key option. To create Basic Auth profiles, see Bot Authorization Overview. </p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ol> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to authenticate successfully.</li> <li>Base URL \u2013 Enter the base tenant URL for the Asana instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your Asana instance.</li> <li> <p>Description \u2013 Enter the description of the basic authentication profile. </p> </li> <li> <p>Click Save Auth to save the authorization profile.</p> </li> <li>Select the new Authorization Profile, which you created to complete integration.</li> </ol> </li> <li> <p>Click Save. When you configure the action for the first time, the Integration Successful pop-up is displayed.</p> </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/configuring-the-asana-action/#step-2-install-the-asana-action-templates","title":"Step 2: Install the Asana Action Templates","text":"<p>Once you have configured the Asana integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button for a template to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li> <p>A dialog task is automatically created for each installed template. </p> </li> <li> <p>Alternatively, you can create a new dialog task and select the Asana integration to select the dialog task from the templates and click Proceed. For example, select the Get Task by Id task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/","title":"Using the Asana Action Templates","text":"<p>You can use the Prebuilt Action Templates from your Asana integration to auto-create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using Asana action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create a Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the Asana option to view the action templates. </p> <p>Note: If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview.  </p> <p></p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#asana-actions","title":"Asana Actions","text":"<p>The following Asana action is supported in the latest version of the XO Platform:</p> Supported Actions Description Method Get a Task by ID     Retrieves a task from the Asana integration using the task ID.     GET     Find Tasks Created By a User     Retrieves tasks created by a user from the Asana integration.     GET     Find Tasks Assigned to User     Retrieves tasks assigned to a user from the Asana integration.     GET     List All Projects     Shows all projects in the Asana integration.     POST     List All Users     Shows all users in the Asana integration.     POST"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#get-task-by-id","title":"Get Task by ID","text":"<p>Steps to fetch a task with ID from the Asana integration:</p> <ol> <li>Refer to the Installing the Asana Templates section to install this template.</li> <li> <p>The Get Task by Id dialog task is added with the following components: </p> <ol> <li>getTaskById: A user intent to fetch a task with ID from the Asana space.</li> <li>taskId \u2013 An entity node for entering the task ID.</li> <li> <p>getTaskByIdService \u2013 A bot action service to fetch the task with the ID from the Asana integration. Click the Plus **icon to expand to view the getTaskByIdService bot action component properties. In the **Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>To add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response</p> <pre><code>{\n        \"data\": {\n            \"gid\": \"1204307990977944\",\n            \"assignee\": {\n                \"gid\": \"1204191722074650\",\n                \"name\": \"Alan Walker\"\n            },\n            \"created_at\": \"2023-03-31T11:11:44.658Z\",\n            \"created_by\": {\n                \"gid\": \"1204191722074650\",\n                \"name\": \"Alan Walker\"\n            },\n            \"name\": \"NEW TASK\",\n            \"notes\": \"The description\",\n            \"permalink_url\": \"https://app.asana.com/0/1xx60369/1XXX944\",\n            \"projects\": [\n                {\n                    \"gid\": \"1204191735460369\",\n                    \"name\": \"Int1\"\n                }\n            ],\n            \"workspace\": {\n                \"gid\": \"21968248715756\",\n                \"name\": \"xyz.com\"\n            }\n        }\n    } \n</code></pre> </li> <li> <p>getTaskByIdMessage \u2013 A message node with script to display responses to find tasks with ID. </p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to find a task with ID on Asana.</li> <li> <p>Enter the task ID when prompted by the VA as shown below: </p> </li> <li> <p>You will notice that a task is found with the ID on Asana. Expand and click the View Task button. </p> </li> <li> <p>You can view the task on Asana. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#find-tasks-created-by-a-user","title":"Find Tasks Created by a User","text":"<p>Steps to fetch tasks created by a user from the Asana integration:</p> <ol> <li>Refer to the Installing the Asana Templates section to install this template.</li> <li> <p>The Find Tasks Created by User dialog task is added with the following components: </p> <ol> <li>findTasksCreatedByUser: A user intent to retrieve tasks created by a user from the Asana space.</li> <li>workSpaceId \u2013 An entity node for entering the workspace ID of your Asana account.</li> <li>userId \u2013 An entity node for entering the user ID of your Asana account.</li> <li> <p>findCreatedTasksService \u2013 A bot action service to find tasks created by a user from the Asana integration. Click the Plus icon to expand to view the findCreatedTasksService bot action component properties. In the Component Properties window, to add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response</p> <pre><code>{\n        \"data\": [\n            {\n                \"gid\": \"1204325494675011\",\n                \"assignee\": {\n                    \"gid\": \"12041917XXX0\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"created_at\": \"2023-04-03T20:32:00.270Z\",\n                \"created_by\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"name\": \"30Apr NEW TASK\",\n                \"notes\": \"The description\",\n                \"Permalink_url\": \"https://app.asana.com/0/12XX369/1XXX11\",\n                \"projects\": [\n                    {\n                        \"gid\": \"1204191735460369\",\n                        \"name\": \"Int1\"\n                    }\n                ],\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            },\n            {\n                \"gid\": \"1204326178006294\",\n                \"assignee\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"created_at\": \"2023-04-03T22:28:25.171Z\",\n                \"created_by\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"name\": \"30Apr NEW TASK\",\n                \"notes\": \"The description\",\n                \"permalink_url\": \"https://app.asana.com/0/1XXX9/12XXX294\",\n                \"projects\": [\n                    {\n                        \"gid\": \"1204191735460369\",\n                        \"name\": \"Int1\"\n                    }\n                ],\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            }\n        ]\n    } \n}\n</code></pre> </li> </ol> </li> <li> <p>createdTaskMessage \u2013 A message node with script to display responses to find tasks by a user.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li> <p>Follow the prompts in the VA console to find tasks created with user ID on Asana as shown below: </p> </li> <li> <p>Enter the user ID when prompted by the VA as shown below: </p> </li> <li> <p>You will notice that a task is found with the ID on Asana. Expand and click the View Task button.</p> </li> <li>You can view the task on Asana. </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#find-tasks-assigned-to-a-user","title":"Find Tasks Assigned to a User","text":"<p>Steps to fetch tasks created by a user from the Asana integration:</p> <ol> <li>Refer to the Installing the Asana Templates section to install this template.</li> <li> <p>The FindTasks Assigned to a User dialog task is added with the following components: </p> <ol> <li>findTasksAssignedToUser: A user intent to retrieve tasks assigned to a user from the Asana space.</li> <li>workSpaceId \u2013 An entity node for entering the workspace ID of your Asana account.</li> <li>userId \u2013 An entity node for entering the user ID of your Asana account.</li> <li> <p>findAssignedTasksService \u2013 A bot action service to fetch the assigned tasks to a user from the Asana integration. Click the Plus icon to expand to view the findAssignedTasksService bot action component properties. In the Component Properties window, to add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response </p> <pre><code>{\n        \"data\": [\n            {\n                \"gid\": \"1204325494675011\",\n                \"assignee\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"created_at\": \"2023-04-03T20:32:00.270Z\",\n                \"created_by\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"name\": \"30Apr NEW TASK\",\n                \"notes\": \"The description\",\n                \"Permalink_url\": \"https://app.asana.com/0/1X69/1XX1\",\n                \"projects\": [\n                    {\n                        \"gid\": \"1204191735460369\",\n                        \"name\": \"Int1\"\n                    }\n                ],\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            },\n            {\n                \"gid\": \"1204326178006294\",\n                \"assignee\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"created_at\": \"2023-04-03T22:28:25.171Z\",\n                \"created_by\": {\n                    \"gid\": \"1204191722074650\",\n                    \"name\": \"Alan Walker\"\n                },\n                \"name\": \"30Apr NEW TASK\",\n                \"notes\": \"The description\",\n                \"permalink_url\": \"https://app.asana.com/0/1369/1294\",\n                \"projects\": [\n                    {\n                        \"gid\": \"1204191735460369\",\n                        \"name\": \"Int1\"\n                    }\n                ],\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            }\n        ]\n    } \n</code></pre> </li> </ol> </li> <li> <p>assignedTaskMessage \u2013 A message node with script to display responses to find tasks assigned to the user.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li> <p>Follow the prompts in the VA console to find a task with ID on Asana as shown below: </p> </li> <li> <p>Enter the user ID when prompted by the VA as shown below: </p> </li> <li> <p>You will notice that a task is found with the ID on Asana. Expand and click the View Task button.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#list-all-projects","title":"List All Projects","text":"<p>Steps to retrieve all projects from the Asana integration:</p> <ol> <li>Refer to the Installing the Asana Templates section to install this template.</li> <li> <p>The List All Projects dialog task is added with the following components: </p> <ol> <li>listAllProjects: A user intent to retrieve tasks assigned to a user from the Asana space.</li> <li> <p>listAllProjectsService \u2013 A bot action service to retrieve all projects from the Asana integration. Click the Plus icon to expand to view the listAllProjectsService bot action component properties. In the Component Properties window, to add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response</p> <pre><code>{\n        \"data\": [\n            {\n                \"gid\": \"1190334540433515\",\n                \"created_at\": \"2020-08-24T13:09:10.888Z\",\n                \"due_on\": null,\n                \"name\": \"integration\",\n                \"owner\": {\n                    \"gid\": \"1190337001098545\",\n                    \"name\": \"Alan\"\n                },\n                \"permalink_url\": \"https://app.asana.com/0/1xx5/1xx5\",\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            },\n            {\n                \"gid\": \"1199516117757228\",\n                \"created_at\": \"2021-01-07T14:21:04.105Z\",\n                \"due_on\": null,\n                \"name\": \"test\",\n                \"owner\": {\n                    \"gid\": \"1190339858363088\",\n                    \"name\": \"John Doe\"\n                },\n                \"permalink_url\": \"https://app.asana.com/0/1xx8/1xx8\",\n                \"workspace\": {\n                    \"gid\": \"21968248715756\",\n                    \"name\": \"xyz.com\"\n                }\n            }\n        ]\n    }\n</code></pre> </li> </ol> </li> <li> <p>listProjectMessage \u2013 A message node with script to display responses to find all projects..</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li> <p>Follow the prompts in the VA console to view all projects on Asana as shown below: </p> </li> <li> <p>You will notice that all projects are found on Asana. Expand and click the **View Project **button.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/asana/using-the-asana-action-templates/#list-all-users","title":"List All Users","text":"<p>Steps to retrieve all users from the Asana integration:</p> <ol> <li>Refer to the Installing the Asana Templates section to install this template.</li> <li> <p>The List All Users dialog task is added with the following components: </p> <ol> <li>listAllUsers: A user intent to retrieve tasks assigned to a user from the Asana space.</li> <li> <p>listAllUsersService \u2013 A bot action service to find all users from the Asana integration. Click the Plus icon to expand to view the listAllUsersService bot action component properties. In the Component Properties window, to add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response</p> <pre><code>{\n        \"data\": [\n            {\n                \"gid\": \"11xxxx674034\",\n                \"email\": \"alan.walker@xyz.com\",\n                \"name\": \"Alan Walker\",\n                \"workspaces\": [\n                    {\n                        \"gid\": \"219xxx756\",\n                        \"name\": \"xyz.com\"\n                    }\n                ]\n            }\n        ]\n    }\n</code></pre> </li> </ol> </li> <li> <p>listAllUsersMessage \u2013 A message node with script to display responses to find all projects.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li> <p>Follow the prompts in the VA console to view all users on Asana as shown below: </p> </li> <li> <p>You will notice that all users are found on Asana. Expand and click the View User button.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/","title":"Configuring the Azure OpenAI Action","text":"<p>The XO Platform lets you easily connect with the Azure OpenAI instance to find answers to your general queries. The Platform supports all common actions on Azure with ready-to-use pre-built dialog templates.</p> <p>This article explains how to authorize and enable the Azure OpenAI action and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication, allowing Azure OpenAI integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the Azure OpenAI integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Azure OpenAI app to access an access token at runtime. To learn more about Azure OpenAI account types, see Azure OpenAI Service.</li> </ul>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#step-1-create-an-azure-openai-app","title":"Step 1: Create an Azure OpenAI App","text":"<p>Prerequisites:</p> <p>Before enabling the Azure OpenAI action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have Azure OpenAI account credentials, create a developer account in Azure OpenAI and note down login credentials. Use the Azure OpenAI Service Documentation for more information.</li> <li>Copy the API Key, User Sub Domain, and Deployment ID values and keep them for future use to enable the integration.</li> </ul> <p>Create an Azure OpenAI Service app and configure it on the Kore.ai XO Platform to establish a communication channel between Azure OpenAI and the Kore.ai XO Platform.</p> <p>Steps to create an Azure OpenAI service:</p> <ol> <li> <p>Log in to the Azure portal, and search for Azure OpenAI from the portal menu. </p> </li> <li> <p>On the Cognitive Services Azure OpenAI page, click Create. </p> </li> <li> <p>Fill in the following required details:</p> <ol> <li>Select an existing Resource Group or create a new one.</li> <li>Select the Region. For example, select the South Central US region.</li> <li>Enter the Name of the Azure OpenAI service. For example, enter PlatformInegration.</li> <li>Select the Pricing Tier option. For example, select the Standard option. </li> </ol> </li> <li> <p>Click Next and then click Review + Submit.</p> </li> <li> <p>Once the Validation Passed message appears, click Create. </p> </li> <li> <p>The Azure OpenAI service is now initialized and deployed in the portal with an endpoint URL and API Keys. Click Go to Resource to view the app details. </p> </li> <li> <p>In the Overview page, copy the User Domain Name as shown below. </p> </li> <li> <p>In the Left Navigation Pane, select the Keys and Endpoints menu and click Show Keys, and then copy the API Key as shown below. </p> </li> <li> <p>In the Left Navigation Pane, select Model Deployments and create a new deployment. For example, enter the model name as PlatformDeploy and select the Model as text-davinci-001. Click Save. </p> </li> <li> <p>Copy the Model Name of the newly created deployment as shown below. </p> </li> <li> <p>You can also copy the Azure OpenAI service credentials from the Azure OpenAI Studio &gt; Playground &gt; GPT- 3 &gt; View Code, as shown below. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#step-2-enable-the-azure-openai-action","title":"Step 2: Enable the Azure OpenAI Action","text":"<p>Once you have created an Azure OpenAI service and copied the required credentials, you can enable the integration.</p> <p>Steps to enable the Azure OpenAI action:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Once you click the Actions menu, all integrations are shown in the Available region. Select the Azure OpenAI action. </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth: You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with the preconfigured Kore.ai app with the Basic Auth option.</p> <p>Steps to authorize the Azure OpenAI action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Azure OpenAI action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>API Key \u2013 The secret API key of your Azure OpenAI service, which you copied in Step 1. Note: The Platform uses the configured API Key to authorize and generate the suggestions from OpenAI.</p> </li> <li> <p>User Sub Domain \u2013 The domain name of the Azure OpenAI service, which you copied in Step 1.</p> </li> <li>Deployment ID \u2013 The deployment ID/model name of the Azure OpenAI service, which you copied in Step 1. Note: You can enter the deployment ID for ChatGPT-3 or ChatGPT-3.5 model to configure the GPT model for the Azure Open AI integration</li> </ol> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> <p>Note: The Azure OpenAI action is moved from Available to Configured region.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#allow-the-end-user-to-authorize","title":"Allow the End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Azure OpenAI app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize an Azure OpenAI action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Azure OpenAI action in the Available Actions region.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.</li> <li>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Azure OpenAI app for authorization.</li> <li> <p>Click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the API Key option. </p> <p>To create Basic Auth profiles, see Bot Authorization Overview.</p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ul> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to authenticate successfully.</li> <li>Base URL \u2013 Enter the base tenant URL for the Azure OpenAI instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your Azure OpenAI instance.</li> <li>Description \u2013 Enter the description of the basic authentication profile.</li> </ul> </li> <li> <p>Click Save Auth to save the authorization profile. </p> </li> <li> <p>Select the new Authorization Profile you created to complete integration.</p> </li> </ol> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/configuring-the-azure-openai-action/#step-3-install-the-azure-openai-action-templates","title":"Step 3: Install the Azure OpenAI Action Templates","text":"<p>Once you have configured an Azure OpenAI integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button to begin the installation. </p> </li> <li> <p>Once the templates are installed, a dialog task is auto-created.</p> </li> <li> <p>When you create a dialog task, you can also select the task from the Azure OpenAI action templates and click Proceed. For example, select the General Query task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/using-the-azure-openai-action-templates/","title":"Using the Azure OpenAI Action Templates","text":"<p>You can use the Prebuilt Action Templates from your Azure OpenAI integration to auto-create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using the Azure OpenAI action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create a Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the Azure OpenAI option to view the action templates. </p> </li> <li> <p>If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/azure-open-ai/using-the-azure-openai-action-templates/#azure-openai-actions","title":"Azure OpenAI Actions","text":"<p>The following Azure OpenAI action is supported:</p> Supported Tasks Description Method General Query     Resolve any query using the intelligence of Azure and OpenAI.     POST"},{"location":"app-settings/integrations/actions/azure-open-ai/using-the-azure-openai-action-templates/#general-query","title":"General Query","text":"<p>Steps to resolve the query in the Azure OpenAI integration:</p> <ol> <li> <p>Refer to the Installing the Azure OpenAI Action Templates section to install this template.</p> </li> <li> <p>The General Query dialog task is added with the following components: </p> <ol> <li>generalQuery: A user intent for a general query.</li> <li>userQuestion and deploymentID \u2013 Entity nodes pass a user\u2019s question.</li> <li>generalQueryService \u2013 A bot action service to send a query in an external integration. Click the Plus icon to expand to view the generalQueryService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters, as shown below: </p> <p>Sample Request</p> <pre><code>{\n\"prompt\": \"I am the owner of a SAAS product company. How can i increase my customer base?\",\n\"temperature\": 0.25,\n\"max_tokens\": 1024, \n\"top_p\": 1, \n\"frequency_penalty\": 0, \n\"presence_penalty\": 0 \n}\n</code></pre> <p>To add one or more response, scroll down and click the +Add Response button:</p> <p>Sample Response</p> <pre><code>{\n\"id\": \"cmpl-6s8YPFcRGYrDtPys2OdVfxxxxxx\", \n\"object\": \"text_completion\", \n\"created\": 1678360613, \n\"model\": \"text-davinci-003\", \n\"choices\": [ \n{ \n\"text\": \"\\n\\n1. Focus on creating a great user experience: Make sure your product is easy to use, intuitive, and provides value to your customers.\\n\\n2. Offer free trials: Give potential customers the opportunity to try out your product before committing to a purchase.\\n\\n3. Leverage word-of-mouth marketing: Ask existing customers to share their experiences with their friends and family.\\n\\n4. Invest in content marketing: Create helpful content related to your product and share it on social media and other platforms.\\n\\n5. Utilize search engine optimization (SEO): Optimize your website and content for search engines to increase visibility and attract more customers.\\n\\n6. Run targeted ads: Use paid advertising to reach potential customers who are likely to be interested in your product.\\n\\n7. Participate in industry events: Attend conferences, trade shows, and other events to network and build relationships with potential customers.\\n\\n8. Offer discounts and promotions: Provide discounts and other promotions to encourage customers to purchase your product.\", \n\"index\": 0, \n\"logprobs\": null, \n\"finish_reason\": \"stop\" \n} \n], \n\"usage\": { \n\"prompt_tokens\": 19, \n\"completion_tokens\": 212, \n\"total_tokens\": 231 \n} \n} \n</code></pre> </li> <li> <p>generalQueryMessage \u2013 A message node with the script to display the query in Azure OpenAI system. </p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to resolve a general query.</li> <li> <p>Enter a question based on a query when prompted by the VA, as shown below: </p> </li> <li> <p>You will notice an answer is generated for your query. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/","title":"Configuring the BambooHR Action","text":"<p>The XO Platform lets you easily connect the HubSpot integration to create, view, and update employees. You can also search and view time off requests, who is out and update request status using the pre-built templates. </p> <p>This document explains how to enable, authorize, configure, and install the BambooHR pre built templates.</p>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication to allow BambooHR integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the BambooHR integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token. </li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s BambooHR app to access an access token at runtime. To learn more about BambooHR account types, see BambooHR documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/#step-1-enable-the-bamboohr-action","title":"Step 1: Enable the BambooHR Action","text":"<p>Prerequisites:</p> <p>Before enabling the BambooHR action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have BambooHR account credentials, create a developer account in BambooHR and note down login credentials. Use the BambooHR Documentation for more information.</li> <li>Copy the user sub domain and API key values and keep them for future use to enable the integration.</li> </ul> <p>Steps to enable the BambooHR action:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Once you click the Actions menu, all integrations are shown in the Available region. Select the BambooHR action. </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with preconfigured Kore.ai\u2019s app with the Basic Auth option.</p> <p>Steps to authorize a BambooHR action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Select the BambooHR action in the Available Actions region.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ul> <li>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </li> <li>API Key \u2013 The secret API key of your BambooHR account.</li> </ul> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful  pop-up is displayed. </p> </li> </ol> <p>Note: You will notice the BambooHR action is moved from Available to Configured region.</p>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/#allow-end-user-to-authorize","title":"Allow End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s BambooHR app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize a BambooHR action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Select the BambooHR action in the Available Actions region.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ul> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.<ul> <li>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s BambooHR app for authorization.</li> </ul> </li> <li>Click the Select Authorization drop-down and select the Create New option. </li> <li>Select the type of authorization mechanism. For example, select the Basic Auth option. To create Basic Auth profiles, see Bot Authorization Overview. </li> </ul> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ul> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to successfully authenticate.</li> <li>Base URL \u2013 Enter the base tenant URL for the BambooHR instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your BambooHR instance.</li> <li>Description \u2013 Enter the description of the basic authentication profile. </li> </ul> </li> <li> <p>Click Save Auth to save the authorization profile.</p> </li> <li> <p>Select the new Authorization Profile, which you created to complete integration. </p> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful  pop-up is displayed.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/configuring-the-bamboohr-action/#step-2-install-the-bamboohr-action-templates","title":"Step 2: Install the BambooHR Action Templates","text":"<p>Once you have configured a BambooHR integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li> <p>Once all templates are installed, a dialog task for each template is auto-created. </p> </li> <li> <p>You can also select the desired dialog task from the templates and click Proceed. For example, select the Create an employee task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/","title":"Using the BambooHR Templates","text":"<p>You can use the Prebuilt Action Templates from your BambooHR integration to auto create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using the BambooHR action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills and then click the Dialog Tasks.</li> <li> <p>Click the Create a Dialog Task to create a new task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the BambooHR option to view the action templates. </p> </li> </ol> <p>Note: If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview. </p>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#bamboo-hr-actions","title":"Bamboo HR Actions","text":"<p>The following BambooHR actions are supported:</p> Supported Actions Description Method Create an employee     Creates an employee in the BambooHR system.     POST     Get employee by ID     Find an employee using the employee ID.     GET     List all employee     Retrieves all employees from the BambooHR system.     GET     Update an employee     Updates an employee details in the BambooHR system.     POST     Get all time off requests     Retrieves all time off requests from the BambooHR system.     GET     Get a list of who is out     Find employees who are out on company holidays and for a period of time sorted by date.     GET     Update a request status     Updates a time off request\u2019s status in the BambooHR system.     POST"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#create-an-employee","title":"Create an Employee","text":"<p>Steps to create an employee in the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The Create an Employee dialog task is added with the following components: </p> <ol> <li>createEmployee \u2013 A user intent to create an employee.</li> <li>companyDomain, firstName, and lastName \u2013 Entity nodes for gathering the required employee details.</li> <li>createEmployeeService \u2013 A bot action service to create an employee in an external integration. Click the Plus icon to expand to view the createEmployeeService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request:</p> <pre><code>{  \n\"firstName\":\"Alen\",\n\"lastName\":\"walker\"\n}\n</code></pre> </li> <li> <p>createEmployeeMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to create an employee as shown below: </li> </ol> </li> <li> <p>Click View Employee to view employee details in the BambooHR: </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#get-employee-by-id","title":"Get Employee by ID","text":"<p>Steps to find an employee by ID from the BambooHR integration:</p> <ol> <li> <p>Refer to the Installing the BambooHR templates section to install this template.</p> </li> <li> <p>The Get Employee by ID dialog task is added with the following components: </p> <ol> <li>getEmployeeByID \u2013 A user intent to find an employee by ID.</li> <li>companyDomain and id\u2013 Entity nodes for gathering the required employee details.</li> <li>getEmployeeByIdService \u2013 A bot action service to find an employee by an ID from an external integration. Click the Plus icon to expand to view the getEmployeeByIdService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request:  </p> <pre><code>{\n\"id\": \"114\",\n\"firstName\": \"Alen\",\n\"lastName\": \"walker\"\n}\n</code></pre> </li> <li> <p>getEmployeeMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to find an employee as shown below: </li> </ol> </li> <li> <p>Click View Employee to view employee details in the BambooHR.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#list-all-employees","title":"List All Employees","text":"<p>Steps to view all employees in the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The List All Employees dialog task is added with the following components: </p> <ol> <li>listAllEmployees \u2013 A user intent to create an employee.</li> <li>companyDomain \u2013 Entity nodes for gathering the required employee details.</li> <li>listAllEmployeesService \u2013 A bot action service to fetch all employees from an external integration. Click the Plus icon to expand to view the listAllEmployeesService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request: <pre><code>{  \n    \"fields\": [ \n    \"firstName\", \n    \"lastName\" \n] }\n</code></pre></p> <p>To add one or more responses, scroll down and click Add Response.  </p> <p>Sample Response: <pre><code>{ \n  \"title\": \"Report\",\n  \"fields\": [ \n  { \n  \"id\": \"firstName\", \n  \"type\": \"text\", \n  \"name\": \"First Name\" \n  }, \n  { \n  \"id\": \"lastName\", \n  \"type\": \"text\", \n  \"name\": \"Last Name\" \n  } \n  ], \n  \"employees\": [ \n  { \n  \"id\": \"112\", \n  \"firstName\": \"John\", \n  \"lastName\": \"Smith\" \n  }, \n  { \n  \"id\": \"113\", \n  \"firstName\": \"Harry\", \n  \"lastName\": \"Anthony\" \n  }, \n  { \n  \"id\": \"114\", \n  \"firstName\": \"Alen\", \n  \"lastName\": \"walker\" \n  } \n] }\n</code></pre></p> </li> <li> <p>listAllEmployeesMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to view all employees as shown below: </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#update-an-employee","title":"Update an Employee","text":"<p>Steps to update an employee in the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The Update an Employee dialog task is added with the following components: </p> <ol> <li>updateEmployee \u2013 A user intent to update an employee.</li> <li>companyDomain, id, chooseField, firstName, and lastName \u2013 Entity nodes for gathering the required employee details.</li> <li> <p>updateEmployeeScript \u2013 A bot action service to update an employee in an external integration. Click the Plus icon to expand to view the updateEmployeeScript bot action component properties. </p> </li> <li> <p>updateEmployeeService \u2013 A bot action service to update an employee in an external integration. Click the Plus icon to expand to view the updateEmployeeService bot action component properties.</p> </li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request: <pre><code>{ \n  \"firstName\":\"Alen\", \n  \"lastName\":\"walker\" \n}\n</code></pre></p> </li> <li> <p>getEmployeeByIdService \u2013 A bot action service to find an employee by an ID from an external integration. Click the Plus icon to expand to view the getEmployeeByIdService bot action component properties.</p> </li> <li>updateEmployeeMessage \u2013 A message node with script to display responses for various scenarios.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to update an employee as shown below: </li> </ol> </li> <li> <p>Click View Employee to view employee details in the BambooHR.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#get-all-time-off-requests","title":"Get All Time Off Requests","text":"<p>Steps to fetch all time off requests from the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The Get All Time Off Requests dialog task is added with the following components: </p> <ol> <li>getTimeoffRequests \u2013 A user intent to get time off requests.</li> <li>companyDomain, startDate, and endDate\u2013 Entity nodes for gathering the required employee details getTimeoffRequestsService \u2013 A bot action service to fetch time off requests in an external integration. Click the Plus icon to expand to view the getTimeoffRequestsService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below:  To add one or more requests, scroll down and click +Add Response.  </p> <p>Sample Response: <pre><code>  [ \n    { \n    \"id\": \"1649\", \n    \"employeeId\": \"112\", \n    \"status\": { \n    \"lastChanged\": \"2022-12-22\", \n    \"lastChangedByUserId\": \"2385\", \n    \"status\": \"approved\" \n    }, \n    \"name\": \"Mark Anderson\", \n    \"start\": \"2022-12-14\", \n    \"end\": \"2022-12-15\", \n    \"created\": \"2022-12-22\", \n    \"type\": { \n    \"id\": \"83\", \n    \"name\": \"Vacation\", \n    \"icon\": \"palm-trees\" \n    }, \n    \"amount\": { \n    \"unit\": \"hours\", \n    \"amount\": \"16\" \n    }, \n    \"actions\": { \n    \"view\": true, \n    \"edit\": true, \n    \"cancel\": false, \n    \"approve\": false, \n    \"deny\": false, \n    \"bypass\": false \n    }, \n    \"dates\": { \n    \"2022-12-14\": \"8\", \n    \"2022-12-15\": \"8\" \n    }, \n    \"notes\": {} \n    }, \n    { \n    \"id\": \"1650\", \n    \"employeeId\": \"112\", \n    \"status\": { \n    \"lastChanged\": \"2022-12-22\", \n    \"lastChangedByUserId\": \"2385\", \n    \"status\": \"requested\" \n    }, \n    \"name\": \"John Smith\", \n    \"start\": \"2022-12-12\", \n    \"end\": \"2022-12-13\", \n    \"created\": \"2022-12-22\", \n    \"type\": { \n    \"id\": \"85\", \n    \"name\": \"Allan Walker\", \n    \"icon\": \"sales\" \n    }, \n    \"amount\": { \n    \"unit\": \"hours\", \n    \"amount\": \"16\" \n    }, \n    \"actions\": { \n    \"view\": true, \n    \"edit\": true, \n    \"cancel\": true, \n    \"approve\": true, \n    \"deny\": true, \n    \"bypass\": true \n    }, \n    \"dates\": { \n    \"2022-12-12\": \"8\", \n    \"2022-12-13\": \"8\" \n    }, \n    \"notes\": {} \n    } \n    ]   \n</code></pre></p> </li> <li> <p>getTimeoffRequestsMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to get all time off requests as shown below: </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#get-a-list-of-who-is-out","title":"Get a List of Who is Out","text":"<p>Steps to get a list of who is out from the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The Get a List of Who Is Out dialog task is added with the following components: </p> <ol> <li>getListWhoisOut \u2013 A user intent to get a list of who is out.</li> <li>companyDomain \u2013 Entity nodes for gathering the required employee details.</li> <li>getListWhoOutService \u2013 A bot action service to get a list who is out in an external integration. Click the Plus icon to expand to view the getListWhoOutService bot action component properties.</li> <li>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </li> <li>getListWhoIsOutMessage \u2013 A message node with script to display responses for various scenarios.</li> </ol> </li> <li> <p>Click the Talk to Bot icon to test and debug the dialog task.</p> </li> <li>Follow the prompts in the VA console to get a list of who is out.</li> </ol>"},{"location":"app-settings/integrations/actions/bamboo-hr/using-the-bamboohr-templates/#update-a-request-status","title":"Update a Request Status","text":"<p>Steps to update a request status in the BambooHR integration:</p> <ol> <li>Refer to the Installing the BambooHR templates section to install this template.</li> <li> <p>The Update a Request Status dialog task is added with the following components: </p> <ol> <li>updateRequestStatus \u2013 A user intent to update a request.</li> <li>companyDomain, requestID, and requestStatus \u2013 Entity nodes for gathering the required employee details.</li> <li> <p>updateRequestStatusScript \u2013 A bot action service to update a request in an external integration. Click the Plus icon to expand to view the updateRequestStatusScript bot action component properties. </p> </li> <li> <p>updateRequestStatusService \u2013 A bot action service to update an employee in an external integration. Click the Plus icon to expand to view the updateRequestService bot action component properties.</p> </li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request: <pre><code>{ \n\"status\": \"approved\", \n\"note\": \"Have fun!\" \n}\n</code></pre></p> </li> <li> <p>updateRequestStatusMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to update a request as shown below: </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/","title":"Configuring the Bitly Action","text":"<p>The Kore.ai XO Platform lets you easily connect with your Bitly instance to shorten any long URLs. Learn more about Bitly.</p> <p>This document explains how to authorize and enable the Bitly action and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports API key authentication to allow Bitly integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the Bitly integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Bitly app to access an access token at runtime. To learn more about Bitly, see Bitly Documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/#enable-the-bitly-action","title":"Enable the Bitly Action","text":"<p>Prerequisites</p> <p>Before enabling the Bitly action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have Bitly account credentials, create an account in the Bitly Developer console and note down the login credentials. See Bitly Documentation for more information.</li> <li>Create a custom app on the Bitly admin page.</li> <li>Copy your Bitly account\u2019s personal access token and keep it for future use.</li> </ul>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with the preconfigured Kore.ai app with the Basic Auth option.</p> <p>Steps to authorize an Bitly action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li> <p>Select the Bitly from the list of Available actions. </p> </li> <li> <p>In the Configurations dialog, select the Authorization tab.</p> </li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>Personal Access Token \u2013 Enter the access token of your Bitly account. </p> </li> <li> <p>Click Save. When you configure the action for the first time, the Integration Successful pop-up is displayed. Note: The Bitly action is moved from Available to Configured region on the Actions page.</p> </li> </ol> </li> <li> <p>You can also click the Skip for Now button to install the Dialog Task templates later. To learn how to use action templates, read the Using the Bitly action templates article. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/#allow-end-users-to-authorize","title":"Allow End Users to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Bitly app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize an Bitly action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Bitly action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Bitly app for authorization. To create a profile, click the Select Authorization drop-down and select the Create New option.</p> </li> <li> <p>Select the type of authorization mechanism. For example, select the API Key option. To create Basic Auth profiles, see Bot Authorization Overview. </p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ol> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to authenticate successfully.</li> <li>Base URL \u2013 Enter the base tenant URL for the Bitly instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your Bitly instance.</li> <li> <p>Description \u2013 Enter the description of the basic authentication profile. </p> </li> <li> <p>Click Save Auth to save the authorization profile.</p> </li> <li>Select the new Authorization Profile, which you created to complete integration.</li> <li>Click Save. When you configure the action for the first time, the Integration Successful pop-up is displayed.</li> </ol> </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/bitly/configuring-the-bitly-action/#step-2-install-the-bitly-action-templates","title":"Step 2: Install the Bitly Action Templates","text":"<p>Once you have configured the Bitly integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button for a template to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li>A dialog task is automatically created for each installed template.</li> <li> <p>Alternatively, you can create a new dialog task and select the Bitly integration to select the dialog task from the templates and click Proceed. For example, select the Short an Url task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bitly/using-the-bitly-action-template/","title":"Using the Bitly Action Template","text":"<p>You can use the Prebuilt Action Templates **from your Bitly integration to auto-create dialog tasks and test them using the **Talk to Bot option.</p> <p>Steps to create a dialog task using Bitly action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the Bitly option to view the action templates. </p> <p>Note: If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview.  </p> <p> </p> </li> </ol>"},{"location":"app-settings/integrations/actions/bitly/using-the-bitly-action-template/#bitly-actions","title":"Bitly Actions","text":"<p>The following Bitly action is supported:</p> Supported Actions Description Method Short an URL     Shortens any long URL.     POST"},{"location":"app-settings/integrations/actions/bitly/using-the-bitly-action-template/#general-query","title":"General Query","text":"<p>Steps to shorten the URL in the Bitly integration:</p> <ol> <li>Refer to the Installing the Bitly templates section to install this template.</li> <li> <p>The Short URL dialog task is added with the following components: </p> <ol> <li>shortUrl: A user intent to shorten an URL.</li> <li>longURL \u2013 An entity node to enter a long URL.</li> <li>shortUrlService\u2013 A bot action service to send a query in an external integration. Click the Plus icon to expand to view the generalQueryService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters, as shown below. </p> <p>Sample Request <pre><code>{\n    \"long_url\": \"https://en.wikipedia.org/wiki/Constantine_V\"\n}\n</code></pre></p> </li> <li> <p>To add one or more responses, scroll down and click the +Add Response button. </p> <p>Sample Response <pre><code>{\n\"created_at\": \"2023-08-25T08:38:00+0000\",\n\"id\": \"bit.ly/3E8Nec6\",\n\"link\": \"https://bit.ly/3E8Nec6\",\n\"custom_bitlinks\": [],\n\"long_url\": \"https://en.wikipedia.org/wiki/Constantine_V\",\n\"archived\": false,\n\"tags\": [],\n\"deeplinks\": [],\n\"references\": {\n\"group\": \"https://api-ssl.bitly.com/v4/groups/Bn448WZsE7j\"\n}\n}\n</code></pre></p> </li> <li> <p>generalQueryMessage \u2013 A message node with the script to display the query in the Bitly system.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to resolve a general query.</li> <li> <p>Enter a long URL when prompted by the VA, as shown below. </p> </li> <li> <p>You will notice that the long URL is shortened. Click View Stats to view URL statistics in the Bitly instance. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/","title":"Configuring the Confluence Action","text":"<p>The XO Platform lets you easily connect with your Confluence instance to create, and view pages or blogs on the Confluence space. Learn more about Confluence.</p> <p>This article explains how to authorize and enable the Confluence action and install the pre-built template.</p>"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports OAuth v2.0 authentication to allow a Confluence integration to exchange data. For more information, see Bot Authorization Overview. </p> <p>The Kore.ai XO Platform supports the following authorization types for the Confluence integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Confluence app to access an access token at runtime.</li> </ul> <p>NOTE: The Confluence integration can be authorized only for the Developer and the Enterprise editions. You cannot authorize Confluence\u2019s Trial edition. To learn more about Confluence, see Confluence documentation.</p> Authorization Type Basic OAuth Pre-authorize the Integration     Yes     Allow Users to Authorize the Integration     Yes"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/#step-1-enable-the-confluence-action","title":"Step 1: Enable the Confluence Action","text":"<p>Prerequisites:</p> <p>Before enabling the Confluence actions, complete the following prerequisites:</p> <ul> <li>Create a developer account in Atlassian and note down login credentials.</li> <li>Create an OAuth app in Atlassian and grant permission to write:confluence-content offline_access. See Confluence Documentation for more information</li> <li>Copy the Client ID, Client Secret Key, Authorization URL, and Callback URL and keep them ready to enable the Confluence integration.</li> </ul> <p>Steps to enable the Confluence action:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Once you click the Actions menu, all integrations are shown in the Available region. Select the Confluence action. </li> </ol>"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>OAuth</p> <p>You can authorize the integration using developer credentials. The developer authorization lets you authorize the integration with the preconfigured Kore.ai app or use the custom authorization profile to let a developer configure the integration.</p> <p>Steps to authorize a Confluence action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Confluence action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ul> <li>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the OAuth option. </li> </ul> <p>System Authorization</p> <p>Pre-authorize Confluence integration with the necessary authorization credentials to obtain the token to access external services.</p> <ul> <li> <p>Select the System card to enable Kore.ai\u2019s preconfigured Confluence app and click Authorize. </p> </li> <li> <p>Once you click Authorize, you are redirected to https://auth.atlassian.com/authorize.</p> </li> <li>Enter your developer account credentials to connect with your Confluence Account successfully.</li> <li>Click the Allow Access button to use Kore.ai\u2019s app to fetch the access token to complete the authorization.</li> </ul> <p>Custom Authorization</p> <p>Create your custom authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Confluence app for authorization.</p> <ul> <li>Select Custom to enable the custom authorization profile.</li> <li> <p>Click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the OAuth v2 option. To create custom OAuth profiles, read the Setting Up Authorization Using OAuth v2 article.</p> </li> <li> <p>Enter the following authentication credentials for the OAuth v2 mechanism:</p> <ul> <li>Call back URL</li> <li>Identity Provider Name</li> <li>Client ID</li> <li>Client Secret</li> <li>Authorization URL</li> <li>Token Request URL</li> <li>Scope</li> <li>Refresh Token URL </li> </ul> </li> <li> <p>Click Save Auth to save Authorization Profile.Select the new Authorization Profile you created to enable integration. </p> </li> </ul> </li> <li> <p>Once you click Authorize, you are redirected to https://auth.atlassian.com/authorize.</p> </li> <li>Enter login credentials to connect with your Confluence Account successfully.</li> <li>Click the Allow Access button if prompted to let your custom app fetch the access token to complete the authorization.</li> <li>Once the authorization is successful, you will see a success message.</li> <li> <p>Click Save. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> <p>Note: The Confluence action is moved from Available to Configured region.</p> </li> <li> <p>You can also click the Skip for Now button to install the Dialog Task templates later. To learn how to use action templates, read the Using the Confluence Action Templates article.</p> </li> </ol>"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/#allow-end-user-to-authorize","title":"Allow End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Confluence app to access an access token at runtime. You can also use the custom authorization profile to fetch the access token based on user credentials.</p> <p>Steps to authorize a Confluence action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Confluence action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ul> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the OAuth option. </li> </ul> <p>System Authorization</p> <p>The end user has to provide credentials during the conversation to authorize users for Confluence integration to obtain the access token.</p> <ul> <li>Select the System card to enable Kore.ai\u2019s preconfigured Confluence app.</li> <li>Once you click the Enable button, a link is sent to the end user to authorize the integration.</li> <li>Click the link and enter the login credentials to allow the user to authorize the integration.</li> </ul> <p>Custom Authorization</p> <p>Create your custom authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Confluence app for authorization.</p> <ul> <li>Select Custom to enable the custom authorization profile.</li> <li>Click the Select Authorization drop-down and select the Create New option. Follow the instructions in the Custom Authorization section.</li> <li> <p>You can also select an existing authorization profile as shown below: </p> </li> <li> <p>Click the Enable button. The users will see the authorize option during the runtime.</p> </li> </ul> </li> </ol>"},{"location":"app-settings/integrations/actions/confluence/configuring-the-confluence-action/#step-2-install-the-confluence-action-templates","title":"Step 2: Install the Confluence Action Templates","text":"<p>Once you have configured a Confluence integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button for a template to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li> <p>Once all templates are installed, a dialog task for each template is auto-created. </p> </li> <li> <p>Select the desired dialog task from the templates and click Proceed. For example, select the Create Content task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/confluence/using-the-confluence-action-templates/","title":"Using the Confluence Action Templates","text":"<p>You can use the Prebuilt Action Templates from your Confluence integration to auto-create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using Confluence action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create a Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the Confluence option to view the action templates. </p> </li> </ol> <p>Note: If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview.</p> <p></p>"},{"location":"app-settings/integrations/actions/confluence/using-the-confluence-action-templates/#confluence-actions","title":"Confluence Actions","text":"<p>The following Confluence action is supported in the latest version of the XO Platform:</p> Supported Actions Description Method Create Content     Creates content in the Confluence space.     POST"},{"location":"app-settings/integrations/actions/confluence/using-the-confluence-action-templates/#create-content","title":"Create Content","text":"<p>Steps to create content using the Confluence integration:</p> <ol> <li>Refer to the Installing the Confluence Templates section to install this template.</li> <li> <p>The createContent dialog task is added with the following components: </p> <ol> <li>createContent: A user intent to create content in the Confluence space.</li> <li>contentType, spaceKey, contentTitle, and contentBody \u2013 Entity nodes for entering the required details to create content.</li> <li> <p>getResourceIdService \u2013 A bot action service to fetch the resource ID from the Confluence integration. Click the Plus icon to expand to view the getResouceIdService bot action component properties. In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request</p> <pre><code>{\n\"title\": \"Page 1\",\n\"type\": \"page\",\n\"space\": {\n\"key\": \"SFPWP\"\n},\n\"status\": \"current\",\n\"body\": {\n\"storage\": {\n\"value\": \"Here is the value of this body\",\n\"representation\": \"storage\"\n}\n}\n}\n</code></pre> <p>To add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response</p> <pre><code>{\n\"id\": \"21004299\",  \n\"type\": \"page\",  \n\"status\": \"current\",  \n\"title\": \"Page 1\",\n\"space\": {\n\"id\": 196612,\n\"key\": \"SFPWP\",\n\"name\": \"Space For Playing with Postman\",\n\"type\": \"global\",\n\"status\": \"current\",\n\"_expandable\": {\n\"settings\": \"/rest/api/space/SFPWP/settings\",\n\"metadata\": \"\",\n\"operations\": \"\",\n\"lookAndFeel\": \"/rest/api/settings/lookandfeel?spaceKey=SFPWP\",\n\"identifiers\": \"\",\n\"permissions\": \"\",\n\"icon\": \"\",\n\"description\": \"\",\n\"theme\": \"/rest/api/space/SFPWP/theme\",\n\"history\": \"\",\n\"homepage\": \"/rest/api/content/196695\"\n},\n\"_links\": {\n\"webui\": \"/spaces/SFPWP\",\n\"self\": \"https://xyz.atlassian.net/wiki/rest/api/space/SFPWP\"\n}\n},\n\"history\": {\n\"latest\": true,\n\"createdBy\": {\n\"type\": \"known\",\n\"accountId\": \"632852448b75455be45293bd\",\n\"accountType\": \"atlassian\",\n\"email\": \"alan.walker@xyz.com\",\n\"publicName\": \"alan.walker\",\n\"profilePicture\": {\n\"path\": \"/wiki/aa-avatar/632852448b75455be45293bd\",\n\"width\": 48,\n\"height\": 48,\n\"isDefault\": false\n},\n\"displayName\": \"alan.walker\",\n\"isExternalCollaborator\": false,\n\"_expandable\": {\n\"operations\": \"\",\n\"personalSpace\": \"\"\n},\n\"_links\": {\n\"self\": \"https://purushottam1.atlassian.net/wiki/rest/api/user?accountId=632852448b75455be45293bd\"\n}\n},\n\"createdDate\": \"2023-07-11T11:29:38.860Z\",\n\"_expandable\": {\n\"lastUpdated\": \"\",\n\"previousVersion\": \"\",\n\"lastOwnedBy\": \"\",\n\"contributors\": \"\",\n\"nextVersion\": \"\",\n\"ownedBy\": \"\"\n},\n\"_links\": {\n\"self\": \"https://purushottam1.atlassian.net/wiki/rest/api/content/21004299/history\"\n}\n},\n\"version\": {\n\"by\": {\n\"type\": \"known\",\n\"accountId\": \"632852448b75455be45293bd\",\n\"accountType\": \"atlassian\",\n\"email\": \"alan.walker@xyz.com\",\n\"publicName\": \"alan.walker\",\n\"profilePicture\": {\n\"path\": \"/wiki/aa-avatar/632852448b75455be45293bd\",\n\"width\": 48,\n\"height\": 48,\n\"isDefault\": false\n},\n\"displayName\": \"alan.walker\",\n\"isExternalCollaborator\": false,\n\"_expandable\": {\n\"operations\": \"\",\n\"personalSpace\": \"\"\n},\n\"_links\": {\n\"self\": \"https://purushottam1.atlassian.net/wiki/rest/api/user?accountId=632852448b75455be45293bd\"\n}\n},\n\"when\": \"2023-07-11T11:29:38.860Z\",\n\"friendlyWhen\": \"just a moment ago\",\n\"message\": \"\",\n\"number\": 1,\n\"minorEdit\": false,\n\"ncsStepVersion\": \"1\",\n\"ncsStepVersionSource\": \"ncs-ack\",\n\"confRev\": \"confluence$content$21004299.4\",\n\"contentTypeModified\": false,\n\"_expandable\": {\n\"collaborators\": \"\",\n\"content\": \"/rest/api/content/21004299\"\n},\n\"_links\": {\n\"self\": \"https://purushottam1.atlassian.net/wiki/rest/api/content/21004299/version/1\"\n}\n},\n\"ancestors\": [\n{\n\"id\": \"196695\",\n\"type\": \"page\",\n\"status\": \"current\",\n\"title\": \"Space For Playing with Postman\",\n\"macroRenderedOutput\": {},\n\"extensions\": {\n\"position\": 435\n},\n\"_expandable\": {\n\"container\": \"/rest/api/space/SFPWP\",\n\"metadata\": \"\",\n\"restrictions\": \"/rest/api/content/196695/restriction/byOperation\",\n\"history\": \"/rest/api/content/196695/history\",\n\"body\": \"\",\n\"version\": \"\",\n\"descendants\": \"/rest/api/content/196695/descendant\",\n\"space\": \"/rest/api/space/SFPWP\",\n\"childTypes\": \"\",\n\"schedulePublishInfo\": \"\",\n\"operations\": \"\",\n\"schedulePublishDate\": \"\",\n\"children\": \"/rest/api/content/196695/child\",\n\"ancestors\": \"\"\n},\n\"_links\": {\n\"self\": \"https://purushottam1.atlassian.net/wiki/rest/api/content/196695\",\n\"tinyui\": \"/x/VwAD\",\n\"editui\": \"/pages/resumedraft.action?draftId=196695\",\n\"webui\": \"/spaces/SFPWP/overview\"\n}\n}\n],\n\"container\": {\n\"id\": 196612,\n\"key\": \"SFPWP\",\n\"name\": \"Space For Playing with Postman\",\n\"type\": \"global\",\n\"status\": \"current\",\n\"history\": {\n\"createdBy\": {\n\"type\": \"known\",\n\"accountId\": \"632852448b75455be45293bd\",\n\"accountType\": \"atlassian\",\n\"email\": \"alan.walker@xyz.com\",\n\"publicName\": \"alan.walker\",\n\"profilePicture\": {\n\"path\": \"/wiki/aa-avatar/632852448b75455be45293bd\",\n\"width\": 48,\n\"height\": 48,\n\"isDefault\": false\n\"\n},\n\"displayName\": \"alan.walker\",\n\"isExternalCollaborator\": false,\n\"_expandable\": {\n\"operations\": \"\",\n\"personalSpace\": \"\"\n},\n\"_links\": {\n\"self\": \"https://xyz.atlassian.net/wiki/rest/api/user?accountId=632852448b75455be45293bd\"\n}\n},\n\"createdDate\": \"2022-11-21T13:02:10.295Z\"\n},\n\"_expandable\": {\n\"settings\": \"/rest/api/space/SFPWP/settings\",\n\"metadata\": \"\",\n\"operations\": \"\",\n\"lookAndFeel\": \"/rest/api/settings/lookandfeel?spaceKey=SFPWP\",\n\"identifiers\": \"\",\n\"permissions\": \"\",\n\"icon\": \"\",\n\"description\": \"\",\n\"theme\": \"/rest/api/space/SFPWP/theme\",\n\"homepage\": \"/rest/api/content/196695\"\n},\n\"_links\": {\n\"webui\": \"/spaces/SFPWP\",\n\"self\": \"https://xyz.atlassian.net/wiki/rest/api/space/SFPWP\n},\n\"macroRenderedOutput\": {},\n\"body\": {\n\"storage\": {\n\"value\": \"Here is the value of this body\",\n\"representation\": \"storage\",\n\"embeddedContent\": [],\n\"_expandable\": {\n\"content\": \"/rest/api/content/21004299\"\n}\n},\n\"_expandable\": {\n\"editor\": \"\",\n\"atlas_doc_format\": \"\",\n\"view\": \"\",\n\"export_view\": \"\",\n\"styled_view\": \"\",\n\"dynamic\": \"\",\n\"editor2\": \"\",\n\"anonymous_export_view\": \"\"\n}\n},\n\"extensions\": {\n\"position\": 3472\n},\n\"_expandable\": {\n\"childTypes\": \"\",\n\"schedulePublishInfo\": \"\",\n\"metadata\": \"\",\n\"operations\": \"\",\n\"schedulePublishDate\": \"\",\n\"children\": \"/rest/api/content/21004299/child\",\n\"restrictions\": \"/rest/api/content/21004299/restriction/byOperation\",\n\"descendants\": \"/rest/api/content/21004299/descendant\"\n},\n\"_links\": {\n\"editui\": \"/pages/resumedraft.action?draftId=21004299\",\n\"webui\": \"/spaces/SFPWP/pages/21004299/storage+ddd\",\n\"context\": \"/wiki\",\n\"self\": \"https://xyz.atlassian.net/wiki/rest/api/content/21004299\",\n\"tinyui\": \"/x/C4BAAQ\",\n\"collection\": \"/rest/api/content\",\n\"base\": \"https://xyz.atlassian.net/wiki\"\n}\n}\n</code></pre> </li> <li> <p>createContentService \u2013 A bot action service to create content in the Confluence space. Click the Plus icon to expand to view the createContentService bot action component properties. In the Component Properties window, click the Edit Request link to edit the request parameters.</p> </li> <li>createContentMessage \u2013 A message node with the script to display responses for creating content.</li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li> <p>Follow the prompts in the VA console to create content on Confluence as shown below: </p> </li> <li> <p>Enter a title and body details when prompted by the VA as shown below: </p> </li> <li> <p>You will notice that content is created with the title and body on Confluence. Expand and click the View Content button. </p> </li> <li> <p>You can view the page on Confluence. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/","title":"Configuring the DHL Action","text":"<p>The Kore.ai XO Platform lets you easily connect your DHL instance to find information regarding DHL Locations and Track Shipments.</p> <p>This document explains how to authorize and enable the DHL action and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication to allow DHL integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the DHL integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s DHL app to access an access token at runtime. To learn more about DHL account types, see DHL Documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/#enable-the-dhl-action","title":"Enable the DHL Action","text":"<p>Prerequisites:</p> <p>Before enabling the DHL action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have DHL account credentials, create an account in the DHL Developer console and note down the login credentials. See DHL Documentation for more information.</li> <li>Create a custom app for a store on the DHL admin page.</li> <li>Copy your DHL account\u2019s API Key and keep it for future use.</li> </ul>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with preconfigured Kore.ai\u2019s app with the Basic Auth option.</p> <p>Steps to authorize a DHL action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li> <p>Select the DHL from the list of Available actions. </p> </li> <li> <p>In the Configurations dialog, select the Authorization tab.</p> </li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>API Key \u2013 The secret API key of your DHL account.</p> </li> <li>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed.</li> </ol> <p>Note: The DHL action is moved from Available to Configured region. 6. You can also click the Skip for Now button to install the Dialog Task templates later. To learn how to use action templates, read the Using the DHL action templates article. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/#allow-end-user-to-authorize","title":"Allow End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s DHL app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize a DHL action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the DHL action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.</li> <li> <p>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s DHL app for authorization. To create a profile, click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the API Key option. To create Basic Auth profiles, see Bot Authorization Overview. </p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ul> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to authenticate successfully.</li> <li>Base URL \u2013 Enter the base tenant URL for the DHL instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your DHL instance.</li> <li> <p>Description \u2013 Enter the description of the basic authentication profile. </p> </li> <li> <p>Click Save Auth to save the authorization profile.</p> </li> <li>Select the new Authorization Profile, which you created to complete integration.</li> <li>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed.</li> </ul> </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/configuring-the-dhl-action/#step-2-install-the-dhl-action-templates","title":"Step 2: Install the DHL Action Templates","text":"<p>Once you have configured the Google Maps integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li> <p>A dialog task is automatically created for each installed template. </p> </li> <li> <p>Alternatively, you can create a new dialog task and select the DHL integration to select the dialog task from the templates and click Proceed. For example, select the Track Shipment task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/using-the-dhl-action-templates/","title":"Using the DHL Action Templates","text":"<p>You can use the Prebuilt Action Templates from your DHL integration to auto-create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using the DHL action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create a Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the DHL option to view the action templates.</p> </li> <li> <p>Select any of the dialog task templates and click Proceed. For example, select the Track Shipment item. </p> </li> <li> <p>If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/using-the-dhl-action-templates/#dhl-actions","title":"DHL Actions","text":"<p>The following DHL actions are supported:</p> Supported Tasks Description Method Track Shipment     Tracks the shipment using the DHL tracking ID.     GET     Find locations     Retrieves locations using the country code and postal code from the DHL system.     GET"},{"location":"app-settings/integrations/actions/dhl/using-the-dhl-action-templates/#track-shipment","title":"Track Shipment","text":"<p>Steps to track the shipment using the DHL tracking ID:</p> <ol> <li>Refer to the Installing the DHL Action templates section to install this template.</li> <li> <p>The Track Shipment dialog task is added with the following components: </p> <ol> <li>trackShipment: A user intent to track a shipment using the DHL ID.</li> <li>trackingNumber \u2013 Entity nodes for entering the tracking number.</li> <li>trackShipmentService \u2013 A bot action service to find places from an external integration using the place name. Click the Plus icon to expand to view the trackShipmentService bot action component properties.</li> <li> <p>(Optional)In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>To add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response:</p> <pre><code>{\n\"shipments\": [\n{\n\"id\": \"7777777770\",\n\"service\": \"express\",\n\"origin\": {\n\"address\": {\n\"addressLocality\": \"-\"\n},\n\"servicePoint\": {\n\"url\": \"http://www.dhl.com/en/country_profile.html\",\n\"label\": \"Origin Service Area\"\n}\n},\n\"destination\": {\n\"address\": {\n\"addressLocality\": \"-\"\n},\n\"servicePoint\": {\n\"url\": \"http://www.dhl.com/en/country_profile.html\",\n\"label\": \"Destination Service Area\"\n}\n},\n\"status\": {\n\"timestamp\": \"2023-05-23T12:30:00\",\n\"location\": {\n\"address\": {\n\"addressLocality\": \"NUERNBERG - GERMANY\"\n}\n},\n\"statusCode\": \"transit\",\n\"status\": \"transit\",\n\"description\": \"Arrived at DHL Delivery Facility NUERNBERG - GERMANY\"\n},\n\"details\": {\n\"proofOfDelivery\": {\n\"signatureUrl\": \"https://proview.dhl.com/proview/adhocnotify?id=vasdsasss\",\n\"documentUrl\": \"https://proview.dhl.com/proview/adhocnotify?id=vQg5\"\n},\n\"proofOfDeliverySignedAvailable\": false\n},\n\"events\": [\n{\n\"timestamp\": \"2023-05-23T12:30:00\",\n\"location\": {\n\"address\": {\n\"addressLocality\": \"NUERNBERG - GERMANY\"\n}\n},\n\"description\": \"Arrived at DHL Delivery Facility NUERNBERG - GERMANY\"\n},\n{\n\"description\": \"Shipment picked up\"\n}\n]\n}\n]\n}\n</code></pre> </li> <li> <p>trackShipmentMessage \u2013 A message node with the script to display responses.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to track shipment, as shown below. </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/dhl/using-the-dhl-action-templates/#find-locations","title":"Find Locations","text":"<p>Steps to find DHL locations using the country and postal codes:</p> <ol> <li>Refer to the Installing the DHL Action templates section to install this template.</li> <li> <p>The Find Locations dialog task is added with the following components: </p> <ol> <li>findLocations: A user intent to find locations using the coordinates.</li> <li>countryCode and postalCode \u2013 Entity node for entering the country and postal codes.</li> <li>findLocationsService \u2013 A bot action service to find locations using a country and postal code from an external integration. Click the Plus icon to expand to view the findLocationsService bot action component properties.</li> <li> <p>(Optional)In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>To add one or more responses, scroll down and click the +Add Response button: </p> <p>Sample Response:</p> <pre><code>{\n\"locations\": [\n{\n\"url\": \"/locations/HYD102\",\n\"location\": {\n\"ids\": [\n{\n\"locationId\": \"HYD102\",\n\"provider\": \"express\"\n}\n],\n\"keyword\": \"\",\n\"keywordId\": \"\",\n\"type\": \"servicepoint\"\n},\n\"name\": \"Madhapur Office, HYDERABAD\",\n\"distance\": 1076,\n\"place\": {\n\"address\": {\n\"countryCode\": \"IN\",\n\"postalCode\": \"500081\",\n\"addressLocality\": \"HYDERABAD\",\n\"streetAddress\": \"H.No.2-52/1, Plot No.12 Opp Kasanigr Hotel,\"\n},\n\"geo\": {\n\"latitude\": 17.441049,\n\"longitude\": 78.392052\n}\n},\n\"openingHours\": [\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Monday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Tuesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Wednesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Thursday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Friday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Saturday\"\n}\n],\n\"closurePeriods\": [],\n\"serviceTypes\": [\n\"express:drop-off-easy\",\n\"express:drop-off\",\n\"express:drop-off-account\",\n\"express:pick-up\",\n\"express:drop-off-prelabeled\"\n],\n\"averageCapacityDayOfWeek\": []\n},\n{\n\"url\": \"/locations/HYD112\",\n\"location\": {\n\"ids\": [\n{\n\"locationId\": \"HYD112\",\n\"provider\": \"express\"\n}\n],\n\"keyword\": \"\",\n\"keywordId\": \"\",\n\"type\": \"servicepoint\"\n},\n\"name\": \"Gachibowli Office, HYDERABAD\",\n\"distance\": 1840,\n\"place\": {\n\"address\": {\n\"countryCode\": \"IN\",\n\"postalCode\": \"500032\",\n\"addressLocality\": \"HYDERABAD\",\n\"streetAddress\": \"Shop No.1, First floor House no. 2-48/T2, Gachibowli\"\n},\n\"geo\": {\n\"latitude\": 17.435879,\n\"longitude\": 78.366746\n}\n},\n\"openingHours\": [\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Monday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Tuesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Wednesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Thursday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Friday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Saturday\"\n}\n],\n\"closurePeriods\": [],\n\"serviceTypes\": [\n\"express:drop-off-easy\",\n\"express:drop-off\",\n\"express:drop-off-account\",\n\"express:pick-up\",\n\"express:drop-off-prelabeled\"\n],\n\"averageCapacityDayOfWeek\": []\n},\n{\n\"url\": \"/locations/HYD119\",\n\"location\": {\n\"ids\": [\n{\n\"locationId\": \"HYD119\",\n\"provider\": \"express\"\n}\n],\n\"keyword\": \"\",\n\"keywordId\": \"\",\n\"type\": \"servicepoint\"\n},\n\"name\": \"Kothaguda X Roads,HYDERABAD\",\n\"distance\": 2332,\n\"place\": {\n\"address\": {\n\"countryCode\": \"IN\",\n\"postalCode\": \"500084\",\n\"addressLocality\": \"HYDERABAD\",\n\"streetAddress\": \"Shop No.5, 1st Flr, Satya Towers Satya Towers,H.No.2-17, Kothaguda X Roads\"\n},\n\"geo\": {\n\"latitude\": 17.4588091,\n\"longitude\": 78.3672857\n}\n},\n\"openingHours\": [\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Monday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Tuesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Wednesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Thursday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Friday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Saturday\"\n}\n],\n\"closurePeriods\": [],\n\"serviceTypes\": [\n\"express:drop-off-easy\",\n\"express:drop-off\",\n\"express:drop-off-account\",\n\"express:pick-up\",\n\"express:drop-off-prelabeled\"\n],\n\"averageCapacityDayOfWeek\": []\n},\n{\n\"url\": \"/locations/HYD109\",\n\"location\": {\n\"ids\": [\n{\n\"locationId\": \"HYD109\",\n\"provider\": \"express\"\n}\n],\n\"keyword\": \"\",\n\"keywordId\": \"\",\n\"type\": \"servicepoint\"\n},\n\"name\": \"Jubilee Hills Office, HYDERABAD\",\n\"distance\": 2909,\n\"place\": {\n\"address\": {\n\"countryCode\": \"IN\",\n\"postalCode\": \"500033\",\n\"addressLocality\": \"HYDERABAD\",\n\"streetAddress\": \"Plot No.243, Rd No.36 Jubilee Hills,\"\n},\n\"geo\": {\n\"latitude\": 17.432275,\n\"longitude\": 78.407039\n}\n},\n\"openingHours\": [\n{\n\"opens\": \"09:00:00\",\n\"closes\" : \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Monday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Tuesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Wednesday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Thursday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Friday\"\n},\n{\n\"opens\": \"09:00:00\",\n\"closes\": \"21:00:00\",\n\"dayOfWeek\": \"http://schema.org/Saturday\"\n}\n],\n\"closurePeriods\": [],\n\"serviceTypes\": [\n\"express:drop-off-easy\",\n\"express:drop-off\",\n\"express:drop-off-account\",\n\"express:pick-up\",\n\"express:drop-off-prelabeled\"\n],\n\"averageCapacityDayOfWeek\": []\n}\n]\n}\n</code></pre> </li> <li> <p>getLocationsbyCoordinatesMessage \u2013 A message node with the script to display responses.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to find the location using the country and postal codes, as shown below. </li> </ol> </li> <li> <p>To view the location details, click and expand the desired item in the results. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/","title":"Configuring the Freshdesk Action","text":"<p>The XO Platform lets you easily connect the Freshdesk integration to create, view, update, search and delete tickets. Click the Freshdesk link to learn more.</p> <p>This article explains how to authorize and enable the Freshdesk action and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication to allow Freshdesk integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the Freshdesk integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Freshdesk app to access an access token at runtime. To learn more about Freshdesk account types, see Freshdesk Documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/#step-1-enable-the-freshdesk-action","title":"Step 1: Enable the Freshdesk Action","text":"<p>Prerequisites:</p> <p>Before enabling the Freshdesk action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have Freshdesk account credentials, create a developer account in Freshdesk and note down login credentials. Use the Freshdesk Documentation for more information.</li> <li>Copy the API Key and Domain name of your Freshdesk account and keep them for future use to enable the integration.</li> </ul> <p>Steps to enable the Freshdesk action:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Once you click the Actions menu, all integrations are shown in the Available region. Select the Freshdesk action. </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with preconfigured Kore.ai\u2019s app with the Basic Auth option.</p> <p>Steps to authorize a Freshdesk action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Select the Freshdesk action in the Available Actions region.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>User Sub Domain \u2013 The domain name of the Freshdesk account.</p> </li> <li>API Key \u2013 The secret API key of your Freshdesk account.</li> <li>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </li> </ol> </li> </ol> <p>Note: The Freshdesk action is moved from Available to Configured region.</p>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/#allow-end-user-to-authorize","title":"Allow End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Freshdesk app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize a Freshdesk action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Freshdesk action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.</li> <li> <p>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Freshdesk app for authorization. To create a profile, click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the Basic Auth option. To create Basic Auth profiles, see Bot Authorization Overview.</p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ul> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select No for the tenancy URLs option.</li> <li>Base URL \u2013 Enter the base tenant URL for the Freshdesk instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your Freshdesk instance.</li> <li>Description \u2013 Enter the description of the basic authentication profile. </li> </ul> </li> <li> <p>Click Save Auth to save the authorization profile. </p> </li> <li> <p>Select the new Authorization Profile, which you created to complete integration.</p> </li> </ol> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/configuring-the-freshdesk-action/#step-2-install-the-freshdesk-action-templates","title":"Step 2: Install the Freshdesk Action Templates","text":"<p>Once you have configured a Freshdesk integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li>Once all templates are installed, a dialog task for each template is auto-created.</li> <li> <p>Select the desired dialog task from the templates and click Proceed. For example, select the Create a Ticket task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/","title":"Using the Freshdesk Action Templates","text":"<p>You can use the Prebuilt Action Templates from your Freshdesk integration to auto-create dialog tasks and test them using the Talk to Bot option.</p> <p>Steps to create a dialog task using the Freshdesk action templates:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks.</li> <li> <p>Click Create a Dialog Task. </p> </li> <li> <p>On the Dialog Task pop-up, under the Integration, select the Freshdesk option to view the action templates. </p> </li> <li> <p>If you have not configured any integration for your virtual assistant, you will see the Explore Integrations option. Once you click this option, you will be redirected to the Actions page to configure an integration for your VA. For more information, see Actions Overview. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#freshdesk-actions","title":"Freshdesk Actions","text":"<p>The following Freshdesk actions are supported in this release:</p> Supported Tasks Description Method Create a Ticket     Creates a ticket in the Freshdesk system.     POST     Get ticket by ID     Fetch ticket details with ID from the Freshdesk system.     GET     List all tickets     Retrieves all tickets from the Freshdesk system.     GET     Update a ticket     Update a ticket in the Freshdesk system.     PUT     Search ticket by field     Search a ticket using the field details from the Freshdesk system.     GET     Delete a ticket     Deletes a ticket from the Freshdesk system.     DELETE"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#create-a-ticket","title":"Create a Ticket","text":"<p>Steps to create a ticket in the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The Create Ticket dialog task is added with the following components: </p> <ol> <li>createTicket \u2013 A user intent to create a ticket.</li> <li>subject, description, email, priority, status, and phone \u2013 Entity nodes for gathering the required ticket details.</li> <li>createTicketScript \u2013 A bot action script to create a ticket in an external integration.</li> <li>createTicketService \u2013 A bot action service to create a ticket in an external integration. Click the Plus icon to expand to view the createTicketService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request:</p> <pre><code>{\n\"email\": \"rhsg@kore.com\",\n\"subject\": \"Support payment\",\n\"description\": \"Payment is pending issue\",\n\"status\": 2,\n\"priority\": 3\n}\n</code></pre> <p>To add one or more responses, scroll down and click the +Add Response button:</p> <p>Sample Response:</p> <pre><code>{\n\"ticket\": {\n\"cc_emails\": [],\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"fr_escalated\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"group_id\": null,\n\"priority\": 1,\n\"requester_id\": 27002140321,\n\"requested_for_id\": 27002140321,\n\"responder_id\": null,\n\"source\": 2,\n\"status\": 2,\n\"subject\": \"Support payment...\",\n\"to_emails\": null,\n\"department_id\": null,\n\"id\": 57,\n\"type\": \"Incident\",\n\"due_by\": \"2022-10-07T21:00:00Z\",\n\"fr_due_by\": \"2022-09-30T18:00:00Z\",\n\"is_escalated\": false,\n\"description\": \"Payment is pending issue\",\n\"description_text\": \"Payment is pending issue\",\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"custom_fields\": {},\n\"created_at\": \"2022-09-28T07:00:14Z\",\n\"updated_at\": \"2022-09-28T07:00:14Z\",\n\"tags\": [],\n\"attachments\": [] }\n</code></pre> </li> <li> <p>createTicketMessage \u2013 A message node with the script to display responses for various scenarios.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to create a ticket as shown below: </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#get-ticket-by-id","title":"Get Ticket by ID","text":"<p>Steps to find a ticket using the ID in the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The Get Ticket by ID dialog task is added with the following components: </p> <ol> <li>getTicketbyId \u2013 A user intent to find a ticket by ID.</li> <li>ticketID \u2013 Entity nodes for gathering the required ticket details.</li> <li>getTicketbyIdService \u2013 A bot action service to find a ticket in an external integration. Click the Plus icon to expand to view the getTicketbyIdService bot action component properties.</li> <li> <p>In the Component Properties window, to add one or more responses, scroll down and click +Add Response: </p> <p>Sample Response:</p> <pre><code>{\n\"ticket\": {\n\"cc_emails\": [],\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"fr_escalated\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"group_id\": null,\n\"priority\": 1,\n\"requester_id\": 27002140321,\n\"requested_for_id\": 27002140321,\n\"responder_id\": null,\n\"source\": 2,\n\"status\": 2,\n\"subject\": \"Support payment...\",\n\"to_emails\": null,\n\"department_id\": null,\n\"id\": 57,\n\"type\": \"Incident\",\n\"due_by\": \"2022-10-07T21:00:00Z\",\n\"fr_due_by\": \"2022-09-30T18:00:00Z\",\n\"is_escalated\": false,\n\"description\": \"Payment is pending issue\",\n\"description_text\": \"Payment is pending issue\",\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"custom_fields\": {},\n\"created_at\": \"2022-09-28T07:00:14Z\",\n\"updated_at\": \"2022-09-28T07:00:14Z\",\n\"tags\": [],\n\"attachments\": [] }\n</code></pre> </li> <li> <p>getTicketbyIdMessage \u2013 A message node with script to display responses for various scenarios.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to find a ticket by ID as shown below: </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#list-all-tickets","title":"List All Tickets","text":"<p>Steps to view all tickets in the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The List All Tickets dialog task is added with the following components: </p> <ol> <li>listAllTickets \u2013 A user intent to view all tickets.</li> <li>listAllTicketsService \u2013 A bot action service to fetch all tickets from an external integration. Click the Plus icon to expand to view the listAllCustomersService bot action component properties.</li> <li> <p>In the Component Properties window, to add one or more responses, scroll down and click +Add Response. </p> <p>Sample Response:</p> <pre><code>{\n\"tickets\": [\n{\n\"subject\": \"Support payment...\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002140321,\n\"responder_id\": null,\n\"due_by\": \"2022-10-07T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-30T18:00:00Z\",\n\"id\": 57,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-28T07:00:14Z\",\n\"updated_at\": \"2022-09-28T07:00:14Z\",\n\"requested_for_id\": 27002140321,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nPayment is pending issue...\n\",\n\"description_text\": \"Payment is pending issue...\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"refer\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002135586,\n\"responder_id\": null,\n\"due_by\": \"2022-09-28T15:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,   \n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-27T16:00:00Z\",\n\"id\": 55,\n\"priority\": 3,\n\"status\": 5,\n\"source\": 2,\n\"created_at\": \"2022-09-27T10:02:42Z\",\n\"updated_at\": \"2022-09-27T10:16:14Z\",\n\"requested_for_id\": 27002135586,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nqfvftwd\n\",\n\"description_text\": \"qfvftwd\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"freshh\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134408,\n\"responder_id\": null,\n\"due_by\": \"2022-09-28T15:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-27T16:00:00Z\",\n\"id\": 54,\n\"priority\": 3,\n\"status\": 4,\n\"source\": 2,\n\"created_at\": \"2022-09-27T07:19:38Z\",\n\"updated_at\": \"2022-09-27T11:53:52Z\",\n\"requested_for_id\": 27002134408,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"Loremdf fwhguhsfsdkjvvnskvfbewuvbwehj\",\n\"description_text\": \"Loremdf fwhguhsfsdkjvvnskvfbewuvbwehj\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"wet\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134241,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",\n\"id\": 53,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-27T06:34:46Z\",\n\"updated_at\": \"2022-09-27T06:34:46Z\",\n\"requested_for_id\": 27002134241,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nhrjtyhrte\n\",\n\"description_text\": \"hrjtyhrte\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"rewet\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134235,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",\n\"id\": 51,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-27T06:31:49Z\",\n\"updated_at\": \"2022-09-27T06:31:49Z\",\n\"requested_for_id\": 27002134235,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\ngnhgfd\n\",\n\"description_text\": \"gnhgfd\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"frown\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134223,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",\n\"id\": 50,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-27T06:24:47Z\",\n\"updated_at\": \"2022-09-27T06:24:47Z\",\n\"requested_for_id\": 27002134223,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nfrwetyefd\n\",\n\"description_text\": \"frwetyefd\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Gehr\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134213,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",    \n\"id\": 48,\n\"priority\": 1,\n\"status\": 3,\n\"source\": 2,\n\"created_at\": \"2022-09-27T06:21:44Z\",\n\"updated_at\": \"2022-09-27T06:21:44Z\",\n\"requested_for_id\": 27002134213,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nright\n\",\n\"description_text\": \"right\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"wfwgtg\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134136,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",\n\"id\": 47,\n\"priority\": 1,\n\"status\": 4,\n\"source\": 2,\n\"created_at\": \"2022-09-27T05:59:30Z\",\n\"updated_at\": \"2022-09-27T05:59:30Z\",\n\"requested_for_id\": 27002134136,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nrwtytuiutyre\n\",\n\"description_text\": \"rwtytuiutyre\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"fergt\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002134094,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T18:00:00Z\",\n\"id\": 46,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-27T05:41:14Z\",\n\"updated_at\": \"2022-09-27T05:51:01Z\",\n\"requested_for_id\": 27002134094,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\newqwrtg\n\",\n\"description_text\": \"ewqwrtg\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"rerun\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002130160,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T15:28:50Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T12:28:50Z\",\n\"id\": 45,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T15:28:50Z\",\n\"updated_at\": \"2022-09-26T15:28:50Z\",\n\"requested_for_id\": 27002130160,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nfuhrer\n\",\n\"description_text\": \"fuhrer\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"deuced\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002130150,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T15:14:51Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-29T12:14:51Z\",\n\"id\": 43,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T15:14:51Z\",\n\"updated_at\": \"2022-09-26T15:14:51Z\",\n\"requested_for_id\": 27002130150,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\ndensity\n\",\n\"description_text\": \"density\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Ingjar\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002130106,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T14:44:03Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T20:44:04Z\",\n\"id\": 42,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T14:44:03Z\",\n\"updated_at\": \"2022-09-26T14:44:03Z\",\n\"requested_for_id\": 27002130106,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nwfkjge\n\",\n\"description_text\": \"wfkjge\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"rehear\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002130041,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T14:41:24Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T20:41:24Z\",\n\"id\": 41,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T14:41:24Z\",\n\"updated_at\": \"2022-09-26T14:41:24Z\",\n\"requested_for_id\": 27002130041,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\njfsg\n\",\n\"description_text\": \"jfsg\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Pueu\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002126922,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T13:27:43Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T19:27:43Z\",\n\"id\": 40,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T13:27:43Z\",\n\"updated_at\": \"2022-09-26T13:27:43Z\",\n\"requested_for_id\": 27002126922,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\newrtr\n\",\n\"description_text\": \"ewrtr\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Support payment...\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002120954,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T12:52:44Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T18:52:44Z\",\n\"id\": 38,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T12:52:44Z\",\n\"updated_at\": \"2022-09-26T12:52:44Z\",\n\"requested_for_id\": 27002120954,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nPayment is pending issue...\n\",\n\"description_text\": \"Payment is pending issue...\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"tow\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002126328,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T12:11:46Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T18:11:46Z\",\n\"id\": 36,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T12:11:46Z\",\n\"updated_at\": \"2022-09-26T12:11:46Z\",\n\"requested_for_id\": 27002126328,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nRORT\n\",\n\"description_text\": \"RORT\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"WJF\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002126324,\n\"responder_id\": null,\n\"due_by\": \"2022-10-06T12:06:33Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T18:06:33Z\",\n\"id\": 34,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-26T12:06:33Z\",\n\"updated_at\": \"2022-09-26T12:06:33Z\",\n\"requested_for_id\": 27002126324,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\njjrwehg\n\",\n\"description_text\": \"jjrwehg\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Support Needed...\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002120952,\n\"responder_id\": null,\n\"due_by\": \"2022-10-05T21:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-28T18:00:00Z\",\n\"id\": 6,\n\"priority\": 1,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-24T18:43:39Z\",\n\"updated_at\": \"2022-09-24T18:43:39Z\",\n\"requested_for_id\": 27002120952,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\nDetails about the issue...\n\",\n\"description_text\": \"Details about the issue...\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Login issue\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002120946,\n\"responder_id\": null,\n\"due_by\": \"2022-09-28T18:00:00Z\",\n\"fr_escalated\": true,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-26T20:00:00Z\",\n\"id\": 5,\n\"priority\": 2,\n\"status\": 2,\n\"source\": 1,\n\"created_at\": \"2022-09-24T18:14:56Z\",\n\"updated_at\": \"2022-09-24T18:18:52Z\",\n\"requested_for_id\": 27002120946,\n\"to_emails\": null,\n\"type\": \"Incident\",\n\"description\": \"\n`\\n\nUnable to login\n\\n\n`\",\n\"description_text\": \"Unable to login\",\n\"custom_fields\": {}\n},\n{\n\"subject\": \"Request for Andrea : Dell Monitor\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002120938,\n\"responder_id\": null,\n\"due_by\": \"2022-09-28T18:00:00Z\",\n\"fr_escalated\": true,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-26T20:00:00Z\",\n\"id\": 3,\n\"priority\": 2,\n\"status\": 2,\n\"source\": 2,\n\"created_at\": \"2022-09-24T17:59:25Z\",\n\"updated_at\": \"2022-09-24T17:59:25Z\",\n\"requested_for_id\": 27002120938,\n\"to_emails\": null,\n\"type\": \"Service Request\",\n\"description\": \"\",\n\"description_text\": \"\",\n\"custom_fields\": {}\n}\n] }\n</code></pre> </li> <li> <p>listAllTicketsMessage \u2013 A message node with the script to display responses for various scenarios.</p> </li> <li>Click the Train tab to complete the Dialog task training.</li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to view all tickets as shown below: </li> </ol> </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#update-a-ticket","title":"Update a Ticket","text":"<p>Steps to update a ticket in the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The Update a Ticket dialog task is added with the following components: </p> <ol> <li>updateTicket \u2013 A user intent to update a ticket.</li> <li>ticketID, updateField, email, subject, description, status, and priority \u2013 Entity nodes for gathering the required ticket details.</li> <li> <p>updateTicketScript \u2013 A bot action service to update a ticket in an external integration. Click the Plus icon to expand to view the updateTicketScript bot action component properties. </p> </li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> <p>Sample Request:</p> <pre><code>{\n\"email\": \"work@kore.com\",\n\"subject\": \"LOGIN ISSUE...\",\n\"description\": \"Unable to login...\",\n\"status\": 4,\n\"priority\": 2\n}\n</code></pre> <p>To add one or more responses, scroll down and click +Add Response.</p> <p>Sample Response:</p> <pre><code>{\n\"ticket\": {\n\"cc_emails\": [],\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"spam\": false,\n\"email_config_id\": null,\n\"fr_escalated\": false,\n\"group_id\": null,\n\"priority\": 2,\n\"requester_id\": 27002140415,\n\"requested_for_id\": 27002140415,\n\"responder_id\": null,\n\"source\": 2,\n\"status\": 4,\n\"subject\": \"LOGIN ISSUE...\",\n\"description\": \"Unable to login...\",\n\"description_text\": \"Unable to login...\",\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"custom_fields\": {},\n\"id\": 54,\n\"type\": \"Incident\",\n\"to_emails\": null,\n\"department_id\": null,\n\"is_escalated\": false,\n\"tags\": [],\n\"due_by\": \"2022-09-30T14:00:00-04:00\",\n\"fr_due_by\": \"2022-09-28T16:00:00-04:00\",\n\"created_at\": \"2022-09-27T07:19:38Z\",\n\"updated_at\": \"2022-09-28T07:22:17Z\",\n\"attachments\": [] }\n}\n</code></pre> </li> <li> <p>updateTicketMessage \u2013 A message node with the script to display responses for various scenarios.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to update a ticket as shown below: </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#search-ticket-by-field","title":"Search Ticket by Field","text":"<p>Steps to search ticket by field from the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The Search Ticket by Field dialog task is added with the following components: </p> <ol> <li>searchTicket -: A user intent to list all invoices.</li> <li>chooseField, priority, email, and status \u2013 Entity nodes for gathering the required ticket details.</li> <li>searchTicketScript \u2013 A bot action service to search a ticket by field in an external integration.</li> <li>searchTicketService \u2013 A bot action service to find a ticket by field in an external integration. Click the Plus icon to expand to view the searchTicketService bot action component properties.</li> <li> <p>In the Component Properties window, to add one or more responses, scroll down and click +Add Response as shown below: </p> <p>Sample Response:</p> <pre><code>{\n\"tickets\": [\n{\n\"subject\": \"refer\",\n\"group_id\": null,\n\"department_id\": null\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002135586,\n\"responder_id\": null,\n\"due_by\": \"2022-09-28T15:00:00Z\",\n\"fr_escalated\": false,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": false,\n\"fr_due_by\": \"2022-09-27T16:00:00Z\",\n\"priority\": 3,\n\"source\": 2,\n\"status\": 5,\n\"created_at\": \"2022-09-27T10:02:42Z\",\n\"updated_at\": \"2022-09-27T10:16:14Z\",\n\"requested_for_id\": 27002135586,\n\"to_emails\": null,\n\"id\": 55,\n\"type\": \"Incident\",\n\"description\": \"\nqfvftwd\n\",\n\"description_text\": \"qfvftwd\"\n},\n{\n\"subject\": \"Support payment...\",\n\"group_id\": null,\n\"department_id\": null,\n\"category\": null,\n\"sub_category\": null,\n\"item_category\": null,\n\"requester_id\": 27002120954,\n\"responder_id\": null,\n\"due_by\": \"2022-09-27T15:00:00Z\",\n\"fr_escalated\": true,\n\"deleted\": false,\n\"spam\": false,\n\"email_config_id\": null,\n\"fwd_emails\": [],\n\"reply_cc_emails\": [],\n\"cc_emails\": [],\n\"is_escalated\": true,\n\"fr_due_by\": \"2022-09-26T16:00:00Z\",\n\"priority\": 3,\n\"source\": 2,\n\"status\": 2,\n\"created_at\": \"2022-09-24T18:46:20Z\",\n\"updated_at\": \"2022-09-25T06:36:43Z\",\n\"requested_for_id\": 27002120954,\n\"to_emails\": null,\n\"id\": 7,\n\"type\": \"Incident\",\n\"description\": \"\nPayment is pending issue...\n\",\n\"description_text\": \"Payment is pending issue...\"\n}\n],\n\"total\": 2\n}\n</code></pre> </li> <li> <p>searchTicketMessage \u2013 A message node with the script to display responses for various scenarios.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to find a ticket by field as shown below: </li> </ol>"},{"location":"app-settings/integrations/actions/freshdesk/using-the-freshdesk-action-templates/#delete-a-ticket","title":"Delete a Ticket","text":"<p>Steps to delete a ticket in the Freshdesk integration:</p> <ol> <li>Refer to the Installing the Freshdesk templates section to install this template.</li> <li> <p>The Delete a Ticket dialog task is added with the following components: </p> <ol> <li>deleteTicket \u2013 A user intent to make payments.</li> <li>ticketID \u2013 Entity nodes for gathering the required ticket details.</li> <li>deleteTicketService \u2013 A bot action service to delete a ticket in an external integration. Click the Plus icon to expand to view the deleteTicketService bot action component properties.</li> <li> <p>In the Component Properties window, click the Edit Request link to edit the request parameters as shown below: </p> </li> <li> <p>deleteTicketMessage \u2013 A message node with the script to display responses for various scenarios.</p> </li> </ol> </li> <li> <p>Click the Train tab to complete the Dialog task training.</p> </li> <li>Click the Talk to Bot icon to test and debug the dialog task.</li> <li>Follow the prompts in the VA console to delete a ticket.</li> </ol>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/","title":"Configuring the Freshservice ITSM Action","text":"<p>The XO Platform lets you easily connect the Freshservice integration to allow you to create, view, update, and delete tickets in the system to manage your IT services. Click the Freshservice link to learn more.</p> <p>This document explains the Freshservice configuration steps to enable, authorize, configure, and install the pre-built templates.</p>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/#authorizations-supported","title":"Authorizations Supported","text":"<p>The Kore.ai XO Platform supports basic authentication to allow Freshservice integration to exchange data. For more information, read the Bot Authorization Overview article.</p> <p>The Kore.ai XO Platform supports the following authorization types for the Freshservice integration:</p> <ul> <li>Pre-Authorize the Integration \u2013 To make the integration process smoother for developers and customers, you can pre-authorize it by providing the necessary authorization credentials to obtain the access token.</li> <li>Allow Users to Authorize the Integration \u2013 This method requires the end user to provide credentials during the conversation for authorization. This authorization process involves requesting permission for Kore.ai\u2019s Freshservice app to access an access token at runtime. To learn more about Freshservice account types, see Freshservice Documentation.</li> </ul>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/#step-1-enable-the-freshservice-action","title":"Step 1: Enable the Freshservice Action","text":"<p>Prerequisites:</p> <p>Before enabling the Freshservice action, complete the following prerequisites:</p> <ul> <li>If you don\u2019t have Freshservice account credentials, create an account in Freshservice and note down login credentials. For more information, see Freshservice Documentation.</li> <li>Copy the API Key and Domain name of your Freshservice account and keep them for future use to enable the integration.</li> </ul> <p>Steps to enable the Freshservice action:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions.</li> <li>Once you click the Actions menu, all integrations are shown in the Available region. Select the Freshservice action. </li> </ol>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/#pre-authorize-the-integration","title":"Pre-authorize the Integration","text":"<p>Basic Auth</p> <p>You can authorize the integration using your credentials. The developer authorization lets you authorize the integration with preconfigured Kore.ai\u2019s app with the Basic Auth option.</p> <p>Steps to authorize a Freshservice action using developer credentials:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Freshservice action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li> <p>Authorization Type \u2013 Select the Pre-authorize the Integration option, and then select the Basic Auth option. </p> </li> <li> <p>User Sub Domain \u2013 The domain name of the Freshservice account.</p> </li> <li>API Key \u2013 The secret API key of your Freshservice account.</li> </ol> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> </li> </ol> <p>Note: The Freshservice action is moved from Available to Configured region.</p>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/#allow-end-user-to-authorize","title":"Allow End User to Authorize","text":"<p>You can authorize the integration at a user level with their login credentials. The user authorization process involves requesting permission for Kore.ai\u2019s Freshservice app to access an access token at runtime. You can also use the basic auth profile to let a user configure the integration at runtime.</p> <p>Steps to authorize a Freshservice action at a user level:</p> <ol> <li>Go to Build &gt; Integrations &gt; Actions and select the Freshservice action.</li> <li>In the Configurations dialog, select the Authorization tab.</li> <li> <p>Enter the following details:</p> <ol> <li>Authorization Type \u2013 Select the Allow Users to Authorize the Integration option, and then select the Basic Auth option.</li> <li> <p>Create your authorization profile to obtain an access token and use it to complete integration without using Kore.ai\u2019s Freshservice app for authorization. To create a profile, click the Select Authorization drop-down and select the Create New option. </p> </li> <li> <p>Select the type of authorization mechanism. For example, select the Basic Auth option. To create Basic Auth profiles, see Bot Authorization Overview. </p> </li> <li> <p>Enter the following authentication credentials for the Basic Auth mechanism:</p> <ul> <li>Name \u2013 Enter the name for the Basic Auth profile.</li> <li>Select Yes; some tasks will have tenancy URLs, and the user must provide the URLs to authenticate successfully.</li> <li>Base URL \u2013 Enter the base tenant URL for the Freshservice instance.</li> <li>Authorization Check URL \u2013 Enter the authorization check URL for your Freshservice instance.</li> <li>Description \u2013 Enter the description of the basic authentication profile.</li> </ul> </li> <li> <p>Click Save Auth to save the authorization profile. </p> </li> <li> <p>Select the new Authorization Profile, which you created to complete integration.</p> </li> </ol> </li> <li> <p>Click Enable. When you configure the action for the first time, the Integration Successful pop-up is displayed. </p> </li> </ol>"},{"location":"app-settings/integrations/actions/freshservice/configuring-the-freshservice-action/#step-2-install-the-freshservice-action-templates","title":"Step 2: Install the Freshservice Action Templates","text":"<p>Once you have configured a Freshservice integration, you can explore and install action templates.</p> <p>Steps to install action templates:</p> <ol> <li> <p>On the Integration Successful dialog, click the Explore Templates button to view the templates. </p> </li> <li> <p>In the Integration Templates dialog, click the Install button to begin the installation. </p> </li> <li> <p>Once the template is installed, click the Go to Dialog button to view the dialog task.</p> </li> <li> <p>Once all templates are installed, a dialog task for each template is auto-created. </p> </li> <li> <p>Select the desired dialog task from the templates and click Proceed. For example, select the Create a Ticket task. </p> </li> <li> <p>Once you click Proceed, the dialog task is auto-created, and the canvas opens with all required entity nodes, service nodes, and message scripts. </p> </li> </ol>"},{"location":"app-settings/language-management/building-multi-language-bots/","title":"Getting Started with Multilingual Virtual Assistants","text":"<p>Consumers are more likely to engage with virtual assistants that communicate in their preferred language. The Kore.ai XO Platform supports enabling multiple languages within an assistant without having to rebuild the definitions. The platform supports over 100 languages and you can choose to enable any of these languages for your assistant. You can start building with one language and enable additional languages as and when you need them.  </p> <p>This article takes you through the general context within which multilingual VAs work. It discusses language use in VA-user conversations and in NLU processes, language enablement options, as well as language detection and selection. </p>"},{"location":"app-settings/language-management/building-multi-language-bots/#building-a-multilingual-va","title":"Building a Multilingual VA","text":"<p>If you want to build a Multilingual VA, there are a few points to keep in mind:</p> <ol> <li>There is a set of basic building blocks to a multilingual VA: the language in which it talks to users, the language in which you train it, and the process through which it detects and selects which languages to use. Please continue reading this article to learn more.</li> <li>You can create a new Virtual Assistant or add new languages to an existing one. Read more about managing languages here.</li> <li>Multilingual VAs have language-specific components and some features exhibit different behaviors compared to single language assistants. Read more about this here.</li> <li>Translation can be automated using pre-built translation services from providers such as Microsoft or Google; or custom services, including any that you may build in-house. Read here to learn more.</li> </ol>"},{"location":"app-settings/language-management/building-multi-language-bots/#the-conversation-bot-language","title":"The Conversation (Bot) Language","text":"<p>Enabling a language requires you to train the model to understand the user\u2019s input and present the responses in the user\u2019s language. To achieve this, the platform allows you to choose a Conversation (Bot) Language and NLU Language for every language that you would like to enable. In most cases, the Conversation Language can be the same as the NLU Language.</p> <p>Conversation Language is the one that users use to interact with the assistant. You can choose any of the over 100 languages as the Conversation Language. You can define the responses (prompts, messages. etc.,) in the Conversation Language. </p> <p>You can also use the automatic response translation feature when you or your team does not have expertise in the user\u2019s language. You can write the responses in your preferred language and the platform will automatically translate them to the user\u2019s language during the conversation. </p>"},{"location":"app-settings/language-management/building-multi-language-bots/#supported-bot-languages","title":"Supported Bot Languages","text":"<p>The following are the Conversation Languages supported by the Platform:</p> Afrikaans \u2013 af     Haitian_creole \u2013 ht     Romanian \u2013 ro     Amharic  \u2013 am     Hungarian \u2013 hu     Russian \u2013 ru     Assamese \u2013 as     Irish \u2013 ga     Sinhalese \u2013 si     Arabic \u2013 ar     Indonesian \u2013 id     Slovak \u2013 sk     Azerbaijani \u2013 az     Igbo \u2013  ig     Slovenian \u2013 sl     Armenian \u2013 hy     Icelandic \u2013 is     Spanish \u2013 es     Albanian  \u2013 sq     Italian \u2013 if     Samoan \u2013 sm     Bulgarian \u2013 bg     Japanese \u2013 ja     Shona \u2013 sn     Belarusian \u2013 be     Javanese \u2013 jv     Somali \u2013 so     Bengali/Bangla \u2013 bn     Kazakh \u2013 kk     Serbian \u2013 sr     Basque \u2013 eu     Khmer \u2013 km     Sesotho \u2013 st     Bosnian \u2013 bs     Kannada \u2013 kn     Sundanese \u2013 su     Burmese \u2013 my     Korean \u2013 ko     Swedish \u2013 sv     Cebuano \u2013 ceb     Kurdish \u2013 km     Swahili \u2013 sw     Catalan \u2013 ca     Kyrgyz \u2013 ky     Tamil \u2013 ta     Chinese \u2013 izh     Kinyarwanda -rw     Tagalog \u2013 tl     Corsican \u2013 co     Latin \u2013 la     Tibetan \u2013 bo     Croatian \u2013 hr     Luxembourgish \u2013 lb      Telugu \u2013 te     Czech \u2013 cs     Laothian/Laos/lao \u2013 lo     Tajik \u2013 tg     Danish \u2013 da     Lithuanian \u2013 lt     Thai \u2013 th     Dutch \u2013 nl     Latvian \u2013 lv     Turkmen \u2013 tk     English \u2013 en     Marathi \u2013 mr     Tagalog/Filipino \u2013 fil     Esperanto \u2013 eo     Malay \u2013 ms     Turkish \u2013 tr     Estonian \u2013 et     Malagasy \u2013 mg     Tatar \u2013 tt     Finnish \u2013 fi     Maori \u2013 mi     Uighur/Uyghur \u2013 ug     French \u2013 fr     Macedonian \u2013 mk     Urdu \u2013 ur     Frisian \u2013 fy     Maltese \u2013 mt     Ukrainian \u2013 uk     German \u2013 de     Malayalam \u2013 ml     Uzbek \u2013 uz     Greek \u2013 el     Mongolian \u2013 mn     Vietnamese \u2013 vi     Galician \u2013 gl     Nepali \u2013 ne     Wolof \u2013 wo     Georgian \u2013 ka     Norwegian \u2013 nb     Welsh \u2013 cy     Gujarati \u2013 gu     Nyanja \u2013 ny     Xhosa \u2013 xh     Hausa \u2013 ha     Oriya/Odia \u2013 or      Yiddish \u2013 yi     Hawaiian \u2013 haw     Punjabi \u2013 pa     Yoruba \u2013 yo     Hebrew \u2013 he     Polish \u2013 pl     Zulu \u2013 zo     Hindi \u2013 hi     Portuguese \u2013 pt     Hmong \u2013 hmn     Persian \u2013 fa     Hmong \u2013 hmn     Persian \u2013 fa"},{"location":"app-settings/language-management/building-multi-language-bots/#the-nlu-language","title":"The NLU Language","text":"<p>The NLU Language is the one that you train the assistant with, to identify the user\u2019s intents. The NLU model is built using the NLU Language that you choose. This language can be the same as the Conversation language or it can be any other supported language. </p>"},{"location":"app-settings/language-management/building-multi-language-bots/#supported-nlu-languages","title":"Supported NLU Languages","text":"<p>The following are the NLU Languages supported by the platform. While most of the NLU features are supported in all languages, there are some exceptions, see here for more details.</p> Arabic \u2013 ar     Kazakh (post v7.2 release) \u2013 kk     Chinese Simplified \u2013 zh_cn     Marathi (post v9.0 release) \u2013 mr     Chinese Traditional -zh_tw     Norwegian (post v8.1 release) \u2013 nb     Catalan (post v9.0 release) \u2013 ca     Polish (post v7.0 release) \u2013 pl     Dutch \u2013 nl     Portuguese (Brazilian) \u2013 pt     English \u2013 en     Russian (post v7.0 release) \u2013 ru     French \u2013 fr     Swedish (post v7.1 release) \u2013 sv     Finnish (post v6.4 release) \u2013 fi     Slovenian \u2013 sl      Hindi (post v8.1 release) \u2013 hi     Spanish \u2013 es     German \u2013 de     Tagalog \u2013 tl     Indonesian \u2013 id     Telugu (post v9.0 release) \u2013 te     Italian \u2013 it     Tamil (post v9.0 release) \u2013 ta     Japanese \u2013 ja     Ukrainian (post v7.0 release) \u2013 uk     Korean \u2013 ko"},{"location":"app-settings/language-management/building-multi-language-bots/#language-specific-nlu-models","title":"Language-specific NLU Models","text":"<p>The platform supports language-specific NLU models for 26 languages. These models are pre-trained to understand system entities, concepts, sentiment, etc. in specific languages. </p> <ul> <li>In most cases, the NLU Language can be the same as the Conversation Language for the 26 languages listed below. </li> <li>There may be cases where you can choose an NLU Language that is different from the Conversation Language. For example, you want to enable the Arabic language for your assistant but train using the English language. You can enable the automatic input translation feature to support this flow. The user input is automatically translated to the NLU Language during the conversation. </li> <li>These models provide a wide range of configurations for you to fully customize the model behavior. </li> </ul>"},{"location":"app-settings/language-management/building-multi-language-bots/#the-multilingual-nlu-model","title":"The Multilingual NLU Model","text":"<p>Multilingual NLU model is a language-agnostic model that understands over 100 languages. </p> <ul> <li>Translation of user input is not required as the model is pre-trained to understand over 100 languages </li> <li>As the model is language agnostic, you can train the model in any of your preferred languages or a combination of languages. </li> <li>This model supports fewer configurations as compared to the language-specific NLU models.</li> </ul>"},{"location":"app-settings/language-management/building-multi-language-bots/#language-enablement-options","title":"Language Enablement Options","text":"<p>The platform offers various options for you to enable additional languages. You can choose a combination of Conversation Language, NLU Language, Input Translation, and Response Translation that suits your needs.</p>"},{"location":"app-settings/language-management/building-multi-language-bots/#scenario-1-enabling-a-language-in-which-you-can-train-as-well","title":"Scenario 1: Enabling a language in which you can train as well","text":"<p>Example</p> Conversation Language     NLU Language     Input Translation     Response Translation     English      English     Not Required     Optional     <ul> <li>This is one of the common ways of enabling languages. </li> <li>The Conversation Language and the NLU Language will be the same. </li> <li>Input Translation and Response Translation are not required for this flow.</li> </ul>"},{"location":"app-settings/language-management/building-multi-language-bots/#scenario-2-enabling-a-language-using-another-language-as-nlu-language","title":"Scenario 2: Enabling a language using another language as NLU Language","text":"<p>Example</p> Conversation Language     NLU Language     Input Translation     Response Translation     Arabic      English     Required     Optional     Georgian     French     Required     Optional     <ul> <li>Use this flow if you want to train the assistant in a language other than the conversation language. </li> <li>You can also use this flow if the language you want to enable is not supported as an NLU Language.</li> <li>Input Translation is required for this flow to translate the user\u2019s input to the NLU Language. </li> <li>You will need to enable the Response Translation option if the responses are defined in a language other than the conversation language.</li> </ul>"},{"location":"app-settings/language-management/building-multi-language-bots/#scenario-3-enabling-a-language-using-the-multilingual-nlu-model","title":"Scenario 3: Enabling a language using the Multilingual NLU model","text":"<p>Example</p> Conversation Language     NLU Language     Input Translation     Response Translation     Arabic      Multilingual Model     Not Required     Optional     Georgian     Multilingual Model     Not Required     Optional     <ul> <li>Use this flow if you want to train using the multilingual NLU model. </li> <li>You can also use this flow if the language you want to enable is not supported as an NLU Language.</li> <li>Input Translation is not required for this flow as the multi-lingual model understands over 100 languages. </li> <li>You will need to enable the Response Translation option if the responses are defined in a language other than the conversation language.</li> </ul>"},{"location":"app-settings/language-management/building-multi-language-bots/#language-detection-and-selection","title":"Language Detection and Selection","text":"<p>Multilingual virtual assistants auto-detect and switch language based on the user\u2019s utterance. An exception to this rule is when the user is expected to enter a value against an entity and the user input satisfies that entity\u2019s criteria.</p>"},{"location":"app-settings/language-management/building-multi-language-bots/#language-detection","title":"Language Detection","text":"<p>There are three ways an assistant can detect the language based upon the user utterance:</p> <ul> <li>By Default: Kore.ai\u2019s platform uses its own language detection algorithm to detect language from the user utterance. This is the default setting and the end user\u2019s language will be detected by the platform.</li> <li>Google API: For on-prem installation, you can go with the above-mentioned default setting of Kore.ai\u2019s in-house language detection algorithm or use Google APIs for language detections. You can set it in the Kore Config file.</li> <li>BotKit SDK: If you are using BotKit SDK, you may also send the following cheat command from your BotKit to the platform:   cheat language &lt; language name or code&gt;</li> </ul> <p>The assistant continues to communicate with the user in the same language. If the user switches to another enabled language anytime later, the assistant changes to the new language automatically.</p> <p>If the assistant fails to detect a user\u2019s language with high confidence, it requests the user to select a preferred language from the list of enabled options.</p>"},{"location":"app-settings/language-management/building-multi-language-bots/#language-selection","title":"Language Selection","text":"<ol> <li> <p>The virtual assistant identifies user language from every utterance. In case a change is detected, it will get a confirmation from the user regarding the switch and will proceed as per the user response.  These standard responses can be customized using the getCurrentOptions utility, see here for more.  </p> <p>Note: The current conversation will be discarded in case the user wants to switch languages.</p> </li> <li> <p>Language selection settings \u2013 In addition, you may want to configure the language selection options. From the menu under the Build tab, click Configurations -&gt; Languages Under Language Selection Logic (scroll down for the option), for language selection time frame, set to one of the following:</p> <ol> <li>Lifetime: The auto-detected language will be set as the user\u2019s preferred language and used for all subsequent communications until the user interacts in another enabled language anytime later. If the user starts to talk in another enabled language, the virtual assistant changes to that language.</li> <li>Per Session: Detects the user\u2019s language at the beginning of every session and responds accordingly.</li> <li>Every User Message: Identifies the user\u2019s language from every utterance. In case a change is detected, the VA will get a confirmation from the user regarding the switch and proceed as per the user response.  </li> </ol> <p>Note: The current conversation will be discarded in case the user wants to switch languages. This feature was introduced in release 7.2 and is the default setting for multilingual virtual assistants.  </p> <p> </p> </li> <li> <p>For testing and debugging purposes, you can override the language selection settings by using the cheat command during a chat session. Replace the language name or code with one of these values:</p> <ol> <li>English: English or EN</li> <li>German: German or DE</li> <li>French: French or FR</li> <li>Spanish: Spanish or ES</li> </ol> </li> </ol>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/","title":"Managing Languages for Multilingual VAs","text":"<p>You can create an assistant from scratch, enable a language for an existing assistant or update the language configuration for an existing assistant. Besides these functionalities, this article also shows you how to switch between languages and how to enable or disable a language.</p>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/#selecting-a-language-when-creating-an-assistant-from-scratch","title":"Selecting a Language when Creating an Assistant from Scratch","text":"<p>To create an Assistant from scratch, follow the below steps:</p> <ol> <li>Log in to your Kore.ai XO Platform account.</li> <li>On the Virtual Assistant landing page, click New Bot on the top-right and select the Start from Scratch option.</li> <li> <p>On the Create New Bot window, enter the Assistant details:</p> <ol> <li>Name \u2013 Give a name to your Assistant. For example, Banking Assistant. If the name is already used, try something else</li> <li>Select the language from the Default Bot Language drop-down list.  </li> </ol> <p></p> </li> <li> <p>If the selected language is from one of the 26 languages supported as NLU languages (read more here) then by default, the VA language will be the same as the NLU language. You can always change the NLU language to any language by clicking on the Advanced Options link to search and select the NLU language from the list of supported languages. </p> </li> <li> <p>Once you select an NLU language, which is different from the default Bot Language, you can enable the following translation modules:</p> <ol> <li>User Input Translation \u2013 This approach uses language translation services to translate the user input into a base language. The conversation is executed in the base language and the responses are auto-translated back to the user\u2019s language using translation services. (Supported from v9.1)</li> <li>Runtime Response Translation \u2013 The Kore.ai XO Platform can automatically translate all the prebuilt responses as well as plain text messages to the user\u2019s language. For this, you will need to provide your API keys for either Google Cloud Translation or Microsoft Translator service in the Translation Configurations section. You can also translate the content of the templated messages inside the JavaScript using the <code>koreUtil.AutoTranslate()</code> function by passing a string or a context variable. For example, <code>koreUtil.AutoTranslate(context.variable1)</code> </li> </ol> <p>Note: If you select Multilingual as the NLU language option, by default the Assistant will be able to understand the user input in 100 plus languages supported by the Kore.ai XO Platform. The Multilingual NLU model is a language-agnostic model, it understands user input in 100 plus languages without the need for translation. However, you could enable Response Translation if the responses are configured in a language other than the assistant language.</p> </li> <li> <p>Click Create when done.</p> </li> </ol>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/#adding-a-language-to-an-existing-virtual-assistant","title":"Adding a language to an existing Virtual Assistant","text":"<p>Even if your assistant has already been created, you can still add new languages to it. Follow these steps to add a new language for your virtual assistant:</p> <ol> <li>Go to Build &gt; Configurations &gt; Languages.</li> <li> <p>On the Language Management page, in the Standard Languages section, click the + Add Language to add languages. </p> </li> <li> <p>The Platform will display all the 100 plus languages that are supported. You can click on the Configure button to enable a language. </p> <p>Note: You can also search for a language by entering its name in the Search field.</p> </li> <li> <p>Once you click configure, you can setup the following language configurations: </p> <p>a. Choose the NLU Language \u2013 Allows you to select any supported language as the NLU model to train your assistant.</p> <p>b. Select the Language Definition Mode - You can choose any of the following options to copy the language definitions:</p> <ul> <li> <p>Basic Mode \u2013 Lets you only copy dialog prompts and messages. Note: A base language is a language that is already enabled in the assistant. You need to choose a Base Language for your assistant from which you want to copy your assistant\u2019s data for both Basic and Advanced modes. </p> </li> <li> <p>Advanced Mode \u2013 Lets you copy dialog prompts, messages, knowledge graph, small talks, traits, and training data as per your need. </p> </li> <li> <p>Use Language Pack \u2013 Lets you upload the language definitions after adding manually translating a JSON file. You can download a JSON language pack of any of the already-enabled languages and then edit the dialog prompts and messages in the JSON file. Upload the updated JSON file to enable the new language for the assistant. </p> </li> </ul> <p>c. Manage Translations \u2013 In case the Translation Engine is not configured, click the Configure link to set up the translation engine for your assistant. To learn how to enable Input Translation or Runtime Response Translation, refer to this article. </p> </li> <li> <p>Once you have configured translations, click Enable to add/enable a new language for the assistant.</p> </li> </ol>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/#updating-a-language-for-an-existing-virtual-assistant","title":"Updating a language for an existing Virtual Assistant","text":"<p>If you want to enable/disable input translation, change the NLU language of the already enabled language for an assistant or modify the dialog prompts then you can use the update feature. </p> <p>To update an already enabled language for an assistant, follow the below steps:</p> <ol> <li>Go to Build &gt; Configurations &gt; Languages.</li> <li>The platform will display all the languages under the Language Management section.</li> <li> <p>Click on the language that is already enabled in the VA. The Manage Language dialog appears, here you can:</p> <p>a. Update the NLU language \u2013 Updating the NLU language will need training for the virtual assistant again.</p> <p>b. Update the dialog prompts \u2013 You can update the language pack file and upload it to update the dialog prompts.</p> <p>c. Update Manage Translations \u2013 You can enable/disable input translation or runtime response translation based on your needs. </p> </li> <li> <p>Click the Update button once all the necessary changes are made.</p> </li> </ol> <p>Note<ul> <li>After you have configured a new language, to make the new language work, you must re-publish the VA. Until then, the VA continues to function with the previously published languages.  </li> <li>The default Synonym library is available only for English, French, Spanish, German, and Chinese languages. However, you can add custom synonyms for any language.</li> </ul> </p>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/#switching-languages","title":"Switching Languages","text":"<p>If you have configured multiple languages for a virtual assistant, you can switch the language to configure the virtual assistant from the top right corner (language dropdown) from within any area of your VA. The dropdown will display all the other supported languages with the corresponding NLU model that is configured for the language. </p> <p> </p> <p>Note<p>The language dropdown will display the Bot Language and NLU language for the languages where the Bot Language is not equal to NLU language. If the Bot Language and the NLU language are the same then the language drop down will display only the Bot Language.</p> </p>"},{"location":"app-settings/language-management/managing-languages-for-multilingual-vas/#disablingenabling-languages","title":"Disabling/Enabling Languages","text":"<p>Languages can be enabled or disabled by going to Build &gt; Configurations &gt; Languages &gt; Standard Languages. Use the toggle to enable/disable a language.</p> <p> </p> <p>Once you have configured and enabled a language you can:</p> <ul> <li>Disable or deactivate a language that is previously enabled for the VA. The actual language-specific data that has been added while enabling the language will continue to exist in the VA even after disabling the language. Disabling would prevent the users from talking  to the assistant in that language (can be viewed in the VA export copy)</li> <li>If a language is disabled you can enable it again, since the data is preserved, you need not enter all the details.</li> </ul> <p>Note<p>Any change in language settings needs to be published before it can take effect in the published assistant.</p> </p>"},{"location":"app-settings/language-management/managing-translation-services/","title":"Managing Translation Services","text":"<p>The Kore.ai XO Platform offers multiple ways to train your virtual assistant for language understanding. One of the ways is to use translation services to translate the user input. In this approach, you can train the virtual assistant in a language (NLU Language) other than the interaction language. For example, you can enable Spanish as an interaction language but train the assistant using English language training data.</p> <p>Translation services can also be used for translating the bot responses if they are defined in a language other than the conversation language. The Platform allows you to define language-specific responses for each of the languages enabled for the assistant. However, you may choose to write responses in a language other than the enabled language.</p> <p>The Platform provides out-of-the-box support for Microsoft Translator and Google Translation APIs. You can also use the Custom Translation Engine feature to integrate with any other translation services or your in-house translation services.</p>"},{"location":"app-settings/language-management/managing-translation-services/#configuring-microsoft-translator-service","title":"Configuring Microsoft Translator Service","text":"<p>To enable automatic translation using Microsoft Translation Services, please follow the steps below:</p> <ol> <li>Go to Build &gt; Configurations &gt; Languages &gt; Translation Configurations.</li> <li>Select Microsoft Translator.</li> <li>Provide the API Key of your Microsoft Translator API service. Learn More.</li> <li>Click Save to complete the setup.</li> </ol> <p></p>"},{"location":"app-settings/language-management/managing-translation-services/#configuring-google-translation-service","title":"Configuring Google Translation Service","text":"<p>To enable automatic translation using Google Translation Services, please follow the steps below: </p> <ol> <li>Go to Build &gt; Configurations &gt; Languages &gt; Translation Configurations.</li> <li>Select Google Translator.</li> <li>Provide the API Key of your Google Translation API service. Learn More.</li> <li>Click Save to complete the setup.</li> </ol> <p></p>"},{"location":"app-settings/language-management/managing-translation-services/#configuring-custom-translation-service","title":"Configuring Custom Translation Service","text":"<p>The Custom Translation Service allows you to use translation services by integrating with other translation providers or to integrate with any in-house translation services you may have.</p>"},{"location":"app-settings/language-management/managing-translation-services/#how-it-works","title":"How it works","text":"<p>Here is how custom translation services work:</p> <ol> <li>Follow the instructions below to enable the Custom Translation Engine feature.</li> <li>You can set up the integration with your translation service APIs using the Get or Post method.</li> <li>Refer to your translation service documentation for the authentication mechanism, request payload, and response payload.</li> <li>This integration is used for translating both the user input as well as the bot responses. The platform will automatically make the following information available in the context during runtime.</li> <li> <p>It will make use of the following functions while defining the request payload.</p> <ol> <li> <p>koreUtil.conversation.sourceText()\u2013 This function will return the text to be translated.</p> <ol> <li>If the user\u2019s input is being translated, then the function will return the user\u2019s input.</li> <li>If the bot response is being translated, then the function will return the bot response.</li> </ol> </li> <li> <p>For translating user input, this function will return the user input. For translating the bot response, the function will return the bot response text.</p> </li> <li> <p>koreUtil.conversation.getSourceLanguage() \u2013 This function returns the current language of the text to be translated.</p> <ol> <li>If the user input is being translated, then the function will return the language in which the user is interacting.</li> <li>If the bot response is being translated, then the function will return the language in which the response is written.</li> </ol> </li> <li> <p>koreUtil.conversation.getTargetLanguage() \u2013 This function returns the language to which the text should be translated to.</p> <ol> <li>If the user input is being translated, then the function will return the language to which the input should be translated.</li> <li>If the bot response is being translated, then the function will return the language to which the response should be translated.The platform invokes the translation service using the defined configurations.</li> </ol> </li> </ol> </li> <li> <p>The translation engine should share the translated text as part of the API response.</p> </li> <li>Map the relevant field from the response payload to be used as the translated text.</li> </ol>"},{"location":"app-settings/language-management/managing-translation-services/#enabling-a-custom-translation-engine","title":"Enabling a Custom Translation Engine","text":"<ol> <li>Go to Build &gt; Configurations &gt; Languages &gt; Translation Configurations.</li> <li> <p>Select Custom, and choose Add Custom Engine from the dropdown. </p> </li> <li> <p>Provide a name for the Custom Translation Engine.</p> </li> <li>Define the request payload for sending the text to be translated. Refer to the details provided above for defining the request payload.</li> <li> <p>Refer to the Service Node documentation to learn more about how to configure service integrations. </p> </li> <li> <p>After defining the request payload, you can test the integration by providing the required details from the Test Request tab. Provide the sample values for the variables shown under the Sample Context Values sections, click Test to verify if the custom translation connection is established. </p> </li> <li> <p>After a successful test, the platform displays the API response received from the translation service.</p> </li> <li> <p>Verify the response payload and map the translated text from the payload in the Translated Output field. </p> </li> <li> <p>Click the Extract button to verify if the translation output is correctly mapped. </p> </li> <li> <p>Click Save &amp; Exit to return to the Languages page.</p> </li> <li>Click Save to complete the configuration. </li> </ol>"},{"location":"app-settings/language-management/multi-lingual-bot-behavior/","title":"Multilingual Virtual Assistant Behavior","text":"<p>In the case of multi-lingual bots, while much of the bot behavior does not change with the language, but the language semantics does impose some restrictions. In this document we will list out the different behaviors that would be language-dependent, so you as bot developer can cater for such scenarios.</p>"},{"location":"app-settings/language-management/multi-lingual-bot-behavior/#pattern-support","title":"Pattern Support","text":"<p>We have seen in this document, how Patterns can be used for Intent detection and Entity extraction. Those rules are for bots in the English language. Though the multilingual bots honor those rules, the language semantics impose some restrictions.</p> <p>Also, patterns can also be used in Small Talk (while defining queries), Knowledge Graph (using alternate question field), and Trait identification but their behavior might differ slightly.</p> PATTERN SYNTAX INTENT DETECTION AND ENTITY EXTRACTION SMALL <p> TALK TRAITS KNOWLEDGE <p> GRAPH SUPPORTED IN LANGUAGES NOT SUPPORTED IN LANGUAGES word1 word2 \u2026 wordn <p> This mandates all the words defined to be available in the user utterance in the same consecutive order with additional words allowed in between, before and after     All languages     \u2013     Yes     Yes     Yes     word1_word2 <p> Enforce phrase, no additional words allowed in between word1 and word2.     All languages      \u2013     Yes     Yes     Yes     word1 * word2 <p> 0 to infinite number of additional words between the specified words/phrases     All languages      \u2013     Yes     Yes     Yes     word1 *n word2 <p> Exactly n number of additional words between the specified words/phrases     All languages      \u2013     Yes     Yes     Yes     word1 *0 word2 <p> To disable wildcards between two tokens.     All languages      \u2013     Yes     Yes     Yes     word1 &lt; word2 <p> Indicates the match for word2 should start from the beginning of a sentence.     All languages      \u2013     Yes     Yes     Yes     word1 &gt; word2 <p> Indicates the end of the sentence and no words are allowed after it.     All languages      \u2013     Yes     Yes     Yes     !abc <p> Indicates the word/concept \u201cabc\u201d should not exist anywhere in the user utterance after this token     All languages      \u2013     Yes     Yes     Yes     !!abc <p> The very next word/concept should not be \u201cabc\u201d     All languages      \u2013     Yes     Yes     Yes     [ \u2026 ] <p> Used to define a group of words/concepts and the match should be against exactly one of the group declared in [ ].     All languages      \u2013     Yes     Yes     Yes     { \u2026 } <p> Used to define an optional group or words/concepts and the match would be against zero or one of the words/patterns declared in { }.     All languages      \u2013     Yes     Yes     Yes     ( \u2026 ) <p> contain a pattern i.e when a pattern or part of a pattern is enclosed in these parentheses, we treat it as a pattern unlike [ ] and { }.     All languages      \u2013     Yes     Yes     Yes     &lt;&lt; \u2026 &gt;&gt; <p> Used to find words in any order     All languages      \u2013     Yes     Yes     Yes     \u2018word1 <p> If you quote words or use words that are not in canonical form, the system will restrict itself to what you used in the pattern     All languages       \u2013     No     No     No     System Concepts <p> Support for built-in concepts     English, <p> German, <p> Spanish, <p> French     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional, <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian, <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan, <p> Tagalog     No     No     No     Developer concepts <p> Support for developer-defined concepts     English, <p> German, <p> Spanish, <p> FrenchPortuguese(Brazilian)*, <p> Italian*, <p> Chinese simplified*, <p> Chinese traditional*, <p> Indonesian*, <p> Korean*, <p> Dutch*, <p> Japanese*, <p> Arabic*, <p> Finnish*, <p> Russian*, <p> Polish*, <p> Ukrainian*, <p> Swedish*, <p> Kazakh*, <p> Norwegian*, <p> Hindi*, <p> Telugu*, <p> Tamil*, <p> Marathi*, <p> Catalan*      \u2013     Yes     Yes     Yes*     Two-letter identifiers for Dates <p> Like Mo for Monday, Tu for Tuesday, etc     English, <p> German, <p> Spanish, <p> Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional, <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian, <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi      French, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan, <p> Tagalog     \u2013     \u2013     No     <p>\u2018*\u2019 - In these cases, developer concepts are not supported in entity extraction</p>"},{"location":"app-settings/language-management/multi-lingual-bot-behavior/#nlp-support","title":"NLP Support","text":"<p>Here we will list out the NLP features and their support.</p> NLP FEATURE SUPPORTED IN LANGUAGES NOT SUPPORTED IN LANGUAGES SMALL TALK TRAITS KNOWLEDGE GRAPH List of Values Full Match      All languages     \u2013     \u2013     \u2013     No     Partial Match      All languages     \u2013     \u2013     \u2013     No     Exact Match      All languages     \u2013     \u2013     \u2013     No     Ambiguity behavior      All languages     \u2013     \u2013     \u2013     No     Ambiguity with multi-item selection      English     Not supported in any language except English     \u2013     \u2013     No     Spell Correction English, <p> German, <p> Spanish, <p> French, <p> Portuguese(Brazilian), <p> Italian, <p> Indonesian, <p> Korean (from ver7.3), <p> Dutch, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian     Chinese simplified, <p> Chinese traditional, <p> Japanese, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi     \u2013     \u2013     Yes     Amend Entities English     Not supported in any language except English     \u2013     \u2013     Yes     Sentiment Analysis English, <p> German, <p> Spanish, <p> French, <p> Dutch, <p> Korean (from ver7.3), <p> Japanese (from ver8.0), <p> Russian (from ver8.0), <p> Kazakh (from ver8.0), <p> Polish (from ver9.2), <p> Norwegian     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Arabic, <p> Finnish, <p> Ukrainian, <p> Swedish, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan     \u2013     \u2013     Yes     Bot Synonyms (default) English, <p> German, <p> Spanish, <p> French     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh     \u2013     \u2013     Yes     Knowledge Graph Patterns     All Languages     \u2013     \u2013     \u2013     Yes     Search in Answer     English, <p> German (from ver7.3), <p> Spanish (from ver7.3), <p> French (from ver7.3), <p> Portuguese(Brazilian) (from ver7.3), <p> Italian (from ver7.3), <p> Indonesian (from ver7.3), <p> Dutch (from ver7.3), <p> Finnish (from ver7.3), <p> Polish (from ver7.3), <p> Swedish (from ver7.3),     Chinese simplified, <p> Chinese traditional, <p> Korean, <p> Japanese, <p> Arabic, <p> Russian, <p> Ukrainian, <p> Kazakh     \u2013     \u2013     Yes     Spell Correction     English, <p> German, <p> Spanish, <p> French, <p> Portuguese(Brazilian), <p> Italian, <p> Indonesian, <p> Korean, <p> Dutch, <p> Arabic, <p> Finnish, <p> Polish, <p> Swedish, <p> Ukrainian <p> Russian (from ver8.0), <p> Kazakh (from ver8.0), <p> Japanese (from ver8.0),     Chinese simplified, <p> Chinese traditional, <p> Catalan     \u2013     \u2013     Yes     Special Character support     All languages except English     English     \u2013     \u2013     Yes     NL Engines Dependency Parser Model     German (from ver7.3), <p> French (from ver7.3), <p> Italian (from ver8.0)     English, <p> Spanish, <p> Portuguese(Brazilian), <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi     \u2013     \u2013     \u2013"},{"location":"app-settings/language-management/multi-lingual-bot-behavior/#universal-bot-support","title":"Universal Bot Support","text":"<p>Here we will list out, language-wise, the trigger phrases used in training the Universal bot (see here) in the supported languages.</p> PHRASE LANGUAGE SUPPORT ENGLISH GERMAN SPANISH FRENCH PORTUGUESE <p> (BRAZILIAN) ITALIAN CHINESE <p> SIMPLIFIED CHINESE <p> TRADITIONAL Ask     Fragen     Pedir     Demander     perguntar     Chiedi     \u95ee     \u554f     Tell     Sagen     Contar     Dire     Contar     Raccontare     \u544a\u8bc9     \u544a\u8a34     Search     Suche     Buscar     Chercher     Procurar     Ricerca     \u641c\u7d22     \u641c\u7d22     Open     \u00d6ffnen     Abierto     Ouvert     Aberto     Aperto     \u6253\u5f00     \u6253\u958b     Load     Belastung     Carga     Charge     Carga     Caricare     \u52a0\u8f7d     \u52a0\u8f09     Begin     Start     Empezar     Commencer     In\u00edcio     Inizio     \u5f00\u59cb     \u958b\u59cb     Launch     Starten     Lanzamiento     lancement     Lan\u00e7amento     Lanciare     \u53d1\u5c04     \u767c\u5c04     Talk to     Reden mit     Hablar con     Parler \u00e0     Falar com     Parlare a     \u4ea4\u8c08     \u4ea4\u8ac7     Run     Lauf     correr     Courir     Corre     Correre     \u8dd1     \u8dd1     Exit     ausgang     salida     sortie     sa\u00edda     uscita     \u51fa\u53e3     \u51fa\u53e3     PHRASE LANGUAGE SUPPORT ENGLISH INDONESIAN KOREAN DUTCH JAPANESE ARABIC FINNISH RUSSIAN Ask     Meminta     \ubb3c\uc5b4\ubcf4\uae30     Vragen     \u983c\u307f\u307e\u3059     \u064a\u0637\u0644\u0628     Kysy\u00e4     \u0421\u043f\u0440\u043e\u0441\u0438\u0442\u044c     Tell     Menceritakan     \ud154     Vertellen     \u4f1d\u3048\u307e\u3059     \u064a\u062e\u0628\u0627\u0631     Kertoa     \u0441\u043a\u0430\u0437\u0430\u0442\u044c     Search     Cari     \uac80\uc0c9     Zoeken     \u63a2\u3059     \u0628\u062d\u062b     Hae     \u041f\u043e\u0438\u0441\u043a     Open     Buka     \uc5f4\ub2e4     Open     \u958b\u3044\u305f     \u0627\u0641\u062a\u062d     Avata     \u043e\u0442\u043a\u0440\u044b\u0442\u043e     Load     Beban     \ud558\uc911     Laden     \u8ca0\u8377     \u062d\u0645\u0644     Ladata     \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0430     Begin     Mulai     \uc2dc\uc791     Beginnen     \u30d9\u30ae\u30f3     \u0627\u0628\u062f\u0623     Alkaa     \u041d\u0430\u0447\u0430\u0442\u044c     Launch     Meluncurkan     \uc2dc\uc791\ud558\ub2e4     Lancering     \u6253\u3061\u4e0a\u3052     \u0625\u0637\u0644\u0627\u0642     Tuoda markkinoille     \u0437\u0430\u043f\u0443\u0441\u043a     Talk to     Berbicara dengan     \ub85c \ud1a0\ud06c     Praten met     \u306b\u8a71\u3059     \u062a\u062d\u062f\u062b \u0627\u0644\u064a     Puhua     \u0413\u043e\u0432\u043e\u0440\u0438\u0442\u044c \u0441     Run     Lari     \uc6b4\uc601     Rennen     \u30e9\u30f3     \u064a\u0631\u0643\u0636     Juosta     \u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c     Exit     keluar     \ucd9c\uad6c     uitgang     \u51fa\u53e3     \u062e\u0631\u0648\u062c     poistuminen     \u0432\u044b\u0445\u043e\u0434     PHRASE LANGUAGE SUPPORT ENGLISH POLISH UKRAINIAN SWEDISH KAZAKH Ask     Zapyta\u0107     \u0437\u0430\u043f\u0438\u0442\u0430\u0442\u0438     Fr\u00e5ga     \u0441\u04b1\u0440\u0430\u0443     Tell     Powiedzie\u0107     \u0441\u043a\u0430\u0437\u0430\u0442\u0438     S\u00e4ga     Tell     Search     Szukaj     \u041f\u043e\u0448\u0443\u043a     S\u00f6k     \u0456\u0437\u0434\u0435\u0443     Open     otwarty     \u0432\u0456\u0434\u0447\u0438\u043d\u0435\u043d\u043e     \u00d6ppna     \u0430\u0448\u044b\u049b     Load     Za\u0142aduj     \u043d\u0430\u0432\u0430\u043d\u0442\u0430\u0436\u0435\u043d\u043d\u044f     Ladda     \u0436\u04af\u043a     Begin     Zaczyna\u0107     \u043f\u043e\u0447\u0430\u0442\u0438     B\u00f6rja     \u0411\u0430\u0441\u0442\u0430     Launch     Uruchomi\u0107     \u0437\u0430\u043f\u0443\u0441\u043a     Lansera     \u04b1\u0448\u044b\u0440\u0443     Talk to     M\u00f3wi\u0107 do     \u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0442\u0438 \u0437     Prata med     \u0421\u04e9\u0439\u043b\u0435\u0441\u0443     Run     Biega\u0107     \u043f\u0440\u043e\u0431\u0456\u0433     Springa     \u0436\u04af\u0433\u0456\u0440\u0443     Exit     wyj\u015bcie     \u0432\u0438\u0445\u0456\u0434     utg\u00e5ng     \u0448\u044b\u0493\u0443"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/","title":"Multilingual VAs: Components &amp; Feature Support","text":"<p>In the case of multilingual VAs, while much of the assistant\u2019s behavior does not change with the language, the semantics does impose some restrictions. In this document we will list out the different behaviors that would be language-dependent, so you can cater for such scenarios.</p> <p>This article discusses language-specific components for multilingual VAs, as well as feature support and behavior, as compared to single language assistants. </p> <p>This article lists the VA elements for which you can provide language-specific values. You need not translate Standard Responses as the Platform automatically translates them when you enable a language.</p>"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#metadata","title":"Metadata","text":"<p>JSON object consisting of the following translatable elements</p> FIELD NAME TYPE DESCRIPTION Bot Name     String     Name of the assistant     Bot Description     String     Description of the assistant     Bot Synonyms     Object     Arrays of important words in the task names and their corresponding synonyms. Enter translation of the words as well as their synonyms. Refer to Managing Synonyms to learn more about bot synonyms.     Bot Error Codes     Object     Arrays of error codes and their corresponding messages. Enter translations of the error message. Refer to Customizing Error Messages to learn more about error messages."},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#dialog-tasks","title":"Dialog Tasks","text":"<p>JSON object consisting of the following translatable components of your VA\u2019s Dialog Tasks.</p> FIELD NAME TYPE DESCRIPTION Dialog Task Name     String     Name of the dialog task     Dialog Task Desc     String     Description of the dialog task     Dialog Task Upgrade Message     String     Message displayed to the developer on the History page for the upgraded task"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#dialog-components","title":"Dialog Components","text":"<p>JSON object consisting of the following translatable components related to the NLP settings of a dialog task.</p> FIELD NAME TYPE DESCRIPTION Dialog Component Intent     String     Name of the User Intent node     Dialog Component Description     String     Description of the User Intent node     Dialog Component Synonyms     Object     Synonyms for the words in the entity node names. Refer to Managing Synonyms to learn more.     Dialog Component Patterns     Object     Patterns for the User Intent and Entity nodes in the dialog task. Refer to Managing Patterns to learn more."},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#message-templates","title":"Message Templates","text":"<p>JSON object with arrays of Message Template IDs and Message Template Text values. They correspond to the User Responses field in the Message node and the** Bot Prompts** and Error Prompts fields in the Entity node of the dialog tasks.</p> FIELD NAME TYPE DESCRIPTION Message Template Text     String     The text entered in User Responses, Bot Prompts, or Error Prompts fields in any Message or Entity node of a dialog task."},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#alert-task","title":"Alert Task","text":"<p>JSON object consisting of the following translatable components of your assistant\u2019s Alert Tasks.</p> FIELD NAME TYPE DESCRIPTION Alert Name     String     Name of the alert task     Alert Short Desc     String     Description of the alert task     Alert Keywords     Array     The search keywords entered for the alert task     Alert Patterns     Array     Array of patterns related to the alert task\u2019s name. Replace the pattern text with the translated text. Refer to Managing Patterns to learn more.     Alert Field Synonyms     Object     Arrays consisting of synonyms for each task field. Replace the field name and the synonyms with the translated text. Refer to Managing Synonyms to learn more.     Alert Field Patterns     Object     Arrays consisting of patterns for each task field. Replace the pattern text with the translated text. Refer to Managing Patterns to learn more.     Alert Ignore Words     Array     Arrays of ignore words related to the alert task. Replace the words with the translated text. Refer to Managing Ignore Words and Field Memory to learn more.     Alert Upgrade Short Message     String     Upgrade short message related to the alert task.     Alert Upgrade Long Message     String     Upgrade long message related to the alert task.     Alert Query Fields     Object     Arrays consisting of key-value pairs of Alert Field Help and Alert Field Title. Replace the text with the translated text.     Alert Payload Fields     Object     Arrays consisting of key-value pairs of Alert Payload fields. Replace the text with the translated text."},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#alert-fields","title":"Alert Fields","text":"<p>JSON object consisting of the following translatable components in the API Request tab of the Alert task.</p> FIELD NAME TYPE DESCRIPTION Alert Field Title     String     The title of the user input field related to the alert task, for example, Choose city Alert Field Help     String     The help text displayed below the field title to describe the task, for example, Which city would you like to get weather alerts for? Alert Field Placeholder     String     The placeholder text displayed inside the field."},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#bot-filters","title":"Bot Filters","text":"<p>JSON object consisting of the following translatable components related to Bot filters</p> FIELD NAME TYPE DESCRIPTION Filter Name     String     Name of the task filter"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#idp-config-form-fields","title":"IDP Config Form Fields","text":"<p>JSON object consisting of the following translatable components related to IDP configuration form</p> FIELD NAME TYPE DESCRIPTION IDP Form Field     String     Name of the IDP Form Field displayed to the end-user in the authentication dialog"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#pattern-support","title":"Pattern Support","text":"<p>We have seen in this document, how Patterns can be used for Intent detection and Entity extraction. These rules are for VAs in the English language. In other languages, there may be differences. </p> <p>Patterns can be used in Small Talk (while defining queries), Knowledge Graph (using alternate question fields), and Trait identification but their behavior might differ slightly. The table below provides an overview of how this may occur.</p> PATTERN SYNTAX INTENT DETECTION AND ENTITY EXTRACTION SMALL <p> TALK TRAITS KNOWLEDGE <p> GRAPH SUPPORTED IN LANGUAGES NOT SUPPORTED IN LANGUAGES word1 word2 \u2026 wordn <p> This mandates all the words defined to be available in the user utterance in the same consecutive order with additional words allowed in between, before and after     All languages     \u2013     Yes     Yes     Yes     word1_word2 <p> Enforce phrase, no additional words allowed in between word1 and word2.     All languages     \u2013     Yes     Yes     Yes     word1 * word2 <p> 0 to infinite number of additional words between the specified words/phrases     All languages     \u2013     Yes     Yes     Yes     word1 *n word2 <p> Exactly n number of additional words between the specified words/phrases     All languages     \u2013     Yes     Yes     Yes     word1 *0 word2 <p> To disable wildcards between two tokens.     All languages     \u2013     Yes     Yes     Yes     word1 &lt; word2 <p> Indicates the match for word2 should start from the beginning of a sentence.     All languages     \u2013     Yes     Yes     Yes     word1 &gt; word2 <p> Indicates the end of the sentence and no words are allowed after it.     All languages     \u2013     Yes     Yes     Yes     !abc <p> Indicates the word/concept \u201cabc\u201d should not exist anywhere in the user utterance after this token     All languages     \u2013     Yes     Yes     Yes     !!abc <p> The very next word/concept should not be \u201cabc\u201d     All languages     \u2013     Yes     Yes     Yes     [ \u2026 ] <p> Used to define a group of words/concepts and the match should be against exactly one of the group declared in [ ].     All languages     \u2013     Yes     Yes     Yes     { \u2026 } <p> Used to define an optional group or words/concepts and the match would be against zero or one of the words/patterns declared in { }.     All languages     \u2013     Yes     Yes     Yes     ( \u2026 ) <p> contain a pattern i.e when a pattern or part of a pattern is enclosed in these parentheses, we treat it as a pattern unlike [ ] and { }.     All languages     \u2013     Yes     Yes     Yes     &lt;&lt; \u2026 &gt;&gt; <p> Used to find words in any order     All languages     \u2013     Yes     Yes     Yes     \u2018word1 <p> If you quote words or use words that are not in canonical form, the system will restrict itself to what you used in the pattern     All languages     \u2013     No     No     No     System Concepts <p> Support for built-in concepts     English, <p> German, <p> Spanish, <p> French     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional, <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian, <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan, <p> Tagalog     No     No     No     Developer concepts <p> Support for developer-defined concepts     English, <p> German, <p> Spanish, <p> FrenchPortuguese(Brazilian)*, <p> Italian*, <p> Chinese simplified*, <p> Chinese traditional*, <p> Indonesian*, <p> Korean*, <p> Dutch*, <p> Japanese*, <p> Arabic*, <p> Finnish*, <p> Russian*, <p> Polish*, <p> Ukrainian*, <p> Swedish*, <p> Kazakh*, <p> Norwegian*, <p> Hindi*, <p> Telugu*, <p> Tamil*, <p> Marathi*, <p> Catalan*     \u2013     Yes     Yes     Yes*     Two-letter identifiers for Dates <p> Like Mo for Monday, Tu for Tuesday, etc     English, <p> German, <p> Spanish, <p> Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional, <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian, <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi     French, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan, <p> Tagalog     \u2013     \u2013     No     <p>'*' - In these cases, developer concepts are not supported in entity extraction</p>"},{"location":"app-settings/language-management/multilingual-vas-components-feature-support/#nlp-support","title":"NLP Support","text":"<p>Here are the NLP features supported by Multilingual VAs:</p> NLP FEATURE SUPPORTED IN LANGUAGES NOT SUPPORTED IN LANGUAGES SMALL TALK TRAITS KNOWLEDGE GRAPH LIST OF VALUES Full Match     All languages     \u2013     \u2013     \u2013     No     Partial Match     All languages     \u2013     \u2013     \u2013     No     Exact Match     All languages     \u2013     \u2013     \u2013     No     Ambiguity behavior     All languages     \u2013     \u2013     \u2013     No     Ambiguity with multi-item selection     English     Not supported in any language except English     \u2013     \u2013     No     Spell Correction English, <p> German, <p> Spanish, <p> French, <p> Portuguese(Brazilian), <p> Italian, <p> Indonesian, <p> Korean (from ver7.3), <p> Dutch, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian     Chinese simplified, <p> Chinese traditional, <p> Japanese, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi     \u2013     \u2013     Yes     Amend Entities English     Not supported in any language except English     \u2013     \u2013     Yes     Sentiment Analysis English, <p> German, <p> Spanish, <p> French, <p> Dutch, <p> Korean (from ver7.3), <p> Japanese (from ver8.0), <p> Russian (from ver8.0), <p> Kazakh (from ver8.0), <p> Norwegian, <p> Tagalog     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Arabic, <p> Finnish, <p> Polish, <p> Ukrainian, <p> Swedish, <p> Hindi, <p> Telugu, <p> Tamil, <p> Marathi, <p> Catalan     \u2013     \u2013     Yes     Bot Synonyms (default) English, <p> German, <p> Spanish, <p> French, <p> Tagalog     Portuguese(Brazilian), <p> Italian, <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh     \u2013     \u2013     Yes     Knowledge Graph Patterns     All Languages     \u2013     \u2013     \u2013     Yes     Search in Answer     English, <p> German (from ver7.3), <p> Spanish (from ver7.3), <p> French (from ver7.3), <p> Portuguese(Brazilian) (from ver7.3), <p> Italian (from ver7.3), <p> Indonesian (from ver7.3), <p> Dutch (from ver7.3), <p> Finnish (from ver7.3), <p> Polish (from ver7.3), <p> Swedish (from ver7.3), <p> Tagalog     Chinese simplified, <p> Chinese traditional, <p> Korean, <p> Japanese, <p> Arabic, <p> Russian, <p> Ukrainian, <p> Kazakh     \u2013     \u2013     Yes     Spell Correction     English, <p> German, <p> Spanish, <p> French, <p> Portuguese(Brazilian), <p> Italian, <p> Indonesian, <p> Korean, <p> Dutch, <p> Arabic, <p> Finnish, <p> Polish, <p> Swedish, <p> Ukrainian <p> Russian (from ver8.0), <p> Kazakh (from ver8.0), <p> Japanese (from ver8.0),     Chinese simplified, <p> Chinese traditional, <p> Catalan, <p> Tagalog     \u2013     \u2013     Yes     Special Character support     All languages except English     English     \u2013     \u2013     Yes     NL Engines Dependency Parser Model     German (from ver7.3), <p> French (from ver7.3), <p> Italian (from ver8.0)     English, <p> Spanish, <p> Portuguese(Brazilian), <p> Chinese simplified, <p> Chinese traditional <p> Indonesian, <p> Korean, <p> Dutch, <p> Japanese, <p> Arabic, <p> Finnish, <p> Russian <p> Polish, <p> Ukrainian, <p> Swedish, <p> Kazakh, <p> Norwegian, <p> Hindi     \u2013     \u2013     \u2013"},{"location":"automation/intelligence/conversation-management/ignore-words-and-field-memory/","title":"Ignore Words and Field Memory","text":"<p>Developers can include words for the NLP engine to ignore when interpreting the user input for a task. Assistants can then respond faster to user input and improve the probability of correct task recognition. The NLP engine comes pre-built with a large set of generic ignore words.</p> <p>To manage this setting,</p> <ol> <li>Open the assistant where you want to configure these ignore words.</li> <li>From the top menu, select Build.</li> <li>On the left pane, click Intelligence &gt; Ignore Words &amp; Field Memory.</li> </ol> <p>Note</p> <p>This option is available only if an Alert task is configured for the Assistant. Otherwise, the option is hidden from the menu.</p> <p>You can edit each task to persist data for that task to pre-populate in another related task for the same VA in the Field Memory settings for each task. For example, for a travel planning assistant, Get Wait Times for Boarding task, you can pre-populate task fields into the related task, Book a FastPass task. </p> <p>You can also configure words to ignore in the user input at the task level. For example, for a 7-day Weather Forecast task, you might want days of the week, such as Monday, Tuesday, and so forth to be ignored since all weekdays are included.</p> <p></p> <p>Click a task name to show task fields that can be configured or edited for Field Memory and other field settings. </p> <p>The task fields are the parameters defined for the selected task. To define ignore words for a task, hover over the task, and then click the Edit icon.</p>"},{"location":"automation/intelligence/conversation-management/ignore-words-and-field-memory/#edit-a-task","title":"Edit a Task","text":"<p>To modify or add a configuration for a task,</p> <ol> <li>Hover over the name of the task, and then click Edit. The Edit Task window is displayed.</li> <li>Turn Off Confirmation Messages \u2013 Select Yes to disable confirmation of the execution of a task when using NLP. When No is selected, the user is asked to confirm the task before running it.</li> <li>Ignore Words \u2013 Enter one or more ignore words for the task name. The list of words to ignore is processed by the XO Platform before interpreting the user input. This means the VA can respond faster to user input and provide the correct task by filtering out words that apply to many tasks but do not help to identify which task. For example, a user may input, I want to get the weather forecast for today. To return the correct task to the user, the XO Platform interpreter only needs to recognize three words, weather, forecast, and today. The rest of the words can be ignored. The Kore.ai interpreter is already defined with a set of generic ignore words, so words like I, you, want, get, etc., do not need to be defined as ignore words. If your assistant uses the same words for many or all tasks, for example, your company name, you might add your company name as an ignore word.</li> <li>Click Save to save the settings and close the Edit Task window.</li> </ol>"},{"location":"automation/intelligence/conversation-management/ignore-words-and-field-memory/#manage-field-memory-for-a-task","title":"Manage Field Memory for a Task","text":"<p>To add or edit Field Memory settings for a task, follow the steps below:</p> <ol> <li>Click the Task Name to display the associated Task Fields; then click the Edit icon to display the Field Memory window. In the Field Memory dialog, you can specify the following options:<ul> <li>Entity Type \u2013 Select the type of data that the NLP interpreter should expect as input to enhance recognition and performance. Learn more.</li> <li>Memory User-Provided Value \u2013 Enable or disable persistence of data provided by the user for a specified time. One of:  No, do not memorize \u2013 The user\u2019s data for this field is not persisted after the task is completed.Yes, memorize this value \u2013 The field value is persisted for the time specified in minutes.</li> </ul> </li> <li>Click Save to save the settings and close the Field Memory window.</li> </ol>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/","title":"Manage Interruptions","text":"<p>Human conversations are characterized by twists and turns, and no two directions are ever the same. Natural conversations often tend to go beyond linear intent resolution paths defined in virtual assistants. Ideally, a user allows the VA to take an intent to its logical conclusion before initiating another, but that is not always the case.</p> <p>Consider the following conversation for example:</p> <p></p> <p>It includes an entity value for the assistant to proceed with the current intent, while also presenting a new user requirement or intent.</p> <p>VAs must account for this by allowing users to pause a task, start and complete another task, and seamlessly return to the original task without losing important contextual data and conversation continuity.</p> <p>Kore.ai provides you with granular control over hold and resume functionality at the VA, task, and node levels, and allows you to control context switching rules and behaviors. You can handle such interruptions in intent flows by providing a whole range of options to define the task-switching experience.</p> <p>The Manage Interruptions options allow you to select if and how a user can switch to another task, as well as the exit strategies. It can be set up at the VA, task, and node levels to ensure the configurations are layered to suit your various business requirements. You can also add conditional exceptions between tasks with the ability to pass contextual data between them.</p> <p>The following sections describe:</p> <ul> <li>The configuration hierarchy at the VA, task, and node levels.</li> <li>The various configurations you can use to Manage Interruptions.</li> </ul>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#interruptions-hierarchy","title":"Interruptions Hierarchy","text":"<p>Apart from defining the generic interruptions options at the VA level, you can customize these options at the dialog task or dialog node level. When you set up the Hold and Resume options in more than one levels, the order of precedence of the settings works as follows:</p> <ol> <li>Node level settings,</li> <li>Dialog task level settings,</li> <li>VA level settings.</li> </ol>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#node-level-settings","title":"Node Level Settings","text":"<p>You can customize the interruptions settings at the node level. If you customize the settings for a node, this configuration takes the highest precedence.</p> <p>To customize the interruptions settings for a node:</p> <ol> <li>Open the dialog task and then the node to change settings.</li> <li>Click the instance tab and select Advanced Controls.</li> <li>Under the Interruptions Behavior section, select Customize for this node and make the necessary configurations. These configurations are the same as discussed above for the VA level Interruptions Settings.</li> </ol> <p></p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#dialog-level-settings","title":"Dialog Level Settings","text":"<p>The dialog level Interruptions customizations have higher priority over VA level settings but rank lower than the node level customizations or any exceptions.</p> <p>To customize the Interruptions settings for a dialog:</p> <ol> <li>Open the Dialog task you want to customize.</li> <li> <p>On the top-right of the dialog builder, click the more options icon and then click Manage Interruptions. </p> </li> <li> <p>Under the Interruptions Behavior section, select Customize for this task and make the necessary configurations. These settings are the same as discussed above for the Bot Level Interruptions. </p> </li> </ol> <p>Note</p> <p>If you do not customize Interruptions settings at the node or task level, the VA level settings apply.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#bot-level-settings","title":"Bot Level Settings","text":"<p>The VA Level interruptions settings can be overridden at the task level as discussed above.</p> <p>You can access the interruption settings for your VA from under Build &gt; Intelligence &gt; Manage Interruptions page. </p> <p>The Platform provides options for Interruptions Behavior under the following three categories:</p> <ul> <li>Allow interruptions: Provides options for you to choose for holding a task and options to resume it later.</li> <li>Do not allow interruptions: Stops new tasks from interrupting the current task.</li> <li>Allow the end user to select the behavior: Seeks end-user confirmation to switch to a new task and provides several resume options for you to pick from.</li> </ul> <p>Note</p> <p>When the user provides input after a session has ended, i.e. after at least 15 minutes of inactivity, and if the input is within the previous session context, it is treated as an interruption scenario. If instead, the user comes back with a new utterance, then the old context is discarded and a new conversation is started.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#allow-interruptions","title":"Allow Interruptions","text":"<p>Once you allow for task interruption, you need to specify the VA\u2019s  behavior in such scenarios as what should happen to the current task, where should the conversation go once the interruption task has been completed, etc.</p> <p>Following are the options under Allow interruptions.</p> OPTION DESCRIPTION Hold the current task and resume back once the new task is completed This option lets the assistant switch to a new intent as soon as it is detected irrespective of the current intent flow. When you select this option, the Resume Options section appears providing further choices to define how to resume the on-hold task once the new intent task is completed.  Refer to the Resume Options section below for details.     Discard the current task and switch to new When you select this option, the VA discards the current task and switches to a new task soon after it encounters another intent. The VA sends a message to notify the user before switching to the new task and the current task would be discarded. You can customize the message from the Manage Response setting.     Switch to a new task without any notification to the user and discard the current task When you select this option, the VA discards the current task and switches to a new task soon after it encounters another intent. The VA does not notify the user about the switch and does not resume the current task later.     Continue with the current task and add a new task to the follow-up task list When you select this option, the VA continues on the current task even if it encounters a new intent. It, however, adds the new intent to the Follow-up intents array. Refer to the Follow-up Intents documentation for more information."},{"location":"automation/intelligence/conversation-management/manage-interruptions/#do-not-allow-interruptions","title":"Do not allow interruptions","text":"<p>When you select this option, the assistant-level interruptions are turned off. However, you may override this behavior for selected tasks, linked dialogs (exceptions), or node levels. Refer to the Interruptions Hierarchy section above for more information.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#allow-the-end-user-to-select-the-behavior","title":"Allow the end user to select the behavior","text":"<p>When you select this option, the VA presents the end-user with a confirmation message asking if the user wants to switch to a new task. The VA switches to the new task only if the end-user chooses to do so. You can customize the confirmation message sent to the user by clicking the Manage Response link next to the option.</p> <p>You need to define a Resume option that the VA should take if the user decides to switch the task. Refer to the Resume Options section below for details.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#resume-options","title":"Resume Options","text":"<p>Once you allow the task to be put on hold and proceed with the interruption task, you must configure the Resume option i.e. how the on-hold task should be handled once the interrupting task is completed.</p> OPTION DESCRIPTION Get confirmation with the user before resuming an on-hold task After executing the new task, the VA gives Yes or No options to the user to return to the last on-hold task. You can write a custom message for the user by clicking the Manage Response link next to the option. <p> Example: <p> <code>User: Hi  VA: Hello!  User: Can you book me a flight for tomorrow?  VA: From which city are you flying?  User: Los Angeles  VA: Where to?  User: By the way, what's the weather forecast for tomorrow?  VA: Please enter the name of the city for the forecast.  User: Los Angeles  VA: Weather Forecast for Los Angeles  Date: March 15  Temperature: 25 C  Condition: Mostly Sunny  VA: Should I continue with the task 'Book Flight'?  User: Yes  VA: Enter the name of the destination airport</code> Notify the user with a message that the on-hold task is being resumed Notifies the user with a message and resumes the last task that\u2019s kept on hold without user confirmation. <p> You can customize the notification message by clicking the Manage Response link next to the option. <p> Example: <p> <code>User: Hi  VA: Hello!  User: Can you book me a flight for tomorrow?  VA: From which city are you flying?  User: Los Angeles  VA: Where to?  User: By the way, what's the weather forecast for tomorrow?  VA: Please enter the name of the city for the forecast.  User: Los Angeles  VA: Weather Forecast for Los Angeles  Date: March 15  Temperature: 25 C  Condition: Mostly Sunny  VA: Resuming interrupted task Book Flight  VA: Enter the name the of the destination airport</code> Resume the on hold task without any specific message to the user Directly resumes the last task that\u2019s kept on hold soon after the current task is executed. <p> Example: <p> <code>User: Hi  VA: Hello!  User: Can you book me a flight for tomorrow?  VA: From which city are you flying?  User: Los Angeles  VA: Where to?  User: By the way, what's the weather forecast for tomorrow?  VA: Please enter the name of the city for the forecast.  User: Los Angeles  VA: Weather Forecast for Los Angeles  Date: March 15  Temperature: 25 C  Condition: Mostly Sunny  VA: Enter the name of the destination airport</code> Always resume the on hold task without any specific message to the user if the task is ended in a single response Sometimes, the switched-over tasks end with a single response. For example, in the weather forecast example above, if the user had directly entered By the way, what\u2019s the weather forecast for LA tomorrow? the VA would have merely responded with the forecast, with no further steps. <p> In such cases, if you select this option, the assistant switches back to the task on hold without any confirmation or notification, regardless of the option you\u2019ve chosen.   <p>Note</p> <p>The switching happens directly, without any notification to the end-user.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#on-hold-quantity","title":"On Hold Quantity","text":"<p>You can select the number of tasks that you want to keep on hold from the On Hold Quantity field. The assistant keeps a maximum of this number of tasks on hold and ignores the tasks once this value is reached.</p> <p>For example, if you specify the On Hold Quantity as 1 and if a third intent comes into play, the VA will not allow the new task to be initiated regardless of interruptions options.</p> <p>Note</p> <p>Tasks always resume in reverse chronological order. So, if you kept task 2 on hold after task 1, task 2 resumes before task 1.</p>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#manage-behavior-for-faqs","title":"Manage Behavior for FAQs","text":"<p>You can choose whether FAQs should honor the interruptions settings or if FAQs should be always responded to.</p> <p></p> <p>The flag Interruption Behavior for FAQs will allow you to:</p> <ul> <li>Always identify and respond to FAQs when interruptions are enabled. This is the default setting.</li> <li>Always identify FAQs when interruptions are enabled and proceed as per the Hold and Resume settings.</li> </ul>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#manage-behavior-for-ambiguous-intents","title":"Manage Behavior for Ambiguous Intents","text":"<p>You can handle ambiguous intents during a conversation flow by setting the flag Behavior for Ambiguous Interruptions.</p> <p></p> <p>These settings allow you to:</p> <ul> <li>Present the ambiguous intents to the end-user and proceed as per the Hold and Resume Settings. In case the user selects a task and the interruptions setting is:<ul> <li>Continue the current task and add a new task to the follow-up task list, then the current task will be kept on hold and the new task will be initiated.</li> <li>Allow the end-user to select the behavior, then the new task will be initiated without asking the user since the selection has been already made.</li> <li>All other hold options will be applied as usual.</li> </ul> </li> <li>Do not present ambiguous intents to the end-users and continue on the current task. This is the default setting.</li> </ul>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#manage-behavior-for-small-talk","title":"Manage Behavior for Small Talk","text":"<p>You can handle small talk during a conversation flow by setting the flag Interruption Behavior for Small Talk. </p> <p></p> <p>These settings allow you to:</p> <ul> <li>Respond to Small Talk and resume the on-hold task \u2013 this is the default setting.</li> <li>Execute the Small Talk using Hold &amp; Resume settings.</li> </ul>"},{"location":"automation/intelligence/conversation-management/manage-interruptions/#manage-behavior-for-user-authorization","title":"Manage Behavior for User Authorization","text":"<p>When a user gives any input at a prompt message for authorization that is not relevant, the following flow is followed:</p> <ul> <li>If Small Talk intent is identified, then the Small Talk\u2019s response is displayed, and the authorization is re-prompted.</li> <li>The Platform checks for the presence of any intents (tasks or FAQs) in the user utterance, irrespective of the configurations set for Manage Interruptions:<ul> <li>If the intent is identified, confirmation to discard the current task and trigger the new task is sought.</li> <li>If multiple intents are identified, an ambiguity dialog along with the option to ignore the utterance and continue with the current task is presented.</li> </ul> </li> <li>If no intent is identified, then the user is re-prompted with the authorization link.</li> </ul>"},{"location":"automation/intelligence/conversation-management/standard-responses/","title":"Standard Responses","text":"<p>Kore.ai Bot Builder tool provides a few default text responses. This section lists them and gives an explanation as to when these responses are triggered. For an overview on Standard Responses, click here.</p>"},{"location":"automation/intelligence/conversation-management/standard-responses/#statements","title":"Statements","text":"MESSAGE DEFINITION When the user confirms to close the conversation in a language and switch to another language     You are now conversing with the bot in the  &lt;language-name&gt; language.     When only field prompt is present in the oob     This is a field prompt message for action and alert tasks. This is only for the Kore platform to use. Enterprises should not be changing this. As part of the next deployment, this will be hidden from the bot developer.     When language preference is set     Shown when the user switches language using cheat lang or picks a language from the options shown.     When task is not accessible to user     Shown when the developer tries to access a bot task for which they do not have access     User confirms alert setup     Applicable to Alert Task Only <p> This response is displayed when an alert is set up successfully and the bot will trigger the task at the given frequency or specified time.     User discards/abandons the current activity     Shown in the following cases: <p> 1. When a user ends the task by saying discard <p> 2. When a task ends on exceeding max tries at an entity or choices not available in an LoV, or a cURL problem in an HTTP request, etc.     User implies to end the conversation (For example, good night, bye, ttyl)     This condition occurs only for Dialog tasks for which the following Follow-up Tasks Setting is configured: Yes, at the end of this dialog ask the user to select and perform a task from the Follow-up task list in the Dialog settings. The bot shows this message when it presents the Follow-Up Intents array to the user at the end of the Dialog.     Location provided by user is invalid for a field in an action     This message is displayed when the Bot is not able to validate the user input for a Location type of entity.     Amending an Alert field     Applicable to Alert Task Only <p> When setting up an alert, the end-user needs to provide values for the parameters that the alert needs along with the frequency at which the alert will be triggered. If the developer specifies that the alert should confirm all values from the user before setting up the alert, the bot will display an option to the user if he wants to amend the values. <p> This bot response is displayed if the user says Yes to amend     Amending a task which has no fields     Applicable to Alert, Action and Information Task <p> The standard confirmation message in case of Action, Alert and Information task ends with an option to amend entities. In case the task does not have any entities (Fields) then this message will be shown.     Ask at least one optional field     Applicable to Action Task Only <p> Under the Advanced settings when defining the action task, the developer can set an option to enforce the user to provide at least one of the optional fields (parameters/entity) of all the configured optional parameters. This is to handle the use case of Modify. <p> This Bot response is displayed if the user does not provide value to any of the optional parameters     Topic retry limit exceeded     This is only for the developer (Developer mode on). <p> The platform has set up a check on loop limit and if the dialog conditions result in looping through the same nodes multiple times (Defined limit) then the task is discarded and this message is shown to the developer.     Universal fallback response     Shown in the following cases: <p> 1. Universal catchall: For any reason, be it technical or others, when the bot is not able to generate further responses <p> 2. When the bot exceeds the maximum number of nodes that can be executed in a volley, and the user is not a bot developer. For a bot developer Topic retry limit exceeded message displays in this case.     Server returned authorisation failure and the user needs to re-authorize     This message is displayed for a Server Authorization failure during the execution of the script node or making API call.     User selects a valid option from the list of options     The message is displayed when the bot displays a list of all the tasks and the user selects an action/alert/information task.     User selects an action     The message is displayed when the user selects an action task to be executed. The bot confirms that the task has been selected and asks the user to provide values for the parameter required to complete the task.     Alert is identified, ask the user to enter alert time     Applicable to Alert Task Only <p> During the setup of the Alert, the bot will ask the user the frequency at which the alert will be triggered. The end-user will need to specify at what interval the alert task will be triggered. <p> This bot message is displayed to request the user to specify the Alert time if the Trigger interval option is set to At a specific time in the day.     Alert is identified, ask the user to enter alert time interval     Applicable to Alert Task Only <p> During the setup of the Alert, the bot will ask the user the frequency at which the alert will be triggered. The end-user will need to specify at what interval the alert task will be triggered. <p> This bot message is displayed to request the user to specify the Alert time interval if the Trigger interval option is set to Every X mins.     User selects an alert     The message is displayed when the user selects an alert task to be executed. The bot confirms that the task has been selected and asks the user to provide values for the parameter required to complete the task.     Task discarded     Shown when the user types discard in the middle of task flow. The bot discards the task.     Bot choosing the default account     Used in alerts. Shown when the user is asked if they want to amend anything before setting up the alert, and what the user replies with is not understood by the bot.     Confirmation Dialog for Task consolidated     Used in Action and Information tasks. <p> Before executing the task, the bot confirms with the user with the parameters captured if it can go ahead and execute the task     Confirmation Dialog for Alert consolidated     Applicable to Alert task Only <p> During a task set up by the end-user, the bot will confirm all the details entered with the user before setting up the alert. It also gives the user an option to amend the values, proceed or discard. <p> This message is displayed only if the developer has enabled confirmation of all parameters before the execution of the task.     Confirmation Dialog for Alert consolidated without fields     Applicable to Alert Task Only <p> If the alert is not expecting any parameters from the end-user, the bot will display this message before the final execution of the alert. <p> This message will be displayed only if the developer has enabled confirmation with the user before the execution of the task.     The alerts will be muted     This message is displayed when the developer has muted the alert notifications     Confirmation Dialog when alerts are muted     Applicable to Alert Task Only <p> This response is displayed when the developer has enabled Mute alert notifications for the RSS feed. Developers can enable or disable Mute alerts notifications if they do not want desktop or mobile phone notifications to display on the desktop or your mobile phone each time an alert for the RSS is received. By default, notifications are enabled.     Alert Frequency description     Applicable to Alert Task Only <p> Alert tasks when configured using web service, make requests based on the frequency selected by the bot user. <p> This message is displayed as an alert task setup confirmation about the frequency of query.     Not understanding the input at confirmation     In the process of setting up the alerts, the user is asked to confirm the frequency settings and the user response does not relate to the frequency query.     No results found for the search string     Applicable to Alert, Action and Information Task <p> When a typeahead field does not return any results     Successful task setup     This message is displayed when an alert task is set up successfully     I am not sure what you mean     Shown when the bot finds one or more not-so-confident intents against a user utterance. Usually shown for FAQ suggestions.     Ambiguity in intent recognition     This response is displayed when the bot fails to identify the intent from the end user utterance. The bot then prompts the user to re-phrase the statement.     User has selected to setup an alert per day and bot needs to know if the choice is based on frequency or specific time     Applicable to Alert Task Only <p> This message is displayed when the bot asks the user to provide the frequency at which the alert task will be auto-triggered. This can be specified in terms of af a particular time as 10 am or frequency like every 10 minutes. This is a message when both the options are set up.     Bot needs to present the filter options     Applicable to Alert Task Only <p> This message displayed when more than one filters are available during the setup of an alert. In this situation, bot will display this message followed by the list of available filters from where the user can select the filter to apply.     Bot needs to present the filter options with exit option     Applicable to Alert Task Only <p> This message displayed when more than one filters are available during the setup of an alert. In that situation, bot will display this message followed by the list of available filters from where the user can select the filter to apply and an option to skip.     User finished configuring filters     Applicable to Alert Task Only <p> This message is displayed after a user completes configuring a filter while setting up an alert task.     User asks Who am I Shown when a user types who am I User asks for help     This message is displayed when the user types Help. The bot lists all the dialog tasks, alert/action/information task it can perform. <p> Part of the Help message.     Skipped values     Applicable to Action and Information Task <p> This is part of the confirmation message for an action/Information task, we mention the skipped parameters in the confirmation message.     While filling fields, ask user to change the field that this fields depends on     Applicable to Actions dropdowns <p> This message is displayed to the user when a drop-down field at actions is dependent on another field and platform is not able to fetch the data from the dependent field     When there is no data     Applicable to Action Tasks <p> This message is displayed when the user chooses to change the account and upon bot confirmation, the user provides no as input     When date given in Invalid format     Shown when the user enters an invalid entry for a date entity. The platform recognizes the following date formats: YYYY-MM-DD, DD-MM-YYYY <p> DD-MM-YY, 1 Jan 1982 or 1st Jan, or the following type of date descriptions This day last year, Next Friday     This message is displayed by the bot when the end user discard the current task in execution. The user can use the discard/discard all command to discard the current task in execution. Other similar commands like exit, cancel etc also results in discard.     Follow up sentence post User discards/abandons the current activity     Confirmation Dialog for task with skipped fields     Applicable to Action and Information Task <p> This message is displayed to confirm the setup of Action/Information before the final execution of the task when a few fields are not mandatory to provide by the user.     Listing all tasks     This message is displayed when the end user types Help and the bot lists all tasks. This is part of the message shown when user utterance does not match any task/faq     Listing all alerts     This message is displayed when the end user types Help and the bot lists all alert tasks. This is part of the message shown when user utterance does not match any task/faq     Listing all FAQs     Shown when responding to the user when requested for Help. This response is part of a bigger response and deals with the knowledge graph collections.     Listing all alerts after tasks     If a bot just has alert tasks, the bot shows this message along with showing the list of all alert tasks when the bot fails to understand the user intent     Listing all alerts after tasks and FAQs     When user provides the input Help and all types of tasks Actions, Dialogs, FAQs and Alerts are configured at the bot     Lists all actions and FAQs for a bot     This message is displayed when the bot is unable to find a matching task for the end-user utterance and lists all actions and FAQs.     Lists all alerts and FAQs for a bot     This message is displayed when the bot is unable to find a matching task for the end-user utterance and lists all alerts and FAQs.     When bot has no tasks     Shown when the developer tries to run a bot that doesn\u2019t have any tasks created.     When a server call fails and the task has to be discarded     Shown when a kore API call couldn\u2019t be made (webhook node or service node) and the task had to be discarded.     User prompt when a task is discarded due to a server call failure     This message is displayed when there is a server call failure due to which the API call was not completed successfully.     Specific bot is not available for conversation     This message is displayed when a bot is not published yet and the end user tries to communicate with it.     Field title and value in confirmation     Applicable to Alert, Action and Information Task <p> This is part of the confirmation step before executing the alert, action or information task. The format of showing the captured parameters is described here.     Recursive dialog found     Shown when the bot calls a dialog recursively and exceeds the maximum limit (100).     Loop limit reached for a node     Shown when the bot repeatedly invokes the same node in a loop for more than an allowed number of times.     Message component doesn\u2019t have a message     When the message from a message node or service node is empty or cannot be resolved, we show this default message.     User says thanks     Shown when user thanks the bot.     User says OK, fine, yes, etc. when there is no task in context     Shown when the user says OK, fine, got it, etc (probably after finishing a task)     User says no, nope etc. when there is no task in context     This is small talk in the response to user utterance is \u2013 No, Nopes, etc.     User says great, awesome etc. when there is no task in context     Shown when the user says great, awesome, etc. (probably after finishing a task)     User says that helped, that was useful, etc.     Shown when the user says good, great, awesome, cool, \u201cfair enough\u201d, \u201cthat helped\u201d, \u201cit helps\u201d, \u201cthat was useful\u201d, \u201cthat was handy\u201d etc. (probably after finishing a task)     User says I am done. That\u2019s it for now! etc.     Shown when the user says I am done, that\u2019s it for now, that\u2019s all, done, etc. (probably after finishing a task)     Successfully added filter     This message is displayed when a filter is added successfully to an alert     After successfully adding a filter, showing the filter options again     Applicable to Alert Tasks only <p> Developers can define filters for end-users to limit the results of an alert task as per the end-user needs. When the alert is set up by the end-user, and the filter applied, only alert messages that meet the filter specifications are displayed to the end-user. <p> This message is displayed when a filter is enabled for an alert.     User gave invalid input for filter, showing the filter options again     Applicable to Alert Task Only <p> The message is displayed when the user specifies a filter name that does not match with the ones that have been configured.     Resume paused task.     This message is displayed when the user chooses to resume the On-hold task. The message is displayed only when the Resume option is set to Notify the user with a message that the on-hold task is being resumed. Notify the user that we have canceled the paused task.     This message is displayed when the user chooses to cancel the on-hold task. This option of canceling the on-hold task is available only when the Resume option is set to Get confirmation with the user before resuming on hold task. When the user is asked to confirm resumption and selects to cancel the on-hold task this message is shown.     Notify the user that we have canceled the current task to switch to another     This message is displayed when the Hold and Resume \u2013 Hold option is set to Discard the current task and switch to new. Before discarding the current task, the bot will display the given message. This message can be customized from the Manage response option.     When an interruption is identified but hold is not allowed     This message is displayed when the user input matches with another task when one task is in execution but the current task cannot be interrupted. In this situation, the bot will add the new task to the follow-up task list and continue the execution of the current task. For this behavior, the developer needs to select Continue the current task and add a new task to the follow-up task list in the Hold and Resume settings. Service call timedout     Shown when a third party API call timed out (webhook node or service node-third party async API timeout)     Dialog has no transitions     Applicable to Dialog Task Only <p> This response is displayed when the bot identifies a dialog task for which no conversation flow has been defined. The task is defined only with an Intent node.     manage account     User says manage bot accounts, add a new phone number, manage my profile, I want to delete my bot account, I want to reactivate my account, etc."},{"location":"automation/intelligence/conversation-management/standard-responses/#queries","title":"Queries","text":"MESSAGE DEFINITION Ask if the user would like to switch to the new language detected during a conversation     Your current conversation is in &lt;current language&gt; language but I have detected &lt;list of new languages&gt; languages from your current input. Please provide your preferred language to proceed.     Ask if the user would like to switch to the new language detected during a conversation     I have detected that your input is in &lt;new language&gt; language. Please say Yes to close the current conversation and switch to . You may say No to continue on the current conversation.     Follow up sentence post Task execution or discard of task     Ok, I am discarding the task for now. We can start over whenever you are ready.     Confirmation before discard     It applies only to selected clients like Citibank. Shown when the user enters Discard or Discard All during task execution.     User Types Change or similar words     Applicable to Alerts <p> While setting filters for an alert, the user says they changed their mind. <p> This message is displayed when the bot discards the current alert setup.     User prompted to enter text to search for the relevant results     Applicable at action, alerts and information tasks. When the parameter is type \u2013 Type ahead, the user will be shown this message.     Ask the user to enter alert frequency     Applicable to Alerts <p> This message is used to prompt the user while setting an alert frequency, and the frequency options are either an interval (every 4 hours) or a time (at 10 am).     Ask the user to enter alert interval     Applicable to Alerts <p> This message is used to prompt the user while setting an alert frequency, and the frequency option is an interval (every 4 hours).     Ask the user to enter alert time     Displayed as per schedule options defined by the developer of the alert and would be prompted while setting up the alert. For example, when the user selects daily, the bot prompts the user to enter a time.     Alert is identified, Ask the user to enter frequency     Displayed as per schedule options defined by the developer at the alert and would be prompted while setting up the alert.     Prompting user to enter name for alert instance     Applicable for alerts \u2013 when users try to install the alert in Kore messaging app \u2013 rooms     User needs to select a value from a list presented as a result of static drop-down     Applicable for alerts. <p> When the user opts to apply a filter on notifications and chooses a filter of field type static dropdown, the options name will be presented to the user with this message.     User needs to select a value from a list presented as a result of search results     Applicable for alerts. <p> When the user opts to apply a filter on notifications and chooses a filter of field type dynamic dropdown, the label key will be presented to the user with this message.     Request for email address to send webhook instructions     Applicable for webhook alerts wherein the developer would be mailed the setup instructions.     Query to get the alert instance description     Applicable to Alerts <p> This message is used to ask the user for description while setting up an alert.     Tell me the alphabet or a unique word for action you want     When the bot has to display a list of options, it displays this message before the list to prompt the user to select an option. If the bot doesn\u2019t use any custom template, the list is displayed as an alphabetically ordered list and the user can either enter the choice or the letter associated with it.     I am not sure what you mean after an invalid choice     When a user utterance leads to the detection of not-so-confident matches, the bot displays the options for the user to pick from. If the user\u2019s follow-on message doesn\u2019t match any of the initially identified ambiguous alerts, this message occurs.     Asking user to pick an alert     Applicable to Alerts <p> This message is displayed when a list of alerts is shown to the user to pick from     Asking user to pick an alert after an error     Applicable to Alerts <p> This message is displayed when a list of alerts is shown to the user to pick from and they pick a wrong choice (a wrong index, maybe)     When User responded with an invalid answer to confirmation dialog     At a confirmation for an action, when the user says they want to amend something but the bot does not understand what, we show this message and ask confirmation again     Typeahead field prompt, when it is the first field in a task     Applicable at action, alerts and information tasks. When the parameter is type \u2013 Type ahead, the user will be shown this message     After user selecting a valid alert from the list of alerts, then tries to change the alert name     Applicable to Alerts <p> Users can change/amend the name of the alert during setup. <p> This message is used to ask the user what they want to name the alert.     After user selects amend and enters the choice     Applicable to Alerts <p> Users can amend parameters like name, description, notification, frequency, etc. during alert setup. <p> This message is used to ask the users if they want to change anything else after any parameter has been amended successfully.     No results found for the search string. Ask user to try again.     Applicable at action, alerts and information tasks. When the parameter is type \u2013 Type ahead, and the user input doesn\u2019t fetch any results from the API response.     Follow up sentence post User discards/abandons the current activity \u2013 Part2     Applicable to Alerts <p> At an alert confirmation, the user says no, and then we ask if they want to change anything (message with the title User says no for alert setup confirmation), to which user says no again.     Listing ambiguous tasks     This message is displayed when the user is prompted to pick a task from a list, and their reply leads to ambiguity     Ask user if they want to continue the last paused task after completing the interrupting task.     This condition applies only to bots for which the following resume option in the Hold and Resume settings is configured: Get confirmation with the user before resuming an on-hold task Resume option. The bot shows this message when it completes executing the new task and confirms if it can resume the on-hold task.     To be displayed to ask if user would like to switch     Applicable to Manage Interruptions <p> This message is displayed when Hold and Resume are set to Allow the end user to select the behavior. In this situation, when the user utterance matches with a task name, the bot will confirm with the end user before switching to the new task."},{"location":"automation/intelligence/conversation-management/standard-responses/#errors-warnings","title":"Errors &amp; Warnings","text":"MESSAGE DEFINITION User exceeds the maximum allowed retries for an entity when another task is on hold     You have exceeded the number of allowed attempts. I am discarding the current task.     Dialog task associated to a FAQ is not available     This response is displayed in case the dialog linked with FAQ is suspended or deleted or not assigned to the user     User needs to authorize or re-authorize     This response is displayed when the end-user authorization or re-authorization is requested. <p> The Authorization URL required for obtaining the user\u2019s authorization is dynamically appended to the messages defined in the Simple mode. For defining the message in Advanced Mode, you can use the <code>koreUtil.getCurrentOptions()</code> function to retrieve the Authorization URL and use it as part of the message. Know more User authorization has failed or user is yet to authorize     If access to a bot/task needs authorization, the bot prompts the user with this message, requesting for authorization. This message is followed by a link that will open in a web-page depending on the type of auth profile.     User\u2019s intent is recognized, but authorization fails     This response is displayed when the intent identified by the bot needs to make a service call that needs authorization and no accounts are created by authorized yet.     User authorization failed for more than 3 times     Shown when the user enters wrong authorization credentials for three times in a row.     User provided value which is not unique.     When a list of partially matched intents is shown to the user, and the user instead of selecting from the options, types something that again creates ambiguity.     Bot did not find any options based on user\u2019s choice     When the set of options to show for a list is empty. <p> Can also be shown if there are no account credentials to select from.     Discarding the task since we did not find any options for a list or lookup.     Shown when the user entered choices is not present in the response after making a service call. The fields at simple tasks for user inputs wherein user input is looked up from the response of the third party is an instance. (Actions, Alerts, and Information tasks \u2013 Dynamic drop down or Type ahead field types with user input from the chat window can be considered an example).     When the task is identified, Server call failure is returned     Shown when the task is identified but user account on kore to access third-party API expired or failed     User enters Invalid email     Shown when the user enters an invalid email address for an alert, action, or information task.     User enters Invalid country     Shown when the user enters an invalid country name for an alert, action, or information task.     User enters Invalid url     Shown when the user enters an invalid URL for an alert, action, or information task.     User enters Invalid phone number     Shown when the user enters an invalid phone number for an alert, action, or information task.     User enters Invalid number     Shown when the user enters a string or description against a number input for an alert, action, or information task.     Invalid date format     Shown when the user enters an invalid date format for an alert, action, or information task.     Missing date     Shown when the user doesn\u2019t enter a date format for an alert, action, or information task.     Ask user to enter time for a field     Shown when the user doesn\u2019t enter time for entities of type \u2013 Date Time at dialog tasks     Ask user to enter time     Shown when the user enters just the date and not time for a DateTime entity. For example, in a Schedule Appointment task, if the bot asks for the preferred date and time, and the user just enters the date.     Invalid time. Ask user to try again for a field     Applies to a DateTime Entity <p> This message is displayed when the bot asks the user to enter the time portion for a DateTime entity and the user\u2019s response didn\u2019t have time, the bot asks them to try again.     Invalid time. Ask user to try again     Shown when the user enters an invalid time value for a DateTime entity. <p> For example, in a Schedule Appointment task, if the bot asks for the preferred date and time, and the user enters something like Aug 29 at 25.     Missing date/time     Applicable to Actions and Alerts <p> This message is displayed as an Error prompt for a DateTime entity in actions and alerts.     You have chosen a wrong choice.     This is a subkey for other keys with the following conditions. <p> Tell me the alphabet or a unique word for the action you want after an invalid choice <p> I am not sure what you mean after an invalid choice <p> Asking the user to pick an alert after an error <p> When need to show the possible intervals for an alert schedule <p> You have chosen the wrong choice for the task schedule <p> Listing all tasks after a wrong choice <p> Listing all alerts after a wrong choice <p> Listing all FAQs after a wrong choice <p> Listing all tasks and alerts after a wrong choice <p> Listing all alerts, tasks, and FAQs after a wrong choice <p> Lists all actions and FAQs for a bot after a wrong choice <p> Lists all alerts and FAQs for a bot after a wrong choice Can not understand your request     Shown when the bot cannot recognize the user\u2019s intent. It is usually displayed along with a list of tasks and FAQs available in the bot for the users to select.     When bot is selected, user is asked for reauthorization     Applicable to Service Calls <p> This message is displayed when an API call fails due to the expiry of user credentials and the bot ask the user to reauthorize.     Listing all tasks after a wrong choice     Help related \u2013 When the developer has only configured Actions/ Dialogs/Information tasks and the user input didn\u2019t match with any task     Listing all alerts after a wrong choice     Help related \u2013 When the developer has only configured Alerts at the bot and the user input didn\u2019t match with any task     Listing all FAQs after a wrong choice     Help related \u2013 When the developer has only configured FAQS at the bot and the user input didn\u2019t match with any FAQ     Listing all FAQs after not understanding your request     If a bot just has a Knowledge Graph, the bot shows this message when the bot fails to understand the user intent.     Listing all actions after not understanding your request     If a bot just has action tasks, the bot shows this message when the bot fails to understand the user intent. It provides the names of the action tasks along with the message.     Listing all actions and alerts after not understanding your request     If a bot just has action and alert tasks, the bot shows this message when the bot fails to understand the user intent. It provides the names of the alert tasks and action tasks along with the message.     Listing all actions and FAQs after not understanding your request     If a bot just has action tasks and a KG Graph, the bot shows this message when the bot fails to understand the user intent. It provides the names of the action tasks and the Knowledge Graph along with the message.     Listing all alerts after not understanding your request     If a bot just has alert tasks, the bot shows this message when the bot fails to understand the user intent. It provides the names of the alert tasks along with the message.     Listing all alerts and FAQs after not understanding your request     If a bot just has alert tasks and a KG Graph, the bot shows this message when the bot fails to understand the user intent. It provides the names of the alert tasks and the Knowledge Graph along with the message.     Listing all tasks after not understanding your request     When the bot fails to understand user intent, it shows this message along with the names of tasks it can perform.     Listing all tasks and alerts after a wrong choice     Shown when a user types Help and from the tasks lists that opens they choose an invalid option. For example, if the tasks lists have options from a to c and the user types d.     Listing all alerts, tasks and FAQs after a wrong choice     Help related \u2013 When the developer has only configured Alerts/ Dialogs/FAQs tasks and the user input didn\u2019t match with any task     Lists all actions and FAQs for a bot after a wrong choice     It occurs only when the bot just has action tasks and a Knowlege Graph. When a bot shows the names of the action tasks and the KG Graph to choose from, the bot shows this message when the user selects an invalid option. For example, if the tasks lists have options from a to c and the user types d.     Lists all alerts and FAQs for a bot after a wrong choice     It occurs only when the bot just has alert tasks and a Knowlege Graph. When a bot shows the names of the action tasks and the KG Graph to choose from, this message is displayed when the user selects an invalid option. For example, if the tasks lists have options from a to c and the user types d.     Task is discarded when user exceeds maximum number of alowed attempts.     Shown when the user enters invalid format for an entity type for 5 times. For example, the entity is of type number and the user enters an email 5 times.     When the entity component in dialog doesn\u2019t have error prompt     Shown when there is not at least one error prompt associated with an Entity node. It typically occurs when you accidentally delete the default error prompt and try to save the node properties.     When the entity component in dialog doesn\u2019t have message attribute     Fallback message if an entity does not have a message prompt defined.     User input exceeds the maximum allowed sentence limit or contains one or more words that exceed the allowed word length.     Shown when the user types an input that exceeds the maximum sentence or word limit. You can customize this message and the language based on your business needs."},{"location":"automation/intelligence/conversation-management/standard-responses/#questions","title":"Questions","text":"MESSAGE DEFINITION When user input matches and frequency is asked     Applicable to Alerts <p> This message is displayed when the user is prompted to set a frequency for an alert, and their reply leads to ambiguity.     When asking the user to input the frequency at which the alert updates need to be checked for     Applicable to Alert Task <p> This message is displayed when the bot asks the user to input the frequency at which the alert will be triggered."},{"location":"automation/intelligence/conversation-management/standard-responses/#choices","title":"Choices","text":"MESSAGE DEFINITION Search results displayed based on user input. (Type ahead search)     Applicable to Alert Task. <p> For an alert task, developers can set up filters to restrict the output of an alert task. In the filter setup, the Field Type can be specified as Type Ahead. This field type displays a dynamically populated drop-down list of choices to the user at runtime when the user enters three or more characters that match the search results based on the response from the URL defined for the task. <p> This message is displayed when the end user provides input for the Field Type of Type Ahead type when setting up the filter for an alert task.     Confirming alert frequency     Applicable to Alert Task. <p> This message is displayed when the bot confirms the current trigger frequency of an alert task with the end user.     Repeat confirmation of default alert frequency     Applicable to Alert Task <p> End user can change/amend the trigger frequency of the alert task. <p> This message is displayed when the user input does not match with the expected input for the alert frequency     Confirmation to set up an alert task with a frequency     Applicable to Alert task <p> This message is displayed to confirm the trigger frequency for an alert task.     Prompting the user to set up filters     Applicable to Alert Task <p> Developers can create filters for an alert task. These filters will limit the results of an alert task to the results an end-user needs. <p> This message is displayed when the bot asks whether the user wants to set up any filter.     Prompting the user to set up filters as soon as an alert is identified     Applicable to Alert Task <p> Developers can create filters for an alert task. These filters will limit the results of an alert task to the results an end-user needs. <p> This message is displayed when the bot asks whether the user wants to set up any filter.     Asking user to set up push notifications     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert notification setting. The user can enable/disable alert notification by responding yes/no.     Repeat asking user to set up push notifications     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message will be displayed when the user input to the amending notification setting does not match the pre-defined response (yes/no).     Amending the request for a description     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert description.     Amending the request for a description     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert description.     Amending the request for frequency     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert trigger frequency.     Amending the request for notification settings     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert notification setting i.e. user can specify whether he wants to receive notifications whenever the alert is triggered.     Prompting user to choose the \u2018Days of the week\u2019 to setup notification frequency     Applicable to Alert Task <p> This message prompts the user to select Weekday/Weekend for the Trigger frequency when setting up the alert. Currently, a dropdown box is displayed with all the options available for the trigger frequency and the user can select any frequency from the list.     Query to choose the interval to set up notification frequency     Applicable to Alert Task <p> During the alert set up, the end-user needs to specify an interval at which the alert will be executed. <p> This message is displayed by the bot prompting the end-user to set up the frequency interval for the alert task.     Query to send webhook setup instructions via email     Applicable for webhook alerts <p> The bot check with the end-user if it needs to send an email to the developer with instructions to configure the webhook alert at the third party app.     Do you want to change the name of the alert &lt;alert-name&gt;?     Applicable to Alert Task <p> The bot confirms the parameters entered by the user before an alert setup. The user can select no or amend on which the bot will allow the user to modify the name, description, notification, frequency or any other parameter in the alert before proceeding with alert setup. <p> This message is displayed when the user wants to change/amend the alert name.     Query to choose the operator while setting up a filter &lt;current-filter&gt;.     Applicable to Alert Task <p> Developers can configure filters for an alert task. The filter will have one or more operations that the end-user can select to apply to the filter. The operation depends on the Data Type selected for the filter. <p> This message is displayed when the user sets up the filter for the alert task. The bot prompts the user to select one of the available operators.     Options to pick the frequency for alert notification days     Applicable to Alert Task <p> Developers can select all the options like Daily, Weekday, Weekend when setting up the Trigger Interval Options for an alert task. Users will need to select/specify the interval from the available list as the frequency at which the alert will be triggered during setup. <p> This message is displayed when all the interval options are available and the bot prompts the user to select one of the Trigger Interval during alert task setup.     When the user needs to choose one of the provided choices     Applicable to Alerts and Actions <p> This message is displayed when the user is prompted to pick a choice for a drop-down in alerts and actions.     Confirming with the user if he/she wishes to re-used a pre-saved context     When need to show the possible intervals for an alert schedule     Applicable for Alert Task <p> Developers can set up the trigger frequency for an alert in terms of interval duration like every 10 minutes, 20 minutes, etc. or specific time like at 9:00 am, 11:00 am, etc. <p> This message is displayed when the frequency is specified in terms of the interval like every 10 minutes, 20 minutes, etc. and the user inputs a specific time like 9:00 am at which he would like to trigger the bot. In this situation, the bot will prompt the user with the available valid frequencies that can be set up for the alert.     When only finding a close frequency for an alert schedule     Applicable to Alert Task <p> Developers specify Default Trigger Interval for the frequency of the Alert task. Users need to select one of these intervals at the time of setting up the alert. <p> This message will be displayed when the interval/time specified does not match with the list of intervals set by the developers. The Alert prompts the nearest available time from the list of frequency available.     When only finding a close time for an alert schedule     Applicable to Alert Task <p> Developers can specify times like 9:00 am, 11:00 am, 3:00 pm as the frequency at which the alert will be triggered. Users need to select a particular time from the available options when setting up the alert. <p> This message will be displayed if the user specifies a time which is not mentioned in the alert setup.     When changing a field     Applicable to an Alert Task. <p> This message is displayed when the user selects No while confirming the parameters of an alert task.     Prompting the user to set up filters after an alert is identified     Applicable to an Alert Task. <p> Developers can set up filters during the configuration of an alert task. Only the notifications that satisfy the filters will be displayed to the end-user. <p> This message is displayed when the user gives input for setting up an alert task.     If asking the user if they want setup instructions to be sent via email is the first prompt in an alert     Applicable to Alerts <p> This message is displayed when the User starts setting up an alert and the first prompt in the process is to ask them if they want an email about installation instructions     While choosing options     Applicable to Alerts and Action Task <p> This message is used to show options returned by the platform for a typeahead entity in an action or an alert     After the user selects a valid task from the list of tasks, then tries to type something for schedule     Applicable to Alerts <p> This message is displayed when an alert is selected by the user from a list and the bot asks them how often they want to be notified     You have chosen a wrong choice for task schedule     Applicable to Alerts <p> This message is displayed when the user gives a wrong value for the frequency while setting an alert and the bot asks again.     After user selecting a valid task from the list of tasks, then tries to enter field value     Applicable to Alerts and Action Task <p> This message is displayed when an action or alert is triggered, and the first field is a dropdown.     User says \u2018no\u2019 for alert setup confirmation     Applicable to Alert Task <p> During alert task configuration, developers can enable confirmation of all parameters with the user before the execution of the alert. The bot will display all the values entered by the user for setting up the alert. The bot will allow the user to select how to proceed with the execution of the alert with the options yes, no, and amend. <p> This message will be displayed if the user selects option no.     After selecting task, user selects wrong choice in Dialog.     When a list of choices is presented (not from a List of Values entity) and the user enters something that cannot be matched to one of those items     User enters a wrong choice for alert frequency     Applicable to Alert Task <p> At the time of setting up alert tasks, users need to provide the frequency at which the alert will be triggered. This value had to match with one of the frequencies given by the developer at the time of creating the alert <p> This message is displayed when the alert frequency given by the user does not match with any of the frequencies specified by the developer.     User enters a wrong value for a dropdown.     Applicable to List of values <p> This message is displayed when the user input does not match any values given in the List of Values     List ambiguous list of values to user to choose from     For a List of Values entity, if a user has entered something that cannot uniquely identify an item then the set of possible items that partially match the input are shown along with this message     User enters an invalid choice for an action     This message is displayed when the user is prompted to pick a task from a list, and their response does not match with the list.     Ambiguous date     Shown when you enter a date value that is ambiguous. For example, if the user enters 6/9 for a date, the bot shows 9 June &lt;year&gt; and 6 September &lt;year&gt; as options for the user to select from.     Ambiguous airport     Shown when you enter a value for an Airport entity that is unclear and requires further selection. For example, if you enter London, the bot shows London Heathrow Airport and Gatwick airport as options to select from.     Ambiguous location     For a Location entity, if the geo code service returns multiple possibilities then the list is shown along with this message     There are more than one account for the user to pick from     When the user has more than one account (third party, eg. Jira) and they are asked to pick one.     The user\u2019s intent is recognized, but there are more than one account for the user to pick from     When the user has more than one account (third party \u2013 Jira) and they are asked to pick one.     Custom lookup query returned more than one value. Ask user to pick one.     Shown when the user query returns more than one items from a list of items. All the items are presented to the user to pick the relevant option.     After the user selecting a valid choice from the list, the chosen list found to be empty     Applicable to Alert and Action Task <p> This message is displayed when a dropdown (in an action or an alert) depends on another field, and the value of that other field does not create any options for this dropdown. In this situation, the bot will ask the user to set a different value for the dependent field.     When user selects an invalid choice.     Same as above but the value provided by the user for the dependent field is not valid.     At the end of a dialog, present user with list of followup tasks identified. Ask them to pick one task to execute     This condition occurs only for Dialog tasks for which the following Follow-up Tasks Setting is configured: Yes, at the end of this dialog ask the user to select and perform a task from the Follow-up task list in the Dialog settings. The bot shows this message when it presents the Follow-Up Intents array to the user at the end of the Dialog.     Ask the user to select an entity to be amended when the entity value provided for amending is valid for multiple entities     Applicable to amending entity values during Dialog execution <p> This message is displayed during a dialog execution when the user wants to amend an entity value by mentioning the entity value and the bot is not able to determine the entity to be amended since multiple entities hold the same value. Eg: change Bangalore to Mumbai and Bangalore is set to more than one entity     The user is trying to put more than the max on-hold quantity of tasks on hold. Ask them to pick a task to cancel one.     When the developers set up the Hold and Resume settings, they can configure the maximum number of tasks that the bot can allow to be put on hold. The bot shows this message when the user executes the bot if the number of tasks that are put on hold is more than that number.     User provides an intent when prompted for String/Description entity     Applicable to an entity node of String/Description type. <p> Developers can configure Intent Detection in the Instance Property of an entity node of String/Description type to Ask the user how to proceed <p> This message will be displayed if the user\u2019s input matches with intent and the bot want to confirm before proceeding to execute the new intent."},{"location":"automation/intelligence/conversation-management/standard-responses/#greeting","title":"Greeting","text":"<p>(These will be moved to Small Talk post ver7.1 release)</p> MESSAGE DEFINITION Response when User says Hi     Shown when the user says hi, hello, hey, etc, or just enters the bot\u2019s name.     Response to how are you?     User asks how are you? <p> NL interprets the following ways in which the user can say that: <p> &lt;how are you&gt;, &lt;how are u doing&gt; &lt;how are u how are u&gt; <p> &lt;how have u been doing&gt; &lt;how have`u`been&gt; &lt;how`do`u`do&gt; &lt;how`are`u`doing&gt; &lt;how`are`u&gt; <p> whazzupp whatcha`upto watsup wassup howzit <p> comment`est`vous comment`ca`va ca`va <p> &lt;what`up &lt;what`is`up`today <p> &lt;what`is`up &lt;what`is`the`word&gt; &lt;what`is`the`latest`word&gt; &lt;what`is`new&gt; &lt;what`is`happening&gt; <p> &lt;what`is`going`on&gt; &lt;what\u2019up &lt;is`everything`OK &lt;is`everything`alright &lt;how`you`feeling <p> &lt;how`you`doing &lt;how`is`tricks &lt;how`is`life &lt;how`is`it`going &lt;how`is`everything <p> &lt;how`is`by`you &lt;how`have`you`been`doing&gt; &lt;how`have`you`been&gt; &lt;how`goes&gt; &lt;how`goes`things <p> &lt;how`goes`it &lt;how`is`your`day &lt;how`do`you`do&gt; &lt;how`are`you&gt; &lt;how`are`things&gt; <p> &lt;heya&gt;     Response to who are you? Shown when the user says who are you"},{"location":"automation/natural-language/nlp-guidelines/","title":"NLP Settings and Guidelines","text":"<p>This article provides you with some essential guidelines to help you optimize your workflow with the XO Platform\u2019s NLP, and thus improve your VA\u2019s performance. Please refer to the guidance below before before intent naming, ML training, and handling entities, concepts, and synonyms.</p>"},{"location":"automation/natural-language/nlp-guidelines/#intent-naming-guidelines","title":"Intent Naming Guidelines","text":"<p>The below guidelines help name your task (intent identifier) optimally:</p> <ul> <li>Use an action verb, an object, and possibly a modifier (placed before or after the object). Typically, an intent name consists of 2 to 4 words.</li> <li>Use less than 5 words to convey the purpose of the task.</li> <li>Use the same verb in different tasks if the action is similar (For example, Show Issue/Show Report instead of Show Issue/Get Report).</li> <li>Avoid single-word actions.</li> <li>Avoid determiners (the, a, my, that, etc.)</li> <li>Avoid digits but if you cannot, always use the numerical form.</li> <li>Avoid Kore.ai Platform terms such as task, alert, action, cancel, discard, amend, and webhook.</li> <li>Avoid using a potential entity in an intent name (For example, Get Weather Today, where today is a potential entity).</li> <li>Don\u2019t use special characters such as () &amp; /  $ [ ] + *.</li> <li>Don\u2019t use punctuation such as \u2013 , . ! ? \u2018 \u201c.</li> <li>Don\u2019t use pronouns (i.e. Show Me All Issues)</li> <li>Don\u2019t use terms related to the VA name (For example, Create Asana Task).</li> <li>Don\u2019t use a word both as a verb and as a noun (For example, Update Issue/Get Updates).</li> <li>For List of Items entity type, do not have the combination of following characters while defining synonyms \u2013 (), %, \u00b0 (degree symbol for degrees i.e. 30\u00b0C).</li> </ul> <p>Dialog Tasks must always contain an action verb, an object, and possibly a modifier (placed before or after the object). You must map almost all actions to the form how + what and complete the sentence the goal is to:</p> <ul> <li>Do Something</li> <li>Get Status</li> <li>Send Detailed Report</li> <li>Email Report Critical</li> <li>Get 3 Day Forecast</li> </ul> <p>Alerts must contain an object and possibly a modifier (placed before or after the object). Avoid using verbs in alert altogether. Avoid using the word alert in an alert name. Alerts must be mapped to the form what and complete the sentence alert me on:</p> <ul> <li>Something</li> <li>Status Updates</li> <li>Critical Status Update</li> <li>Changes</li> </ul>"},{"location":"automation/natural-language/nlp-guidelines/#ml-training-guidelines","title":"ML Training Guidelines","text":"<p>Here are a few recommendations that will improve the training of the Machine Learning engine within your assistant:</p>"},{"location":"automation/natural-language/nlp-guidelines/#general-recommendations","title":"General Recommendations","text":"<ul> <li>Batch test suites are compulsory, for comparing various ML models. Run the batch suite, configure the parameters, re-run the suite and compare the results.</li> <li>There is no set rule as to which ML model to go for. It is a trial and error method \u2013  configure the engine, run batch suites and compare results.</li> <li>If your dataset is large, then the stop words and synonyms are recognized automatically by the ML engine and taken care of without having to enable them explicitly.</li> <li>Check for influencer words and if needed add them as stop words, for the n-gram algorithm.</li> <li>Prepare examples that are as diverse as possible.</li> <li>Avoid adding noise or pleasantries. If unavoidable, add noise so that it is equally represented across intents, else you can easily overfit noise to intents.</li> </ul>"},{"location":"automation/natural-language/nlp-guidelines/#using-the-confusion-matrix","title":"Using the Confusion Matrix","text":"<p>The Confusion Matrix can be used to identify training sentences that are borderline and fix them accordingly. Each dot in the matrix represents an utterance and can be individually edited. </p> <p>The graph can further be studied for each of the following parameters:</p> <ul> <li>Prevent false positives and false negatives by assigning the utterance to the correct intent. Click on the dot and on the edit utterance page assign the utterance to the correct intent.</li> <li>Improve cohesion by adding synonyms or rephrasing the utterance. Cohesion can be defined as the similarity between each pair of intents. The higher the cohesion the better the intent training. </li> <li>Enlarge the distance between each pair of training phrases in the two intents. The larger the distance the better the prediction.</li> <li>Confusing phrases should be avoided i.e. phrases that are similar between intents.</li> </ul>"},{"location":"automation/natural-language/nlp-guidelines/#using-the-k-fold-model","title":"Using The K-fold Model","text":"<p>The K-fold Model is ideal for large datasets, but can be used for less data too with two-folds. Track and fine-tune the F1-score, Precision, and Recall as per your requirements. A higher value of recall score is recommended.</p>"},{"location":"automation/natural-language/nlp-guidelines/#patterns","title":"Patterns","text":"<p>While using synonyms is great for words used in the name, users may sometimes refer to a task using slang, metaphors, or other idiomatic expressions.</p> <p>For example, a task name might be Get Current Weather, but the user inputs, What\u2019s happening with today\u2019s rain situation?. In such cases, none of the words used in the task name are used, yet the input has the same meaning. To optimize the accuracy and recognition of the NLP interpreter for your VA, you can create patterns.</p> <p>When the NLP interpreter matches a synonym to one task or field, and a pattern to a different task or field, the pattern match is prioritized and used for recognition over the synonym match.</p> <p>Note</p> <p>Patterns are evaluated in the order of their listing, so ensure  that you add patterns in the order of most restrictive to least restrictive.</p> <p>The following are some general guideline for creating intent patterns:</p> <ul> <li>Use a minimum of 3 words.</li> <li>Use words in their canonical forms (i.e. infinitive verbs, singular nouns).</li> <li>Use lowercase both for words and their synonyms.</li> <li>Use the US spelling of words (i.e. normalize instead of normalize).</li> <li>Avoid using determiners and pronouns (the, a, my, that).</li> <li>Avoid using digits.</li> <li>Avoid using entity values in defining a task pattern.</li> <li>Don\u2019t use elision (i.e. what\u2019s ).</li> <li>Don\u2019t use special characters such as () &amp; /  $ [ ] + *.</li> <li>Don\u2019t use punctuation such as \u2013 , . ! ? \u2018 \u201c.</li> </ul> <p>For a quick guide towards the usage of patterns, refer to How to use Patterns.</p>"},{"location":"automation/natural-language/nlp-guidelines/#pattern-operators","title":"Pattern Operators","text":"<ul> <li>AND: ( X Y ): An ordered relationship of words in sequence. This is the default setting. i.e. when you specify a pattern as cancel booking, it _is the same as _(cancel booking ).  For example, (Cancel booking ) matches Cancel my flight booking but doesn\u2019t match I have booked a flight, can I cancel?. The XO Platform uses patterns with increasing numbers of wildcards between words (up to 3 for an intent). So a pattern of Cancel Order can match:<ul> <li>cancel booking,</li> <li>cancel my booking,</li> <li>cancel that last booking,</li> <li>cancel last week\u2019s booking.</li> </ul> </li> <li>OR: [X Y Z]: Any of these can be interchangeably used in the user utterance. For example, ([get make] me [food drink dessert]) will match any of the below utterances:<ul> <li>Get me food,</li> <li>Make me a drink,</li> <li>Get me a drink,</li> <li>Get me a dessert,</li> <li>Make me some quick food.</li> </ul> </li> <li>NOT: !X: Words that should not appear in the user utterance for an intent match. For example, (!forecast) is marked as a pattern for an intent named Get current weather and the VA supports another intent called Get 3-day weather forecast.<ul> <li>User utterance: Planning a trip to California get me the forecast<ul> <li>will not match Get current weather</li> <li>will match Get 3-day weather forecast. _Note that the word means _not after this point. So (!forecast the weather) and (get the weather !forecast) are different. The utterance get the forecast for the weather matches the second but not the first.</li> </ul> </li> </ul> </li> <li>Optional: {X}: For example, {phone} If the user utterance is Get me a phone number or get me a number the Platform will treat it equally.</li> <li>Enforce Phrase: X_Y: To enforce occurrence of the phrase as is in the user utterance, without any words in between. For example, book_tickets. The utterance book tickets or I want to book tickets _will match but not _Can I book some tickets?.</li> <li>Concepts: The XO Platform has a large set of inbuilt concepts that developers can use to define a pattern. For example, (I [like love] ~world_country) will match<ul> <li>I like India,</li> <li>I love traveling to Australia,</li> <li>I would like to visit an African country.</li> </ul> </li> <li>Unordered: &lt;&lt;, &gt;&gt;: Used to find words in any order. For example, &lt;&gt; matches Cancel my flight booking and also I have a flight booking, can I cancel?. <li>Start/End of Statement: &lt;, &gt;: For example, ( book tickets  &gt; ) will match I want to book tickets_but will not match _book tickets tomorrow.</li> <li>Quote: \u2018 \u2013: If you quote words or use words that are not in canonical form, the system will restrict itself to what you used in the pattern. For example, (like to book tickets) This matches I would like to book tickets for a trip to London _but not _I need to book tickets for a trip to London. </li>"},{"location":"automation/natural-language/nlp-guidelines/#entity-patterns","title":"Entity Patterns","text":"<p>As above, to detect entities, developers can use a combination of entity patterns and NER training. Entity patterns guide the XO Platform to where to look for a valid value for the entity. It is possible for an entity pattern to be found in several places in a sentence and the Platform will extract the value from the first instance that has a valid value. Apart from the task pattern guidelines above, follow the below guideline for entity patterns:</p> <ul> <li>Include the positional wildcard * that indicates the expected position of the entity ( i.e. (from * to), (in * &gt;)); without it the pattern is invalid.</li> <li>Use words that should be present in the pattern before and after the position of the entity. Words after the positional wildcard help to delimit the search range for a valid entity value.</li> <li>Use start and end of sentence symbols (&lt; and &gt;) to separate the positional wildcard, but these are not strictly necessary because the XO Platform tool does not cross a sentence boundary to extract an entity value (except for a Description).</li> <li>Don\u2019t use other positional wildcards in your field pattern. All field patterns are processed in the same way and all other positional wildcards except one are ignored.</li> <li>Don\u2019t use field names or their synonyms in patterns or entity patterns. Only consider up to two wildcard words between the specified words.</li> </ul> <p>Examples</p> <p>Following are some examples of entity patterns to recognize the from and to flight number for an intent to change flight.</p> <p>The pattern operators defined above can be applied to entity patterns also.</p> <ul> <li> <p>Pattern: word1 *n \u2013 up to n words after the occurrence of word1  pattern for entity ToFlight \u2013  to *1.</p> <p>ToFlight captured from user utterance change flight to ABC123 but not from change flight for ABC123.</p> </li> <li> <p>Pattern: word1 * word2 or word1 word2 *n \u2013 multiple entities from a user utterance.  patterns for entity ToFlight\u2013  to * from, and from to *1 patterns for entity FromFlight \u2013  from * to and to from *1. ToFlight &amp; FromFlight captured from user utterance change flight from XYZ321 to ABC123 and change flight to ABC123 from XYZ321 but not from change flight for ABC123 using XYZ321.</p> </li> </ul> <p>Note</p> <p>When multiple patterns are entered for an entity, a match of either one will be taken.</p> <ul> <li>Pattern: [ word1 word2 ] *n \u2013 match against any one word or phrase as defined within [\u2026] pattern for entity ToFlight\u2013  to *1 pattern for entity FromFlight \u2013  [ using from ] *1. ToFlight &amp; FromFlight are captured from user utterance change flight  from XYZ321 to ABC123 and change flight  to ABC123 using XYZ321 but not from change flight  for ABC123 using XYZ321.</li> <li>Pattern: ~concept *n \u2013 pattern built using concepts.  pattern for entity ToFlight\u2013  to *1 the pattern for entity FromFlight \u2013  ~from *1, where from is a concept as (using) (from) ToFlight &amp; FromFlight are captured from user utterance change flight from XYZ321 to ABC123 and change flight  to ABC123 using XYZ321 but not from change flight for ABC123 using XYZ321.</li> </ul> <p>For more information on how to add patterns, refer to Managing Patterns.</p>"},{"location":"automation/natural-language/nlp-guidelines/#negative-patterns","title":"Negative Patterns","text":"<p>Negative patterns are used to eliminate intents detected by the Fundamental Meaning or Machine Learning models.</p> <p>For example, a user says I was trying to Book a Flight when I faced an issue. Though the machine identifies the intent as Book a Flight, that is not what the user wants to do. In such a case, defining <code>was trying to *</code> as a negative pattern, would ensure that the matched intent is ignored.</p>"},{"location":"automation/natural-language/nlp-guidelines/#synonyms","title":"Synonyms","text":"<p>Synonyms must be used when the words used to identify an intent/entity are used interchangeably. Synonyms are defined for both intents and entities.</p> <p>Each intent has a name. For example, if your intent name is Guided Search. There are many synonyms that a user might enter to start this task, such as Search Flights, or Show me flights.</p> <p>As a developer, you must limit the name of a task to only two or three words, then consider synonyms for each of those words.</p> <p>Example</p> <ul> <li>Browse \u2013 Find, Search.</li> <li>Flight\u2013  Seat, Ticket.</li> </ul> <p>Consider alternative spelling for your synonyms, for example: check in, check-in or checkin.</p> <p>Synonyms must be ideally defined only for words defined as part of the task name. The synonyms added at the VA level are applicable for all the tasks, i.e. when a developer adds a synonym for a word in Task A, those synonyms are also used for any other tasks with the same words in the task name. For example, synonyms defined for the word browse in the Guided Search are also used for the Keyword Search. Synonyms can (and should) be used to increase the number of variations that we expect from a user requesting an intent. They supplement existing intent names with alternative wording, while not being so generic as to match everything. Remember that synonyms are unidirectional so tool=bar does not mean bar=tool.</p> <p>The general guideline for Synonyms are as follows:</p> <ul> <li>Use words in their canonical forms (i.e. infinitive verbs, singular nouns).</li> <li>Use lowercase both for words and their synonyms.</li> <li>Keep synonym phrases to less than 5 words.</li> <li>Use the US spelling of words (i .e. normalize instead of normalize).</li> <li>Use intent over meaning (i.e. get is a good synonym to show if the context of the action means find and display).</li> <li>Don\u2019t add synonyms to determiners or pronouns (the, a, my, that, etc.).</li> <li>Don\u2019t use a synonym that could match in two conflicting tasks.</li> <li>Don\u2019t use special characters such as () &amp; /  $ [ ] + *.</li> <li>Don\u2019t use punctuation such as \u2013 , . ! ? \u2018 \u201c.</li> <li>Don\u2019t assign synonyms to multiple words (For example, this is wrong: wrong, bad).</li> <li>Don\u2019t add synonyms to digits.</li> <li>Don\u2019t use the phrasal form (i.e. don\u2019t use lookup as a synonym; simply use look).</li> <li>Don\u2019t abbreviate to less than 2 letters.</li> </ul>"},{"location":"automation/natural-language/nlp-guidelines/#synonym-operations","title":"Synonym Operations","text":"<p>A match between the user input and synonym for entity (only for List of Values and Lookup types) identification can occur in one of the following ways:</p> <ul> <li>Partial Match \u2013 This is the default behavior whereby one or more words in the input must match one or more words for a given synonym. For example, the user utterance  inflight services will match inflight magazine..</li> <li>Exact Match \u2013 Here the input must contain all the words for a given synonym. For example, book inflight services will match add inflight services. But inflight services will not match inflight magazine. To trigger an exact match, the synonym must be enclosed within double-quotes.</li> <li>Full Match \u2013 The entire input must exactly match a given synonym word. For example, a flight booking should match &lt;flight booking&gt; but my flight booking should NOT match &lt;flight booking&gt;. Similarly, a flight booking should not match &lt;my flight booking&gt;. To trigger an exact match, the synonym must be enclosed within angular brackets.</li> </ul> <p>Canonical Form Match \u2013 This is the default behavior wherein the user input is matched with the synonym or its canonical form. For example, Book me a flight will match with the synonym booking request since book is the canonical form of booking. To disable this behavior, prefix the synonym with a single apostrophe as checking. (post v7.1)</p> <p>Note</p> <p>Synonyms can be added to identify intents as well as entities. Entity identification is triggered only after an Intent is identified.</p> <p>For more information on how to add synonyms, refer to Managing Synonyms.</p>"},{"location":"automation/natural-language/nlp-guidelines/#concepts","title":"Concepts","text":"<p>Concepts are clusters of related and synonymous terms that you want to be considered as a group identified by a single term.</p> <p>Allowed concept naming conventions:</p> <ul> <li>Must have ~ as a prefix</li> <li>Allowed characters in concept name are:<ul> <li>a to z and A-Z</li> <li>1 to 9</li> <li>_ (underscore)</li> </ul> </li> <li>At least one alphabet symbol must follow the ~.</li> <li>Must not start or end with a _ (underscore).</li> <li>Concepts are case insensitive. i.e ~myConcept is the same as ~myconcept</li> </ul> <p>Examples for allowed concept names:</p> <ul> <li>~my_concept</li> <li>~Sample</li> <li>~test123</li> <li>~my_new_concept</li> </ul> <p>Examples of invalid concepts names:</p> <ul> <li>~_concept</li> <li>~concept_</li> <li>~a-concept</li> <li>~123test</li> </ul> <p>You can also define custom concepts using emojis.</p> <p>For more information, refer to Custom Concepts.</p>"},{"location":"automation/natural-language/nlp-guidelines/#standard-responses","title":"Standard Responses","text":"<p>Standard Responses are template messages that the Platform uses to respond to specific situations during a conversation. Examples of these situations include resolution of ambiguous user inputs, requisition for authorization, obtaining confirmations, informing about interruptions and resumptions, and more. Standard Responses are categorized into the following:</p> <ul> <li>Statements</li> <li>Greetings</li> <li>Queries</li> <li>Errors &amp; Warning</li> <li>Questions and Choices</li> </ul> <p>While the Platform does come with canned responses, developers are encouraged to customize these messages and to add variations.</p> <p>To provide a seamless end-user experience across the conversational journey, developers may have to review each of the Standard Responses to ensure that they fit the overall persona/theme of the VA.</p> <p>Standard Responses can be plain text messages or can be generated through JavaScript to compose dynamic messages and templates for supported channels. Where applicable, Standard Responses support contextual tags that help the developer to customize the messages.</p> <p>For example, when a user requests what a VA can do, the VA responds with a message. Here_ are the tasks I can perform for you_. &lt;list-of-tasks&gt;. In this example, the developer may choose to modify this message and reuse the tag &lt;list-of-tasks&gt;where appropriate. These tags are replaced with the actual text context during the conversation with run-time values.</p>"},{"location":"automation/natural-language/nlp-guidelines/#the-knowledge-graph","title":"The Knowledge Graph","text":"<p>For executable tasks, the intent is identified based on either the task name (used in the Fundamental Meaning model) or Machine Learning utterances defined for a task. This approach is appropriate when a task can be distinctly identified from other tasks, using language semantics, and statistical probabilities derived from the machine learning model.</p> <p>In the case of FAQs, this approach may not fare well as most of the FAQs are similar to each other in terms of semantic variation, and will require additional intelligence about the domain to find a more appropriate answer.</p> <p>Kore.ai\u2019s Knowledge Graph-based model provides that additional intelligence required to represent the importance of key domain terms and their relationships in identifying the user\u2019s intent (in this case the most appropriate question).</p> <p>We will use the following two examples to explain the different configurations required to build a Knowledge Graph.</p> EXAMPLE A EXAMPLE B Consider a VA trained with the following questions: <ul> <li>A1: How to book a flight? <li>A2: What is the process to check in for a flight? </li> Consider a VA trained with the following questions: <ul> <li>B1: Can I book tickets for two people? <li>B2: How do I book an extra seat for my baby? <li>B3: How can I change my booking? <li>B4: How do I check in for my flight? </li> <p>The following are a few challenges with intent recognition using a typical model based on pure machine learning and semantic rules:</p> <ul> <li>Results obtained from machine learning-based models have a tendency to produce a false positive result if the user utterance has more matching terms with the irrelevant question.</li> <li>The model fails when the VA needs to comprehend based on domain terms and relationships. For example, the user utterance What is the process to book a flight? will incorrectly fetch A2 as a preferred match instead of A1. As A2 has more terms matching with user utterance than A1.</li> <li>This model fails to fetch the correct response if part of a question is stated in a connection with another question. Example, A: the user utterance I have booked a flight, can I check in? results in the ambiguity between A1 &amp; A2. Example B: User utterance I booked tickets for two people, how do I do the check in? will incorrectly match B1 over B4.</li> </ul> <p>In the Kore.ai Knowledge Graph model, having all the questions at the root level is equivalent to using a model based on term frequency and semantic rules. This challenge is mitigated by the multilevel KG approach which allows you to assign FAQs to nodes based on key terms and organize them into parent and child nodes.</p>"},{"location":"automation/natural-language/nlp-guidelines/#key-domain-terms-and-their-relationship","title":"Key Domain Terms and their Relationship","text":"<p>Identifying key terms and their relationships is an important aspect of building ontology. </p> <p>Let us understand this using our sample Example A. Both A1 and A2 are about an air travel procedure, one talks about booking a flight  while the other talks about checking in for a flight. So while creating an ontology, we can create a parent node with two child nodes as booking and check in. Then A1 and A2 can be assigned to the child nodes of booking and check in respectively.</p>"},{"location":"automation/natural-language/nlp-guidelines/#knowledge-graph-traits","title":"Knowledge Graph Traits","text":"<p>Note</p> <p>Traits replace Classes starting from v6.4 of the XO Platform.</p> <p>When using traits, ensure you use it judicially as overuse may result in false negatives. When using traits, please also ensure:</p> <ul> <li>Good coverage of traits.</li> <li>Traits should not get generalized improperly.</li> <li>All the FAQs get tagged to mutually exclusive traits.</li> </ul> <p>Following is the example of how classes work: Let\u2019s say we create a class called Request and add request related phrases to it. If the user says I would like to get WebEx and I would like to get trained for the Request class, this FAQ is only considered across the Knowledge Graph paths where the word request is tagged with. This is a positive scenario. But if the user says Can you help with getting WebEx?, and we did not have similar utterances trained for the Request class, it gets tagged with None class, and this FAQ is only used with the paths where the word request isn\u2019t present. This results in a failure.</p> <p>Another possibility is that if the user says I want to request help fixing WebEx and we have trained the Request class with some utterances having I want to request, and based on the training provided across all classes, the engine may generalize and tag this feature (phrase containing I want to request ) to the Request class. In this case, if the Request class is not present in the help path for WebEx, this results in failure of identifying the input against help &gt; WebEx.</p> <p>The cases where traits are useful are when we have a mutually exclusive set of FAQs. For example, in a Travel Assistant, we can have a set of FAQs for the booking process, and one for booking issues. </p> <ul> <li>FAQs for the booking process<ul> <li>How do I make a booking online?</li> <li>What is the process for booking a flight??</li> </ul> </li> <li>FAQs for booking Issues<ul> <li>I am having issues making a booking.</li> <li>How to resolve an issue with my booking?</li> </ul> </li> </ul> <p>When a user says What is the process for making a booking when your mobile app doesn\u2019t work?, the engine may find that this input is similar to both A2 and B2, and may present both of them as suggestions. </p> <p>We know that Issue is mutually exclusive to buy, and it does not make sense to present buy related FAQs at all, in this case. The opposite (matching Issue FAQs for buy related questions) may be a much bigger problem. To solve this, we will create two traits, one for type issues and another for buy. Every input is classified into either buy or issue and only the relevant questions will be used in finding an appropriate answer.</p>"},{"location":"automation/natural-language/nlp-introduction/","title":"Natural Language Processing","text":"<p>Conversational VAs enable machines to interact organically with users and deliver high-quality customer experiences. The key for a conversational VA to understand human interactions lies in its ability to identify the user\u2019s intention (Intent Detection), extract useful information (Entity Extraction), and map them to relevant actions or tasks (Dialog Task execution). </p> <p>Learn more about how Conversational VAs work and the key components that define their functioning.</p> <p>Natural Language Processing (NLP) is the science of deducing the intention and related information from natural conversations. The conversation flow in Kore.ai virtual assistants passes through various Natural Language Understanding (NLU) engines and conversation engines before the VA decides upon action and response.</p> <p>This article gives an overview of the NLP flow within a Kore.ai virtual assistant and demonstrates how a developer can leverage the XO Platform\u2019s features to build efficient VAs that elevate customer experiences..</p>"},{"location":"automation/natural-language/nlp-introduction/#koreais-nlp-approach","title":"Kore.ai\u2019s NLP Approach","text":"<p>The Kore.ai Experience Optimization (XO) Platform employs a multi-engine approach to natural language, which combines the following three models for optimal outcomes:</p> <ul> <li>Fundamental Meaning (FM): A computational linguistics approach that is built on ChatScript. The model analyzes the structure of a user\u2019s utterance to identify each word by meaning, position, conjugation, capitalization, plurality, and other factors;</li> <li>Machine Learning (ML): Kore.ai uses state-of-the-art NLP algorithms and models for machine learning to enable VAs to be trained and to gradually improve their intelligence;</li> <li>Knowledge Graph Engine (KG): The Knowledge Graph helps you turn your static FAQ text into an intelligent and personalized conversational experience.</li> </ul> <p>With its three-fold approach, the Kore.ai XO Platform enables you to accelerate the Natural Language Understanding (NLU) performance of the virtual assistant and achieve optimal accuracy with relatively less training data. Kore.ai automatically enables the trained NLP capabilities to all built-in and custom VAs, and powers the way they communicate, understand, and respond to a user request.</p>"},{"location":"automation/natural-language/nlp-introduction/#nlp-building-blocks","title":"NLP Building Blocks","text":"<p>When a virtual assistant built on the Kore.ai XO Platform receives a user utterance, it is processed to identify the user intent, extract any additional information (entities), and then answer the user via a task execution. NLP is mostly concerned with the first two \u2013 intent detection and entity extraction.</p> <p></p>"},{"location":"automation/natural-language/nlp-introduction/#steps-in-a-conversation-flow","title":"Steps in a Conversation Flow","text":"<p>The Conversation Flow involves the following steps:</p> <ol> <li>NLP Analysis: The user utterance goes through a series of NLP engines for entity extraction and intent detection. (You can extend the out-of-the-box NLP functionality to use your own engine. You can install the Bot Kit SDK and easily integrate the virtual assistant with any 3rd party NLP engine. The output from the 3rd party NLP engine complements the outputs from Kore.ai thus adding to the efficiency and accuracy of the engine.) The engines provided by the Kore.ai XO Platform are as follows:<ul> <li>Fundamental Meaning Engine which breaks up the utterances based on the grammar constructs;</li> <li>Machine Learning Engine which classifies individual words in the utterance, using an example-based, auto-learning training process;</li> <li>Knowledge Collection Engine which mostly deals with FAQ type user queries. It can also be configured to trigger tasks in response to the user query;</li> <li>Traits Engine which is a multiclass classifier and can identify multiple categories in user utterances thus aiding in refining user intent detection;</li> <li>Small Talk Engine which adds human flavor to the conversations;</li> <li>Ranking and Resolver to score the results from the above engines and rank them according to the set business rules, with the purpose of deciding on the winning intent.</li> </ul> </li> <li>Task Execution: The winning intent along with the entities extracted then passes through the conversation engine for the actual task execution. This engine maintains the state or context of the conversation with information like user details, the previous intents requested by the user, and any other information as tagged by the business rules. This helps provide a near-human conversation experience. The conversation engine uses this state information along with the following conditions to accept or reject the intent identified by the NLU engines<ul> <li>Pre-conditions \u2013 if an intent has a set of predefined conditions configured and if any of these conditions are not satisfied the winning intent is then rejected. For example, a booking payment intent should have the payee details available.</li> <li>Negative patterns capture the presence of a pattern that should not identify a particular intent. For example \u201cI lost my bag, how do I retrieve it\u201d should, not assume that the user wants to be provided with information about baggage, and instead attempt to track their bag, based on the presence of the phrase \u201clost my bag\u201d</li> <li>Event handling \u2013 events defined for a welcome message, sentiment analysis, etc</li> </ul> </li> <li>Interruptions handling: Other conditions such as Interruption settings (to handle situations where another intent is identified during the course of an ongoing task) or Sentiment Analysis settings (user sounds angry and hence should be transferred to an agent) are crucial for the action to be taken.</li> <li> <p>Response Generation: A response is generated and presented to the user based on the channel of interaction. The response could be a success message, information as requested by the user, prompt for missing information or message concerning their transfer to a human agent.</p> <p></p> </li> </ol> <p>Important References</p> <p><ul><li>To understand NLP Settings and Guidelines, click here.</li> <li>To learn about NLP Training for your VA, click here.</li></ul></p>"},{"location":"automation/natural-language/nlu-configurations/amend-entities/","title":"Amend Entities","text":"<p>Time and again, we come across situations wherein the users change their preferences during task execution.</p> <p>For example, while booking a flight, the user might change the date of travel and at times even the destination.</p> <p>Amend Entity is a feature for such scenarios. Using this feature, you can allow the users to amend entity values and also control the post-amendment dialog behavior.</p> <p>The entity amendment process is divided into three stages:</p> <ol> <li>Amend Identification: Identifying that the end-user wants to amend is driven by the VA\u2019s built-in NLP capabilities.</li> <li>Amending Entities: On identifying the intention to amend, the current task is put on hold and the amend flow is triggered. Three kinds of amend flows are possible based upon the user utterance:<ul> <li>When the user refers to the entity name (or entity synonyms), then they are prompted for the entity value. For example, the user utterance I want to change the destination triggers the prompt for the destination entity. If the same entity node is present multiple times in the dialog, then the latest entity node for which the user has already provided input will be amended.</li> <li>When the user gives the entity value then the entity is updated accordingly. For example, the user utterance I want to fly to JFK changes the destination entity value. If the value is compatible with two or more entities in the dialog, then the user is prompted to select an entity to amend.</li> <li>When the user refers to both the entity and its value, then the entity is updated. For example, the user utterance change my destination to JFK will change the destination entity value.</li> </ul> </li> <li>Post Amendment Behavior: After an entity is successfully amended, there are three possible dialog execution flows that your VA can be configured for:<ul> <li>The dialog can be re-executed from the node that is amended by evaluating that entity\u2019s connections.</li> <li>The dialog can resume from the node where amend was identified or made.</li> <li>The dialog can be resumed from a specified node present in the dialog.</li> </ul> </li> </ol> <p>Note</p> <p>This feature is not supported in all languages, Click here for details.</p>"},{"location":"automation/natural-language/nlu-configurations/amend-entities/#implementation-hierarchy","title":"Implementation Hierarchy","text":"<p>On the Kore.ai XO Platform, Amend Entity behavior is defined at two levels:</p> <ul> <li>VA level</li> <li>Task level</li> </ul>"},{"location":"automation/natural-language/nlu-configurations/amend-entities/#bot-level","title":"Bot Level","text":"<p>To Set VA Level Amend Entity Behavior, follow the below steps:</p> <ol> <li>Select the Build tab from the top menu</li> <li>From the left menu, click Intelligence &gt; Amend Entity.</li> <li>By default, this option s disabled.</li> <li>Once you Allow amend entities, various Dialog Resumption options are available:<ul> <li>Re-execute dialog from amended entity \u2013 use this option to resume the dialog by evaluating the amended entity\u2019s connections. You can further choose to:<ul> <li>Clear entity values captured downstream \u2013 to clear all entities captured between the identified entity and the amend</li> <li>Skip display of previously displayed messages \u2013 messages from Message nodes alone.</li> </ul> </li> <li>Resume dialog from amend identification node \u2013 use this option to resume the dialog from the node where the amend was identified.</li> </ul> </li> <li>The amend process can be extended to entities marked as Hidden using the Amend Hidden Entities option. </li> </ol>"},{"location":"automation/natural-language/nlu-configurations/amend-entities/#task-level","title":"Task Level","text":"<p>Amend entity behavior is set at the Task level also. The configurations defined at the task level will override the VA-level configurations.</p> <p>To set Task Level Amend Entity Behavior, follow the below steps:</p> <ol> <li>Go to Build &gt; Conversation Skills &gt; Dialog Tasks and select the task that you want to configure.</li> <li> <p>On the Dialog Task page, click the More Options icon and select the Manage Amend Behavior.</p> <p></p> </li> <li> <p>On the Manage Amend Behavior dialog box, by default, the Use bot level settings option is selected and the bot level setting is displayed.</p> </li> <li>Select Customize for this task to override the bot level settings:<ul> <li>Do not allow amend entities \u2013 It will not allow the user to amend entity values for this task.</li> <li>Allow amend entities \u2013 It will further give you three Dialog Resumption options:<ul> <li>Re-execute dialog from amended entity \u2013 Amend entity behavior is set at the task level also. The configurations defined at the task level will override the bot-level configurations.<ul> <li>Clear entity values captured downstream \u2013 to clear all entities captured between the identified entity and the amend</li> <li>Skip display of previously displayed messages \u2013 messages from Message nodes alone.</li> </ul> </li> <li>Resume dialog from amend identification node \u2013 use this option to resume the dialog from the node where the amend was identified.</li> <li>Jump to a specific node in the dialog \u2013 use this option to select a node from the current dialog where the task flow needs to jump. You can use this option to add custom behavior before resuming with the dialog. The Context object will contain the details of the entities amended, along with the previous and current values. You may use this information to customize the dialog.</li> <li>The amend process can be extended to hidden entities using the Amend Hidden Entities option. </li> </ul> </li> </ul> </li> </ol>"},{"location":"automation/natural-language/nlu-configurations/amend-entities/#triggers","title":"Triggers","text":"<p>The following are patterns supporting the Amend Entity behavior. User utterance around these patterns triggers Amend Entity.</p> <ul> <li><code>~amend_synonyms &lt;entity_name&gt; from &lt;old_value&gt; to &lt;new_value&gt;</code>For example, \u201cchange the departure date from today to tomorrow\u201c.</li> <li><code>~amend_synonyms &lt;entity_name&gt; [to as from with] &lt;new_value&gt; [instead_of rather_than not] &lt;old_value&gt;</code>For example, \u201cmodify departure date to tomorrow instead of today\u201c.</li> <li><code>~amend_synonyms &lt;entity_name&gt; &lt;old_value&gt; [to as with] &lt;new_value&gt;</code>For example, \u201creplace departure date with tomorrow\u201c.</li> <li><code>~amend_synonyms &lt;entity_name&gt; from &lt;old_value&gt;</code>For example \u201calter departure date from today\u201c.</li> <li><code>~amend_synonyms &lt;entity_name&gt; [to as from with] &lt;new_value&gt;</code>For example, \u201cmodify departure date to tomorrow\u201c.</li> <li><code>~amend_synonyms {from} &lt;old_value&gt; [to as with] &lt;new_value&gt;</code>For example, \u201cchange from today to tomorrow\u201c.</li> <li><code>~amend_synonyms [to as from] &lt;new_value&gt; [instead_of rather_than not] &lt;old_value&gt;</code>For example, \u201cchange to tomorrow instead of today\u201c.</li> <li><code>~amend_synonyms [to as from] &lt;new_value&gt; instead</code>For example, \u201cchange to tomorrow instead\u201c.</li> <li><code>~amend_synonyms [([it that this] {to}) it that this to] &amp;&lt;new_value&gt;</code>For example, \u201cchange it from today to tomorrow\u201c.</li> <li><code>~amend_synonyms &lt;entity_name&gt;</code>For example, \u201camend departure date\u201c.</li> <li><code>~amend_synonyms &lt;old_value&gt;</code>For example, \u201cchange today\u201c</li> <li><code>[to as from] &lt;new_value&gt; [instead_of rather_than not] &lt;old_value&gt;</code>For example, \u201cto tomorrow instead of today\u201c</li> <li><code>[to as from] &lt;new_value&gt; instead</code>For example, \u201cto tomorrow instead\u201c</li> </ul> <p>In the above-mentioned patterns the concept <code>~amend_synonyms</code> includes <code>\"amend\", \"change\",\"modify\",\"alter\",\"update\", \"replace\", \"make\", \"move\", \"upgrade\", \"want\"</code>.</p> <p>Note</p> <p>The user can use these patterns to change multiple entity values. For example, Change the departure date from today to tomorrow and departure city to Chicago results in the changes to both departure date and city.</p> <p>Additional Notes</p> <p>The Platform's in-built training data drives the identification of the amend requests, and it is currently supported only for the dialog task conversations in English. The scope of this feature currently includes only the replacement of previously populated entities. It does not include other scenarios like partial modifications, deletions, additions to entity values.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/","title":"NLP Engine Tuning and Advanced Configurations","text":"<p>You can fine-tune intent detection for each language enabled for your Virtual Assistant (VA). To perform this action, follow the below steps:</p> <ol> <li>On the left pane, click Natural Language &gt; Training &gt; Thresholds &amp; Configurations.</li> <li>Under the Thresholds &amp; Configurations section, you can perform by customizing<ul> <li>The Fundamental Meaning model \u2013 Learn more.</li> <li>Machine Learning model \u2013 Learn more.</li> <li>Knowledge Graph \u2013 Learn more.</li> <li>Ranking &amp; Resolver engine \u2013 Learn more.</li> </ul> </li> </ol> <p>Apart from these, under the Advanced NLP Configurations section, there are advanced settings that you can use for specific use cases and requirements.</p> <p>Warning</p> <p>The default settings for these configurations are ideal for most use cases. Do not change these settings unless you are fully acquainted with the functionality you are setting, as they might have a detrimental effect on the VA's performance if not done properly.</p> <p></p> <p>The following table gives the details of the various configurations that can be set from this section. Apart from these you can add Custom configurations, reach out to our support team to know how.</p> CONFIGURATION     DESCRIPTION     AFFECTED NLP ENGINE     VALID INPUTS     NOTES     Split Compound <p> Words The setting <p> enables the <p> splitting of the <p> compound words <p> into multiple <p> stems and then <p> processing the <p> individual stem.     ML     Enable,\u00b6 <p> Disable <p> (default)     Supported only for assistants in the <p> German language     None Intent Once enabled, a dummy, placeholder intent is created which reduces the chances of getting a false positive for an intent match using the ML engine.     ML     Enable (default), <p> Disable     Epochs Number iterations for training the neural network.     ML     Between 20 and 300, <p> increments of 10 <p> (default setting 20)     Valid only when Network Type is set to MLP-BOW, <p> MLP-WordEmbeddings, <p> LSTM, <p> CNN     Batch Size Number of training samples used for each batch while training     ML     Between 10 and 30, <p> increments of 5 <p> (default setting 10)     Valid only when Network Type is set to MLP-BOW, <p> MLP-WordEmbeddings, <p> LSTM, <p> CNN     Learning rate A hyper-parameter to control how much the weights of the network are adjusted with respect to the loss gradient     ML     Between 1e-4 and 1e-3, <p> increments of 1e-2 <p> (default setting 1.00E-03)     Valid only when Network Type is set to MLP-BOW, <p> MLP-WordEmbeddings, <p> LSTM, <p> CNN     Dropout Regularization parameter to avoid overfitting of the model     ML     Between 0 and 0.8, <p> increments of 0.1 <p> (default setting 0)     Valid only when Network Type is set to MLP-BOW, <p> MLP-WordEmbeddings, <p> LSTM, <p> CNN     Vectorizer Feature extraction technique on training data     ML     count (default), <p> tfidf     Valid only when Network Type is set to MLP-BOW     Maximum sequence length Length of the training sample or user input     ML     Between 10 and 30, <p> increments of 5 <p> (default setting 20)     Valid only when Network Type is set to MLP-WordEmbeddings, <p> LSTM, <p> CNN     Embeddings Type Feature extraction technique on training data     ML     generated, <p> random (default)     Valid only when Network Type is set to MLP-WordEmbeddings, <p> LSTM, <p> CNN     Embeddings Dimensions Embeddings Dimensions to be used in featurization     ML     Between 100 and 400, <p> increments of 50 <p> (default setting 300)     Valid only when Network Type is set to MLP-WordEmbeddings, <p> LSTM, <p> CNN     K Fold kfold parameter for Cross-validation     ML     Between 2 and 10, <p> increments of 1 <p> (default setting 2)     Fuzzy Match This setting enables the use of the fuzzy matching algorithm for intent identification     ML     Enable (default), <p> Disable     Handle Negation This setting enables the handling of negated words in intent identification     ML     Enable (default), <p> Disable     Ignore Multiple Occurences Once enabled, the frequency of the words are disregarded for vectorization     ML     Enable (default), <p> Disable     Valid only when Network Type is set to MLP-BOW     Entity Placeholders in User Utterances Enable to replace entities present in user utterances with corresponding placeholders     ML     Enable (default), <p> Disable     Valid only when Network Type is set to MLP-BOW     Sentence Split Split the sentences in user utterance and perform intent detection using the complete user input     ML     Enable (default), <p> Disable     Multiple Intent Models Enable separate ML models for each of the primary intents constituting all its sub-intents     ML     Enable, <p> Disable (default)     Lemmatize KG <p> Synonyms Enable to use <p> the lemmatized <p> versions of KG <p> Synonyms to <p> detect intents.     KG     Enable <p> (default), <p> Disable.     Use only Tagged Utterances for NER Training Uses only the Tagged Utterances for Named Entity Recognition (NER) Training. When enabled, the ML Engine uses the utterances with one or more NER tags, to train the NER model for entity detection.     ML     Enable (default), Disable     Neurons in Hidden Layer Used to configure the number of Neurons used in the Hidden Layer     ML     Range \u2013 0 to 1000     Applicable only for Standard Network Type     Softmax Temperature Use to define how confidently the ML Engine should identify the winning intent from the ML Model. Temperature is a hyperparameter that is applied to logits(Model outputs) to affect the final probabilities from the softmax.     ML     Range 0 to 100     Any Network Type, except Standard Network     Spell Correction for ML Enable to support spell correction on the ML bot dictionary while predicting.     Custom (ML)     Enable, <p> Disable (default)     Applicable only for English language VAs.     Intent Elimination Rules Enable to apply prebuilt rules to eliminate intent matches.     RR     Enable (default), <p> Disable     Applicable only for English, Spanish, French, and German language VAs.     Cosine similarity dampening Avoid penalty on short length questions using Cosine Similarity Dampening     KG     Enable (default), <p> Disable     FAQ Name as Intent Name To use the Primary Question of the FAQ as the intent name even when the FAQ is linked to a Dialog     KG     Enable, <p> Disable (default)     FAQs Order for Disambiguation Configure the order in which the FAQs are to be presented for resolving the ambiguity     KG     Order by Hierarchy, <p> Default Order (default)     Auto qualify FAQs from fully matched Paths Automatically qualify all FAQs from the path if the path is fully matched even if no question from that path has matched the user query.     KG     Enable, <p> Disable (default)     Taxonomy based KG Enable this option if only a full match of all the terms in the path should be considered as a path qualification.     Custom <p> (KG)     Enable, <p> Disable (default)     Default Max. Wildcards for Intent Patterns Use this option to define the maximum number of wildcards to be allowed by default between words for intent patterns. This does not limit you from explicitly writing patterns containing more wildcards.     FM     any number from 0-9; <p> set to 3 by default     Default Max. Wildcards for Entity Patterns Use this option to define the maximum number of wildcards to be allowed by default between words for entity patterns. This does not limit you from explicitly writing patterns containing more wildcards.     FM     any number from 0-5; <p> set to 2 by default     Matching Order of Intent Patterns Choose whether to pick the first pattern match of the intent (as per the order in which patterns are defined) or to go through all the patterns defined for the intent and find the best one.     FM     First (default), <p> Best     Grading of Pattern Matches Choose whether the Pattern Matches should be classified as Probable matches, based on the number of wildcards present in the user input when compared to the pattern definition.     FM      any number from 0-9; <p> set to 3 by default     Precedence for Intents with Ambiguous Entities Enable to Use Precedence, Intent Over Entity, or Entity Over Intent options for intents with ambiguous entities. FM Enable <p>Disable (default)</p> Prefer Only the First Pattern Match in a Sentence Choose whether to prefer only the first pattern match from a sentence or to pick all the pattern matches in a sentence, when multiple patterns are matched in a single sentence     FM     Enable (default), <p> Disable     Exact Task Name Match Choose whether the system should auto-generate the strict pattern when \u2018Intent Detection using Task Name Words\u2019 is Disabled.     FM     Enable (default), <p> Disable"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#machine-learning-engine-settings","title":"Machine Learning Engine Settings","text":""},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#split-compound-words","title":"Split Compound Words","text":"<p>Compound words are formed when two or more words are joined together to create a new word that has an entirely new meaning. This is particularly the case with the German language, where two (or more) words are combined to form a compound, leading to an infinite amount of new compounds. For example, the components are connected with a transitional element, as the -er in Bilder | buch (picture book); or parts of the modifier can be deleted. For example, Kirch | turm (church tower), where the final -e of the lemma Kirche is deleted. Often the compound words mean something entirely different from the stem words. For example, Grunder (founder) with stem words grun | der (green|the). </p> <p>From an NLP perspective, it's crucial to determine when NLP engines should break down compound words and process their constituent parts separately, as well as when the entire compound word should be analyzed.</p> <p>This configuration is employed to specify how compound words should be handled. When activated, compound words in user utterances are divided into their stem words before being considered for intent detection.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#none-intent","title":"None Intent","text":"<p>The Machine Learning (ML) engine is responsible for analyzing and assessing user inputs to construct and refine a model. The ML model's primary goal is to categorize user inputs into predefined intents for which it has been trained. Nonetheless, when confronted with out-of-context utterances, the ML system may erroneously attempt to associate them with the incorrect intent.</p> <p>To address this issue, you can prevent misclassifications by activating the None Intent option in the Training &gt; Thresholds &amp; Configurations section for various languages. The None intent serves as a temporary category that safeguards against the ML model assigning untrained or ambiguous utterances to inappropriate intents. This safeguard is enabled by default for newly created virtual assistants.</p> <p>For example, for an Airlines VA, an Intent \u201cBook Flight Ticket\u201d is mapped. If a customer requests to \u201cBook a Movie Ticket\u201d the ML tries to associate the closest intent \u201cBook Flight Ticket\u201d (wrong intent) as the successful intent and triggers it. This error can be eliminated by enabling the None intent.</p> <p>Adding an extra None Intent ensures classifying random input to these intents in the VA. Once enabled, the ML Model is tuned to identify these none intents when a user utterance contains the words that are not used in the VA\u2019s training. i.e., bot vocabulary. You can define the None Intent for the Linked Bots in a Universal Bot. For more information, see Creating a Universal Bot article.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#externalization-of-the-ml-engine","title":"Externalization of the ML Engine","text":"<p>In machine learning, a hyperparameter governs the learning process by controlling specific aspects of it.</p> <p>Hyperparameters offer the means to further tailor the behavior of your Virtual Assistants (VAs). The following list outlines the machine learning configurations that are available for this customization.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#network-type","title":"Network Type","text":"<p>You can choose the Neural Network that you want to use. This setting is moved to the Machine Learning section post v8.1. Learn more.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#epochs","title":"Epochs","text":"<p>In terms of artificial neural networks, an Epoch signifies a complete cycle through the entire training dataset. </p> <p>Achieving optimal performance on data that was not part of the training set typically requires multiple traversals of the training data. The quantity of epochs serves as a hyperparameter, determining the count of full passes made through the training dataset.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#batch-size","title":"Batch Size","text":"<p>Batch size denotes the quantity of training examples employed in a single iteration. It plays a pivotal role in determining the precision of the error gradient estimate during the training of neural networks. The batch size is, in essence, a hyperparameter that governs the quantity of training samples to be processed before updating the internal parameters of the model.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#learning-rate","title":"Learning Rate","text":"<p>The Learning Rate is a configurational element within an optimization algorithm, and it assumes the role of setting the size of each step taken during each iteration as the algorithm converges towards the minimum of a loss function. Essentially, it acts as a parameter that regulates the adjustment of weights within a neural network in response to the loss.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#dropout","title":"Dropout","text":"<p>Dropout refers to the process of excluding units, encompassing both hidden and visible components within a neural network. In simpler terms, dropout entails neglecting a randomly chosen set of neurons during the training phase. This technique serves as a form of regularization aimed at safeguarding against the overfitting of data</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#vectorizer","title":"Vectorizer","text":"<p>Vectorization is a way to optimize algorithms by using vector operations for computations instead of element-by-element operations. It is used to determine the feature extraction technique on training data. It can be set to one of the following:</p> <ul> <li>Count Vectorizer is used to convert the given text documents to a vector of term/token counts based on the frequency (count) of each word occurrence in the text. This is helpful when there are multiple texts, and each word in the text needs to be converted into vectors for use in further text analysis. It enables the \u200bpre-processing of text data prior to generating the vector representation.</li> <li>TFIDF Vectorizer is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document (Term Frequency TF), and the Inverse Document Frequency (IDF) of the word across a set of documents.</li> </ul>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#maximum-sequence-length","title":"Maximum Sequence Length","text":"<p>When handling a sentence, for training or prediction purposes, the sequence length is defined as the count of words present within that sentence. </p> <p>The Maximum Sequence Length parameter sets a limit on the maximum number of words considered during training. If the user's input or training phrase sentence exceeds this maximum sentence length, it is truncated to match this predefined length. Conversely, if it falls short of the maximum length, the sentence is padded with special tokens to reach the required limit.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#embeddings-type","title":"Embeddings Type","text":"<p>A (word) embedding is a vector representation of a word or phrase in an input/training text. Words with similar meaning will have similar vector representations in n-dimensional space and the vector values are learned in a way that resembles a neural network.</p> <p>Embeddings Type can be set to one of the following:</p> <ul> <li>Random (default setting): At first, all the words are assigned random embeddings, then the embeddings are optimized for the given training data while training.</li> <li>Generated: Word Embeddings are generated just before the training starts. Word2Vec model is used for generating word embeddings. These generated embeddings are used while training. These generated word embeddings are optimized for the given training data while training.</li> </ul>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#embeddings-dimensions","title":"Embeddings Dimensions","text":"<p>The embedding dimension defines the size of the embedding vector. If the word embeddings are random or generated, any number can be used as an embedding dimension.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#k-fold-cross-validation","title":"K Fold Cross-Validation","text":"<p>Cross-validation is a resampling technique employed to assess the performance of machine learning models when working with a restricted data sample. This process involves a key parameter known as \"k,\" which signifies the number of partitions into which the data sample is divided. This configuration provides you with the capability to adjust and set the value of the parameter \"k.\" Learn more for more on cross-validation.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#fuzzy-match","title":"Fuzzy Match","text":"<p>Fuzzy matching is a method for approximate string matching that aids the system in recognizing matches that aren't exact. The ML Engine leverages fuzzy matching logic to identify precise matches. </p> <p>This technique assigns a Fuzzy Search Score to intents based on their similarity to the user's input. Any intent scoring 95 or higher on the Fuzzy Search scale (ranging from 0 to 100) is identified as a definitive match.</p> <p>Nonetheless, fuzzy matching may generate false positives when dealing with words that have similar spellings but distinct meanings. For instance, words like \"possible\" and \"impossible,\" or \"available\" and \"unavailable.\" This behavior can be problematic in certain scenarios. You have the option to deactivate this feature, preventing the ML engine from employing this matching algorithm.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#negation-handling","title":"Negation Handling","text":"<p>This setting is configured to choose the ML engine\u2019s behavior when negated words are present in the user utterance. When the Negation Handling configuration is enabled, the intent\u2019s ML score would be penalized if there are any negated predilection words present in the user utterance.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#ignore-multiple-occurrences","title":"Ignore Multiple Occurrences","text":"<p>Sometimes the intent identification gets skewed if multiple occurrences of the same word are present in the user utterance. When the Ignore Multiple Occurrences configuration is enabled, then multiple occurrences of the same word present in the user utterance are discarded. The repeated word is considered only once for the vectorization and the subsequent intent matching.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#entity-placeholders-in-user-utterances","title":"Entity Placeholders in User Utterances","text":"<p>Sometimes you want the system to replace the entity values present in the user utterance with entity placeholders so that the intent detection can be improved. Note that the entities that are not resolved by the NER model would not be used for replacement, so if you enable this option we strongly urge that you annotate all the training utterances. These entities are replaced in user utterance in End-user interactions, Batch testing, Utterance testing, Conversation testing.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#sentence-split","title":"Sentence Split","text":"<p>If the user input has multiple sentences, multiple intent calls are made, one for each sentence. This might not be an ideal situation in some cases. For example user utterance, I want to book tickets. Redirect me to Book My Show. will result in a 0.6 ML score for I want to book tickets and Redirect me to Book My Show and the total ML score of 0.6.</p> <p>Disabling this configuration sends the original user input to ML for intent identification and results in a definite score like 0.99 for the above example.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#multiple-intent-model","title":"Multiple Intent Model","text":"<p>Enabling this feature creates multiple ML intent models for your VA. All the Primary Dialog Intents will be part of the Bot Level Intent Model. Separate Dialog Level ML Models are created for each of the other Dialog Tasks and Sub Dialog Tasks, consisting of all the sub-intents used in the respective task definition. Learn more.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#lemmatization-of-kg-synonyms","title":"Lemmatization of KG Synonyms","text":"<p>Lemmatization, in the field of linguistics, involves the task of consolidating the various inflected forms of a word into a single unit, which is then represented by the word's lemma or dictionary form. The incorporation of Parts of Speech information from the user's utterance during the lemmatization process can enhance the accuracy of identifying a more precise FAQ.</p> <p>For example,</p> <p>Word: \"Running\"</p> <p>Inflected Forms: \"Runs,\" \"Ran,\" \"Running\"</p> <p>Lemma (Dictionary Form): \"Run\"</p> <p>In lemmatization, all the inflected forms of the word \"running\" are reduced to the common lemma \"run,\" which represents the base or dictionary form of the word. This process simplifies the analysis and understanding of the word's core meaning and aids in efficient text analysis.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#use-only-tagged-utterances-for-ner-training","title":"Use only Tagged Utterances for NER Training","text":"<p>Enabling this flag allows only Tagged Utterances for NER Training and avoids training of utterances without NER tags. This is an accurate and time-saving approach. By default, this flag is enabled for all new VAs. If the flag is not set for a VA, then it is in the disabled state under the Advanced NLP Configurations.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#neurons-in-hidden-layer","title":"Neurons in Hidden Layer","text":"<p>Neurons in Hidden Layer determine the intensity/rigor to be adopted while performing intent identification by the ML Model. A higher number of neurons increases the accuracy but would require a longer duration for completing the training. A lower number of neurons decreases the accuracy but would speed up the training time. By default, it is fixed as 1000. Ideally, it should be 1x times the number of intents in a VA and can go up to 2x for better accuracy. This is a general recommendation and would vary depending on the quality of the training</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#softmax-temperature","title":"Softmax Temperature","text":"<p>Softmax temperature allows you to define how confidently the ML Engine should identify the winning intent from the ML Model. Temperature is a hyperparameter that is applied to logits (Model outputs) to affect the final probabilities from the softmax. Any value between 0 to 1 indicates that the ML Engine should identify the winning intent with lower confidence. 0 being very low confidence and 1 being regular confidence. Any value between 1 to 100 indicates that the ML Engine should associate a high amount of confidence for the winning intent. 1 being regular confidence and 100 being the higher confidence possible.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#spell-correction-in-ml","title":"Spell Correction in ML","text":"<p>For VAs in the English language, spell correction does not happen on the ML bot dictionary. This might cause an issue for VAs that are heavily dependent on ML training. The issue can be rectified by enabling spell correction on the ML bot dictionary while predicting. This is achieved by adding custom config in NLP Advanced Settings.</p> <p>This is a Custom configuration, to enable follow the steps below:</p> <ol> <li>Select Add Custom.</li> <li>Enter name as ML spell correction</li> <li>Enter the value as enabled or disabled.</li> </ol>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#ranking-and-resolver-engine-settings","title":"Ranking and Resolver Engine Settings","text":""},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#intent-elimination-rules","title":"Intent Elimination Rules","text":"<p>There are a few safeguard rules in the R&amp;R engine that reject a possible ML match. For example, rejection of intent when the user input contains only a verb word. But chances are that you do not want the R&amp;R engine to apply any elimination rules and present all the qualified/winning intents to the end-users for resolving any ambiguity. Disabling this setting gives you that flexibility and NOT eliminate the intents that match the rules like single verb match (ML &amp; FM), an entity only match with CR sentence (ML), earlier pattern match (multi-sentence scenario) (FM), or earlier definitive match (multi-sentence scenario) (All).</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#knowledge-graph-engine-settings","title":"Knowledge Graph Engine Settings","text":""},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#cosine-similarity-dampening","title":"Cosine Similarity Dampening","text":"<p>FAQ identification is done based on word match. The problem with this approach is that a user utterance with fewer words than the corresponding trained utterance is scored poorly. This scoring causes failure in Intent Identification.</p> <p>When the Cosine Similarity Dampening configuration is enabled, the user utterances that have fewer words than the trained utterances (i.e. Primary and Alternate Questions) results in a higher match score than when the configuration is disabled.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#faq-name-as-intent-name","title":"FAQ Name as Intent Name","text":"<p>This option controls whether you see the Primary Question or Dialog Task name in the following scenarios:</p> <ul> <li>Where intent names are present to the user<ul> <li>Disambiguation flow</li> <li>Follow-ups</li> </ul> </li> <li>Utterance testing</li> <li> <p>Batch testing  In this testing, when you enable the FAQ Name as Intent Name setting and then export the batch test suite results, the MatchedIntent field shows the FAQ name. If it is disabled, the Intent name is displayed instead of FAQ name. </p> </li> <li> <p>NLP Analysis</p> </li> <li>Analytics (Dashboards, Custom Dashboards, Conversation Flows, and Metrics)</li> <li>Intent detection \u2013 ranking flows</li> </ul>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#faqs-order","title":"FAQs Order","text":"<p>When a user asks a query in case of ambiguity, the FAQs are presented to the user to disambiguate in random order. But you might want to provide a better experience for the end-user by presenting the questions in the order based on where they appear in the KG i.e. start with generic ones and then followed by more specific ones. You can use this option \u201cFAQs Order for Disambiguation\u201d for just that purpose. By setting this option to Order by Hierarchy, the FAQs at the parent level will be presented first, followed by the FAQs added to the immediate next level and so on and this order will be honored by the R&amp;R Engine as well.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#auto-qualify-faqs","title":"Auto-Qualify FAQs","text":"<p>When a user query matches a specific path in KG but does not match with any of the questions added to that path, you can choose to present the questions in the matched path to the user as ambiguous. If the matched path contains only one FAQ, then it would be considered as the \u2018winning\u2019 FAQ. Note that the root term match will not be considered.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#taxonomy-based-kg","title":"Taxonomy based KG","text":"<p>The Knowledge Graph model works on a two-step model i.e. path qualification and followed by question matching. By default, the path need not be fully qualified at all times. Even a partial path match (above a threshold) is considered as a qualification and the questions in these paths are used for matching the user input.</p> <p>In the \u2018taxonomy\u2019 based approach, the \u2018path\u2019 should fully match at all times. This is to cater to situations where every term in the path is equally important and only a full match of all the terms in the path should be considered as a qualification. Once a path is qualified, the questions in that path or paths should be considered for intent identification against user input.</p> <p>This is a Custom configuration, to enable follow these steps:</p> <ol> <li>Click Add Custom.</li> <li>Enter name as KG taxonomy based.</li> <li> <p>Enter the value as Enable.</p> <p> <p>Note</p> <p>Enabling this setting would add the following configurations for Term settings \u2013 Term Display Name, Auto Qualify Path, and the following configurations would not be available \u2013 Path Coverage and Minimum and Definitive Level for Knowledge Tasks. Learn more.</p> </p> </li> </ol>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#fundamental-meaning-engine-settings","title":"Fundamental Meaning Engine Settings","text":""},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#default-maximum-wildcards-for-intent-patterns","title":"Default Maximum Wildcards for Intent Patterns","text":"<p>Define the maximum number of wildcards to be allowed in intent patterns by default. FM Engine will match intent patterns only if the user input has a maximum of X wildcards between the words used in the pattern definition.  Any utterance with more X wildcards will not be qualified as an intent pattern match. For example, if the value is set as 4, then the \u2018Book Ticket to \u2019 pattern will match with \u2018_Book a direct oneway flight ticket to Chicago\u2019.  This will have no impact when you explicitly write an entity pattern containing a higher number of wildcards (for example, _~Y)</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#maximum-allowed-wildcards-in-entity-patterns","title":"Maximum Allowed Wildcards in Entity Patterns","text":"<p>Define the maximum number of wildcards to be allowed in entity patterns by default. FM Engine will match entity patterns only if the user input has a maximum of X wildcards between the words used in the pattern definition.  Any utterance with more X wildcards will not be qualified as an entity pattern match. For example, if the value is set as 4, then the \u2018Book Ticket to \u2019 pattern will match with \u2018_Book a direct oneway flight ticket to Chicago\u2019.  This will have no impact when you explicitly write an entity pattern containing a higher number of wildcards (for example, _~Y)</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#intent-pattern-matching-order","title":"Intent Pattern Matching Order","text":"<p>Define whether to choose the first pattern match or to evaluate all the patterns and choose the best. \u201cFirst\u201d means to consider the first intent pattern match found for an intent, \u201cBest\u201d means to process all of the intent\u2019s patterns and use the best scoring one. Note that FM scope is used for determining the best match, the R&amp;R score is used for identifying the \u2018best pattern\u2019.  It may be difficult to determine the best order for intent patterns, so allowing the platform to find the best is often helpful.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#grading-of-pattern-matches","title":"Grading of Pattern Matches","text":"<p>By default, all pattern matches are Definitive Matches. However, it might be helpful to mark pattern matches as Probable matches if they contain too many wildcards. Choose the threshold number of wildcards to be present in user input to consider a pattern match as a probable match. If the user input contains more wildcards (&gt; = X) than the threshold, then those pattern matches will be classified as Probable matches. Pattern matches within the threshold limit (&lt; X ) will continue to be treated as Definite Matches.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#precedence-for-intents-with-ambiguous-entities","title":"Precedence for Intents with Ambiguous Entities","text":"<p>The Precedence for Intents with Ambiguous Entities configuration setting allows bot designers to control an entity prompt at a general level whether the response processing at an entity should favor entities or intents when, and only when, the entity value is ambiguous.</p> <p>Bot designers can customize the flow on how the bot should respond when a user input results in an ambiguous entity with an intent by choosing the following options:</p> <ul> <li>Use Precedence \u2013 Uses the Instance Properties setting specific to each entity, rather than global EoI/IoE settings. Applies to all Entity types except String and Description nodes. Learn more.</li> <li> <p>Intent over Entity\u2013  Terminates the ongoing intent automatically by initiating a new dialog task. For example: If a customer intends to place an order and during the interaction changes their intent and requests to edit the order, the system terminates the ongoing intent (place order) and initiates a new intent (edit order).</p> <p> <p>Note</p> <p>The Intent over Entity option implies that you think the customer is generally going to say something different other than answer the prompt. The list of item entity type includes a phrase for ignoring the entity with ambiguity and proceeding with the intent instead.</p> </p> </li> <li> <p>Entity over Intent\u2013 Completes the ongoing dialog task normally once the user resolves the ambiguity in the intent. This option considers the customer input as an entity value, and allows the dialog task to progress to the next node. For example: If a customer intends to place an order and during the interaction changes their intent and requests to edit the order, the system continues with the ongoing intent to place the order.</p> <p>When the user\u2019s input for an entity consists of a valid value for the entity and another intent, you can control the experience by choosing between Intent Over Entity or Entity Over Intent options. Learn more.</p> </li> </ul>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#prefer-only-the-first-pattern-match-in-a-sentence","title":"Prefer Only the First Pattern Match in a Sentence","text":"<p>When multiple patterns are identified in a sentence, define whether the FM Engine should consider only the first pattern match or all the pattern matches. If enabled, the FM Engine will only use the first pattern match and discards all other pattern matches. If disabled, then the FM Engine will qualify all the pattern matches from the sentence, and they will be considered for disambiguation.</p>"},{"location":"automation/natural-language/nlu-configurations/engine-tuning/#exact-task-name-match","title":"Exact Task Name Match","text":"<p>The FM Engine configuration Intent Detection using Task Name Words (see here for details) allows you to choose whether to match a task by using the words present in the task name. It is advised that this configuration be disabled if it conflicts with other training. </p> <p>When disabled, the platform generates a strict pattern that does \u2018exact matching\u2019 i.e. if the user input exactly matches with the task name then it will consider as a match. The Exact Task Name Match configuration allows you to choose whether the platform should auto-generate the strict pattern when \u2018Intent Detection using Task Name Words\u2019 is Disabled.</p>"},{"location":"automation/natural-language/nlu-configurations/multi-intent-detection/","title":"Multi-Intent Detection","text":"<p>Kore.ai\u2019s NLP engine breaks conversations down to their essence, identifies and follows-up on multiple action items, or intents, from a single message. The virtual assistant can then execute tasks in a sequential and logical manner.</p> <p>You can allow the NLP engine to detect and execute multiple intents identified in a single user utterance. By default, this setting is disabled and you can enable it. Once enabled, the NLP engine identifies multiple intents in a user utterance based upon the presence of keywords like:</p> <ul> <li>later</li> <li>following that</li> <li>second</li> <li>then</li> <li>before that</li> <li>first</li> <li>beforehand</li> <li>prior to that</li> </ul> <p>The sequence in which these intents are executed is based on the standard phrases like before that, after that, and then, etc. in the user utterance. If no order is specified or identified by the NLP engine, then the intents are executed in the order they are present in the original utterance.</p> <p>After the execution of each intent, the Platform will automatically trigger the next intent in the identified order.</p> <p>If a task fails to get executed, then the Platform will not initiate the subsequent tasks (identified from the utterance).</p> <p>Following are the steps to enable multi-intent detection:</p> <ol> <li>Open the VA for which you want to add multiple intents.</li> <li>Select the Build tab from the top menu.</li> <li>From the left menu, click Intelligence **&gt; Multi Intent Detection**.</li> <li>Turn on the toggle to enable it. </li> </ol>"},{"location":"automation/natural-language/training/machine-learning-engine/","title":"The Machine Learning Engine","text":"<p>Developers need to provide sample utterances for each intent (task) the assistant needs to identify, to train the machine learning model. The Kore.ai XO Platform Machine Learning (ML) engine will build a model that will try to map a user utterance to one of the VA\u2019s intents.</p> <p>The XO Platform allows fully unsupervised machine learning to constantly expand the language capabilities of your assistant \u2013 without human intervention. Unlike unsupervised models in which AI assistants learn from any input \u2013 good or bad \u2013 the Kore.ai XO Platform enables assistants to automatically increase their vocabulary only when the VA successfully recognizes the intent and extracts the entities of a human\u2019s request to complete a task.</p> <p>However, we recommend keeping Supervised learning enabled to monitor the VA performance and manually tune where required. Using the XO Platform, developers can evaluate all interaction logs, easily change NL settings for failed scenarios, and use the learnings to retrain the VA for better conversations.</p> <p>This article discusses the processes behind the Machine Learning Engine, and how to perform training for optimum performance.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#the-machine-learning-process","title":"The Machine Learning Process","text":""},{"location":"automation/natural-language/training/machine-learning-engine/#intent-detection","title":"Intent Detection","text":"<p>The below diagram summarizes the intent detection pipeline for both training and prediction stages. For the training pipeline, the language detection and auto-correction are not run with the assumption that the trainer would be aware of the language in which training needs to be done and of the spellings to be used which might include domain-specific non-dictionary words like Kore, etc. </p> <p></p>"},{"location":"automation/natural-language/training/machine-learning-engine/#entities-extraction","title":"Entities Extraction","text":"<p>Entity extraction involves identifying any information provided by the user apart from the intent that can be used in the intent fulfillment. Entities are of three types</p> <ol> <li>System entities like date, time, color, etc are provided out-of-the-box by the Platform. It includes nearly 22-24 entities and these are recognized by the ML engine automatically with no training except for string &amp; description entity types.</li> <li>Custom entities are defined by the bot developer and these include the list of values \u2013 enumerated, lookup, and remote, regex expressions, and composite entities. These are also mostly auto-detected by the ML engine.</li> <li>NER or named entity recognition needs the training to identify the same entity type for different entities e.g. source &amp; destination cities for flight booking intent, both of which are city type entities and the engine needs the training to distinguish between the two. NER can be conditional random field-based or neural network-based. CRF is preferred since it works on lesser data and has a faster training time compared to the NN-based method.</li> </ol> <p>The following diagram summarizes the NER entity extraction pipeline.</p> <p></p>"},{"location":"automation/natural-language/training/machine-learning-engine/#ml-output","title":"ML Output","text":"<p>The ML Engine runs the classification against the user utterance and generates the following scores output which Ranking and Resolver uses for identifying the correct intent:</p> <ul> <li>The probability Score for each class/intent, can be interpreted as follows<ul> <li>Definitive Match/Perfect Match: If the probability score &gt;0.95 (default and adjustable) </li> <li>Possible match: If the score is &lt;0.95%, it becomes eligible for ranking against other intents which may have been found by other engines.</li> </ul> </li> <li>The fuzzy score for each of the traits/intents which are greater than the Threshold score(default is 0.3) \u2013 Fuzzy logic goes through each utterance of a given intent and compares it against the user input to see how close the user input and the utterance are. The scores are usually from 0-100 and can be interpreted as follows:<ul> <li>Definite Match/Perfect Match: If the score is above 95%(default  &amp; adjustable) </li> <li>Possible match: If the score is &lt;95%, becomes eligible for Ranking against other intents which may have been found by other engines.</li> </ul> </li> <li>CR Sentences\u2013 The ML engine also sends the top 5 ML utterances for each of those Intents which have qualified using the Threshold score. These 5 ML utterances are derived using the Fuzzy score. Ranking &amp; Resolver uses these CR sentences to Rescore and choose the best of these utterances (compares each utterance against user input and chooses an utterance with topmost score)</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#limitations","title":"Limitations","text":"<p>Though the ML model is very thorough, it has its own limitations, as follows:</p> <ul> <li>In cases where sufficient training data is not available, the ML model tends to overfit small datasets and subsequently lead to poor generalization capability, which in turn leads to poor performance in production.</li> <li>Domain adaptation might be difficult if trained on datasets originating from some common domains like the internet or news articles.</li> <li>The ability to control and interpret are hard because, most of the time, they work like a black box, making it difficult to explain the results.</li> <li>Cost is high both in terms of resources and time.</li> <li>The above two points also result in maintenance or problem resolution being expensive (again both in terms of time &amp; effort) and can result in regression issues.</li> </ul> <p>Hence, ML engines augmented by FM engines would yield better results. One can train the assistant with a basic ML model, and any minor issues can be addressed using FM patterns and negative patterns for idiomatic sentences, command-like utterances, and quick fixes.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#training-the-ml-engine","title":"Training the ML Engine","text":""},{"location":"automation/natural-language/training/machine-learning-engine/#training-overview","title":"Training Overview","text":"<p>The Machine Learning Engine builds a model, based on training through intent detection and entity extraction, as follows: </p> <ul> <li>The intent prediction model is trained using statistical modeling and neural networks.  Intent classification tags the user utterance to a specific intent. The classification algorithm learns from the set of sample utterances that are labeled on how they should be interpreted. Training utterance preparation and curation is one of the most significant aspects of building a robust Machine learning model. </li> <li>Entity Detection involves recognizing System Entities (Out Of the Box, Rule-based model), predicting Custom Entities (Custom-trainable Rules-based Model), and Named Entity Recognition (NER). System Entities are defined using built-in rules. However, using the NER approach, any named entity can be trained using Machine Learning by simply choosing the value from the ML training utterances and tagging them against the named entity. </li> </ul> <p>Training the ML Engine involves the following steps:</p> <ol> <li>Choosing and gathering data that can be used as the training set,</li> <li>Dividing the training set for evaluation and tuning (test and cross-validation sets),</li> <li>Training a few ML models according to algorithms (feed-forward neural networks, support vector machines, and so on) and hyperparameters (for example, the number of layers and the number of neurons in each layer for neural networks),</li> <li>Evaluating and tuning the model over test and cross-validation sets,</li> <li>Choosing the best performing model and using it to solve the desired task.</li> </ol> <p>The NLP module improves the performance by constantly validating the ML Engine and presents  actionable insights to resolve the conflicts in intent and entity training.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#optimizing-intent-recognition","title":"Optimizing Intent Recognition","text":""},{"location":"automation/natural-language/training/machine-learning-engine/#adding-machine-learning-utterances","title":"Adding Machine Learning Utterances","text":"<p>To add utterances to the Machine Learning Engine, please follow the steps below:</p> <ol> <li>Open the VA for which you want to add sample user utterances.</li> <li>Select the Build tab from the top menu.</li> <li>From the left menu, select the Natural Language -&gt; Training option.</li> <li>By default, the tab with a list of all Intents would be displayed.</li> <li>You can use the filter option to restrict the display items to Dialog Intents, Sub Intent Dialogs or Sub-Intents. You can also choose to Include Hidden Tasks. </li> <li>Click Utterances &gt; + Utterance against the Intent for which you want to add the utterances. </li> </ol> <p></p> <ol> <li>The user utterance page opens.</li> </ol> <p>Here is where you can enter the utterances. </p> <p>Note</p> <p>Utterances greater than 3,000 characters in length are not allowed.</p> <p></p> <p>Note</p> <p>Utterances should be unique, but in the case of multiple intent models, the same utterance can be used across different models. Read more about multiple intent models below.</p> <p>The negation of trained intents will be ignored by the Platform.</p> <p>For example, consider a Travel Assistant trained on the Book a Flight utterance. A user might say: Your app takes me to the booking screen, but I don\u2019t want to book a flight. In this case, the Book a Flight intent will not trigger.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#adding-entities-for-named-entity-recognition","title":"Adding Entities for Named Entity Recognition","text":"<p>Apart from the intent, you can train your VA to recognize the entities, if present, in the user utterance. For example, if the user says: Book Flight from Hyderabad to Mumbai apart from recognizing the intent as \u201cBook Flight\u201d the source and destination of the flight should also be recognized. This can be achieved by marking the entities in the user utterance during training.</p> <p>You can mark entities in your utterances, by selecting the entity value and clicking the corresponding entity name.</p> <p></p> <p>The Platform will also try to identify and mark the entities. You have the option to accept or discard these suggestions. The Platform will identify the entities based upon:</p> <ul> <li>System entities;</li> <li>Static List of items \u2013 either enumerated or lookup;</li> <li>NER trained entities (from above).</li> </ul> <p>For each of the entities thus marked, the confidence scores identified by the ML engine are displayed. This score is available only when the Conditional Random Field is selected as the NER model.</p> <p></p> <p>Further, if you have enabled Entity Placeholders, the Platform will replace the entity values in the training utterance with entity name placeholders for training the ML model. Using actual entity values as well as multiple additions of an utterance with just a change in the entity value will have an adverse impact on the ML training model. The name of entities also starts contributing highly to the intent detection model.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#using-negative-patterns","title":"Using Negative Patterns","text":"<p>Negative patterns can be used to eliminate intents detected by the Fundamental Meaning or Machine Learning models. Learn more.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#training-your-assistant","title":"Training your Assistant","text":"<p>After you added user utterances, you should train the Kore.ai interpreter to recognize the utterances and the associated user intent. When you have untrained utterances in your VA, the following message is displayed:</p> <p>\u201cYou have untrained utterances in your ML model. Train your VA to update with all your utterances.\u201d</p> <p>Click Train. A status bar is displayed to show progress for utterance training. When complete, the Utterances trained successfully message is displayed. The user utterances are added to the Machine Learning Database. You can further configure the ML engine, identify the dummy intents when a user utterance contains the words that are not used in the VA\u2019s training i.e. vocabulary, Learn more.</p> <p>Once you have trained your VA, you can test it on the newly trained data. Learn how to test your assistant.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#auto-training","title":"Auto-Training","text":"<p>By default, machine learning is automatically trained for any defined user utterances whenever a task is:</p> <ul> <li>Updated with a new<ul> <li>Task name or intent name,</li> <li>Entity name or parameter name,</li> <li>Entity type,</li> <li>VA name</li> </ul> </li> <li>Published</li> <li>Suspended by the Admin.</li> <li>Deleted by the Admin.</li> </ul> <p>On the XO Platform, when auto-train is in progress, a warning message that \u201cuntrained user utterances cannot be identified\u201c is displayed if you try to test the VA before auto-train is complete.</p> <p>To set up the Auto Train option, follow the steps below:</p> <ol> <li>Open the VA for which you want to modify the settings.</li> <li>Select the Build top menu option.</li> <li>On the left navigation menu, click Natural Language -&gt; Thresholds &amp; Configurations -&gt; Machine Learning.</li> <li> <p>Select \u201cYes, add the successfully identified user utterances to the ML training model (Unsupervised Training)\u201d for the Auto Training For Machine Learning option.</p> <p></p> </li> </ol>"},{"location":"automation/natural-language/training/machine-learning-engine/#thresholds-configurations","title":"Thresholds &amp; Configurations","text":"<p>To train and improve the performance of your Assistant, Threshold and Configurations can be specified for all three NLP engines \u2013 FM, KG, and ML. You can access these settings by navigating to Build &gt; Natural Language &gt; Thresholds &amp; Configurations.</p> <p>Note</p> <p>If your VA is multilingual, you can set the Thresholds differently for different languages. If not set, the Default Settings will be used for all languages.</p> <p>The Threshold &amp; Configurations for the ML engine are discussed in detail in the following sections.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#machine-learning-model-configuration-overview","title":"Machine Learning Model Configuration Overview","text":"<p>The XO  Platform ver 6.3 upgraded its Machine Learning (ML) model to v3. This includes a host of improvements and also allows developers to fine-tune the model using parameters to suit business requirements. The developers can change parameters like stop word usage, synonym usage, thresholds, and n-grams, as well as opt between Deep Neural Network or Conditional Random Field-based algorithms for the Named-Entity Recognition (NER) model.</p> <p>In v8.0 of the Platform, provision has been enabled to use the v5 of the ML intent model and externalize several hyperparameters. This can be achieved through the Advanced NLP Configuration, Learn more.</p> <p>When the Multiple Intents Model =is enabled, the ML Engine maintains multiple intent models for the VA as follows:</p> <ul> <li>Bot level Intent Model containing all the Primary Intents of the assistant which includes Primary Dialog Intents, and Alert Task Intents.</li> <li>Dialog Intent Models \u2013 one for every primary dialog intent and sub-dialog intent which includes the Sub-intent nodes added to the dialog definition, Sub-intents scoped as part of the Group nodes and Interruption exceptions added to the dialog definition.</li> </ul> <p>You can configure the Thresholds and Configurations separately for each of the intent models. This includes:</p> <ul> <li>All the configurations under Thresholds and Configurations \u2013 ML Engine as discussed in the below section;</li> <li>All the ML Engine configurations under the Advanced NLP Configurations discussed in detail here.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#the-multiple-intent-model","title":"The Multiple Intent Model","text":"<p>Training of \u201csimilar intents\u201d with different purposes is usually difficult as the training given for an intent can add noise or conflict with the training given to the other intent. This is more evident in cases where the intents have a contextually different meaning or purpose.</p> <p>Consider the following case: A user is in the Make a Booking task, so any query related to the Booking refund policy should be answered within this context. However, the query can also trigger FAQs from Cancel a Booking. </p> <p></p> <p>Enabling the Multiple Intent Models from the Advanced NLP Configurations (see here for how) allows you to have a dedicated ML model only for the primary intents and separate ML Models for each of the dialogs with their associated sub-intents so that the intent detection of sub-intents gets preferential treatment.</p> <p>Continuing with the above example, with a Multiple Intent Model, you can define a separate context-based FAQ and ensure a proper response to the user.</p> <p></p> <p>All the primary intents of the VA will be part of the Bot Level Intent Model. Each of the Dialog tasks will have its own ML Model consisting of all the sub-intents added to it. The Thresholds and Configurations can be individually configured for each of the models. For example, the Bot Level Intent Model can use \u2018Standard\u2019 Network Type and a specific Dialog\u2019s intent model can use \u2018LSTM\u2019 Network Type.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#configuring-machine-learning-parameters","title":"Configuring Machine Learning Parameters","text":"<p>The XO Platform provides language-wise defaults for the following parameters related to the ML performance of your VA. You can customize them to suit your particular needs.</p> <p></p> <p>Key Pointers on ML configurations</p> <ul><li>The illustration below shows the list of all possible configurations and these are available for both single and multiple intent models.</li> <li>When the multiple intent model is enabled, you can configure the individual models by selecting the Configure link against the model.</li> <li>While there is only one VA level intent model, you can add multiple dialog intent models using the Add New button and configure each as per your requirements.</li> <li>Advanced ML Configurations can be applied from here or from the Advanced NLP Configurations section.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#network-type","title":"Network Type","text":"<p>You can choose the Neural Network that you would like to use to train the intent models. This setting has been moved to Machine Learning from Advanced NLP Configurations in v8.1.</p> <p>You can choose between the following types. Based on the selection additional configurations can be done from the Advanced NLP Configurations section, Learn more.</p> <ul> <li>Standard.</li> <li>MLP-BOW \u2013 The bag-of-words model is a simplifying representation used in natural language processing and information retrieval. In this model, a text is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity.</li> <li>MLP-WordEmbeddings \u2013 Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers.</li> <li>LSTM (Long Short-Term Memory) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. LSTM has feedback connections and hence has the ability to capture long-term dependencies for texts of any length and is well suited for longer texts.</li> <li>CNN (convolutional neural networks) is a class of deep neural networks in deep learning most commonly applied to analyzing visual imagery. It makes use of the word order for a specific region size and has achieved remarkable results on various text classification tasks.</li> <li>Transformers use a Universal Sentence encoder in the vectorization stage of the Training pipeline. The output of the sentence encoder is fed to a Multi-Layer perceptron network for training. SentenceEncoder has an inbuilt capability of understanding the semantic similarity between sentences taking into account the synonyms and various usage patterns of the same sentence.  The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is the variable-length English text and the output is a 512-dimensional vector.</li> <li>KAEN (Kore Advanced Embeddings Network) \u2013 Models trained with Sentence Embeddings alone can not understand the domain-specific terminology especially if the words from training are non-dictionary words. Kore.ai provides a model which can understand the meaning of the sentence and at the same time give importance to the domain-specific terminology. There are two parallel layers in work in this model \u2013 one to optimize the weights against the sentence embeddings and the other to optimize the word importance for a given sentence.  The activation function used for these two layers is RReLU (Randomized Leaky Rectified Linear Unit, Learn more)</li> <li>Zero-Shot Model with OpenAI: Helps define descriptive intents that the VA identifies in the user utterance based on semantic similarity without requiring training data.</li> <li>Few-shot Model (Kore.ai Hosted Embeddings): Helps define more number of granular intents that describe the user\u2019s intention in the utterance more accurately with limited training requirement.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#zero-shot-learning-model-with-openai","title":"Zero-Shot Learning Model with OpenAI","text":"<p>Important</p> <p>Before using this feature, enable the OpenAI Integration.</p> <p>The Kore.ai XO platform allows developers to create a Natural Language Understanding (NLU) model through OpenAI integration integration for use in a virtual assistant. The Zero-Shot Learning (ZSL) Model allows developers to quickly create the model without needing training data. Instead, it relies on a pre-trained language model and a logic learning machine (LLM) to identify the intention of a user through the utterance based on semantic similarity. This feature uses the intent name to map or identify the intent name\u2019s similarity with the user input to predict the utterances accurately. Thus, the intents have to be defined very well. This approach is well-suited for virtual assistants with relatively fewer intents and distinct use cases.</p> <p>Benefits</p> <ul> <li>The ZSL network type helps create an NLU model quickly as it does not require training data.</li> <li>Uses OpenAI\u2019s LLM &amp; Generative AI models to identify the intent names by comparing the user utterance.</li> <li>The user must only provide a descriptive intent name to leverage this functionality.</li> </ul> <p>Important Considerations</p> <ul><li>This model identifies and defines granular intents describing the purpose of the user interaction, and not what the virtual assistant can do.</li> <li>ZSL works well when the virtual assistant has good intent coverage.</li> <li>Utterances are required to train entities.</li> <li>Intent names and user utterances will be shared with OpenAI.</li> <li>Bot Designer should enable the integration with OpenAI by providing the API Key.</li> <li>When using ZSL, dialog intents and FAQs need to be treated the same.</li> <li>The ZSL network type applies only to the ML engine and not the FM, KG, and Traits engines. The Platform continues to use Patterns for Intent matching by the FM engine.</li> <li>There is no option to tweak the training if something does not work.</li> <li>ZSL is available in the bot-level model configuration and not in the dialog intent model.</li> <li>Multiple intent models are not supported when Zero-Shot is enabled.</li> <li>Bot Synonyms and stop words are not used for intent detection.</li> <li>When ZSL is enabled, all the matches from the ML engine are definite.</li> <li>The Definite Score is changed to 80% by default for ZSL based on the NLP performance and accuracy.</li> <li>Only the Incorrect Patterns and Wrong Entity Annotation goal-driven validations are enabled when Zero-Shot Learning Model with OpenAI is enabled.</li></ul> <p>How it works</p> <ol> <li>The user defines the intent to be identified by the system. For example, in the banking use case, instead of saying \u201cI see invalid transactions\u201c, the intent you provide has to be more descriptive within a subject, object, and nouns. It should be something more descriptive like \u201cI received an alert on my phone about transactions that I have not done.\u201c. This helps the virtual assistant correctly identify the intent \u201cDispute credit card Transaction.\u201c </li> </ol> <p>If required, the user can add dialogs for the intents. 2. The user should enable the Zero-Shot Network Type under Training. 3. The system identifies the most logical intent by matching the user utterance with the defined intent names (without training utterances). It then responds with the relevant intent. Intents identified by the Zero-Shot model are considered definitive matches.</p> <p>Rescoring of Intents for Definitive Matches</p> <p>When Prefer Definite Matches is disabled, and Rescoring of Intents is enabled, the platform continues rescoring for definite matches based on the similarity between the training data and user utterance to discover the winning intent(s). However, enabling Prefer Definite Matches is recommended to rescore for definitive matches based on the similarity between the intent names and user utterances.</p> <p>Demonstrating with an Example</p> <p>For an online shopping virtual assistant, the following needs to be ensured to implement the ZSL model:</p> <ul> <li>The intent names should be very descriptive.</li> <li>Provide descriptive names, as the model relies heavily on intent names.</li> </ul> <p>When an intent is named \u201cShow the status of my order,\u201d for example, under Build &gt; Conversational Skills &gt; Dialog Tasks.</p> <p></p> <p>For a new bot, under Build &gt; Natural Language &gt; Training &gt; Intents, ensure that no training utterances are added for the intent.</p> <p></p> <p>When you enable ZSL network type for an existing bot, the system does not identify the intent for its training data/utterances.</p> <p>Note</p> <p>For more descriptive intent names like \u201cI want to place an order\u201d and \u201cWill I be able to place an order?\u201d, the system considers the punctuation and the case (upper or lower) to identify the intent.</p> <p>Enable the Zero-Shot Learning Network Type</p> <p>To enable the ZSL model, follow the steps below:</p> <ol> <li>Navigate to Build &gt; Natural Language &gt; Thresholds and Configurations &gt; Machine Learning.</li> <li>Select Zero-Shot Model with OpenAI in the dropdown list for Network Type, and click Save. </li> </ol> <p>Testing the Utterance</p> <p>To test the utterance for the Zero-Shot Learning Model with OpenAI Network Type, follow the steps below:</p> <ol> <li>Navigate to Build &gt; Testing &gt; Utterance Testing.</li> <li>Type the utterance.</li> </ol> <p>Example 1: \u201cI don\u2019t want the product.\u201d </p> <p>Example 2: \u201cWhere is my delivery?\u201d </p> <ol> <li>Click Save &amp; Run.</li> <li>The Machine Learning Model identifies and displays the following intents in the NLP Analysis window for each example.</li> </ol> <p>Example 1: Cancel My Order for \u201cI don\u2019t want the product.\u201d </p> <p>Example 2: Show the status of my order for \u201cWhere is my delivery?\u201d </p> <p>The most relevant intent is identified and considered a definitive match.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#few-shot-model-koreai-hosted-embeddings","title":"Few-Shot Model (Kore.ai Hosted Embeddings)","text":"<p>The Few-shot model allows you to train your virtual assistants using the task names and a few training utterances if required. Kore.ai uses custom NLU models pre-trained with large datasets to identify the intents based on their semantic similarity in the user utterance. This model works in the same manner as the ZSL Model except that more intents are considered while identifying the user\u2019s intention in the utterances through LLMs hosted by the Platform. This model does not share any data externally and needs no additional enablement or costs.</p> <p>Few-Shot as the Default ML Model</p> <p>The Platform sets the Few-Shot model as the default ML Engine model selection with the recommended thresholds for new standard workspace bots when English is selected as the NLU Language.</p> <p></p> <p>Since this model helps obtain good accuracy levels with fewer training utterances, it works best for the following configurations and is set as the default ML Model:</p> <p>ConfigurationDefault Setting</p> ML Engine <ul> <li>\u2018Multiple Intent Models\u2018 is disabled.  <li>The minimum value for ML Threshold is set to 0.6.  <li>The ML Definitive Score is set to 90% (0.9). </li> Ranking &amp; Resolver \u2018Rescoring of Intents\u2018 (by the R&amp;R engine to find the top-qualifying/winning intents) is disabled.     Fundamental Meaning \u2018Intent Detection using Task Name Words\u2019 (to determine if the FM Engine should identify the intents using the words in the Task Name) is disabled.     Advanced NLP Settings <ul> <li>\u2018ML Suggestion Proximity\u2018 (for ML Engine) is added to the list by default with value set to 5.  <li>\u2018Exact Task Name Match\u2018 (for FM Engine) is added to the list by default and set to the Disabled state.  <li>\u2018Multi-intent Model\u2018 is set to the Disabled state. </li> <p>Benefits</p> <ul> <li>The FSL model requires limited utterance training.</li> <li>Provides consistent responses with improved predictability.</li> <li>Easy to scale performance with additional training.</li> </ul> <p>Important Considerations</p> <ul><li>It is important to give descriptive names for your tasks so that the model finds the semantic similarity between the task names and the user utterances.</li> <li>This model identifies and defines granular intents describing the purpose of the user interaction, and not what the virtual assistant can do.</li> <li>Works well when the virtual assistant has good intent coverage.</li> <li>You may need to add training utterances to identify entities by the NER model for specific scenarios.</li> <li>When using FSL, dialog intents and FAQs need to be treated the same.</li> <li>Bot Synonyms, Stop Words and a few other ML Configurations are not used by the Few-Shot Model (Kore.ai Hosted Embeddings).</li> <li>The new Few-Shot Model (Kore.ai Hosted Embeddings) for Traits in NLP V3 allows the NLP Engine to train and identify Traits when set as the default model. This feature is available for only the new bots that have English as the NLU language.  Learn more. <li>Intents are rescored by the R&amp;R Engine by comparing the closest training sentences (including the task name) with the user utterance.</li> <p>How it works</p> <p>The model uses embeddings generated using large pre-trained language models to compare the similarity between the training data and the user utterances.</p> <ol> <li> <p>You can start by just creating intents with descriptive names. Post-testing the performance of the intent, you can consider adding a few utterances only for the failed variations. For example, in the banking use case, when the utterance \u201cI forgot my pin\u201d (which is very straightforward) is given, the virtual assistant correctly identifies the intent \u201creset credit card pin.\u201d </p> </li> <li> <p>However, for a more complex utterance like \u201cI received an alert on my phone about transactions that I have not done.\u201c, the virtual assistant identifies the intent \u201cDispute credit card Transaction\u201d correctly only when a training utterance like \u201cUnidentified Transactions\u201d is added to nudge the model in the right direction. </p> </li> <li> <p>This behavior varies from scenario to scenario where the correct intent can be identified accurately based on the training utterance you provide.</p> </li> <li>The system identifies the most logical intent by matching the user utterance(s) with the defined intent names. It then responds with the relevant intent. Intents identified by Few-Shot are considered definitive matches.</li> </ol> <p>Enable the Few-Shot Network Type</p> <p>To enable the FSL model, follow the steps below:</p> <ol> <li>Navigate to Build &gt; Natural Language &gt; Thresholds and Configurations &gt; Machine Learning.</li> <li>Select Few-Shot Model (Kore.ai Hosted Embeddings) in the dropdown list for Network Type, and click Save. </li> </ol>"},{"location":"automation/natural-language/training/machine-learning-engine/#support-for-standard-bot-traits","title":"Support for Standard Bot Traits","text":"<p>The Few-shot Model is now the default model for managing Traits. This feature is only available for the new bots created in NLP V3.</p> <p>Note</p> <p>All the older bots on NLP V3 will continue to use the Standard ML Model as the default traits model instead of the Few-shot model.</p> <p>To manage the Few-shot Model as the default Network Type for traits, follow the steps below:</p> <ol> <li>Click Build on the top menu.</li> <li>Navigate to Natural Language &gt; Training, and click the Traits tab.</li> <li>Click the trait you want to configure from the list. Otherwise, add a new trait by clicking Add Traits.</li> <li>In the resulting window, click Manage to view the Manage Traits panel.</li> <li>The system selects Few-shot Model (Kore.ai Hosted Embeddings) by default as the Network Type, and the following settings appear:i. ML Threshold is set to the default value 0.5.ii. The Feature Extraction and Sequence Length options available for Standard Models don\u2019t appear as they\u2019re not applicable. </li> </ol>"},{"location":"automation/natural-language/training/machine-learning-engine/#support-for-bot-synonyms","title":"Support for Bot Synonyms","text":"<p>The Few-Shot model supports Bot synonyms where a specific word in the user utterance including an abbreviation, acronym, or enterprise-specific word like \u201cA/C\u201d is replaced by the relevant term or word (Account) which will enable better intent recognition.</p> <p>For example:</p> <p>When the User utterance is \u201cCheck my a/c balance,\u201d the Training data matched is \u201cCheck my account balance.\u201d</p> <p>In this case, MPNET provides a high score (ML Threshold and ML Definitive scores) where the intent/entity/question is understood by the Virtual Assistant and matched to the training data. This support is helpful for migrating the solution-specific bots to the LLM approach.</p> <p>Enabling Bot Synonyms</p> <p>On the Platform, you can use Bot Synonyms as part of the Few-shot model by enabling the Bot Synonyms option in the Bot Level Intent Model Configurations window (after selecting the Few-Shot Model (Kore.ai Hosted Embeddings) Network Type under BUILD &gt; NATURAL LANGUAGE &gt; THRESHOLDS AND CONFIGURATIONS.</p> <p></p> <p>When the Bot Synonyms option is enabled, the following happens:</p> <ul> <li>The Platform looks for any synonyms present in the training utterances and replaces them with the Synonym Key.</li> <li>The training sentences with the replaced words are used for training the model.</li> <li>The modified sentence is used for intent identification (generation of embedding as well as similarity checks).</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#nlu-language-selection","title":"NLU Language Selection","text":"<p>When you select the Zero-shot Model with OpenAI or Few-shot Model Network Types to train the intent models (on the Bot Level Intent Model Configurations page), you must ensure that the NLU Language enabled is English (default) under Configurations &gt; Languages.</p> <p>If you enable another language, the system does not allow selecting these two network types, and displays an error message as shown below:</p> <p></p>"},{"location":"automation/natural-language/training/machine-learning-engine/#ml-threshold","title":"ML Threshold","text":"<p>ML Threshold defines the criteria for qualifying a probability score of an intent to be a possible or definite match. The default value is set to 0.3. This means that any intent which scores &gt;0.3 is considered as a qualified Intent. Intents scoring &lt; 0.3 are rejected.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#ml-definitive-score","title":"ML Definitive Score","text":"<p>Configure the threshold score for definite matches, which can be set to a value between 80-100%, with the following classification:</p> <ul> <li>Probability Score \u2013 If the probability score by the classification Engine is &gt;0.95 (default which is adjustable using \u201cML Definitive Score\u201d divided by 100) Intent is considered as a Definite Match/Perfect Match.</li> <li>Fuzzy logic goes through each utterance of a given Intent and compares it against the user input to see how close the user input and the utterance are (scores are usually from 0-100). If the score is above 95% (default which is adjustable using \u201cML Definitive Score\u201d) Intent is considered as a Definite Match/Perfect Match.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#bot-synonyms","title":"Bot Synonyms","text":"<p>This setting is Disabled by default. Enable this option if you would like to consider intent synonyms in building the ML model.</p> <p>Enabling Synonyms allows the ML model to take the synonyms defined under \u201cSynonyms and Concepts\u201d to be considered while training the ML model. It helps in avoiding preparing duplicate utterances.</p> <p>For example: \u201cI want to book a flight\u201d.</p> <p>If we had defined \u201cbuy\u201d, \u201creserve\u201d, \u201cpurchase\u201d as synonyms of \u201cbook\u201d and \u201cticket\u201d or  \u201cseat\u201d as synonyms of \u201cflight\u201d, then you need not add training utterances like \u201cI want to buy a ticket\u201d or \u201cI want to reserve a seat\u201d etc.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#stop-words","title":"Stop Words","text":"<p>This setting is Disabled by default. Enable this option if you would like to remove the stop words in the training utterances in building the ML model. Once enabled, stop words are used to filter out the words/phrases from the Training utterances before training the ML model and are removed from the user utterance before prediction.</p> <p>This setting is not valid when Network Type is set to Transformer.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#support-for-non-cs-languages","title":"Support for Non-CS Languages","text":"<p>The Kore.ai XO Platform now supports the following 150 Polish stop words for ML Engine Training, in addition to the current stop words:</p> <p>Alphabet Polish Words</p> A <code>\"a\",\"aby\",\"ach\",\"acz\",\"aczkolwiek\",\"aj\",\"albo\",\"ale\",\"ale\u017c\",\"ani\",\"a\u017c\"</code> B <code>\"bardziej\",\"bardzo\",\"bez\",\"bo\",\"bowiem\",\"by\",\"byli\",\"bym\",\"bynajmniej\",\"by\u0107\",</code> <p> <code>\"by\u0142\",\"by\u0142a\",\"by\u0142o\",\"by\u0142y\",\"b\u0119dzie\",\"b\u0119d\u0105\"</code> C <code>\"cali\",\"ca\u0142a\",\"ca\u0142y\",\"chce\",\"cho\u0107\",\"ci\",\"ciebie\",\"ci\u0119\",\"co\",\"cokolwiek\",\"coraz\",</code> <p> <code>\"co\u015b\",\"czasami\",\"czasem\",\"czemu\",\"czy\",\"czyli\",\"cz\u0119sto\"</code> D <code>\"daleko\",\"dla\",\"dlaczego\",\"dlatego\",\"do\",\"dobrze\",\"dok\u0105d\",\"do\u015b\u0107\",\"dr\",\"du\u017co\",\"dwa\",</code> <p> <code>\"dwaj\",\"dwie\",\"dwoje\",\"dzisiaj\",\"dzi\u015b\"</code> G <code>\"gdy\",\"gdyby\",\"gdy\u017c\",\"gdzie\",\"gdziekolwiek\",\"gdzie\u015b\",\"go\",\"godz\"</code> H <code>\"hab\"</code> I <code>\"i\",\"ich\",\"ii\",\"iii\",\"ile\",\"im\",\"inna\",\"inne\",\"inny\",\"innych\",\"in\u017c\",\"iv\",\"ix\",\"i\u017c\"</code> J <code>\"ja\",\"jak\",\"jaka\u015b\",\"jakby\",\"jaki\",\"jakich\u015b\",\"jakie\",\"jaki\u015b\",\"jaki\u017c\",\"jakkolwiek\",\"jako\",</code> <p> <code>\"jako\u015b\",\"je\",\"jeden\",\"jedna\",\"jednak\",\"jednak\u017ce\",\"jedno\",\"jednym\",\"jedynie\",\"jego\",</code> <p> <code>\"jej\",\"jemu\",\"jest\",\"jestem\",\"jeszcze\",\"je\u015bli\",\"je\u017celi\",\"ju\u017c\",\"j\u0105\"</code> K <code>\"ka\u017cdy\",\"kiedy\",\"kierunku\",\"kilka\",\"kilku\",\"kim\u015b\",\"kto\",\"ktokolwiek\",\"kto\u015b\",\"kt\u00f3ra\",\"kt\u00f3re\",</code> <p> <code>\"kt\u00f3rego\",\"kt\u00f3rej\",\"kt\u00f3ry\",\"kt\u00f3rych\",\"kt\u00f3rym\",\"kt\u00f3rzy\",\"ku\"</code> L <code>\"lat\",\"lecz\",\"lub\"</code> M <code>\"ma\",\"maj\u0105\",\"mam\",\"mamy\",\"ma\u0142o\",\"mgr\",\"mi\",\"mia\u0142\",\"mimo\",\"mi\u0119dzy\",\"mnie\",\"mn\u0105\",\"mog\u0105\",\"moi\",</code> <p> <code>\"moim\",\"moja\",\"moje\",\"mo\u017ce\",\"mo\u017cliwe\",\"mo\u017cna\",\"mu\",\"musi\",\"my\",\"m\u00f3j\"</code> N <code>\"na\",\"nad\",\"nam\",\"nami\",\"nas\",\"nasi\",\"nasz\",\"nasza\",\"nasze\",\"naszego\",\"naszych\",\"natomiast\",</code> <p> <code>\"natychmiast\",\"nawet\",\"nic\",\"nich\",\"nie\",\"niech\",\"niego\",\"niej\",\"niemu\",\"nigdy\",\"nim\",\"nimi\",</code> <p> <code>\"ni\u0105\",\"ni\u017c\",\"no\",\"nowe\",\"np\",\"nr\"</code> O <code>\"o\",\"o.o.\",\"obok\",\"od\",\"ok\",\"oko\u0142o\",\"on\",\"ona\",\"one\",\"oni\",\"ono\",\"oraz\",\"oto\",\"owszem\"</code> P <code>\"pan\",\"pana\",\"pani\",\"pl\",\"po\",\"pod\",\"podczas\",\"pomimo\",\"ponad\",\"poniewa\u017c\",\"powinien\",\"powinna\",</code> <p> <code>\"powinni\",\"powinno\",\"poza\",\"prawie\",\"prof\",\"przecie\u017c\",\"przed\",\"przede\",\"przedtem\",\"przez\",\"przy\"</code> R <code>\"raz\",\"razie\",\"roku\",\"r\u00f3wnie\u017c\"</code> S <code>\"sam\",\"sama\",\"si\u0119\",\"sk\u0105d\",\"sobie\",\"sob\u0105\",\"spos\u00f3b\",\"swoje\",\"s\u0105\"</code> T <code>\"ta\",\"tak\",\"taka\",\"taki\",\"takich\",\"takie\",\"tak\u017ce\",\"tam\",\"te\",\"tego\",\"tej\",\"tel\",\"temu\",</code> <p> <code>\"ten\",\"teraz\",\"te\u017c\",\"to\",\"tobie\",\"tob\u0105\",\"tote\u017c\",\"trzeba\",\"tu\",\"tutaj\",\"twoi\",\"twoim\",\"twoja\",</code> <p> <code>\"twoje\",\"twym\",\"tw\u00f3j\",\"ty\",\"tych\",\"tylko\",\"tym\",\"tys\",tzw\",\"t\u0119\"</code> U <code>\"u\",\"ul\"</code> V <code>\"vi\",\"vii\",\"viii\",\"vol\"</code> W <code>\"w\",\"wam\",\"wami\",\"was\",\"wasi\",\"wasz\",\"wasza\",\"wasze\",\"we\",\"wed\u0142ug\",\"wie\",\"wiele\",\"wielu\",\"wi\u0119c\",</code> <p> <code>\"wi\u0119cej\",\"wszyscy\",\"wszystkich\",\"wszystkie\",\"wszystkim\",\"wszystko\",\"wtedy\",\"www\",\"wy\",\"w\u0142a\u015bnie\",\"w\u015br\u00f3d\"</code> X <code>\"xi\",\"xii\",\"xiii\",\"xiv\",\"xv\"</code> Z <code>\"z\",\"za\",\"zapewne\",\"zawsze\",\"za\u015b\",\"ze\",\"znowu\",\"zn\u00f3w\",\"zosta\u0142\",\"z\u0142\",\"\u017caden\",\"\u017cadna\",\"\u017cadne\",</code> <p> <code>\"\u017cadnych\",\"\u017ce\",\"\u017ceby\"</code>"},{"location":"automation/natural-language/training/machine-learning-engine/#feature-extraction","title":"Feature Extraction","text":"<p>Using this option (introduced in ver8.0) you can associate the ML intent model with the preferred algorithm. This option is not valid when Network Type is set to MLP WordEmbeddings, LSTM, CNN, and Transformer.</p> <p>The options are:</p> <ul> <li>n-gram \u2013 this is the default setting and can be used to define the contiguous sequence of words to be used from training sentences to train the model.  For example, if Generate weather forecast report is the user utterance and if the n-gram is set to 2, then Generate weather, Weather forecast, and Forecast report are used in training the model. If n-gram is set to 3, then Generate weather forecast, and Weather forecast report will be used in training the model.  You can set the n-gram using the n-gram Sequence Length \u2013 The minimum n-gram limit is 1 by default. You can set the maximum limit up to 4.</li> <li>skip-gram \u2013 when the corpus is very limited or when the training sentences, in general, contain fewer words then skip-gram would be a better option. For this you need to define:<ul> <li>Sequence Length \u2013 the length for skip-gram sequences, with a minimum of 2 and a maximum of 4</li> <li>Maximum Skip Distance \u2013 the maximum words to skip to form the grams, with a minimum of 1 and a maximum of 3.</li> </ul> </li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#the-ner-model","title":"The NER Model","text":"<p>Choose the NER model to be used for entity detection. The XO Platform provides two entity recognition models for training using NER that follow the same approach with</p> <ul> <li>Conditional Random Fields: lightweight and is easy to use for all sizes of datasets</li> <li>Neural network: works well with medium to large datasets but training time is very high</li> </ul> <p>Note</p> <p>The CRF model supports all languages and the Deep Neural Network model supports English, Spanish, German, and French. This option appears on the screen only when the selected VA language is supported by the Deep Neural Network model.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#ner-threshold","title":"NER Threshold","text":"<p>NER Threshold is a user-configurable parameter to set the minimum confidence score required for the system to identify and return only entity values above the set threshold. An entity with a confidence score below the set threshold is considered a Probable Match and one with a score that is equal to or above the threshold is considered an Exact Match.</p> <p>This setting helps filter out low-confidence recognitions and remove false positive results. This is beneficial for improving the accuracy of Named Entity Recognition (NER) results by excluding less reliable or uncertain identifications.</p> <p></p> <p>Important Considerations</p> While using the NER Threshold setting, the following considerations should be made: <ul><li>This feature is useful for identifying NER entities for CRF and DNN methods.</li> <li>The user can set the threshold value between 0 and 1 in multiples of 0.01.</li> <li>For all the existing bots and languages, the default threshold value is 0, for all new bots, the default value is configurable. To 0.3 currently.</li> <li>During runtime, the system returns only the matched entity values with a confidence score above the threshold.</li> <li>The confidence score based on this setting is reflected in the following locations:</li> <ul><li>Utterance Testing: On the left panel.</li> <li>Batch Testing: In the CSV file and More Details section of the Test Case Details screen.     </li> <li>Health and Monitoring Dashboard: In the More Details section of the Test Case Details screen.</li></ul> <li>In scenarios where multiple entity values are identified for an entity, the system compares the confidence scores and returns the entity value with the maximum confidence score.</li> <li>When multiple entities are identified for a value, the system compares the confidence scores and qualifies the entity with the maximum confidence.</li></ul> <p>Example of NER Identification</p> <p>For a flight booking service, when you set the NER Threshold value for the following entities:</p> <ul> <li>Source City</li> <li>Destination City</li> <li>Date of Travel</li> </ul> <p>The training utterance is as follows:</p> <p>\u201cI want to book a flight from New York to Boston.\u201d</p> <p>When the user provides the following inputs to the virtual assistant:</p> <ul> <li>Utterance 1: \u201cI want to fly from New York to Boston.\u201d</li> <li>Utterance 2: \u201cBook a ticket to New Jersey from Boston.\u201d</li> <li>Utterance 3: \u201cHelp me book a flight ticket on 25th of July, 2023.\u201d</li> </ul> <p>The system identifies all the entity names and checks their NER confidence score. Only the matched entities with a confidence score above the set limit are returned instead of all the recognized entities. Thus, the following results are returned:</p> <ul> <li>Source City: New York</li> <li>Destination City: Boston</li> <li>Date of Travel: 25 July 2023</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#entity-placeholders","title":"Entity Placeholders","text":"<p>Enable to replace entity values present in the training utterances with the corresponding entity placeholders in the training model. Entity placeholders remove the contribution of real entity values in Intent detection. This works only when the entity training(NER) is done via ML. </p> <p>Note</p> <p>Enabling this flag reduces scores contributed by entity values.</p> <p>Example: I want to fly to London tomorrow.</p> <p>In the above example, we don\u2019t want the engine to learn that \u201cLondon\u201d and \u201ctomorrow\u201d are important features. Hence they are replaced with their Placeholders once NER is done and the Entity Placeholders flag is enabled. Training utterance becomes \u201cI want to fly &lt;to&gt; on &lt;date&gt;.</p> <p>This option is not valid when Network Type is set to Transformer.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#upgrading-the-ml-model-for-old-vas","title":"Upgrading the ML Model (for old VAs)","text":"<p>All new VAs that are created use the new ML model by default. Developers can upgrade the ML model for old VAs or downgrade the model for the VAs using the new model.</p> <p>If you are using a previous model of ML in the XO Platform, you can upgrade it as follows:</p> <ol> <li>Open the assistant for which you want to upgrade the ML model and go to Natural Language &gt; Thresholds &amp; Configurations.</li> <li>Expand Machine Learning. Under the ML Upgrade section, click the Upgrade Now button. It opens a confirmation window.</li> <li>Click Upgrade and Train. You can see new customizable options under the Machine Learning section.</li> </ol> <p>Note</p> <p>If a VA is exported using the older model (V2) and imported as a new VA, it continues to be in the V2 model until you upgrade it.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#training-validations","title":"Training Validations","text":"<p>The ML engine enables you to identify issues proactively in the training phase itself with the following set of recommendations: </p> <ul> <li>Untrained Intents \u2013 notifies about intents that are not trained with any utterances so that you can add the required training. </li> <li>Inadequate training utterances \u2013 notifies the intents that have insufficient training utterances so that you can add more utterances to them. </li> <li>Utterance does not qualify any intent (false negative) \u2013 notifies about a utterance for which the NLP model cannot predict any intent. For example, an utterance added to Intent A is expected to predict Intent A. Whereas in some cases the model won\u2019t be able to predict neither the trained Intent A nor any other Intents within the model. Identifying such cases proactively helps you to rectify the utterance and enhance the model for prediction. </li> <li>Utterance predicts wrong intent (false positive) \u2013 Identifies utterances that predict intents other than the trained intent. For example, when you add an utterance that is similar to utterances from another intent, the model could predict a different intent rather than the intent to which it is trained to. Knowing this would help you to rectify the utterance and improve the model prediction</li> <li>Utterance predicts intent with low confidence \u2013 notifies about the utterances that have low confidence scores. With this recommendation, you can identify and fix such utterances to improve the confidence score during the virtual assistant creation phase itself.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#viewing-nlu-training-validations","title":"Viewing NLU Training Validations","text":"<ol> <li>On the virtual assistant\u2019s Build menu, click Natural Language -&gt; Training.</li> <li> <p>In the Intents tab, you can see the set of recommendations for the Intents and ML utterances. </p> <p> <p>Note</p> <p>The errors and warnings in this screen are examples. The ML validations vary based on the error or warning recommendation as explained in the Goal-Based NLU Training Validations section above.</p> </p> </li> <li> <p>Hover over the validation options and view the following recommendations:</p> <ul> <li> <p>Hover on the Error icon to view the recommendations to resolve the error.</p> <p> <p>Note</p> <p>An Error is displayed when the intent has a definite problem that impacts the virtual assistant's accuracy or intent score. Errors are high severity problems.</p> </p> </li> <li> <p>Hover on the Warning icon and follow the instructions in the warning to enhance the training for ML utterances. </p> <p> <p>Note</p> <p>A warning is displayed when the issue impacts the VA's accuracy and it can be resolved. Warnings are less severe problems when compared to errors. </p> </p> </li> </ul> </li> </ol> <p>Once you click on the Intent with an error or warning, hover over the Bulb icon to view the summary of error or warning messages as illustrated below:</p> <p></p>"},{"location":"automation/natural-language/training/machine-learning-engine/#exporting-and-importing-machine-learning-utterances","title":"Exporting and Importing Machine Learning Utterances","text":"<p>You can import and export ML utterances of a VA into another in CSV and JSON formats. You can choose between \u2018In-Development\u2019 or \u2018Published\u2019 tasks to export, whereas importing utterances always replace the latest copy of the task.</p>"},{"location":"automation/natural-language/training/machine-learning-engine/#how-to-export-or-import-ml-utterances","title":"How to Export or Import ML Utterances","text":"<ol> <li>On the VA\u2019s Build menu, click Natural Language &gt; Training.</li> <li> <p>The \u2018In-Development\u2019 version of the VA\u2019s ML utterances open by default. If you want to see the utterances in the \u2018Published\u2019 version, toggle on the top right side of the window to Published. </p> <p> <p>Note</p> <p>The export of ML utterances varies based on this selection as explained in the Versioning and Behavior of the Exported Utterances section below.</p> </p> </li> <li> <p>Click the options icon and select an option:</p> <ul> <li>Click Import Utterances and upload a CSV or JSON file with the utterances to import, or</li> <li>Click Export Utterances and select CSV or JSON formats to export the utterances. </li> </ul> </li> </ol>"},{"location":"automation/natural-language/training/machine-learning-engine/#versioning-and-behavior-of-imported-utterances","title":"Versioning and Behavior of Imported Utterances","text":"<ul> <li>The imported utterances in CSV/JSON entirely replace the utterances present in the latest copy of the tasks.</li> <li>If the task is in Upgrade in Progress status, the utterances related to the task get entirely replaced with the task utterances present in the imported file. The utterances in the Published copy of the task aren\u2019t affected.</li> <li>If the task is in the Published status, an Upgrade in Progress copy of the task gets created by default and the new utterances present in the imported file will be added to the upgraded copy. The utterances in the Published copy of the task aren\u2019t affected.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#versioning-and-behavior-of-exported-utterances","title":"Versioning and Behavior of Exported Utterances","text":"<ul> <li>When you export a VA\u2019s utterances, all the utterances related to every task type \u2013 alert, dialog \u2013 get exported.</li> <li>When you export an In Development copy of the VA, the utterances of all tasks in the latest available copy get exported.</li> <li>When you export a Published copy of the assistant, all the utterances in the published state get exported.</li> <li>In the case of multi-language VAs, the export of utterances includes utterances added in all of the languages.</li> <li>Export of utterances to JSON includes NER tagging present in the tasks, whereas CSV export doesn\u2019t include them.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#training-recommendations","title":"Training Recommendations","text":""},{"location":"automation/natural-language/training/machine-learning-engine/#general-ml-training-recommendations","title":"General ML Training Recommendations","text":"<ul> <li>Give a balanced training for all the intents that the VA needs to detect, add approximately the same number of sample utterances. A skewed model may result in skewed results.</li> <li>Provide at least 8-10 sample utterances against each intent. The model with just 1-2 utterances will not yield any machine learning benefits. Ensure that the utterances are varied and you do not provide variations that use the same words in a different order.</li> <li>Avoid training common phrases that could be applied to every intent, for example, \u201cI want to\u201d. Ensure that the utterances are varied for larger variety and learning.</li> <li>After every change, train the model and check the model. Ensure that all the dots in the ML model are diagonal (in the True-positive and True-negative) quadrant and you do not have scattered utterances in other quadrants. Train the model until you achieve this.</li> <li>Regularly train the assistant with new utterances.</li> <li>Regularly review the failed or abandoned utterances and add them to the utterance list against a valid task or intent.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#nlp-intent-detection-training-recommendations","title":"NLP Intent Detection Training Recommendations","text":"<ul> <li>If there are a good number of sample utterances, try training the VA using Machine Learning approach first, before trying to train the fundamental meaning model.</li> <li>Define bot synonyms to build a domain dictionary such as pwd for a password; SB for a savings bank account.</li> <li>After every change to the model training, run the batch testing modules. Test suites are a means to perform regression testing of your VA\u2019s ML model.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#nlp-entity-detection-training-recommendations","title":"NLP Entity Detection Training Recommendations","text":"<p>The best approach to train entities is based on the type of entity as explained below:</p> <ul> <li>Entity types like List of Items (enumerated, lookup), City, Date, Country do not need any training unless the same entity type is used by multiple types in the same task. If the same entity type is used in a task, use either of the training models to find the entity within the user utterances.</li> <li>When the entity type is String or Description the recommended approach is to use Entity patterns and synonyms.</li> <li>For all other entity types, both NER and Patterns can be used in combination.</li> </ul>"},{"location":"automation/natural-language/training/machine-learning-engine/#entity-training-recommendations","title":"Entity Training Recommendations","text":"<ul> <li>Use NER training where possible \u2013 NER coverage is higher than patterns.</li> <li>NER approach best suits detecting an entity where information is provided as unformatted data. For entities like Date and Time, the Platform has been trained with a large set of data.</li> <li>NER is a neural network-based model and will need to be trained with at least 8-10 samples to work effectively.</li> </ul>"},{"location":"automation/natural-language/training/nlp-training-overview/","title":"NLP Training","text":"<p>NLP  Training ensures that virtual assistants meet the designated business case requirements. NLP Training to achieve the best results requires leveraging the features on the XO Platform. The NLP Engine is the core component that interprets what users say at any given time and converts that language to structured inputs the system can process.</p> <p>The XO Platform employs NLP engines for Machine Learning, Fundamental Meaning, Knowledge Graph, Traits, and intents ranking to handle complex use cases. </p>"},{"location":"automation/natural-language/training/nlp-training-overview/#the-nlp-training-process","title":"The NLP Training Process","text":"<p>Morphology is the underlying principle behind NLP. Morphology is the study of words, how they are formed, and their relationship to other words in the same language. It analyzes the structure of words and parts of words, such as stems, root words, prefixes, and suffixes. Morphology also looks at parts of speech, intonation, and stress, and the ways the context can change a word\u2019s pronunciation and meaning.</p> <p>Based on this, a user utterance undergoes the following preprocessing before an attempt at entity extraction and intent detection:</p> <ul> <li>Tokenization \u2013 Splitting of utterances into sentences (Sentence tokenization) and Splitting of Sentence(s) into words. Kore.ai NLP uses TreeBank Tokenizer for English. Each language might have its own tokenizer.</li> <li>toLower() \u2013 Convert all the text into lower (Not done for German, since the word meaning changes based on the case). This process is done only by ML and KG engines.</li> <li>StopWord removal \u2013 Each language has its own set of stop words that can be edited by the developer. Removes words that may not contribute to improving the learning. This process is done only in ML and KG engines. This setting is optional, but is disabled by default.</li> <li>Lemmatization or Stemming depending on the language <ul> <li>Stemming \u2013 Retains the stem of the word like \u201cWorking\u201d-&gt; \u201dwork\u201d, \u201cRunning\u201d-&gt; \u201dRun\u201d, \u201chousing\u201d-&gt; \"house\u201d. It basically cuts the words. The output word may not be a valid language word.</li> <li>Lemmatization \u2013 Converts the word to its base form using the dictionary. Like in earlier examples \u201cWorking\u201d-&gt; \u201dwork\u201d, \u201cRunning\u201d-&gt; \u201dRun\u201d however,  \u201chousing\u201d-&gt; \u201dhouse\u201d. </li> </ul> </li> <li>N-grams \u2013 Helps in combining co-occurring words. For example, \u201cNew York City\u201d and \u201cInternet Explorer\u201d. Each word has its own meaning. But when we take tri-gram in the first case and bi-gram in the second case, it actually results in a more meaningful word. N-grams also help in getting some context before or after a word.</li> </ul>"},{"location":"automation/natural-language/training/nlp-training-overview/#scoping","title":"Scoping","text":"<p>The first step in NLP training is to define the scope of the VA, narrowing down the problem the Virtual Assistant will need to solve. This helps in configuring the various training nuances you will require. This involves brainstorming sessions with various stakeholders like SMEs/BAs, Conversation Experience Designers, VA Developers, NLP Analysts/Data Engineers, NLP Trainers, and Testers.</p> <p>The basic guidelines we suggest to keep in mind while scoping the VA are the following:</p> <ul> <li>Start with a problem to solve: Get a clear idea of what the VA is supposed to accomplish. Talk to business analysts and VA developers to understand the requirements and the actual functionality of the Virtual Assistant.</li> <li>Create a list of Intents: This will streamline the entire process<ul> <li>For each intent, identify the key results that the VA is aiming to accomplish;</li> <li>The focus should be on the needs of the user, not the platform requirements.</li> </ul> </li> <li>Detail out example conversations: Both user utterances and responses<ul> <li>Create user personas and think about the conversations they might engage in with your VA. </li> <li>Think through edge cases, follow-ups, and clarifying questions;</li> <li>You can leverage the Storyboard feature of the platform if it has not been already used for the VA development phase.</li> </ul> </li> <li>Brainstorm what an end user might ask as part of achieving their intent: These would be the alternate utterances for every intent. Try to also include idioms and slang.</li> </ul>"},{"location":"automation/natural-language/training/nlp-training-overview/#primary-nlu-engines","title":"Primary NLU Engines","text":"<p>The XO Platform offers the following primary NLU engines for bot training and optimization:</p> <ul> <li>Machine Learning (ML)</li> <li>Fundamental Meaning (FM)</li> <li>Knowledge Collection  / Knowledge Graph (KG)</li> <li>Traits Engine</li> <li>Ranking and Resolver</li> </ul> <p>When do you use each engine? Each of these engines has settings and configurations for Optimizing NLP to Improve VA Performance. Here we will list out guidelinesand scenarios to leverage each type of NLP engine.</p>"},{"location":"automation/natural-language/training/nlp-training-overview/#machine-learning-engine","title":"Machine Learning Engine","text":"<p>Machine Learning (ML) is the recommended engine for training a VA. The reason for this is its flexibility and auto-learn feature. Given a few examples, the engine learns and is capable of understanding similar new utterances. The training utterances need not be full sentences, as the ML can learn from phrases too.</p> <p>If you have a large corpus for each intent that you are planning to implement, then use Machine Learning. If you don\u2019t have a corpus it would be a good idea to develop one. In the long run, it is better to spend time building a large corpus and use ML rather than going for the other less time-consuming, easier options.</p> <p>The way you define a large corpus could differ depending on the intents. For example, if the intentions are very different from each other and can be understood using their sample data like \u201cFind Flight\u201d or \u201cChange Sear\u201c, then a corpus of 200-300 for each intent is sufficient. However, if intents are closer to each other (and usually start with a similar utterance, such as \u201cChange Seat\u201d and \u201cChange Flight\u201d, then the corpus should be in 1000s.</p> <p>Similarly, if you are planning to use Deep Neural Networks, you need a higher number of samples for better predictions of both True Positives and True Negatives, as these networks are data-hungry. Learn more about the ML Engine.</p>"},{"location":"automation/natural-language/training/nlp-training-overview/#knowledge-graph-engine","title":"Knowledge Graph Engine","text":"<p>If your intents are more query-like in nature than transactional tasks or if the content is in documents and you want the VA to answer user queries from documents, then use Knowledge Collection. This engine can also be used to trigger dialog tasks in response to user queries thus incorporating other features available within the Kore.ai XO Platform.</p> <p>If you have a lot of Intents and do not have time to prepare alternate utterances, but you are able to manually annotate some important terms, use Knowledge Collection. It is advisable to spend some time building a corpus and going for Machine Learning since annotation in the Knowledge Graph works in a similar way to ML\u2019s auto-learning process. Learn more about the Knowledge Graph.</p>"},{"location":"automation/natural-language/training/nlp-training-overview/#fundamental-meaning-engine","title":"Fundamental Meaning Engine","text":"<p>If you have cases where users employ idiomatic sentences or command-like sentences or if you are not too strict about some false positives then use the Fundamental Meaning (FM) engine. Learn more about the FM Engine.</p>"},{"location":"automation/natural-language/training/nlp-training-overview/#nlp-optimization-within-the-xo-platform","title":"NLP Optimization within the XO Platform","text":"<p>To get started optimizing your VA\u2019s NLP, you need to select the VA you\u2019re working with, then access  Build &gt; Natural Language. The NLP options are categorized under various headings for your convenience:</p> <ul> <li>Training \u2013 In the Training section, you can define how the NLP interpreter recognizes and responds to the user input for a VA, and then train the interpreter to recognize the correct user intent.</li> <li>Thresholds &amp; Configurations \u2013 In this section, you can define the recognition confidence levels required for minimum recognition actions, the confidence range for asking a user to choose from a list of possible matches, and a recognition confidence level for a positive match for the knowledge graph.</li> <li>Modify Advanced Settings like auto training settings for user utterances and negative intent patterns.</li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/","title":"Ranking and Resolver","text":"<p>The Kore.ai NLP engine uses Machine Learning, Fundamental Meaning, and Knowledge Graph (if any) models to match intents. All the three Kore.ai engines finally deliver their findings to the Kore.ai Ranking and Resolver component as either exact matches or probable matches. Ranking and Resolver determines the final winner of the entire NLP computation.</p> <p>The Ranking &amp; Resolver engine receives the outputs from the above engines and further processes them.</p> <p>Important Information</p> <p><ul><li>With the introduction of the Few-shot Model in ML and KG engines, rescoring by Ranking &amp; Resolver is no longer required for intent identification. Therefore, we have introduced a new version of Ranking &amp; Resolver (Version 2) for Few-shot models that only ranks intents based on scores from ML and KG engines.</li> <li>The version significantly improves the accuracy of intent identification.</li></ul> <p>You can choose one of the following Ranker and Resolver versions to define how to rank matched intents from NLP engines and determine the winning intent:</p> <ul><li>Version 1 rescores the intents matched by the NLP engines and ranks them based on the rescored results to identify the winning intent in the user input.</li> <li>The latest Version 2 for the Few-shot ML Model only ranks the scores of the definitive matches from ML and KG engines (not the FM engine) without intent rescoring, to ensure the best intent identification accuracy.</li></ul> <p>Before selecting this feature, please consider the following for Version 2:</p> <ul><li>Changing to Version 2 will change how the winning intent is determined for user input. If Version 1 works best for your NLP engine(s), please do not change it.</li> <li>It works best when the ML and KG engines use the Few-shot ML model. For the other models, choosing the appropriate R&amp;R version is recommended.</li> <li>Since the FM engine does not identify intents based on task names, configurations for this feature are disabled in Version 2 by default.</li> <li>This version works solely by eliminating the intents with lower proximity of probable matches. It does not eliminate intents with semantic similarity to user input, matched utterances, or questions.</li></ul> </p>"},{"location":"automation/natural-language/training/ranking-and-resolver/#enable-ranking-resolver-version-2","title":"Enable Ranking &amp; Resolver Version 2","text":"<p>To enable Version 2 for the Few-shot Model, follow the steps below:</p> <ol><li>Navigate to Build &gt; Natural Language &gt; Thresholds &amp; Configurations &gt; Ranking and Resolver Engine.</li> <li>Select Version 2 for Rank and Resolver Version.</li> <li>Click Enable Now in the confirmation window.     </li> Once enabled, you can use Utterance Testing to see your bot's behavior with R&amp;R V2. Learn more.</ol>"},{"location":"automation/natural-language/training/ranking-and-resolver/#how-ranking-and-resolver-works-for-different-nlp-engines","title":"How Ranking and Resolver Works for Different NLP Engines","text":"<p>Here is an overview of the various parameters that the R&amp;R engine works with:</p> <ul> <li>The output of the ML Engine: for a given utterance:<ul> <li>Deterministic match: fuzzy score match of &gt;= 95% match against user input.</li> <li>Probable matches: Confidence scores for each intent</li> <li>Top 5 utterances (from ML training dataset) of each intent whose confidence score is &gt; threshold (default is 0.3)</li> <li>Top 5 utterances are found by ML engine which are close to the user input.</li> </ul> </li> <li>The output of the KG Engine<ul> <li>Deterministic Match: Fuzzy score if Deterministic (fuzzy match of &gt;= 95% match against user input).</li> <li>Probable matches: Confidence scores of Questions that matched minimum threshold(&gt;=50% match of path terms &amp; &gt;=60% word match)</li> <li>Synonyms matched, Nodes matched, Path terms matched, Class/Traits matched</li> <li>Original Question, Modified question(replaced with synonyms which matched)</li> <li>Alternate questions of each matched question</li> </ul> </li> <li>The output of the FM Engine<ul> <li>Deterministic Match: Intents that matched deterministically (Pattern match or input is exactly the same as the task name)</li> <li>Probable matches: Partial label matches including synonyms.</li> </ul> </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#working-processes","title":"Working Processes","text":"<p>The NLP engine uses a hybrid approach using Machine Learning, Fundamental Meaning, and Knowledge Graph (if the assistant has one) models to score the matching intents on relevance. The model classifies user utterances as either being Probable Matches or Definitive Matches.</p> <p>Definitive Matches get high confidence scores and are assumed to be perfect matches for the user utterance. In published assistants , if user input matches with a single Definitive Match, the VA directly executes the task. If the utterances match with multiple Definitive Matches, they are sent as options for the end-user to choose one.</p> <p>On the other hand, Probable Matches are intents that score reasonably well against the user input but do not inspire enough confidence to be termed as exact matches. Internally the system further classifies probable matches into good and unsure matches based on their scores. If the end-user utterances were generating probable matches in a published assistant, the VA sends these matches as Did you mean? suggestions for the end-user.</p> <p>Based on the ranking and resolver, the winning intent between the engines is ascertained. If the Platform finds ambiguity, then an ambiguity dialog is initiated. The Platform initiates one of these two system dialogs when it cannot ascertain a single winning intent for a user utterance:</p> <ul> <li>Disambiguation Dialog: Initiated when there are more than one Definitive matches returned across engines. In this scenario, the VA asks the user to choose a Definitive match to execute. You can customize the message shown to the user from the NLP Standard Responses.</li> <li>Did You Mean Dialog: Initiated if the Ranking and Resolver returns more than one winner or the only winning intent is an FAQ whose KG engine score is between lower and upper thresholds. This dialog lets the user know that the VA found a match to an intent that it is not entirely sure about and would like the user to select to proceed further. In this scenario, the developer should identify these utterances and train the assistant further. You can customize the message shown to the user from the NLP Standard Responses.</li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#deciding-the-winning-intent","title":"Deciding the Winning Intent","text":"<p>The wining intent is decided by the Ranking &amp; Resolver as follows:</p> <ul> <li>Definitive match(es) found<ul> <li>If any engine has found an Intent Definitively, that\u2019s the winning Intent</li> <li>If more than one engine found different intents but Deterministically, then consider them as ambiguous and present the found intents as choices to the user to choose the intent which user felt is right.</li> </ul> </li> <li>Probable match(es) found<ul> <li>Score each of the 5 utterances given by the ML engine and find the highest scoring utterance against each probable Intent.</li> <li>Score each of the alternate questions, modified questions given by the KG engine, and find the highest scoring question against each intent.</li> <li>Rank the scores and choose the Top scoring intent as the winning intent.</li> <li>If Topper and the immediate next intent are within the range of 2% then consider them as ambiguous.</li> <li>If a deterministic Intent is found, ignore all probable matches.</li> <li>If only FM or ML engines found an Intent but probable, that\u2019s the winning intent.</li> <li>If only the KG engine found a probable intent and its score is &gt; higher threshold(80%) then that\u2019s the winning intent.</li> <li>If only the KG engine found a probable Intent and its score is &gt;60% but &lt;80% then that\u2019s the winning intent, but since the confidence is low, show it as a suggestion (user will see \u201cDid you mean\u201d)</li> <li>If more than one probable intents were found. Learn more about model scores and resolver.</li> </ul> </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#thresholds-configuration","title":"Thresholds &amp; Configuration","text":"<p>To set up Thresholds &amp; Configuration for the Ranking and Resolver Engine, follow the below steps:</p> <ul> <li>Open the vA for which you want to configure thresholds.</li> <li>Select the Build tab from the top menu.</li> <li>From the left navigation click Natural Language &gt; Thresholds &amp; Configurations.</li> <li>The Ranking &amp; Resolver Engine section allows you to set the threshold:<ul> <li>Prefer Definitive Matches can be used to prioritize definitive matches over probable matches so that all the matches are considered for rescoring and the end-user gets to choose the right intent in case of any ambiguity. This setting is enabled by default and you can disable it. If enabled (default behavior), definitive matches will win and the probable matches would be discarded, in case of no definitive match, then probable matches would get rescored. If disabled, all the matches \u2013 definitive and probable, would be rescored.</li> <li>Rescoring of Intents can be turned off so that all the qualified intents from the different intent engines are assumed winning intents and are sent to the end-users to choose the required intent. If only one intent is qualified, then it is considered a winner, if more than one is qualified then the user will be presented with results for disambiguation.</li> <li>Negative Patterns When enabled, uses negative patterns to eliminate intents detected by Fundamental Meaning or Machine Learning models.</li> <li>Proximity of Probable Matches which defines the maximum difference to be allowed between top-scoring and immediate next probable intents to consider them as equally important. Before v7.3 of the Platform, this setting was under the Fundamental Meaning section. </li> </ul> </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#dependency-parsing-model","title":"Dependency Parsing Model","text":"<p>The Platform has two models for scoring intents by the Fundamental Meaning Engine and the Ranking &amp; Resolver Engine:</p> <ol> <li>The first model predominantly relies on the presence of words, the position of words in the utterance, etc. to determine the intents and is scored solely by the Fundamental Meaning Engine. This is the default setting.</li> <li>The second model is based on the dependency matrix where the intent detection is based on the words, their relative position, and most importantly the dependency between the keywords in the sentence. Under this model, intents are scored by the Fundamental Meaning Engine and then rescored by the Ranking and Resolver Engine.</li> </ol> <p>Dependency Parsing Model can be enabled and configured from the Ranking and Resolver section under Build &gt; Natural Language &gt; Training &gt; Thresholds &amp; Configurations.</p> <p>Note</p> <p>This feature is supported only in select languages, see here for supported languages.</p> <p>The Dependency Parsing Model can be configured as follows:</p> <ul> <li>Minimum Match Score to define the minimum score to qualify an intent as a probable match. It can be set to a value between 0.0 to 1.0 with the default set to 0.5.</li> <li>Advanced Configurations are used to customize the model by changing the weights and scores associated with various parameters. This opens a JSON editor where you can enter the valid code. You can click the restore to default configurations to get the default threshold settings in a JSON structure, you can change the settings provided you are aware of the consequences. </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#nlp-detection","title":"NLP Detection","text":"<p>The Natural Language Analysis will result in the following scenarios, which will be discussed below:</p> <ul> <li>NLP Analysis identifying a Definitive match with FM or ML or KG engines.</li> <li>NLP Analysis with multiple engines returning a probable match and selecting a single match.</li> <li>NLP Analysis with multiple engines returning a probable match and resolver returning multiple results.</li> <li>NLP Analysis with no match.</li> </ul> <p>To understand NLP detection, let us use the example of a Travel Planning assistant with the following details:</p> <ul> <li>The assistant consists of several dialog tasks and its intents are trained with Synonyms, Patterns, and ML utterances.</li> <li>The Knowledge Graph is defined with 86 FAQs distributed across 4 top-level terms.</li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-1-fm-identifying-a-definitive-match","title":"Scenario 1 \u2013 FM Identifying a Definitive Match","text":"<p>In this example, the following occurs: </p> <ul> <li>The Fundamental Meaning (FM) model identified the utterance as a Definitive match.</li> <li>The Machine Learning (ML) model did not identify a match.</li> <li>An intent using the same verb form has been eliminated. , so the FM model termed it a Definitive match.</li> <li> <p>The Knowledge Graph engine has also considered the utterance as a Probable match to the question: How do I book my flight?</p> <p></p> </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-2-ml-identifying-a-definitive-match","title":"Scenario 2 \u2013 ML Identifying a Definitive Match","text":"<p>In this example, both the FM and ML models show this intent as a match \u2013 Definitive and Probable respectively. </p> <p></p>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-3-kg-identifying-a-definitive-match","title":"Scenario 3 \u2013 KG Identifying a Definitive Match","text":"<p>This scenario can be explained as follows:</p> <ul> <li>The user utterance is How do I book a flight?</li> <li>The user utterance contains all the terms required to match it to the How do I book my flight question.</li> <li>As 100% path term matched the path was qualified. As part of confidence scoring, the terms in the user query are similar to that of the actual Knowledge Graph question. Thus, it returns a score of 100. As such, the intent is marked as a Definitive match and selected.</li> <li>The ML and FM models also found a Probable Match to the Book Flight intent. </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-4-multiple-engines-returning-a-probable-match","title":"Scenario 4 \u2013 Multiple Engines Returning a Probable Match","text":"<p>In this scenario, we can see that:</p> <ul> <li>All the 3 engines returned a probable match and no definitive match.</li> <li>Each engine has found one probable match. All probable matches identified are re-ranked in the Ranking and Resolver.</li> <li>The Ranking and Resolver component returned the highest score for the single match (Task name \u2013 Book Flight ) from the FM engine. The score for this match is highest, which is why it is the winning intent that is presented to the user. </li> <li>Though most of the keywords in the user utterance map to the keywords in the KG query, still this is not a definitive match because the number of path terms is not 100%. </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-5-resolver-returning-multiple-results","title":"Scenario 5 \u2013 Resolver Returning Multiple Results","text":"<p>This example shows the following:</p> <ul> <li>The FM Engine detected probable matches. The ML and KG engines each returned one probable match.</li> <li>Ranking and resolver found the 2 queries with close scores. .</li> <li>Both intents are selected and presented to the user as Did-you-mean.</li> <li>Both the intents were selected as terms in both matches and the score for both the paths is more than 60%.     </li> </ul>"},{"location":"automation/natural-language/training/ranking-and-resolver/#scenario-6-no-match-identified","title":"Scenario 6 \u2013 No Match Identified","text":"<p>In this final example, there is no match for the utterance:</p> <ul> <li>None of the engines could identify any trained intent or Knowledge Graph intent.</li> <li> <p>The default intent is triggered.</p> <p></p> </li> </ul>"},{"location":"automation/natural-language/training/traits/","title":"Traits","text":"<p>In natural conversations, it is very common that a user provides background/relevant information while describing a specific scenario.</p> <p>Traits are specific entities, attributes, or details that the users express in their conversations. The utterance may not directly convey any specific intent, but the traits present in the utterance are used in driving the intent detection and bot conversation flows.</p> <p>For example, the utterance: My flight is late and I will miss my connection because of it expresses two traits: flight delay and emergency. In this scenario, the utterance does not convey any direct intent. However, the presence of the emergency trait is used to directly assign the conversation to a human agent.</p> <p>The Traits feature of the XO Platform is aimed at identifying such characteristics present in user utterances and use them for intent detection and in customizing the VA definition using these characteristics.</p>"},{"location":"automation/natural-language/training/traits/#how-traits-work","title":"How Traits work","text":"<p>Traits are entities that can be extracted from the user input, before intent recognition. They can be used in multiple scenarios listed below:</p> <ul> <li>Indirect entity extraction, e.g.: gender or age-specific words can be inferred from the text.  A phrase such as: \u201cSeat in front of the plane with extra legroom\u201d implies, for example, a First Class seat.</li> <li>Intent recognition, using rules. Any rule match for intent will be considered a definitive match.</li> <li>Identification based on keywords/phrases and their synonyms. For Example, Trait-Color: Blue\u2013 \u201cBlue\u201d, \u201cSapphire\u201d, \u201cTeal\u201d; Trait-Color-Red \u2013 Red, Maroon, Crimson Trait-Status: NotWorking: \u201cdoesn\u2019t work\u201d, \u201cswitched off\u201d;  Trait-Status:Working: \u201cworking\u201d, \u201cturned on.\u201d</li> <li>Inference from a keyword or specific phrase in the sentence. There is no obvious association between certain words in the sentence and the value of the entity, but rather you need the sentence as a whole to determine the value. For example, Trait-Greeting-Emotion: Positive \u2013 \u201cGood Morning\u201d, \u201cHow are you\u201d; Trait-Greeting-Emotion: Negative \u2013 \u201cI hate to say\u201d, \u201cI am not having trouble\u201d.</li> </ul> <p>Configuring Traits involves:</p> <ul> <li>Trait Definition</li> <li>Trait Association Rules</li> <li>Trait Detection</li> </ul> <p>We will discuss these in detail throughout this article, but first, let us look at a use case for traits.</p>"},{"location":"automation/natural-language/training/traits/#use-case","title":"Use Case","text":"<p>A Travel Planning VA might have an added requirement to book a flight based on the cost preference.</p> <p>You might have the following user utterance: I am looking for a low-cost option to London, which must result in ordering the available flights and picking the lowest-priced ticket.</p> <p>This can be achieved by the following:</p> <ul> <li>Adding a Trait Type called Flight Fare with Trait Economy trained with the utterance low cost.</li> <li>Adding a Rule for book flight to be triggered in the presence of Economy Trait.</li> <li>Add transition conditions in case Trait Economy is present in the context.</li> </ul>"},{"location":"automation/natural-language/training/traits/#trait-definition","title":"Trait Definition","text":"<p>To access Traits, follow the steps below:</p> <ol> <li>Navigate to Build &gt; Natural Language &gt; Training &gt; Traits. </li> </ol> <p>The following key features can be leveraged when defining Traits:</p> <ol> <li> <p>Trait Type is a collection of related traits like Travel Class in the above example.</p> <ul> <li>Trait Type can be ML Based or Pattern Based. Each trait of a trait type can be trained using words, phrases, utterances, or patterns based on the type. Manage Trait Type allows you to define the training configuration. See below for ML-based trait configuration.</li> <li>A Trait Type can have one or more Traits. </li> </ul> </li> <li> <p>Traits names should be unique in a group. But traits with the same name can be present in multiple groups.</p> <ul> <li>For ML-based Traits, you can define the words, phrases, or utterances that identify the trait. One trait per trait type is detected for ML-based trait types.</li> <li> <p>For Pattern-based Traits, you can define the patterns associated with the given trait. There is a possibility of multiple traits getting detected for pattern-based trait types. Ordering of Traits within the Trait Type signifies the importance of a trait in a trait type and detects only one trait.</p> <p> <p>Note</p> <p>The latest version of the Platform supports a new patterns engine flag for performance optimization. It offers better response times for pattern evaluation after the virtual assistant training is done.</p> </p> </li> </ul> </li> <li> <p>Once added, Train the assistant for the Traits to be detected from user utterances.</p> </li> </ol> <p>Key Considerations</p> <ul><li>You can add language-specific traits in the case of multi-lingual assistants.</li> <li>When a trait name is modified, ensure that all the rules defined using that trait are corrected. This has to be done manually, the Platform will not handle it automatically.</li> <li>The trait name must be unique in a group.</li> <li>Traits with the same name can be present in multiple groups, but distinguishing them in trait rules or trait detection results is difficult.</li></ul>"},{"location":"automation/natural-language/training/traits/#the-ml-model-for-traits","title":"The ML Model for Traits","text":"<p>When choosing to train traits using the ML model, by default, the n-gram model is used. An n-gram is the contiguous sequence of words used from training sentences to train the model. But this might not be effective when the corpus is very less or when the training sentences, in general, contain fewer words.</p> <p>From v8.0 of the platform, an option is included to skip or use the n-gram model. Further, the option to parameterize the n-gram algorithm is included.</p> <ul> <li>When the n-gram option is selected, you can configure the n-gram Sequence Length by setting the maximum value of the n-gram. It is set to 1 by default and can be configured to any integer value between 1 and 5.</li> <li> <p>When skip-gram is selected, you can configure the following:</p> <ul> <li>Sequence Length specifying the number of words to be included in a non-consecutive sequence. It is set to 2 by default and it can take any integer value between 2 and 4.</li> <li>Maximum Skip Distance for the number of words that can be skipped to form a non-consecutive sequence of words. This value is set to 1 by default and can take any integer value from 1 to 3.</li> </ul> <p> <p>Note</p> <p>While the settings are same for all languages (in case of multilingual bot), for some languages like Chinese and Korean sequence of characters from grams and for other (Latin-based) languages are word grams. </p> </p> </li> </ul>"},{"location":"automation/natural-language/training/traits/#trait-association-rules","title":"Trait Association Rules","text":"<p>Trait Rules define Dialog Execution and Knowledge Graph Intent detection.</p>"},{"location":"automation/natural-language/training/traits/#dialog-execution","title":"Dialog Execution","text":"<p>Intent detection or Dialog execution is achieved using traits, along with the ML utterances and patterns. To achieve this, intent must be associated with the required traits by adding Rules.</p> <p>There are multiple ways to add rules:</p> <ol> <li> <p>From the Traits section using the Add New Rule link. </p> </li> <li> <p>From the Intent Node using the Rules section under the NLP Properties. </p> </li> <li> <p>Click the Rules tab for a given Intent to view the rules under Build &gt; Natural Language &gt; Training. </p> </li> </ol> <p>Each rule can have one or more conditions with AND as the operator. Multiple trait rules can be defined for a given intent and the intent is considered as a definite match if any one of the rules matches.</p>"},{"location":"automation/natural-language/training/traits/#knowledge-graph-intents","title":"Knowledge Graph Intents","text":"<p>The Knowledge Graph can also be part of the discovery process using Traits. For this, each term or node can be associated with a trait. A given term can be associated with a single Trait.</p> <p></p>"},{"location":"automation/natural-language/training/traits/#trait-detection","title":"Trait Detection","text":"<p>Only one trait from a group (trait type) will be detected and is considered as a definite match.</p> <p>Traits detected are included in the context object. The context is populated with unique traits identified (without reference to trait type). This information can be used in:</p> <ul> <li>Intent identification</li> <li>Dialog transition</li> <li>Entity population</li> <li>VA definitions</li> </ul> <p>Batch Testing reports also include information about traits detected as do the Find Intent API.</p>"},{"location":"automation/natural-language/training/traits/#intent-detection","title":"Intent Detection","text":"<p>The Ranking and Resolver gets input from the three NL engines and Traits to analyze and come up with the possible/definitive matches.</p> <ul> <li>The intent is considered as a definite match only if all the traits (one in the case of Knowledge Graph) present in a trait rule are detected.</li> <li>NL Analysis includes information on traits detected and the NLP Flow shows the information about traits detected. </li> </ul>"},{"location":"automation/natural-language/training/traits/#dialog-transition","title":"Dialog Transition","text":"<p>The Conversation Flow is controlled using Traits. For a Dialog, Connection Rules are defined using the Trait Context. This is done from the Connection tab under the Properties Panel for the Dialog.</p> <p>The Traits Context is accessed using <code>context.traits</code>. It returns an array of all traits matching the intent, hence the condition to be used is \u2018contains'. </p>"},{"location":"automation/testing/utterance-testing/","title":"Utterance Testing","text":"<p>To make sure your assistant responds to user utterances with related tasks, it is important that you test it with a variety of user inputs. Evaluating a VA with a large sample of expected user inputs not only provides insights into its responses but also gives you a great opportunity to train it in interpreting diverse human expressions. </p> <p>You can perform all the training-related activities for a VA from the Utterance Testing module. We will use a sample Travel Planning assistant to provide examples within this article.</p>"},{"location":"automation/testing/utterance-testing/#testing-the-assistant","title":"Testing the Assistant","text":"<p>Simply put, testing a VA refers to checking if it can respond to a user utterance with the most relevant task. Given the flexibility of language, users will use a wide range of phrases to express the same intent.</p> <p>For example, you can rephrase I want to change my ticket from San Francisco to Los Angeles on Jan 1 as Please change my travel date. Can\u2019t make it on Jan 1. The trick is to train the assistant to map both of these utterances with the same intent.</p> <p>The first step to start testing a VA is to identify a representative sample of user utterances to test the responses. Look for sources of data that reflect real-world usage of the language, such as support chat logs, online communities, FAQ pages of relevant portals.</p>"},{"location":"automation/testing/utterance-testing/#how-to-test-the-assistant","title":"How to test the assistant","text":"<p>Follow these steps to test your assistant:</p> <ol> <li>Open the assistant that you want to test.</li> <li>Select the Build tab from the top menu.</li> <li>From the left menu click Testing -&gt; Utterance Testing.</li> <li>In the case of a multiple intent model, you can select the Intent Model against which you want to test the utterance. The ML Engine will detect the intents only from the selected model.</li> <li>In the Type a user utterance field, enter the utterance that you want to test. Example: Book a flight.</li> <li>The result appears with a single, multiple, or no matching intents</li> </ol> <p></p>"},{"location":"automation/testing/utterance-testing/#types-of-test-results","title":"Types of Test Results","text":"<p>When you test an utterance, the NLP engine tries to identify an intent using the following  engines and intent identification features:</p> <ul> <li>Machine Learning engine, </li> <li>Fundamental Meaning engine,</li> <li>Knowledge AI, including the Knowledge Graph engine and the Answer from Documents feature,</li> <li>Ranking and Resolver.</li> </ul> <p>Note</p> <p>Utterance testing differs for Knowledge AI and Ranking and Resolver, depending on the NLP version, Ranking and Resolver version, and whether you are using the Few-Shot Knowledge Graph model.</p>"},{"location":"automation/testing/utterance-testing/#utterance-match-classification","title":"Utterance Match Classification","text":"<p>Test results are classified as either Probable Matches or Definitive Matches, as follows; </p> <p>Definitive Matches get high confidence scores and are assumed to be perfect matches for the user utterance. In published assistants, if user input matches with a single Definitive Match, the VA directly executes the task. If the utterances match with multiple Definitive Matches, they are sent as options for the end-user to choose one.</p> <p>On the other hand, Probable Matches are intents that score reasonably well against the user input but do not inspire enough confidence to be termed as exact matches. Internally the system further classifies possible matches into good and unsure matches based on their scores. If the end-user utterances were generating possible matches in a published VA, the assistant sends these matches as \u201cDid you mean?\u201d suggestions for the end-user.</p> <p>Below are the possible outcomes of a user utterance test:</p> <ul> <li>Single Match (Possible or Definitive): The NLP engine finds a match for the user utterance with a single intent or task. The intent is displayed below the User Utterance field. If it is a correct match, you can move on to test the next utterance or you can also further train the task to improve its score. If it is an incorrect match, you can mark it as incorrect and select the appropriate intent.</li> <li> <p>Multiple Matches (Possible or Definitive or Both): NLP engine identifies multiple intents that match with the user utterance. From the results, select the radio button for the matching task and train it. </p> </li> <li> <p>Unidentified Intent: The user input did not match any task in any of the linked assistants. Select an intent and train it to match the user utterance. </p> </li> </ul>"},{"location":"automation/testing/utterance-testing/#entity-match","title":"Entity Match","text":"<p>During testing of the VA, the matched entities are displayed. The entities from the utterance are processed in the following order:</p> <ul> <li>first NER and pattern entities </li> <li>then the remaining entities.</li> </ul> <p>Post v. 8.0 of the XO Platform, the details of how the entity is matched, and with what confidence scores are also displayed. The details include:</p> <ul> <li>Identification Engine \u2013 Machine Learning, Fundamental Meaning or Knowledge Graph;</li> <li>Training Type \u2013 match can be from NER, pattern training, entity name, system concept, etc.. In case of pattern match, click the row to get the details for the same;</li> <li>Confidence Score identified by the ML engine using NER training (only when Conditional Random Field is selected as the NER model) </li> </ul> <p></p>"},{"location":"automation/testing/utterance-testing/#analyzing-the-test-results","title":"Analyzing the Test Results","text":"<p>When you test a user utterance, in addition to the matching intents you will also see an NLP Analysis box that provides a quick overview of the shortlisted intents, the NLP models using which they were shortlisted, corresponding scores, and the final winner. </p> <p>Under the Fundamental Meaning tab, you can see the scores of all the intents even if they aren\u2019t shortlisted.</p> <p>As mentioned above, the Kore.ai NLP engine uses Machine Learning, Fundamental Meaning, and Knowledge Graph (if any) models to match intents. If the NLP engine finds a single Definitive Match through one of the underlying models, you will see the task as the matching intent. If the test identifies more than one definitive match, you will receive them as options to pick the right intent.</p> <p>If the models shortlist more than one possible match, all the shortlisted intents are re-scored by the Ranking and Resolver using the Fundamental Meaning model to determine the final winner.</p> <p>Sometimes, multiple Possible Matches secure the same score even after the rescoring in which case they are presented as multiple matches to the developer to select one. You can click the tab with the name of the learning model in the NLP Analysis box to view the intent scores.</p> <p>Note</p> <p>The NLP score is an absolute value and can only be used to compare against other tasks with the same input. Task scores cannot be compared across different utterances.</p> <p></p> <p>From each model dialog, clicking the icon on the top right will display the configurations and thresholds in place for the corresponding engines.</p>"},{"location":"automation/testing/utterance-testing/#ml-model","title":"ML Model","text":"<p>The ML model tries to match the user input with the task label and the training utterances of each task. If the user input consists of multiple sentences, each sentence is run separately against the task name as well as the task utterances.</p> <p>Click on the Machine Learning Model button to open the Machine Learning Model section of NLP Analysis. This shows only the names of the tasks that secure a positive score. In general, the more the number of training utterances that you add to a task, the greater are its chances for discovery. For more information, read Machine Learning. </p>"},{"location":"automation/testing/utterance-testing/#fm-model","title":"FM Model","text":"<p>Apart from the ML model, each task in the VA is also scored against the user input using a comprehensive custom NLP algorithm that involves different combinations of task names, synonyms, and patterns. The Fundamental Meaning (FM) Model tab shows the analysis for all the intents in the VA. Click the tab to view the scores of each task. Clicking the Processed Utterance shows how the user utterance was analyzed and processed.</p>"},{"location":"automation/testing/utterance-testing/#fm-scoring-model","title":"FM Scoring Model","text":"<p>From v. 7.2, the FM engine generates the model in two ways, depending upon the language of the VA.</p> <p>Approach 1: Supported for German and French languages.</p> <p>The word analysis factors pertaining to Original Word, Universal Parts of Speech, Dependency Relation and Related Word are elaborated.</p> <p>Next, the score breakup for each of the intents processed is displayed. Selecting a scored intent (matched or eliminated) displays the details of the scoring for each word. This includes the words from the utterance and score assigned to each based upon the dependency parsing. </p> <p>Approach 2: Supported for languages, other than the ones mentioned above.</p> <p>The word analysis factors pertaining to Original Word, Role in the sentence and Processed word (in case of spell correction) are elaborated.</p> <p>Next, the score breakup for each of the intents processed is displayed. Selecting a scored intent (matched or eliminated) displays the details of the scoring for each word. The detailed breakdown is given below. </p> <p>The other scoring methods are:</p> <ul> <li>Words Matched: The score given for the number of words in the user input that matched words in the task name or a trained utterance for the task.</li> <li>Word Coverage: The score given for the ratio of the words matched with that of the overall words in the task, including task name, field names, utterances, and synonyms.</li> <li>Exact Words: The score given for the number of words that matched exactly and not by synonyms.</li> <li>Bonus<ul> <li>Sentence Structure: Bonus for the sentence structure match to the user input.</li> <li>Word Position: Score given to a word based on its position in a sentence Individual words towards the start of the sentence are given higher preference. Extra credit if the word is near to the sentence start.</li> <li>Order Bonus: Bonus for the number of words in the same order as the task label.</li> <li>Role Bonus: Bonus for the number of primary and secondary roles (subject/verb/object) matched.</li> <li>Spread Bonus: Bonus for the difference between the position of first and last matched words in a pattern. The higher the difference, the greater the score.</li> </ul> </li> <li>Penalty:<ul> <li>Penalty if there are several phrases before the task name or if there is a conjunction in the middle of the task label.  </li> </ul> </li> </ul>"},{"location":"automation/testing/utterance-testing/#knowledge-graph","title":"Knowledge Graph","text":"<p>If the VA includes a Knowledge Graph, the user utterances are processed to extract the terms and are mapped with the Knowledge Graph to fetch the relevant paths. All the paths containing more than a preset threshold of the number of terms get shortlisted for further screening. Path with 100% terms covered and having a similar FAQ in the path is considered a perfect match.</p> <p>In case the utterance triggers a dialog (as per run a dialog option in KG), the same is displayed as matched intent and matched utterance. You can further train the VA as you would for an intent from ML or FM engine. Know more about Knowledge Graph Training from here. </p>"},{"location":"automation/testing/utterance-testing/#answer-from-documents","title":"Answer from Documents","text":"<p>If you have enabled Answer from Documents for your VA, and a match is found within your uploaded documents, you will see results for this match, provided the intent is not identified using any other method (a dialog task, a Knowledge Graph FAQ, the Machine Learning or the Fundamental Meaning engine).</p> <p>When an utterance is answered from a document, you will see a note mentioning that no Intent was identified by the ML, FM, and KG engines. Click Add to KG to add an FAQ to the Knowledge Graph to address the utterance and improve intent identification. </p> <p>When the Answer from Document feature is used in reply to a test utterance, the following information is provided:</p> <ol> <li>The document from which the answer has been retrieved;</li> <li>An option to view this document;</li> <li>The page where the answer has been identified;</li> <li>A similarity score between the tested utterance and the top-matched document;</li> <li>The content of the answer.</li> </ol> <p></p>"},{"location":"automation/testing/utterance-testing/#ranking-and-resolver","title":"Ranking and Resolver","text":"<p>Ranking and Resolver determines the final winner of the entire NLP computation. If either the ML model or the Knowledge Graph find a perfect match, the ranking and resolver doesn\u2019t re-score the intent and presents it as a matched intent. Even if there are multiple perfect matches, they will be presented as options to the developers from which they can choose.</p> <p>The Ranking and Resolver re-scores all the other good and unsure matches identified by the three models using the Fundamental Meaning model. After re-scoring, if the final score of an intent crosses a certain threshold, it too is considered as a match.</p> <p>Selecting the Ranking and Resolver tab provides you with details on how the winning intent has been determined.</p> <p>The ranking and details for each match can be viewed by selecting the matched utterance. </p>"},{"location":"automation/testing/utterance-testing/#rr-scoring-model","title":"RR Scoring Model","text":"<p>Depending upon the Bot language the scoring model can be:</p> <ul> <li>based on a mixture of word roles, sentence/word positions, and word order; or</li> <li>based on dependency parsing (supported for German and French languages)</li> </ul> <p>The basis for intent elimination by Ranking &amp; Resolver when the three engines return different definite/possible matches is as follows:</p> <ul> <li>Intents matched based upon entity values like date, number etc., by the Machine Learning Model are eliminated.</li> <li>All possible matches identified by any of the three engines are eliminated if a definitive match was found.</li> <li>Definitive match eliminated if another definitive match was found prior to this in the user utterance \u2013 case when the user utterance includes two intents. For example, \u201cBook me a flight and then book a cab\u201d would match \u201cBook Flight\u201d and \u201cBook Cab\u201d but \u201cBook Cab\u201d is eliminated over \u201cBook Flight\u201d.</li> <li>Intent pattern matches following a definitive intent match are eliminated. For example, user utterance \u201ccreate a task to send an email\u201d can match the intents \u201ccreate task\u201d and \u201csend email\u201d, in such cases the \u201csend email\u201d will be eliminated since it follows the intent \u201ccreate task\u201d</li> <li>Intents with scores below the minimum value set in the Threshold and Configurations section are eliminated.</li> <li>Definitive matches which match a Negative Pattern.</li> <li>Intents for which the pre-conditions, in case defined, are not met are eliminated.</li> <li>If the definitive match was from Knowledge Graph Engine by Search In Answer and there is another matched intent.</li> </ul>"},{"location":"automation/testing/utterance-testing/#ranking-and-resolver-v2","title":"Ranking and Resolver v2","text":"<p>Version 2 of the Ranking and Resolver only ranks the scores of the definitive matches from ML and KG engines (not the FM engine) without intent rescoring to ensure the best intent identification accuracy. If you enable Ranking and Resolver Version 2, your test results adjust as follows: </p> <p>The Ranking &amp; Resolver window displays the following:</p> <ul> <li>The definitive intent that is matched based on ranking.</li> <li>The number of definitive and probable matches.</li> <li>The winning intent name and the ranking score.</li> <li>The other definitive intent(s), the reason for elimination, and the ranking score.</li> <li>The result, including the winning and eliminated intents.</li> </ul> <p></p> <p>The NLP Analysis page within the NLP Insights dashboard displays the following:</p> <ul> <li>The given user utterance.</li> <li>The flow of how the NLP models generated the rescored matching intents.</li> <li>The flow of Version 2 of R&amp;R, including the ranking, identification, and marking of the winning intent as the definitive match.</li> <li>The identification and marking of the probable match.</li> </ul> <p></p>"},{"location":"automation/testing/utterance-testing/#training-the-assistant","title":"Training the Assistant","text":"<p>Training is how you enhance the performance of the NLP engine to prioritize one task or user intent over another based on the user input. You should test and, if needed, train your assistant for all possible user utterances and inputs.</p>"},{"location":"automation/testing/utterance-testing/#utterance-based-training","title":"Utterance-based Training","text":"<p>Below is the process we recommend you use for utterance training:</p> <ol> <li>After you enter a User Utterance, depending on the test result do one of the following to open the training options:<ol> <li>For an unmatched intent: From the Select an Intent drop-down list, select the intent that you want to match with the user utterance.</li> <li>For multiple matched intents: Select the radio button for the intent you want to match.</li> <li>For a single matched intent: Click the name of the matched intent.</li> </ol> </li> <li>The user utterance that you entered gets displayed in the field under the ML Utterances section. To add the utterance to the intent, click Save. You can add as many utterances as you want, one after another. For more information, read Machine Learning.</li> <li>Under the Intent Synonyms section, each word in the task name appears as a separate line item. Enter the synonyms for the words to optimize the NLP interpreter accuracy to recognize the correct task. For more information, read Managing Synonyms.</li> <li>Under the Intent Patterns section, enter task patterns for the intent. For more information, read Managing Patterns.</li> <li>When you are done making the relevant training entries, click Re-Run Utterance to see if you have improved the intent to get a high confidence score. </li> </ol> <p></p>"},{"location":"automation/testing/utterance-testing/#view-matched-training-data","title":"View Matched Training Data","text":"<p>The Ranker and Resolver NLP Analysis window lists the matched training data (ML utterances, intent synonyms, questions, patterns, and traits) that helped the ML, KG, or FM engine to identify the qualified intent during utterance testing. This crucial information is available in all the NLU languages of R&amp;R V1 and V2, and helps understand why the given intent is qualified.</p> <p>The system displays the matched training data for the following NLP engines and network models:</p> NLP ENGINE SUPPORTED NETWORK MODELS MATCHED TRAINING DATA Machine Learning     Standard and Few-shot Model.     Sample utterance for every intent qualified.     Knowledge Graph     Ontology and Few-shot Model.     Questions/alternate questions of the qualified FAQs.     Fundamental Meaning     All Models     Pattern for the qualified intents.     <p>For the intents qualified and eliminated in R&amp;R, the system displays the elimination reason in addition to the matched utterance, processed utterance, and the winning intent. </p> <p>Train with FAQ</p> <p>If you want the assistant to respond to user utterance with FAQs there are two ways to do it:</p> <ul> <li>set the terms, term configuration, or classes from the FAQ page, train the KG and retest the utterance.</li> <li>add the utterance as an alternate question to the selected FAQ from the Knowledge Graph page, train the KG and retest the utterance. Know more about Knowledge Graph Training.</li> </ul> <p>Mark an Incorrect Match</p> <p>When a user input matches an incorrect task, do the following to match it with the right intent: </p>"},{"location":"automation/testing/regression-testing/batch-testing/","title":"Batch Testing","text":"<p>Once you have built and trained your bot, the most important question that arises is how good is your bot\u2019s learning model? So, evaluating your bot\u2019s performance is important to delineate how good your bot understands the user utterances.</p> <p>The Batch Testing feature helps you discern the ability of your bot to correctly recognize the expected intents and entities from a given set of utterances. This involves the execution of a series of tests to get a detailed statistical analysis and gauge the performance of your bot\u2019s ML model.</p> <p>Note: The Batch Testing dashboard displays the summary of test coverage, performance, and training recommendations for multiple test suites based on validations of the intent identification capabilities of your NLU model. The Health and Monitoring dashboard is a one-stop place that displays this information for the individual test suite(s) the user selects. Learn More.</p> <p>To conduct a batch test, you can use predefined test suites available in the builder or create your own custom test suites. Based on your requirement, the test suites can be run to view the desired results. This option can be accessed from the Testing -&gt; Batch Testing option from the left navigation menu.</p>"},{"location":"automation/testing/regression-testing/batch-testing/#best-practices","title":"Best Practices","text":"<ul> <li>An optimal approach to bot NLP training is to first create a test suite of most of the use cases(user utterances) that the bot needs to identify, run it against the model and start training for the ones that failed.</li> <li>Create/update batch testing modules for high usage utterances.</li> <li>Publish the trained model only after detailed testing.</li> <li>When naming the intent, ensure that the name is relatively short (3-5 words) and does not have special characters or words from the Stop Wordlist. Try to ensure the intent name is close to what the users request in their utterance.</li> <li>Batch Test executions do not consider the context of the user. Hence you might see some False Negatives in the test results which in fact are True Positives in the actual bot when the context is taken into consideration.</li> <li>The \u2018count\u2019 in Batch Test results refers to the \u2018unique assertion\u2019 statements and not necessarily the number of the rows in the CSV file. Batch tests use a rule to validate the unique assertions based on the \u2018utterance\u2019 in consecutive rows. If two consecutive rows have same utterances and different entity values, the XO platform considers it as one assertion statement which accepts both the entity values.</li> </ul>"},{"location":"automation/testing/regression-testing/batch-testing/#managing-test-suites","title":"Managing Test Suites","text":"<p>Kore.ai provides a few out-of-the-box Test Suites to perform batch testing. 'Developer defined utterances\u2019 and 'Successful user utterances\u2019 are the built-in test suites that can be run to perform Batch Testing. You can also create a New Test Suite for testing a custom set of utterances.</p>"},{"location":"automation/testing/regression-testing/batch-testing/#developer-defined-utterances","title":"Developer defined utterances","text":"<p>This test suite validates the utterances that have been previously added and trained by the developer from Machine Learning Utterances screen. Using this test suite would mean testing collectively the entire set of utterances that a developer has added for all tasks of the bot.</p> <p></p>"},{"location":"automation/testing/regression-testing/batch-testing/#successful-user-utterances","title":"Successful user utterances","text":"<p>This test suite includes all the end-user utterances that have successfully matched one or more intents and the corresponding task is fully executed. You can also find these utterances from the \u2018Intent found\u2019 section of the Analyze module.</p> <p></p>"},{"location":"automation/testing/regression-testing/batch-testing/#adding-a-new-test-suite","title":"Adding a New Test Suite","text":"<p>To add a new test suite, follow the steps below:</p> <ol> <li>Go to Build &gt; Testing &gt; Batch Testing, and click New Test Suite. </li> <li>In the New test Suite window, add a name and provide a description.</li> <li>Next, choose how to add test cases: either manually or by uploading a test case file.<ul> <li>Selecting Add Manually lets you add test cases manually or use LLM and Generative AI to generate test cases automatically.</li> <li>Selecting Upload Test Cases File lets you upload a file containing test cases. </li> </ul> </li> </ol>"},{"location":"automation/testing/regression-testing/batch-testing/#adding-test-cases-manually","title":"Adding Test Cases Manually","text":"<p>Once you create a test suite to which you have chosen to add test cases manually, you can either add them manually or generate them automatically.</p> <p>In the Test Cases page, click the +Add Test Case.</p> <p></p> <p>In the Add Test Case window, select or enter information in the following fields:</p> <ol> <li>The Intent that corresponds to the Dialog Task you want to test. You can add/tag one or more intents to a test utterance.  You can add up to three intents (Dialog, FAQ, or Small Talk) for a test utterance. It helps in scenarios where ambiguity is by-design and should be considered as True Positive. For example, for the utterance \u201cI need help to book a flight ticket,\u201d the expected intent can be either \u201cBook flight\u201d (Dialog) or \u201cHow to book a flight?\u201d (FAQ).</li> <li>The Parent Intent within that task.</li> <li>Test Utterances: You can add multiple utterances, each on a new line.</li> <li> <p>The Entity Order: Select one from the available options, depending on the intent you are working with. You can only select one item. The Entity Order selection is not available if you have added multiple intents.  </p> <p>One Intent for a Test Utterance </p> <p>Multiple Intents for a Test Utterance </p> </li> <li> <p>Click Save when ready.</p> </li> <li>Once added, your test cases are listed and ready to run. You can use the Add Manually button at the top of the list to add more test cases. The option to Generate Test cases only displays if you have enabled LLM and Generative AI for the VA. </li> </ol>"},{"location":"automation/testing/regression-testing/batch-testing/#generating-test-cases-automatically","title":"Generating Test Cases Automatically","text":"<p>You can automatically generate batch test cases if you have enabled LLM and Generative AI  for your Virtual Assistant. You can access the feature either right after creating a new test case, as shown above, or from the test cases list.</p> <p> </p>"},{"location":"automation/testing/regression-testing/batch-testing/#steps-to-generate-test-cases","title":"Steps to Generate Test Cases","text":"<p>To generate test cases automatically, follow the steps below:</p> <ol> <li>Click Generate Test Cases from any of the two areas mentioned above.</li> <li>In the Generate Test Case window, select the Dialog Task you want to test. </li> <li> <p>Click Generate. Wait for a few moments until the generation completes. </p> </li> <li> <p>Once test cases are generated, you can reject some of them. If required, click Generate more to get more suggestions. </p> </li> <li>Click Add Test Cases when ready. </li> </ol> <p>Once you add the test cases, they are listed within your test suite, along with any other cases you might have added manually or generated in the past. You can continue adding test cases to the suite using these two methods.</p> <p> </p>"},{"location":"automation/testing/regression-testing/batch-testing/#adding-a-test-suite-by-uploading-a-test-cases-file","title":"Adding a Test Suite by Uploading a Test Cases File","text":"<p>If you Upload a Test Cases File, you can import an array of test utterances, also known as a Dataset at once in a batch file. The Dataset file must be in a CSV or JSON format and can have a maximum of 1000 utterances. You can download the sample CSV or JSON file formats while creating the test suite.</p> <p>Important Tip: For a Universal Bot, to create a test suite, you can add multiple intents in the CSV/JSON file using the upload method. The format includes the intents and the corresponding bot names as follows:</p> <pre><code>{\n\"input\": \"Utterance\",\n\"intent\": \"Intent 1|Intent 2|Intent 3\",\n\"botName\": \"Bot 1|Bot 2|Bot 3\"\n}\n</code></pre> <p>Example</p> <pre><code>{\n\"input\": \"Need to check the multibot function\",\n\"intent\": \"Age Predictor|IVRnode|Check Rephase\",\n\"botName\": \"Check Bot|XOP211|Check Rephase\"\n}\n</code></pre> <p>The ability to create test suites manually is not yet available for universal bots.</p> <p>JSON Format for Test Suite</p> <p>The JSON format for creating custom suites allows you to define an array of test cases where each test case should consist of an utterance to be tested, the intent against which the utterance to be tested, and optionally define the list of expected entities to be determined from the utterance. If expected intent is a child intent, then you can also include the parent intent to be considered.</p> <p>The sample code is given below:</p> <pre><code>{\n    \"testCases\": [\n    {\n      \"input\": \"Send 200 dollars to Leonardo\",\n      \"intent\": \"Transfer Funds\",\n      \"entities\": [\n        {\n          \"entityValue\": \"200 USD\",\n          \"entityName\": \"TransferAmount\"\n        },\n        {\n          \"entityValue\": \"Leonardo\",\n          \"entityName\": \"PayeeName\"\n        }\n      ],\n      \"entityOrder\":[\"TransferAmount\", \"PayeeName\"]\n    },\n    {\n      \"input\": \"What is the balance in my checking account\",\n      \"intent\": \"Show Balance\",\n      \"parentIntent\": \"Transfer Funds\"\n    },\n    {\n      \"input\": \"Repeat this transfer every month\",\n      \"intent\": \"Setup Auto Pay\",\n      \"parentIntent\": \"Transfer Funds\"\n    },\n    {\n      \"input\": \"Show my past 20 transactions\",\n      \"intent\": \"Show Account Statement\",\n      \"entities\": [\n        {\n          \"entityValue\": \"20\",\n          \"entityName\": \"HistorySize\"\n        }\n      ]\n    },\n    {\n      \"input\": \"Pay my credit card dues\",\n      \"intent\": \"Pay Bill\"\n    },\n    {\n      \"input\": \"I need to pay my monthly credit card bill\",\n      \"intent\": \"Pay Bill | Setup Auto Pay | Transfer Funds\"\n    },\n    {\n\n      \"input\": \"Open an account for me\",\n      \"intent\": \"Open Account | How to Open Account?\"\n    },\n    {\n      \"input\": \"looks like something is wrong in my statement\",\n      \"intent\":\"trait: Account Statement||Issue||Account Type\"\n    },\n    {\n      \"input\": \"How are you doing today\",\n      \"intent\":\"emohowzit\"\n    },\n    {\n      \"input\": \"Thank you\",\n      \"intent\":\"thank~you\"\n    },\n    {\n      \"input\": \"I understand\",\n      \"intent\":\"i_understand\"\n    },\n    {\n      \"input\": \"That's great\",\n      \"intent\":\"~positiveackwords\"\n    },\n    {\n      \"input\": \"How many people can you speak to at once?\",\n      \"intent\":\"How many people can you speak to at once?\"\n    },\n    {\n      \"input\": \"That's sweet\",\n      \"intent\":\"That's sweet\",\n      \"parentIntent\": \"How many people can you speak to at once?\"\n    },\n    {\n      \"input\": \"What else can you do?\",\n      \"intent\":\" What else can you do?\",\n      \"parentIntent\": \"How many people can you speak to at once? &gt;&gt; That's sweet \"\n    },\n    {\n      \"input\": \"What else can you do?\",\n      \"intent\":\"What else\"\n    },\n    {\n      \"input\": \"What's your age?\",\n      \"intent\":\"How old are you?\"\n    },\n    {\n      \"input\": \"Who created you?\",\n      \"intent\":\"Who made you?\"\n    },\n    {\n      \"input\": \"How many people talk to you?\",\n      \"intent\":\"How many people can you speak to at once?\"\n    },\n    {\n      \"input\": \"What's your name?\",\n      \"intent\":\"What is your name?\"\n    },\n    {\n      \"input\": \"What are you called?\",\n      \"intent\":\"What ~you called?\"\n    }\n  ]\n}\n</code></pre> <ul> <li>For Entities that have the Multi-Item enabled, values need to be given as: <code>entity1||entity2</code></li> <li>Composite Entities require passing values in the following format: <code>component1name:entityValue|component2name:entityValue2</code></li> </ul> <p>The sample code is given below:</p> <pre><code>{\n  \"testCases\": [\n    {\n      \"input\": \"Add cart to Apples , Grapes\",\n      \"intent\": \"Add to cart\",\n      \"entities\": [\n        {\n          \"entityValue\": \"Apples||Grapes\",\n          \"entityName\": \"LOV\"\n        }\n       ]\n     },\n      {\n         \"input\": \"I booked a ticket from Hyderabad on July 6th, 2018 and it costed me Rs. 1200\",\n         \"intent\": \"Book a flight\",\n         \"entities\": [\n           {\n            \"entityValue\": \"City:Hyderabad|Date:2018-07-06}Curr:1200 INR\",\n            \"entityName\": \"Composite5\",      \n           }\n        ]\n      }\n   }\n</code></pre> <ul> <li>The order in which the entities are to be extracted can be given as: <code>\"entityOrder\":[\"TransferAmount\", \"PayeeName\"]</code>.  If the order is not provided or partially provided, the platform determines the shortest route covering all the entities as the default order.</li> </ul> PROPERTY NAME TYPE DESCRIPTION Test Cases     Array     Consists of the following: <ul> <li>input  <li>intent  <li>entities </li> input     String     End-user Utterance. Note that if any of the utterances are beyond 3000 characters, the file upload would be rejected.     intent     String     Determine the objective of an end-user utterance (can be task name or primary question in case of FAQ test case) <p> Post-release 7.3, this property can be used to define traits to be identified against this utterance by using the prefix \u201ctrait\u201d for example, Trait: Trait Name1|| Trait Name2||Trait Name3 <p> Post-release 8.0, this property can include the expected Small Talk pattern.     entities     Array [Optional]     Consists of an array of entities to be determined from the input sentence: <ul> <li>entityValue  <li>entityName </li> entityValue     String     Value of the entity expected to be determined from the utterance. You can define the expected Entity Value as a string or use a Regular Expression. For the purpose of Batch Testing, the platform flattens all entity values into string formats.     Please refer to the [Entity Format Conversions](#entity-format-conversions) section for more information.     entityName     String     Name of the entity expected to be determined from the utterance     entityOrder <p> (ver7.1 onwards)     Array [Optional]     An array of entity names specifying the order in which the entities are to be extracted. <p> If the order is not provided or partially provided, the platform determines the shortest route covering all the entities as the default order.     parentIntent     String [Optional]     Define parent intent to be considered if the intent is a sub-intent. <p> In the case of Small Talk, this field should be populated when the Small Talk is contextual follow-up intent; in case of multi-level contextual intent the parent intents should be separated by the delimiter ||     <p>CSV Format for Test Suite</p> <p>CSV format for creating custom suites allows you to define test cases as records in CSV file where each test case should consist of an utterance to be tested, the intent against which the utterance to be tested, and optionally define entities to be determined from the utterance. If your test case requires more than one entity to be detected from a sentence, then you have to include an extra row for each of the additional entities to be detected. If expected intent is a child intent, then you can also include the parent intent to be considered.</p> <pre><code>input,intent,parentIntent,entityName,entityValue,entityOrder\nSend 200 dollars to Leonardo, Transfer Funds,,TransferAmount,200 USD,,\n,,,PayeeName,Leonardo, TransferAmount&gt;PayeeName\nWhat is the balance in my checking account,Show Balance, Transfer Funds,,,\nRepeat this transfer every month, Setup Auto Pay, Transfer Funds,,,\nShow my past 20 transactions, Show Account Statement,,HistorySize,20,,\nPay my credit card dues,Pay Bill,,,,,\n</code></pre> <ul> <li>For Entities that have the Multi-Item enabled values need to be given as: <code>entity1||entity2</code></li> <li>Composite Entities require the values in the following format:<code>component1name:entityValue|component2name:entityValue2</code> Sample:</li> </ul> <pre><code>input,intent,parentIntent,entityName,entityValue\n\"Add cart to Apples , Grapes\",Add to cart,LOV,Apples||Grapes,,\n\"I booked a ticket from hyderabad on July 6th, 2018 and it cost me Rs. 1200\",Composite Test,Composite55,City5:Hyderabad|Date5:2018-07-06\"|Curr5:1200 INR\n</code></pre> <ul> <li>The order of extraction of entity value can be mentioned in the following format: <code>entity3&gt;entity4&gt;entity1</code>.  If the order is not provided or partially provided, the platform determines the shortest route covering all the entities as the default order.</li> </ul>  table, th, td {   border: 1px solid black; }  COLUMN NAME TYPE DESCRIPTION input     String     Utterance given by the end-user. Note that if any of the utterances are beyond 3000 characters, the file upload would be rejected.     intent     String     Determine the objective of an end-user utterance (can be task name or primary question in case of FAQ test case) <p> Post release 7.3, this property can be used to define traits to be identified against this utterance by using the prefix \u201ctrait\u201d for example, Trait: Trait Name1|| Trait Name2||Trait Name3 <p> Post-release 8.0, this property can include the expected Small Talk pattern.     parentIntent     String [Optional]     Define parent intent to be considered if the intent is a sub-intent <p> In the case of Small Talk, this field should be populated when the Small Talk is contextual follow-up intent and the intent would be matched assuming that the follow-up intent criteria is met; in the case of multi-level contextual intent the parent intents should be separated by the delimiter ||     entityValue     String [Optional]     Value of the entity expected to be determined from the utterance. You can define the expected Entity Value as a string or use a Regular Expression. For the purpose of Batch Testing, the platform flattens all entity values into string formats. Please refer to the [Entity Format Conversions](#entity-format-conversions) section for more information.      entityName     String [Optional]     Name of the entity expected to be determined from the utterance     entityOrder <p> (ver7.1 onwards)     Array [Optional]     An array of entity names separated by &gt; specifying the order in which the entities are to be extracted. <p> If the order is not provided or partially provided, the platform defines the implicit order to process first the NER and pattern entities and then the remaining entities."},{"location":"automation/testing/regression-testing/batch-testing/#entity-format-conversions","title":"Entity Format Conversions","text":"table, th, td {   border: 1px solid black; }  ENTITY TYPE SAMPLE ENTITY VALUETYPE VALUE IN FLAT FORMAT ORDER OF KEYS Address     P.O. Box 3700 Eureka, CA 95502     P.O. Box 3700 Eureka, CA 95502     Airport     { \u201cIATA\u201d: \u201cIAD\u201d, \u201cAirportName\u201d: \u201cWashington Dulles International Airport\u201d, \u201cCity\u201d: \u201cWashington D.C.\u201d, \u201cCityLocal\u201d: \u201cWashington\u201d, \u201cICAO\u201d: \u201cKIAD\u201d, \u201cLatitude\u201d: \u201c38.94\u201d, \u201cLongitude\u201d: \u201c-77.46\u201d }     Washington Dulles International Airport IAD KIAD 38.94 -77.46 Washington D.C. Washington     AirportName IATA ICAO Latitude Longitude City CityLocal     City     Washington     Washington     Country     { \u201calpha3\u201d: \u201cIND\u201d, \u201calpha2\u201d: \u201cIN\u201d, \u201clocalName\u201d: \u201cIndia\u201d, \u201cshortName\u201d: \u201cIndia\u201d, \u201cnumericalCode\u201d: 356}     IN IND 356 India India     alpha2 alpha3 numericalCode localName shortName     Company or Organization Name     Kore.ai     Kore.ai     Color     Blue     Blue     Currency     [{ \u201ccode\u201d: \u201cUSD\u201d, \u201camount\u201d: 10 }]     10 USD     amount code     Date     2018-10-25     2018-10-25     Date Period     { \u201cfromDate\u201d: \u201c2018-11-01\u201d, \u201ctoDate\u201d: \u201c2018-11-30\u201d }     2018-11-01 2018-11-30     fromDate toDate     Date Time     2018-10-24T13:03:03+05:30     2018-10-24T13:03:03+05:30     Description     Sample Description     Sample Description     Email     user1@emaildomain.com     user1@emaildomain.com     List of Items(Enumerated)     Apple     Apple     List of Items(Lookup)     Apple     Apple     Location     { \u201cformatted_address\u201d: \u201c8529 Southpark Cir #100, Orlando, FL 32819, USA\u201d, \u201clat\u201d: 28.439148,\u201dlng\u201d: -81.423733 }     8529 Southpark Cir #100, Orlando, FL 32819, USA 28.439148 -81.423733     formatted_address lat lng     Number     100     100     Person Name     Peter Pan     Peter Pan     Percentage     0.25     0.25     Phone Number     +914042528888     +914042528888     Quantity     { \u201cunit\u201d: \u201cmeter\u201d, \u201camount\u201d: 16093.4, \u201ctype\u201d: \u201clength\u201d, \u201csource\u201d: \u201c10 miles\u201d }     16093.4 meter length 10 miles     amount unit type source     String     Sample String     Sample String     Time     T13:15:55+05:30     T13:15:55+05:30     Time Zone     -04:00     -04:00     URL     https://kore.ai     https://kore.ai     Zip Code     32819     32819     <p>Importing a Dataset file</p> <ol> <li>Click New Test Suite on the batch testing page. A dialog box to import the dataset appears.</li> <li>Enter a Name, Description, and choose a Dataset Type in the respective boxes for your dataset file.</li> <li> <p>To import the Dataset file, click Choose File to locate and select a JSON or CSV file containing the utterances as per the Dataset Type selected. </p> </li> <li> <p>Click Create. The dataset file is displayed as an option to run the test suite on the Batch Testing page:</p> </li> </ol>"},{"location":"automation/testing/regression-testing/batch-testing/#running-test-suites","title":"Running Test Suites","text":"<p>The following steps guide you on how to run a batch test on your bot and get a detailed analytical report on the utterances based on the test results. To get started, go to Build &gt; Testing &gt; Batch Testing.</p> <p>Note</p> <p>Before testing, it is essential to add and train your bot with a considerable number of utterances using Machine Learning.</p> <p></p> <p>To run a Test Suite, follow the steps below:</p> <ol> <li>Click the desired test suite name in the Batch Testing window. Note that Developer Defined Utterances and Successful User Utterances are default test suites to validate user utterances through Batch Testing.</li> <li>Select In Development to run batch tests on test suites for only the in-development version of the Virtual Assistant(s). Alternatively, select Published to run batch tests on test suites for only the published version of the Virtual Assistant(s).</li> <li>Click Run Test Suite to initiate the batch test execution. </li> </ol>"},{"location":"automation/testing/regression-testing/batch-testing/#execution-of-newly-created-batch-test-suites","title":"Execution of Newly Created Batch Test Suites","text":"<p>Once you create a new test batch test suite, by default, the system automatically initiates test run execution for both In-development and Published VA versions. This makes it convenient to assess test results while the VA is in development and once a VA is published following a production release.</p> <p> </p>"},{"location":"automation/testing/regression-testing/batch-testing/#view-test-case-details","title":"View Test Case Details","text":"<p>Running a test suite will display the results as described below.</p> <p>Note: The test case with multiple intents is considered a test case for all the intents mentioned. For example, if a test case has Intent 1 and Intent 2 as expected intents, then Intent 1 and Intent 2 are shown as covered in the batch test summary.</p> <p>Each test run creates a test report record and displays a summary of the test result. The batch test result in the screenshot below includes the following information:</p> <ul> <li>Last Run Date &amp; Time that displays the date and time of the latest test run.</li> <li>F1 Score is the weighted average of Precision and Recall i.e. (2*precision*recall)/(precision+recall).</li> <li>Precision is the number of correctly classified utterances divided by the total number of utterances that got classified (correctly or incorrectly) to an existing task ie the ratio of true positives to all classified positives (sum of true and false positives) i.e. TP/(TP+FP).</li> <li>Recall is the number of correctly classified utterances divided by the total number of utterances that got classified correctly to any existing task or classified incorrectly as an absence of an existing task ie the ratio of correctly classified utterances to actual matching intents/tasks (sum of true positives and false negatives) i.e. TP/(TP+FN).</li> <li>Intent Success % that displays the percentage of correct intent recognition that has resulted from the test.</li> <li>Entity Success % that displays the percentage of correct entities recognized that has resulted from the test.</li> <li>Version Type identifies the version of the bot against which the test suite was run \u2013 development or published.</li> <li> <p>There are three possible outcomes from each test run:</p> <ol> <li>Success \u2013 when all records are present in the file are processed</li> <li>Success with a warning \u2013 when one or more records present in the suite are discarded from detection due to system error</li> <li>Failed \u2013 when there was a system error and the test could not be resumed post-recovery.</li> </ol> </li> <li> <p>Hovering over the warning/error icon will display a message suggesting the reason. </p> </li> </ul>"},{"location":"automation/testing/regression-testing/batch-testing/#download-a-csv-report","title":"Download a CSV Report","text":"<p>To get a detailed analysis of the test run, click the Download icon to download the test report in CSV format. You have an option to delete the test results if needed. The top section of the report comprises the summary with the following fields:</p> <ul> <li>Bot Name</li> <li>Report name of the test suite</li> <li>Bot Language (post 7.3 release)</li> <li>Run Type identifies the version of the bot against which the test suite was run \u2013 development or published.</li> <li>Threshold Setting (post 7.3 release) detailing the NLP thresholds applied when running this test suite, this would be followed by the settings for each of the three NL engines with the following details:<ul> <li>Mode \u2013 ml, faq, or, cs</li> <li>minThreshold</li> <li>maxThreshold</li> <li>exactMatchThreshold</li> <li>isActive</li> <li>taskMatchTolerance</li> <li>wordCoverage</li> <li>suggestionsCount</li> <li>pathCoverage</li> </ul> </li> <li>Last Tested: Date of the latest test run for developer-defined utterances.</li> <li>Utterance Count: Total number of utterances included in the test run.</li> <li>Success/Failure Ratio: Total number of successfully predicted utterances divided by the total count of utterances multiplied by 100.</li> <li>True Positive (TP): Percentage of utterances that have correctly matched expected intent.In the case of Small Talk, TP is indicated when the list of expected and actual intents are the same.In the case of Traits, a TP state includes the traits matched over and above the expected matches. Note that when you tag multiple intents (dialog, FAQ, and small talk) to a test utterance, the test result appears as TP if the actual intents match the expected intents but also include ambiguous intents.</li> <li>True Negative (TN): Percentage of utterances that were not expected to match any intent and they did not match. Not applicable to Small Talk.</li> <li>False Positive (FP): Percentage of utterances that have matched an unexpected intent. In the case of Small Talk, it would be when the list of expected and actual intents are different.</li> <li>False Negative (FN): Percentage of utterances that have not matched expected intent. In the case of Small Talk, it would be when the list of expected Small Talk intent is blank but the actual Small Talk is mapped to an intent. </li> </ul> <p>The report also provides detailed information on each of the test utterances and the corresponding results.</p> <ul> <li>Utterances- Utterances used in the corresponding test suite.</li> <li>Expected Intent\u2013 The intent expected to match for a given utterance, will include trait where applicable with trait prefix</li> <li>Matched Intent \u2013 The intent that is matched for an utterance during the batch test. This will include matched traits with trait prefix (post 7.3 release). This will include matched Small Talk intents (post 8.0 release).</li> <li>Parent Intent \u2013 The parent intent considered for matching an utterance against an intent.</li> <li>Task State \u2013 The status of the intent or task against which the intent is identified. Possible values include Configured or Published</li> <li>Result Type\u2013 Result categorized as True Positive or True Negative or False Positive or False Negative</li> <li>Entity Name \u2013 The name of the entity detected from the utterance.</li> <li>Expected EntityValue \u2013 The entity value expected to be determined during the batch test.</li> <li>Matched EntityValue \u2013 The entity value identified from an utterance.</li> <li>Entity Result \u2013 Result categorized as True or False to indicate whether the expected entity value is the same as the actual entity value.</li> <li>Expected Entity Order \u2013 entity values from the input file</li> <li>Actual Entity Order \u2013<ul> <li>if the order for all expected entities is provided, then the same is included in this column</li> <li>if no order is provided, the system determined order will be included in the column</li> <li>If an order is provided for some entities, then a combination of user-defined order and system-defined order will be included</li> </ul> </li> <li>Matched Intent\u2019s Score \u2013 For False Positives and False Negatives, the confidence scores from FM, ML, and/or KG engines are displayed for the matched intent from the utterance. Note that the scores are given only if the engine detects the intent, which means that you may not see the scores from all three engines at all times.</li> <li>Expected Intent\u2019s Score \u2013 For False Positives, the confidence scores for the intent expected to match for the given utterance is given. Again the score will be given by the engines detecting the intent.</li> </ul> <p>Tip</p> <p>For any of the batch tests, if results indicate that your bot is unable to recognize the correct intents, you can work on improving its performance by adding or modifying utterances to the Machine Learning model.</p>"},{"location":"automation/testing/regression-testing/batch-testing/#batch-test-results-for-universal-bots","title":"Batch Test Results for Universal Bots","text":"<p>The XO Platform now displays Batch Test Results for Universal bots for each test run in the summary view for FAQs, Dialog Intents, and Small Talk during Batch Testing. The actionable insights help understand the test coverage and NLP performance for each intent type in the Universal Bot. Learn more.</p>"},{"location":"automation/testing/regression-testing/batch-testing/#view-individual-test-run-summary","title":"View Individual Test Run Summary","text":"<p>You can view the individual Batch Test Run summary of a test suite by clicking the View Summary icon of a test as shown below.</p> <p> </p> <p>This displays the relevant NLP and Flow Health metrics on the Health and Monitoring Dashboard for intents mapped to Dialogs, FAQs, and Traits. Learn More.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/conversation-testing-landing-page/","title":"Conversation Testing Overview","text":"<p>Conversation Testing enables you to simulate end-to-end conversational flows to evaluate the dialog task execution or perform regression. You can create Test Suites to capture various business scenarios and run them at a later time to validate the assistant\u2019s performance.</p> <p>The Conversation testing framework tracks the transition coverage and determines how well the Virtual Assistant (VA) understands the user queries and executes the dialogs and other intents of user conversations for a particular input(s). Like the NLP Health in the Health and Monitoring dashboard a Flow health feature available in the Health and Monitoring dashboard presents a summary of the total coverage of dialog flows and analysis of conversation test results of your VA. This summary helps you understand the flow transitions and intent coverage in test suites. It enables you to add relevant test cases to cover missing transitions and intents. You can also use the test result analysis to identify and fix the issues in the dialog task definitions and improve the performance of your VA. </p>"},{"location":"automation/testing/regression-testing/conversation-testing/conversation-testing-landing-page/#conversation-testing-landing-page","title":"Conversation Testing Landing Page","text":"<p>Go to Build \u2192 Testing \u2192 Conversation Testing to access the Conversation Testing page. It lists all the Test Suites with details in a grid. All the Test Suite details like the Test Suite name, the execution status in the Result column, Duration of execution, Number of passed and failed test cases, Number of test cases not executed, the percentage of passed test cases, and tags added to the test suite during its creation are all displayed in the grid. Using tags, you can easily organize the test suites and filter them.</p> <p> </p> <p>Note<p>Only the results of the latest executions of test suites are displayed on the page. The details in each column can be searched and filtered as shown below.</p> </p> <p> </p> <p>You can also filter the details at the grid level by applying filters for intents covered in all the test suites.</p> <p>Note<p>Using this feature, you can identify test suites covering specific intent(s) and run them if you want to perform regression after definitions of an Intent or set of Intents are changed.</p> </p> <p> </p> <p>Note<p>On the Conversation Testing dashboard, you can edit the test suite, clone, export, or delete it, as shown in the following screenshot. You can also rearrange the order of the columns by dragging and placing them in a different place in the grid.</p> </p> <p> </p> <p>The Conversation Testing allows you to capture the flow, track the executed nodes, covered transitions, and metadata. Following are the major options available on the Conversation Testing page:</p> <ul> <li>Create a Test Suite</li> <li>Test Editor</li> <li>Test Case Assertion</li> <li>Test Case Execution Summary</li> </ul> <p>  [Previous](../../batch-testing){:target=\"_blank\"} <pre> <pre> [Next](../create-a-test-suite\"){:target=\"_blank\"}"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/","title":"Create a Test Suite","text":"<p>A Test Suite contains a collection of test cases grouped to simulate a specific conversation between the user and the bot and used anytime for test execution. You can know the execution status and determine and analyze the results in a test suite.</p> <p>In Conversation testing, you can create the test suites in the following two different ways:</p> <ul> <li>Record Conversation to Create a Test Suite</li> <li>Upload File to Create a Test Suite</li> </ul>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#record-conversation-to-create-a-test-suite","title":"Record Conversation to Create a Test Suite","text":"<p>The option to record the test suite captures the metadata in the background which helps to test the flow sequence, transitions, and track the test coverage. The following step-by-step process explains how to record a conversation as a test suite, and validate and create the test cases.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#record-test-suite","title":"Record Test Suite","text":"<ol> <li>On the Conversation Testing page, click New Test Suite.</li> <li> <p>Click the Record option to start recording the new test. </p> </li> <li> <p>In the displayed pop-up, click Proceed to record the test with the On-Connect event or click the Skip On-Connect button. </p> </li> </ol> <p>Note: \"On-Connect\" is the message you receive as soon as you open the chat window, even before you enter any message. The option is displayed for VAs with an On-Connect message. If you skip it, the On-connect message does not get added as a test case. If you click Proceed, then the On-connect message is created as a separate test case.      </p> <ol> <li>The Chat window is displayed. The chat transcript is recorded and the recording status is displayed at the top. You can click Stop to stop the recording. </li> </ol> <p>Note: If there is an error while recording due to any limitation set on the platform, it is displayed on the page.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#generated-user-response-suggestions","title":"Generated User Response Suggestions","text":"<p>If you have enabled LLM and Generative AI for your Virtual Assistant, you will see User Response suggestions while recording a Conversation Test Case. </p> <p>This feature provides a regression tool that creates a conversation test suite for each intent (new and old) to evaluate the impact of a change on the conversation execution. It helps check if the task or intent is robust enough to handle random user utterances. </p> <p>It also helps you predict and simulate the end user\u2019s behavior and check if the VA can execute all the defined flows by generating user responses and presenting any digressions from the specified intent.</p> <p>Click any suggestion to send it to your VA and test the response. </p> <p>You can refresh the suggestions list or minimize the suggestions panel. You can also talk to your VA by typing in your responses. </p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#validate-test-suite","title":"Validate Test Suite","text":"<p>The conversation is recorded and all the metadata at each test case is captured. Once the recording is completed, the Platform provides you an option to validate the test suite as follows:</p> <ol> <li> <p>Upon successful completion of recording, click Validate Test Suite. </p> </li> <li> <p>The ongoing validation is displayed. You may click Cancel if you want to cancel the step or click Continue in Background to continue the validation as a background task. </p> </li> <li> <p>If you click Continue in Background, you can see the status in the top right corner of the landing page by clicking the Draft icon. </p> </li> </ol> <p>Note: \"On-Connect\" is the message you receive as soon as you open the chat window, even before you enter any message. The option is displayed for VAs with an On-Connect message. If you skip it, the On-connect message does not get added as a test case. If you click Proceed, then the On-connect message is created as a separate test case.  </p> <ol> <li>The Chat window is displayed. The chat transcript is recorded and the recording status is displayed at the top. You can click Stop to stop the recording. </li> </ol> <p>Note: If there is an error while recording due to any limitation set on the platform, it is displayed on the page.  </p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#capture-test-suite-metadata","title":"Capture Test Suite Metadata","text":"<p>Using Conversation Testing, you can test the sequence of nodes executed by the VA for user input(s) and capture the following metadata at the time of test suite creation to verify if the VA is executing the conversation flows as expected:</p> <ul> <li>Intent ID, Intent Name</li> <li>Node ID, Node Name</li> <li>Transition flow</li> </ul> <p>The metadata are captured in both Record and Upload scenarios for all the VA responses of all the test suites. The details to be captured vary based on the intent type of the VA response. For more information on the details captured here, see Test Editor.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#create-test-suite","title":"Create Test Suite","text":"<ol> <li> <p>Upon approval, a Create Test Suite pop-up is displayed in which you can enter the following details:</p> <ul> <li>Test Suite Name</li> <li>Description</li> <li>Tags </li> </ul> </li> <li> <p>You can either click Create to create the test suite or discard this step.</p> </li> <li> <p>On clicking Create, the new test suite is created. You can click the Run Test Suite button to execute the test suite. </p> </li> <li> <p>The dialog Before you execute the test Suite is displayed. Select the version of your VA to be executed. If any authorization profiles are available, they are displayed here. </p> </li> <li> <p>Click Continue to continue the execution. The test cases execution progress is displayed on the top right corner of the page. </p> </li> </ol> <p>If the test cases are passed, the Result is displayed as Passed, as shown in the screenshot below. </p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#upload-file-to-create-a-test-suite","title":"Upload File to Create a Test Suite","text":"<p>Using this option, you can create test suites by uploading chat transcripts in a pre-defined JSON file. This alternative way of creating test suites is quick and scalable, as compared to recording the flow every time. The following step-by-step process explains how to upload a JSON file, validate and create the test suites.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#upload-a-json-file","title":"Upload a JSON File","text":"<ol> <li>Click New Test Suite.</li> <li> <p>Click the Upload option to upload a chat transcript in JSON format. </p> </li> <li> <p>You can drag and drop a predefined JSON file in the Upload pop-up or select the file in the local directory using the browse option. </p> </li> </ol> <p>Note: Only JSON files can be uploaded. The maximum file size allowed for upload is 2MB. You can also download a sample JSON file by clicking the Download JSON Sample button.</p> <p>If there is an error during upload due to any limitation set on the platform, an error is displayed as follows.  </p> <p>If an uploaded JSON file exceeds the configured size limit of 2 MB, an error is displayed as shown below.  </p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#validate-test-suite_1","title":"Validate Test Suite","text":"<p>The platform processes the uploaded file to simulate the conversation flow and capture all the metadata at each test case. When validating the test suite, there is an option to go back to Conversation testing while the test suite is being validated in the background.</p> <p>The steps to validate test suites are the same as in Record Test suite Flow. See Validate Test Suite for more information. To understand more about testing the sequence of nodes and capturing metadata, see Capture Test Suite Metadata under Validate Test Suite.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/create-a-test-suite/#create-test-suite_1","title":"Create Test Suite","text":"<p>The steps to create a test suite are the same as in Record Test suite Flow. See Create Test Suite to know more.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/","title":"Glossary","text":"<p>The following list provides definitions of commonly used terms in conversation testing.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#dynamic-text-marking","title":"Dynamic Text Marking","text":"<p>The dynamic text annotation feature allows you to annotate a section of the text. During test execution, the annotated portion of the text is ignored by the platform for text assertion. To know more, see Dynamic Text Marking.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#test-assertion","title":"Test Assertion","text":"<p>A test case assertion is an expression that encapsulates a testable logic specified for a conversation testing test case.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#test-coverage","title":"Test Coverage","text":"<p>The test coverage shows the amount of testing performed for the test suites by capturing details like how many transition flows or Intents are covered for the test suites. It helps to add more test cases to cover the missed intents and transitions.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#test-case","title":"Test Case","text":"<p>A test case is a set of actions designed to test the behavior of a conversational system in a specific scenario. Test cases ensure that the conversational system is functioning correctly and meeting the specified requirements and guidelines. When creating a test case, you can define a set of user inputs and expected bot responses and then perform the test by interacting with the conversational system and verifying that it provides the expected responses.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#test-suite","title":"Test Suite","text":"<p>A conversation test suite has a set of test cases that helps the testers to execute and report the test execution results.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#test-suite-metadata","title":"Test Suite Metadata","text":"<p>The test suite metadata captured in conversation testing are details like Intent id, node id, intent and node names, transition flows, etc., that provide more information about the test suites. The metadata captured can be used to track the test coverage and to perform the flow and text assertions.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/glossary/#transition-flow-of-nodes","title":"Transition Flow of Nodes","text":"<p>In conversation testing, you test the correct sequence of the nodes traversed in the background for any user input. For more information, see Nodes.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/","title":"Test Case Assertion","text":"<p>A test case assertion is a statement specifying a condition that must be satisfied for a test case to be considered successful. In the context of conversational systems, test case assertions can be used to validate various aspects of the conversation, such as the correctness of the response to a user\u2019s input, the correctness of the conversation flow, and the correctness of the conversation context. By including multiple assertions in a test case, you can thoroughly test the behavior of a conversational system and ensure that it is functioning as expected.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#types-of-assertions","title":"Types of Assertions","text":"<p>This section describes the types of assertions available for different intent types.</p> <p>Dialog Node Assertions</p> <p>If the virtual assistant\u2019s response is from a Dialog node, then the following assertions are available:</p> <ul> <li> <p>Flow Assertion: A Flow assertion tests the flow of the path traversed by every user input during a conversation to check whether the responses are provided from the correct node or not. It helps to detect and handle any deviations from the expected flow.</p> <ul> <li>It refers to the tasks, nodes, FAQs, or standard responses that were triggered during the flow execution. This ensures that the bot has traversed the same path as expected.</li> <li>It is enabled by default. You can disable it if required.</li> <li> <p>This section shows the summary on the right side of the Test Suite panel:</p> <ul> <li>Expected Node</li> <li>Expected Intent</li> <li>Transitions  </li> </ul> <p></p> </li> </ul> </li> <li> <p>Text Assertion: A Text assertion tests the content presented to the user (string-to-string match), and provides support for dynamic values. Text assertions compare the text of the expected output with the actual output.</p> <ul> <li>It is enabled by default. You can disable it if required.</li> <li> <p>This section shows the summary on the right side of the Test Suite panel:</p> <ul> <li>Expected Response: Contains all possible responses/variations with the annotated dynamic values.  </li> </ul> <p> </p> </li> </ul> <p>Note: In case of text assertion, if the expected output has dynamic values, then it should be annotated using Dynamic Text Marking. If not marked, the text assertion fails and eventually leads to failure of the test case. For the test case to pass, the text for that specific output must be dynamically marked.  </p> <p>For example, in the following test case, the city name entered by the user can be different every time. It is marked as dynamic for that specific test case to pass. </p> <p>The test case and text assertion can be seen as passed in the Result Summary. If the text is not marked as dynamic, the test case would fail. </p> </li> <li> <p>Context Assertion: A context assertion can be used to test the presence of specific context variables during a conversation. By using a context assertion, you can verify that the correct context variables are present at a specific point in the conversation, which can be helpful for ensuring the smooth and successful execution of the conversation flow.  </p> <ul> <li> <p>It is disabled by default. You can enable it if required. </p> </li> <li> <p>Once enabled, you can click the Add button to add key-value pairs of context variables. </p> <p> </p> </li> <li> <p>This section shows a summary of added variables:</p> <ul> <li>Key</li> <li>Value  </li> </ul> </li> </ul> <p>Note: The Context assertion label is added or removed to the test case in a validated chat based on whether it is enabled or disabled. As you add one pair, text boxes to add another pair get displayed. Once added, the saved key-value pairs are retained even if the assertion is disabled.  If the VA response is from a FAQ or Small Talk or Standard Response, the Flow assertion has only Expected Node. The behavior of Text and Context assertions is the same as how it is for Dialog intent.</p> </li> </ul>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#dynamic-text-marking","title":"Dynamic Text Marking","text":"<p>The dynamic text annotation feature in the Expected Output allows you to annotate a section of the text. You can add one or more annotations for a VA response.  </p> <p>During test execution, the annotated portion of the text is ignored by the platform for text assertion. You can view all the added annotations of VA\u2019s responses and be able to remove them.</p> <p>Note<p>Even if the value of the specific marked text is different, the test cases are marked as a success during execution. This feature is handy when different values are expected every time you interact with the bot.</p> </p> <p>The following steps explain the dynamic text marking with an example:</p> <ol> <li>Click any Test Suite on the Conversation Testing page.</li> <li>In the Test Editor tab, navigate to the Test Suite Details Panel.</li> <li> <p>In the Test Suite Details panel, select a text in the Expected Output for a test case and click the Dynamic Marker icon (see the following screenshots). </p> <p> </p> <p>Note: The selected state variable in the Expected Output is annotated and highlighted in blue. One or multiple words can be marked as dynamic text.  </p> </li> <li> <p>You can again click the Dynamic Marker icon to deselect the text and remove the dynamic marking.</p> </li> <li>Click the Dynamic Marker icon next to the list to expand and see the list of dynamic values. </li> </ol>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#test-coverage","title":"Test Coverage","text":"<p>The Test Coverage captures details like how many transitions or Intents are covered for this test suite. It helps add more test cases to cover the missed intents and transitions.</p> <p>This section explains how to access the Test Coverage and its details. </p> <p>On the Conversation Testing landing page, in the Test Suite Details grid, click any Test Suite and then click the Test Coverage tab. Test Coverage contains the following three sub-tabs:</p> <ul> <li>Dialog Intents</li> <li>FAQs</li> <li>Small Talks</li> </ul>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#dialog-intents","title":"Dialog Intents","text":"<p>This page provides transition coverage information and details of transitions across the Dialog intents.</p> <p>Transition Coverage</p> <p>The following details are displayed in the Transition Coverage section:  </p> <ul> <li>Total Transitions \u2013 Total number of unique transitions available in the VA definition across all the intents.  </li> <li>Covered \u2013 Count and percentage of unique transitions covered as part of the Test Case definition against the Total Transitions list.  </li> <li>Not Covered \u2013 Count and percentage of unique transitions not covered as part of the Test Case definition against the Total Transitions list.  </li> </ul> <p></p> <p>For example, the VA has total 292 transitions, out of which the coverage is as follows:</p> <ul> <li>Covered \u2013 15 Transitions and 5.14%</li> <li>Not Covered \u2013 277 Transitions and 94.86%</li> </ul> <p>Note<p>If you delete the node transition in a particular intent, then such transitions are displayed as Not Valid in the Coverage Status column.</p> </p> <p>Intent Coverage</p> <p>All the intents and their transition coverage details are displayed in this section.  </p> <p>The following details are displayed in the grid:</p> <ul> <li>Intent Name  </li> <li>Coverage Status  </li> <li>Total Transitions  </li> <li>Transition Covered  </li> <li>Transition Coverage (%)</li> </ul> <p></p> <p>You can obtain Node transition details of an intent by clicking the View Transitions slider. The Node Transitions pop-up displays the following details:  </p> <ul> <li>From Node  </li> <li>To Node  </li> <li>Coverage Status</li> </ul> <p></p> <p>Note<p>A transition must have one of the following three values displayed in the Coverage Status column:</p> <ul> <li>Covered  </li> <li>Not Covered  </li> <li>Not Valid</li> </ul> </p> <p>You can sort, search, and filter the data for all the columns in the Intent coverage grid.  </p> <p></p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#faqs","title":"FAQs","text":"<p>In the FAQs tab of Test Coverage, all the unique FAQ names covered in this test suite are displayed.  </p> <p></p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-assertion/#small-talk","title":"Small Talk","text":"<p>All the Small Talks covered in the test cases are displayed in this tab in two columns:  </p> <ul> <li>Pattern  </li> <li>Group</li> </ul> <p>To know more about Patterns and Groups, see Small Talk.</p> <p></p> <p>Note<p>You can filter and sort the details displayed in the Small Talks grid.</p> </p> <p>On the main page, the Test Suite is marked as Passed only when all the test cases are passed; else, it is marked as Failed.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/","title":"Test Case Execution Summary","text":"<p>The Test Case Execution Summary allows you to view the test case results, identify the failed test cases, and resolve the flow of the virtual assistant. It gives complete details of the overall test results and the defects found.</p> <p>The following sections explain the options available on the Conversation Testing to execute the test cases and interpret the results, which help analyze the performance of the test suite as a whole and the individual test cases.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#test-case-execution","title":"Test Case Execution","text":"<p>You can execute test cases on the Conversation Testing Landing Page and the individual Test Case details page. Follow these steps for test execution:</p> <ol> <li> <p>On the Test Suite Details page, select the test suite and then click the Run Test Suite button for that specific suite. </p> <p>Note: You can also execute the test cases by clicking the Run Test button on the Test Suite Details page.  </p> <p> </p> </li> <li> <p>Choose the Version of the VA you want to test.  </p> <p>Note: Ensure that you have valid authorization tokens for the VA to make the service calls that would be part of the test suite.  </p> <p></p> </li> <li> <p>You can monitor the progress of the test suite in the Result column and the status docker. The Result column displays the Passed or Failed status upon successful execution. </p> </li> </ol> <p>When a test case is executed, the test case result is determined with the features like assertions, dynamic texts, OneOf, and so on. To know more, see Test Case Assertion.</p> <p>The platform simulates all the user inputs against the current VA definition in sequence, as available in the test case. For every user input, the VA\u2019s responses are captured along with the metadata. See Capture Test Suite Metadata under Validate Test Suite to know more.</p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#test-assertions-execution","title":"Test Assertions Execution","text":"<p>The platform performs the assertions tagged to each VA response of a test case. For example, a VA\u2019s response can have Flow, Text, and Context Assertions tagged. The platform performs all three assertions to determine their assertion results. </p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#flow-assertion","title":"Flow Assertion","text":"<ul> <li> <p>For any VA response in a test case, the assertion is determined as pass when the following conditions are true:</p> <ul> <li>The Intent ID of the Expected and Actual responses is the same.</li> <li>The Node ID of the Expected and Actual responses is the same.</li> <li>The Transition(s) of the Expected and Actual responses are the same.</li> <li>The Prompt type (Error or User Prompt) is the same in case of Entity nodes.</li> </ul> </li> <li> <p>If the above conditions are not met, the assertion is determined as Failed.</p> </li> </ul>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#text-assertion","title":"Text Assertion","text":"<ul> <li> <p>For any VA response in a test case, the assertion is determined as passed when the following condition is true:</p> <ul> <li>The expected and actual responses are the same (string comparison).</li> </ul> </li> <li> <p>Dynamic text values are not considered when performing the comparison.</p> </li> <li>In case of multiple responses in the Expected Output (when a node has multiple variations), one of the expected responses must match for the assertion to pass.</li> </ul>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#context-assertion","title":"Context Assertion","text":"<ul> <li> <p>For any VA response in a test case, the context assertion is determined as passed when the following conditions are true:</p> <ul> <li>The expected and actual values are the same for the added context variable.</li> <li>A VA response has multiple context assertions and multiple context assertion results.</li> </ul> </li> <li> <p>A context assertion fails if the expected value and the actual value of the variable are not the same.</p> </li> </ul> <p>Note<p>The test case result is determined as Pass only when all the assertions of all the VA responses of the test case are passed.</p> </p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#past-test-executions","title":"Past Test Executions","text":"<p>The Past Executions tab is available on the Test Suite summary page, which displays the test result summary of all past executions. The details help in referring to test executions and understanding the results. </p>"},{"location":"automation/testing/regression-testing/conversation-testing/test-case-execution-summary/#result-summary","title":"Result Summary","text":"<p>The following steps show how to access the test result summary and the details displayed.</p> <ol> <li> <p>Click the Result Summary button to view the summary of all the executions. </p> </li> <li> <p>Two chat panels are displayed:</p> <ul> <li>Ideal Test Suite \u2013 It shows Test Cases with metadata and assertions from the test editor.</li> <li>Test Suite Execution \u2013 It shows Test results along with the metadata and assertion results identified during Test Exec </li> </ul> </li> <li> <p>The test result summary is displayed with the following details:</p> <ul> <li>Total test cases</li> <li>Breakdown of Passes, Failed, and Not Executed test cases</li> <li>Duration of test case execution</li> <li>The status of the Test Suite \u2013 Passed or Failed </li> </ul> </li> <li> <p>The test case details and their assertion result summary are also displayed. </p> </li> </ol>"},{"location":"automation/testing/regression-testing/conversation-testing/test-editor/","title":"Test Editor","text":"<p>You can use the Test Editor to view the test cases and their metadata. This section explains the steps to access the test editor and use the available options:</p> <ol> <li> <p>On the Conversation Testing page, click on any Test Suite to go to the Test Editor. </p> </li> <li> <p>In the Test Editor, the platform shows the validated chat along with its metadata and assertions for each test case. </p> </li> <li> <p>To see the details, choose a test case in the right side pane \u2013 Test Suite Details, or click the test case in the Validated Chat of the left pane.  A  test case consists of: </p> <ul> <li>One user input  </li> <li>One or more VA responses for a user input </li> </ul> </li> <li> <p>If the VA response is from a dialog intent, the following details are displayed:  </p> <ul> <li>Intent name  </li> <li> <p>Node name</p> <ul> <li>Error Prompt/User Prompt for Entity node. For more information, see Entity Node.</li> </ul> </li> <li> <p>Transitions</p> </li> <li>User Input  </li> <li>Expected Output  <ul> <li>All the variations of the node prompt are added as expected output  </li> <li>If a node has more than one variation, then the OneOf operator is added by default  </li> </ul> </li> </ul> <p>Note: The OneOf operator is used to test randomization scenarios where a node can have multiple bot responses. For any node in which multiple responses are configured, the operator is activated by default. If one of the multiple responses is obtained from the VA during the test execution, then the assertion will be passed. </p> </li> <li> <p>If the VA response is from FAQ/Small Talk/Standard Responses, the following details are captured:  </p> <ul> <li>Intent Name (FAQ Name, Small Talk Pattern, Standard Response)  </li> <li>User Input  </li> <li>Expected Output: It has the same details displayed as in Dialog Intent.  </li> <li>Assertions  <ul> <li>Flow (Enabled by default)  </li> <li>Text (Enabled by default)  </li> <li> <p>Context </p> <p> </p> </li> </ul> </li> </ul> </li> <li> <p>You can export the entire test suite to your local directory as a JSON file. The downloaded test suites include the user inputs and VA responses. </p> <p>Note: You can also clone the test suite or delete it as per the requirement.</p> </li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/","title":"Flow Health","text":""},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#introduction","title":"Introduction","text":"<p>The Flow Health dashboard summarizes how well the flows of Virtual Assistant (VA) are performing and shows the coverage of intents and transitions in the bot definition. The Flow Health dashboard displays the overall pass or fail percentage of test cases with options to view the transitions coverage. </p> <p>The Flow Health dashboard also shows the summary of user intents that are covered and missed in test cases. You can review the uncovered intents and add relevant test cases to cover missing user intents in the test suite. </p> <p>You can also use the test result analysis to identify the issues in the dialog task definitions and fix them with actionable recommendations to improve overall NLU and Flow health.</p> <p>Note: The Flow Health Dashboard is available on the XO Platform version 10.0, released on Jan 21st, 2023.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#use-case-scenario","title":"Use-Case Scenario","text":"<p>In this article, the Hotel Booking virtual assistant is used as an example to understand the flow of transitions and test results analysis. The Hotel Booking VA has the Search A Hotel, Book a Hotel, Get User Data, Show User Data, and Raise Complain dialog intents with various test cases in the test suites in the Conversation Testing module.</p> <p>A transition shows how a user intent is transferred from one node to another node in a dialog task. A transition is a flow of intent between two nodes. It has a From node and a To node.  For example, \u201cBook a Hotel\u201d is a user intent in a dialog task. A city is an entity node in the dialog flow to which the book a hotel user intent is transitioned, and then it transitions to the state node. From the state node, it transitions to country and reservemessage nodes. Therefore, in the Book a Hotel task, you have four transitions in total. For more information, see User Intent. </p> <p>Once you record a conversation flow, save it and run it in the Conversation Testing module.  The conversation testing module helps in knowing how a dialog task performs. For example, if you have a Get User Data dialog task and want to see how this dialog task is performing, you can create a Show User Data test suite with various test cases. Run the Show User Data test suite and see whether it was completed successfully, failed, paused, or not executed. For more information, see the Conversation Testing article.</p> <p>The test suite results are tracked in the Conversation Testing, and the analytics for test suites are displayed in the Flow Health dashboard.  </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#how-to-use-the-flow-health-dashboard","title":"How to Use the Flow Health Dashboard","text":"<p>To access the Flow Health Dashboard, follow these steps:</p> <ol> <li> <p>Navigate to BUILD &gt; Testing &gt; Health &amp; Monitoring and select the Flow tab. </p> </li> <li> <p>Drill down to learn how to view the Dialog Intent, FAQ, and Small Talk summary sections. In these sections, you can view the intent level summaries, along with test coverage details to easily identify the transitions or intents to be covered. You can also expand to the test case results to view the execution analytics.  </p> </li> </ol> <p>Note: The test suites are used to verify the Intents, Small Talks, FAQs, and Standard Responses with test cases. The Flow Health dashboard considers standard responses in test cases to calculate overall percentages. However, the dashboard has no separate summary tile for the Standard Responses. For this reason, you will notice a slight difference in the test results\u2019 overall count or percentage.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#flow-metrics","title":"Flow Metrics","text":"<p>The Flow Health dashboard extrapolates all test suite results from the conversation testing and presents insights into your test cases with performance analytics.</p> <p>View the overall percentage of the test case results in the test suites with the following flow metrics:</p> <ul> <li>Pass \u2013 Total Number of test cases passed across all test suites.</li> <li>Fail \u2013 Total Number of Test cases failed across all test suites.</li> <li> <p>Not Executed \u2013 Total Number of Test cases aborted or not executed before execution across all test suites. </p> </li> <li> <p>Click the View Test Suites link to view all the test suites that are considered in the VA with the following details:</p> <ol> <li>Test Suite  \u2013 The name of the test suite.</li> <li>Result \u2013 The result of the test suite, such as Passed, Failed, Aborted, or Not Executed.</li> <li>Duration \u2013 The duration for the execution of the test suite.</li> <li>Test Cases \u2013 The number of test cases in the test suite.</li> <li>Pass \u2013 The number of test cases that passed.</li> <li>Fail \u2013 The number of test cases that failed.</li> <li>Not Executed \u2013 The number of test cases that are not executed.</li> <li>Pass percentage \u2013 The overall pass percentage of the test cases.  </li> </ol> <p></p> </li> <li> <p>Click the Test Suite Name to analyze how the test suite is performing. For example, click the FAQ_TS_Pass test suite to view the test results analysis as shown below: </p> </li> <li> <p>Select the Test Coverage tab to view the Dialog Intents, FAQs, and Small Talks covered and that are not covered in the test suite. </p> </li> <li> <p>By default, the Dialog Intents are displayed. Click the FAQs to view FAQs details. </p> </li> <li> <p>Click the Small Talks tab to view small talk details. </p> </li> <li> <p>Click the X icon to close the Intent Details window.</p> </li> </ul>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#flow-dashboard-components","title":"Flow Dashboard Components","text":"<p>The key components of the Flow Health dashboard include transition coverage and intent summary panels for the test suites. The details on the available panels are explained below.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#dialog-intent-summary","title":"Dialog Intent Summary","text":"<p>The Dialog Intent Summary shows the summary of test results analysis of dialog intents in the test cases from the Conversation Testing. The Dialog Intent summary also provides insights into flow transitions that are covered and ones that are missed.</p> <p>In the Dialog Intent Summary region, you can view flow transitions and test result analysis-level summaries, along with the test coverage, to easily identify intents to be covered. You can drill down to view the analytics of test results.</p> <p>Note: All the test cases across test suites expecting a dialog node for assertion are considered for generating the flow summary. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#transitions-coverage","title":"Transitions Coverage","text":"<p>The Flow Health dashboard calculates the number of transitions in a dialog and shows the analysis of covered and not covered transitions. The Transition Coverage section helps you quickly understand how transitions are performing and fix issues in the specific transitions with actionable recommendations. You can analyze the transitions that are missed and add relevant test cases in the test suite to cover them in multiple iterations.</p> <p>The percentage of transitions coverage is displayed as follows: </p> <ul> <li>Total Transitions Covered \u2013 Shows all covered transitions out to total transitions in the VA definition. </li> <li>Covered \u2013 Shows the number of transitions that are covered in the test cases.</li> <li>Not Covered \u2013 Shows the percentage of total transitions that are not covered in the test cases.</li> </ul> <p></p> <ol> <li> <p>Click the  icon beside the percentages to open the Dialog Transitions page and view the following details:</p> <ol> <li>Task Name \u2013 The name of the dialog intent. </li> <li>From Node \u2013 The From node where the conversation starts to transition.</li> <li>To Node \u2013 The To node from where the conversation is transferred to.</li> <li>Status \u2013 The Status of the transition  \u2013 covered or not covered. </li> </ol> </li> <li> <p>Click the  icon beside Not Covered percentage to view missed transitions. </p> </li> <li> <p>Create a new test suite and record missed transitions to cover them. For more information, see Conversation Testing.</p> </li> <li> <p>Click the  icon to search and filter the dialog intent tasks for which you want to see the transitions coverage. You can filter transitions using the From Node, To Node, and Coverage Status filters.  </p> <p>For example, in the Status Coverage column, click the to select all, covered, and not covered statuses, as shown below: </p> </li> <li> <p>Click the X icon to close the Dialog Transitions window.</p> </li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#conversation-test-results-analysis","title":"Conversation Test Results Analysis","text":"<p>The Conversation Test Results Analysis section summarizes all test suite results. You can use the test result analysis to identify the issues in the dialog task definitions and fix them.</p> <p>The percentage of test results analysis is displayed as follows: </p> <ul> <li>Total Test Cases \u2013 Shows the total number of test cases in a test suite.</li> <li>Pass, Fail, or Not Executed \u2013 Shows the count and percentage of test case results that have passed, failed, or not executed. </li> </ul>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#view-intent-summary","title":"View Intent Summary","text":"<p>The View Intent Summary shows how well test cases are covering and performing at the intent level, making it easier to identify the most important failing and less-covered intents.</p> <ol> <li> <p>Click the View Intent Summary link to view the intent details in the Dialog Intent Details view. </p> </li> <li> <p>Once you click the View Intent Summary link, the Dialog Intent Details displays all intents that are covered in a test suite.  </p> <p>This summary shows the intents covered in the test suite with the total number of transitions that are covered and missed. It also shows the percentage of test cases that have passed, failed, or not executed status against the total number of test cases for an intent. </p> </li> <li> <p>In the Dialog Intent Details window, click on Covered By for any Intent Name to view the summary. For example, the Raise Complain intent is covered in a test suite with a total of Nine transitions, out of which only Eight are covered and One is missed. The total number of test cases in this intent are Eight, out of which Seven have passed and One has failed, with Zero test case not executed. </p> </li> </ol> <p>To view the intent summary and identify the issues, follow these steps:</p> <ol> <li> <p>Click the &gt; icon to open the intent details summary for the desired intent. </p> </li> <li> <p>Click the Test Suite Name to analyze how the test suite is performing. For example, click the Dialog_TS_Suite_RaiseComplain_Fail test suite to view the test results analysis as illustrated in the screenshot below: </p> </li> <li> <p>In this test suite, the test case1 has failed because it has an incorrect data type selected for the Date field as shown below: </p> </li> <li> <p>Text assertion fails because there is a mismatch between the Expected and Actual output. For more information, see Test Case Assertion. </p> </li> <li> <p>Click the X icon to close the Intent Details window.</p> </li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#faqs-summary","title":"FAQs Summary","text":"<p>The FAQ Summary section displays the FAQ Coverage and Conversation Test Results Analysis generated for all the FAQ intents in all the test cases of the selected test suite, as discussed in the View Intent Summary section. </p> <p>Click View Intent Summary to get a drill-down view of the FAQ Intents that are covered or not covered in the test suites on the FAQ Intent Details window.</p> <p>FAQ Intent Details Window</p> <p>This window gives the drill-down view of the FAQ-level details for the selected test suite. The primary objective here is to help users know the top-performing and low-performing FAQs to identify issues proactively and work on fixing them accordingly. </p> <p>For more information, see View Intent Summary section.</p> <ul> <li>Intent Name: The name of the dialog intent.</li> <li>Path: The node path in the Knowledge Graph.</li> <li>Covered by (Test Suites): The count of the test suites in which the FAQ intents are covered.</li> <li>Total Test Cases: The count of the test cases in the selected test suites for that FAQ intent.</li> <li>Pass: The count of the passed FAQ intent test cases that passed.</li> <li>Fail: The count of the FAQ intent test cases that failed.</li> <li>Not Executed: The count of the FAQ intent test cases that are not executed.</li> <li>Pass %: The overall pass percentage of the test cases.</li> </ul>"},{"location":"automation/testing/regression-testing/health-and-monitoring/flow-health-dashboard/#small-talk","title":"Small Talk","text":"<p>The Small Talk Summary section displays the Small Talks Coverage and Conversation Test Results Analysis generated for all the Small Talk intents in the selected test suite as discussed in the View Intent Summary section. </p> <p>Small Talk Intent Details Window</p> <p>Click View Intent Summary to view the Small Talk Details window that gives the drill-down view of the Small Talk level details for the selected test suite. The primary objective here is to help users know the top-performing and low-performing intents to identify issues proactively and fix them accordingly. </p> <p>For more information, see View Intent Summary section.</p> <ul> <li>Intent Name: The intent name captured in the Small Talk interaction.</li> <li>Group: The group to which the Small Talk interaction is mapped.</li> <li>Covered by (Test Suites): The count of the test suites in which the Small Talk intent is covered.</li> <li>Total Test Cases: The count of the test cases present in the selected test suites for that Small Talk intent.</li> <li>Pass: The count of the Small Talk intent test cases that have passed.</li> <li>Fail: The count of the Small Talk intent test cases that failed.</li> <li>Not Executed: The count of the Small Talk intent test cases that are not executed.</li> <li>Pass %: The overall pass percentage of the test cases.</li> </ul>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/","title":"Health and Monitoring","text":"<p>The Health and Monitoring dashboard offers a goal-driven approach to improving the accuracy of the virtual assistant\u2019s Natural Language Processing (NLP) model. The training data is analyzed along with the test coverage and test results of the test suites to provide insights into the NLP Model\u2019s performance.</p> <p>This dashboard lets you achieve the following:</p> <ul> <li>Run the test suites against the in-development version of the bot to see the Virtual Assistant\u2019s health.</li> <li>Review the test execution summary for every intent type.</li> <li>Drill down and view the coverage and key metrics of the virtual assistant determined by the Batch Test and Conversation Test executions.</li> <li>Identify incorrect intent patterns, short training utterances, incorrect entity annotations, and training recommendations and take corrective action.</li> <li>View the expected and matched results, and the detailed NLP analysis.</li> <li>Tag specific test case results that need follow-up actions and collaborate with your team to improve the performance.</li> </ul> <p>Note<p>The Health &amp; Monitoring Dashboard is available only post 9.3 release, i.e. post-July 24, 2022. This feature only considers the latest In-development test executions.</p> </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#navigating-to-health-and-monitoring","title":"Navigating to Health and Monitoring","text":"<p>To navigate to the Health and Monitoring dashboard, follow these steps:</p> <ol> <li>Click the Build tab on the top menu of the Virtual Assistant dashboard.</li> <li>Click Health &amp; Monitoring under Testing in the left navigation menu. </li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#dashboard-sections-and-components","title":"Dashboard Sections and Components","text":"<p>The Health and Monitoring Dashboard is divided into two sections that include the following:</p> <ol> <li>NLP: This panel extracts all test suite results from Batch Testing and presents insights into your test cases with performance analytics. The key components of this panel include the execution summary, the key performance metrics, and the total test coverage of the selected test suites for the Dialog intents, FAQs, Small Talks, and Traits. The key recommendation scores presented here depict if your virtual assistant is trained sufficiently or not.</li> <li>Flow: This panel summarizes the coverage of all the conversation flows by the Virtual Assistant you\u2019ve defined including its performance, intents\u2019 coverage and transitions. Learn more. The key components of the Flow panel include transition coverage and intent summary panels for the test suites. Learn more.</li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#health-and-monitoring-metrics","title":"Health and Monitoring Metrics","text":""},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-intent-coverage-metrics","title":"NLP Intent Coverage Metrics","text":"<p>The following metrics extracted from Batch Testing results are displayed in two ways:</p> <ol> <li> <p>As aggregate values in the Bot Health summary section. </p> </li> <li> <p>As individual scores in the Dialog Intents, FAQs, Small Talk, and Traits summary panels. </p> </li> <li> <p>Accuracy: Determines if the intent identified by your ML model is correct or not.</p> </li> <li>F1 Score: Classifies the distribution and balances precision and recall scores. It is calculated as the weighted average of Precision and Recall.</li> <li>Precision Score: Defines how precise/accurate your model is and is calculated as the ratio of true positives over total predicted positives (sum of true and false positives).</li> <li>Recall Score: Defines the fraction of the relevant utterances that are successfully identified and is calculated as the ratio of true positives over actual positives (sum of true positives and false negatives).</li> <li>Total Test Coverage %: The average of the Total Test Coverage scores for Dialog Intents, FAQs, Small Talk, Traits, and Entities.</li> </ol> <p>These metrics help gain actionable insights into your test cases to perform ML Model Validation.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#flow-health-metrics","title":"Flow Health Metrics","text":"<p>The Flow Health metrics display all the test suite results from the conversation testing and present insights into your test cases with performance analytics. Learn more.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#test-cases-detailed-analysis","title":"Test Cases Detailed Analysis","text":"<p>To get the detailed NLP data of all the test cases executed for all the test suites that are considered in the VA, click the View Test Cases link in the NLP section.</p> <p></p> <p>The Test Cases- Detailed Analysis window displays test results for Intents, Entities, and Traits as described below. The summary data helps identify the errors or areas of improvement for each category and fix them.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#navigating-to-the-test-case-details-section","title":"Navigating to the Test Case Details Section","text":"<p>To view the Details section, in the Test Cases \u2013 Detailed Analysis window, click the Intents, Entities, or Traits tab. A summary table with the following details is displayed:</p> <p>Intents</p> <ul> <li>Test Cases: The test case name.</li> <li>Intent Type: Displays if the intent is a Dialog intent, FAQ, or Small Talk.</li> <li>Expected Intent: Intent expected in the user utterance.</li> <li>Matched Intent: Intent actually matched in the utterance.</li> <li>Result Type: Displays if the match detected is True Positive, False Positive, or False Negative.</li> <li>Tags: The tag labeled for the conversation by the analyst.</li> </ul> <p></p> <p>Entities</p> <p>A summary table with the following details is displayed:</p> <ul> <li>Utterances: The user utterance captured in the test case.</li> <li>Entity Name: The entity name mapped to the test case for the utterance.</li> <li>Expected Value: The Entity expected in the user utterance.</li> <li>Matched Value: The Entity actually matched in the utterance.</li> <li>Entity Result: Displays if an entity is matched (True), or not (False).</li> <li>Tags: The tag labeled for the conversation by the analyst. </li> </ul> <p>Traits</p> <p>A summary table with the following details is displayed:</p> <ul> <li>Test Cases: The test case of the trait.</li> <li>Intent Type: Displays Trait.</li> <li>Trait Name: The name of the trait analyzed in the test case.</li> <li>Expected Trait: The trait expected in the user utterance.</li> <li>Matched Trait: Displays the actual trait matched in the utterance.</li> <li>Trait Result: Displays if the match detected is True Positive, False Positive, or False Negative.</li> <li>Tags: The tag labeled for the conversation by the analyst.</li> </ul> <p></p> <p>Tags</p> <p>After analyzing the reason for failure, you can collaborate with your team members using tags for test case executions. Tags are labels mapped to the test case results of intents, entities, and traits, indicating follow-up actions or suggestions.</p> <p>The following tags are available for intents, entities, and traits:</p> <ul> <li>Add Negative Pattern: Indicates that the user has to add a negative pattern to the intent/entity/trait test execution.</li> <li>NeedNLPHelp: Indicates that the test execution requires explicit NLP help.</li> <li>Needs Negative Pattern: Indicates that the intent/entity/trait test execution needs a negative pattern to execute as expected.</li> <li>Needs Training: Indicates that the virtual assistant needs training for the identified intent/entity/trait after the test execution.</li> <li>New Intent: Indicates a new intent during test execution.</li> </ul> <p>Hover over the desired entry, and click the detailed view icon. </p> <p>A sliding window with the test results for the selected test case and intent type appears.</p> <p>Intent and Entity Details </p> <p>Trait Details are displayed in the test case details window if you select the trait intent type. </p> <p>Click the expansion arrow icon under Entity to view the entity order expected by the ML engine and the actual entity order. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-analysis","title":"NLP Analysis","text":"<p>The NLP Analysis section displays the detailed view of the historic analysis generated at the time of the test case execution for failed and successful test cases. For the selected intent type, this section gives an overview of the intents that are qualified (the definitive and probable matches) and disqualified to serve as crucial information for users trying to decode the reason for failed test cases. The following details are displayed as a graphical representation in this section:</p> <ul> <li>Traits (if applicable)</li> <li>Machine Learning (ML) engine</li> <li>Fundamental Meaning (FM) engine</li> <li>Knowledge Graph (KG) engine</li> <li>Trait Rule (if applicable)</li> <li>Ranking and Resolver</li> </ul> <p>This is different from analyzing the test results under Utterance Testing where the current analysis information is displayed based on the changes to the trained data. Learn more.</p> <p>To view the NLP Analysis section, follow these steps:</p> <ol> <li>Please follow steps 1 to 3 mentioned in the Navigating to the Test Case Details section.</li> <li>Click the NLP Analysis tab as shown below: </li> </ol>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#test-suite-summary","title":"Test Suite Summary","text":"<p>For Flow Health, clicking the View Test Suites link displays the following details:</p> <ul> <li>Test Suite</li> <li>Result</li> <li>Duration</li> <li>Test Cases</li> <li>Pass</li> <li>Fail</li> <li>Not Executed</li> <li>Pass percentage</li> </ul> <p>Please click here to learn more about Test Suite Performance and Test Coverage Analysis.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#utterance-testing","title":"Utterance Testing","text":"<p>Based on the test case failures, you can retrain your virtual assistant using the Utterance testing option for all possible user utterances and inputs. Training is how you enhance the performance of the NLP engine to prioritize one task or user intent over another based on the user input. To learn more, please refer to this link.</p> <p>To navigate to the Utterance Testing window, click the go to utterance testing (magic wand) icon on the Test Cases \u2013 Detailed Analysis page. </p> <p>In the Utterance Testing window shown below, you can do the following:</p> <ul> <li>Test &amp; Train your virtual assistant based on these recommendations  to understand different user utterances and match them with intents and entities.</li> <li>View the NLP analysis flow and Fields/Entities analysis data including the confidence score based on the NER training.</li> <li>Use the Mark as an incorrect match link to match the user input with the right intent when it is mapped to an incorrect task. </li> </ul>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#dialog-intent-summary","title":"Dialog Intent Summary","text":"<p>This section provides the performance metrics, test coverage and analytics for only the Dialog Intents test cases. </p> <p>The sub-sections available include:</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#test-coverage","title":"Test Coverage","text":"<p>This section displays the count and percentage of the intents covered and not covered. You can find the list of intents not covered using the View details option and start adding test cases for them. An Intent is considered as covered when the intent has at least one test case in the selected test suite(s).</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-performance-metrics","title":"NLP Performance Metrics","text":"<p>This section gives the breakdown of the test case results for the given intent type. The result type could have one of the following values:</p> <ul> <li>True Positive (TP): Percentage of utterances that have correctly matched expected intent. In the case of Small Talk, it would be when the list of expected and actual intents are the same. In the case of Traits, this would include the traits matched over and above the expected matches.</li> <li>False Positive (FP): Percentage of utterances that have matched an unexpected intent. In the case of Small Talk, it would be when the list of expected and actual intents are different.</li> <li>False Negative (FN): Percentage of utterances that have not matched expected intent. In the case of Small Talk, it would be when the list of expected Small Talk intent is blank but the actual Small Talk is mapped to an intent.</li> </ul> <p>Recommendation Notification: Shows any training recommendations available for the dialog intents.</p> <p>The test execution results for the selected test suite(s) and intent type can be analyzed in the details window which provides a drill-down view of the following performance metrics for intents, entities, and traits</p> METRIC NAME DESCRIPTION INTENT ENTITY TRAIT Expected Intent/Value Please refer to Intents in this section.     Yes     Yes     Yes     Matched Intent/Value Please refer to Intents in this section.     Yes     Yes     Yes     Parent Intent Learn more.     Yes     No     Yes     Task State The status of the intent or task against which the intent is identified. Possible values include Configured or Published. <p> .     Yes     No     Yes     Result Type Please refer to Intents in this section.     Yes     No     Yes     Matched Intent Score and Expected Intent Score Displays the individual scores for the following <ul> <li>Machine Learning (ML) score <li>Fundamental Meaning (FM) score <li>Ranking and Resolver (RR) score </li> Yes     No     Yes     Entity Name Please refer to Entities in this section..     No     Yes     No     Result Returns True if an entity is identified and False if not.     No     Yes     No     Identified by The NLU engine that identified the entity.     No     Yes     No     Identified using The reference entity type that was used to identify the entity during test execution.     No     Yes     No     Confidence Score A score to determine if the test execution resulted in a favorable outcome (high score) or not (low score) when an utterance is trained for the entity.     No     Yes     No"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#dialog-intent-flow-health","title":"Dialog Intent Flow Health","text":"<p>Please refer to this link for more information.</p> <p>The following sections can be accessed from the Dialog Intent Summary panel:</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#conversation-test-results-analysis","title":"Conversation Test Results Analysis","text":"<p>Please refer to this link for more information.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#transitions-coverage","title":"Transitions Coverage","text":"<p>Please refer to this link for more information.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#view-intents-summary","title":"View Intents Summary","text":"<p>Please refer to this link  for more information.</p> <p>View Recommendations</p> <p>You can view relevant training recommendations for dialog intents, FAQs, or Small Talks when errors and warnings are triggered during the test execution. To view the recommendations summary, click View Recommendations on the top right of the details page.</p> <p>To view the details of the utterance validations, errors, warnings, and recommendations and correct them, click the Recommendations column. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#viewing-specific-test-results","title":"Viewing Specific Test Results","text":"<p>To know how to get the drill-down view of a specific NLP test case execution, please refer to the Test Cases \u2013 Detailed Analysis section.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-faqs-summary","title":"NLP- FAQs Summary","text":"<p>The FAQ Summary section displays the recommendation scores generated for FAQs from the latest batch test executions. </p> <p>Viewing Additional FAQ Recommendations: For FAQ Details, clicking View Recommendations will display the report that was already run during the previous run time. To know how to view and manage additional recommendations, please refer to this link. </p> <p> </p> <p>Knowledge Graph: Clicking this button will take you to the Knowledge Graph section where you can perform KG Analysis. </p> <p></p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#flow-faqs-summary","title":"Flow- FAQs Summary","text":"<p>Please refer to this link for more information.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-small-talk-summary","title":"NLP- Small Talk Summary","text":"<p>The Small Talk Summary panel displays the recommendation scores generated for Small Talk interactions from the latest batch test executions. </p> <p>Small Talk button: Click this button to view the group name and the relevant user utterances, and Bot utterances. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#flow-small-talk-summary","title":"Flow- Small Talk Summary","text":"<p>Please refer to this link for more information.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#trait-and-entity-summary-information","title":"Trait and Entity Summary Information","text":"<p>The Trait Summary and Entity Summary sections display the recommendation scores generated for traits and entities respectively from the latest batch test executions.</p> <p>Trait Summary </p> <p>Entity Summary </p> <p>Test Coverage and Test Results Analysis</p> <p>Please refer to Test Coverage and Test Results Analysis for information on the sub-sections of these summary panels.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#nlp-batch-test-results-summary-for-universal-bots","title":"NLP Batch Test Results Summary for Universal Bots","text":"<p>The XO Platform now displays batch test results for Universal bots for each test run in the summary view for FAQs, Dialog Intents, and Small Talk during Batch Testing. The actionable insights help understand the test coverage and NLP performance for each intent type in the Universal Bot.</p> <p>The only difference between Standard and Universal Bots is that the insights derived are based on the intents of all the linked bots. For instance, the intent coverage is based on the comparison of the intents covered in the test suite and the total number of intents present in all the linked bots. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#test-suite-summary_1","title":"Test Suite Summary","text":"<p>The Test Suite Summary for the Universal Bot is the same for Dialog Intents, FAQs, and Small Talk. However, for the Universal Bot, the system takes the total number of respective intents in all the linked bots as the denominator to calculate the coverage metrics.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#intent-summary","title":"Intent Summary","text":"<p>The NLP Intent Summary sections are the same for Universal Bots, except the Recommendations information is not displayed for Dialogs and FAQs, as shown below: </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#dialog-intents","title":"Dialog Intents","text":"<p>The Dialog Intent Details page for Universal Bot summarizes the following information:</p> <ul> <li>Intent Name</li> <li>Bot Name</li> <li>Training Utterance</li> <li>Test Cases</li> <li>NLP performance metrics: TP, FP, FN, and F1.</li> <li>Coverage metrics: Precision, Recall, and Accuracy.</li> <li>Covered In (The Test Suites that cover the intent). </li> </ul> <p>Please refer to Intent Details Window for more information on the above values.</p> <p>Note: The Recommendations option is not available for Universal Bot on this page.</p> <p>To view the intents not covered on the Dialog Intent Details page, click the Three-dotted/Ellipses icon and select View Intents Not Covered. </p> <p>In the Not Covered Intents List, you can view the respective Bot Name, as shown below. This helps analyze which Bots don\u2019t identify the tested intents and improve test execution accordingly. </p> <p>The Search and Filter options help select specific intents not covered by a Bot.</p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#faq","title":"FAQ","text":"<p>The FAQ Details page for Universal Bot summarizes the following information:</p> <ul> <li>Intent Name</li> <li>Bot</li> <li>Path</li> <li>Alt Question</li> <li>Test Cases</li> <li>NLP performance metrics: TP, FP, FN, and F1.</li> <li>Coverage metrics: Precision, Recall, and Accuracy.</li> <li>Covered In (The Test Suites that cover the intent). </li> </ul> <p>Please refer to Intent Details Window for more information on the above values.</p> <p>Note<p>The 'Knowledge Graph' and 'Recommendations' options are not available for Universal Bot on this page.</p> </p> <p>To view the intents not covered on the FAQ Details page, click the Three-dotted/Ellipses icon and select View Intents Not Covered. </p> <p>In the Not Covered Intents List, you can view the respective Bot Name, as shown below. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#small-talk","title":"Small Talk","text":"<p>The Small Talk Details page for Universal Bot summarizes the following information:</p> <ul> <li>Intent</li> <li>Group</li> <li>Bot</li> <li>Test Cases</li> <li>NLP performance metrics: TP, FP, FN, and F1.</li> <li>Coverage metrics: Precision, Recall, and Accuracy.</li> <li>Covered In (The Test Suites that cover the intent). </li> </ul> <p>Please refer to Intent Details Window for more information on the above values.</p> <p>Note<p>The 'Small Talk' option is not available for Universal Bot on this page.</p> </p> <p>To view the intents not covered on the Small Talk Details page, click the Three-dotted/Ellipses icon and select View Intents Not Covered. </p> <p>In the Small Talk-Intents Not Covered List, you can view the respective Bot Name, as shown below. </p>"},{"location":"automation/testing/regression-testing/health-and-monitoring/virtual-assistants-health-and-monitoring/#intent-details-window","title":"Intent Details Window","text":"<p>The View Details link in the Dialog intent, FAQ, and Small Talk summary sections provides access to a drill-down view of the key performance metrics and recommendations of the covered intents.</p> <p>The given data helps identify the intent-related issues proactively in the training phase itself to work on fixing them accordingly. </p> <p>Here\u2019s what you can do:</p> <p>View the Training Data Summary</p> <p>You can view the training data summary with the relevant recommendation metrics for Dialog Intents, FAQs, and Small Talks in the details panel. </p> <p>The summary of all the metrics displayed is given below:</p> RECOMMENDATION METRIC DIALOG INTENT FAQ SMALL TALK Intent The name of the dialog intent.     The name of the FAQ intent.     The name of the Small Talk intent.     Utterances The count of the training utterances for that intent.     N/A     Test Cases The count of the test cases that are present in the selected test suites for that intent.     True Positive (TP) The count of the intent test cases that resulted in TP.     False Negative (FN) The count of the intent test cases that resulted in FN.     False Positive (FP) The count of the intent test cases that resulted in FP.     Covered In Name of the test suites in which the intent test cases are present.     F1, Accuracy, Precision, and Recall scores These recommendation scores are displayed based on the outcomes.     Recommendations Displays the count of training recommendations for that intent. Clicking on it will display the summary of the training recommendations and their probable corrective actions.     N/A     N/A     Group N/A     N/A     The group to which the Small Talk interaction is mapped.     Path N/A     The node path in the Knowledge Graph.     N/A     Alt Question N/A     The number of alternative questions mapped to an FAQ.     N/A     <p> </p> <p>View Intents Not Covered</p> <p>This feature helps identify the intents not covered so as to include them in the test data for better and holistic testing of the virtual assistant. Click the three-dot menu on the right side of the panel to view the list of intents not covered in batch testing. </p> <p>You can include the intents from this list to retrain your virtual assistant and improve performance. </p>"},{"location":"automation/tools/intent-discovery/","title":"Intent Discovery (Beta)","text":"<p>The new Intent Discovery module helps you auto-extract popular intents from previous user conversations. It reduces the time and effort to build a virtual assistant and leads to the success of your Conversational AI Journey. This is a beta feature and is available only for the English language and Enterprise users.</p> <p>You can upload your historical transcripts in CSV format. After the transcripts are uploaded into the bot, the bot uses LLMs to identify the different topics, intents, or conversations between the user and the bot. It intelligently identifies all the intents available. You can review each intent to understand which conversations have resulted in identifying these intents. After the review, you can also see the underline utterances that resulted in identifying an intent. You can either add these intents as new intents for your virtual assistant or pick specific utterances and train them as utterances for your existing dialogs and FAQs. So, it helps both ways \u2013 either create new intents or enhance the training you provide to your virtual assistant.</p> <p> </p> <p>The Intent Discovery journey consists of the following steps:</p> <ol> <li>Create a Project: You may have many business use cases to automate. Projects help manage intent discovery for each business use case separately \u2013 a project for a specific use case.</li> <li>Upload Transcripts: Upload your use case-specific historical transcripts in CSV format. Conversations are extracted from the uploaded transcripts.</li> <li>Extract Intents: Intents and training data are extracted from the conversations.</li> <li>Train the Utterances to create new intents or add them as training data: You can add new intents as dialogs or FAQs or train them for existing dialogs or FAQs.</li> </ol>"},{"location":"automation/tools/intent-discovery/#create-a-project","title":"Create a Project","text":"<ol> <li> <p>Go to Build &gt; Tools &gt; Intent Discovery. </p> </li> <li> <p>Click the Create Project button.</p> </li> <li> <p>Enter a name and a brief description of the project. Note that the character limit for Project Name is 256, and Description is 1000. Click Proceed. </p> </li> <li> <p>The new project is created. You see the Intent Discovery page with the header \u2018Projects / {{New Project\u2019s Name}}\u2019. </p> </li> </ol> <p>The Intent Discovery landing page lists all the projects with conversational insights for each project, such as the status of the project, number of sessions, intents extracted, and results in terms of added dialogs, added FAQs, trained dialogs, and trained FAQs. Note that the result will be NA for the projects for which intent extraction is incomplete.</p> <p>The status of a project can be any of the following, displayed in the Status column:</p> <ul> <li>No Files Uploaded</li> <li>Intents Not Extracted</li> <li>Intent Extraction In Progress</li> <li>Intents Extracted</li> </ul> <p> </p> <p>Note<p>You can create a maximum of 10 projects per VA. You can change an existing project\u2019s name and description anytime.</p> </p>"},{"location":"automation/tools/intent-discovery/#upload-transcripts","title":"Upload Transcripts","text":"<p>On the Intent Discovery page for the new project, you can see a button to initiate the upload of the transcript file(s) and a link to download a sample transcript file.</p> <p> </p> <p>You can download the sample CSV file by clicking the link. Ensure to upload transcripts in the format specified in the sample file. Please note that all the columns in the file must be filled.</p>"},{"location":"automation/tools/intent-discovery/#format-of-the-csv-transcript-file","title":"Format of the CSV (Transcript) file","text":"FIELD NAME     DESCRIPTION     Id     The session ID of the conversation. (For all the conversations in a session, the Id must be the same.)     Sender ID     The ID of the bot or agent.       Other Party ID     The ID of the user talking to the bot or agent.     Direction     The message direction \u2013 in (user input) or out (bot/agent response).     Message     The message shown to the user or the bot/agent, depending on the message direction.     Message Type     Format in which the message is sent or received \u2013 text/html.     Created on     Date &amp; time on which the message is sent or received."},{"location":"automation/tools/intent-discovery/#limitations","title":"Limitations","text":"<ul> <li>Number of transcripts files allowed: Up to 5 CSV files per project.</li> <li>Maximum size of CSV transcript file: 1MB each</li> </ul>"},{"location":"automation/tools/intent-discovery/#steps-to-upload-the-transcripts","title":"Steps to upload the transcripts:","text":"<ol> <li> <p>Click the Upload Transcript button, and then browse and select the transcripts files (CSV format). The selected files are uploaded, and you see a prompt to manage the transcripts on the next page. </p> <p> </p> </li> <li> <p>If some transcript files are uploaded but No intents extracted so far, the Manage Transcripts button is displayed as shown in the screenshot below. </p> </li> <li> <p>On clicking Manage Transcripts, you can see the Transcripts dialog box with the list of all the transcript files. Below details are displayed on the window:</p> <ol> <li>File Name: Name of the transcript file uploaded</li> <li>Upload Time: Time of transcript upload</li> <li>Sessions: Count of sessions in the transcript, gets populated after the successful extraction of conversations. </li> <li>Status, which can be one of the following:<ul> <li>Conv. Extraction In-progress: </li> <li>Conversations Extracted</li> <li>Intents Extracted</li> <li>Invalid File</li> <li>Upload Failed</li> </ul> </li> </ol> <p></p> </li> </ol> <p>The dialog box has the provision to download a sample file using the Sample File button and upload additional transcript files by clicking the Upload Transcripts button.</p>"},{"location":"automation/tools/intent-discovery/#view-conversations-in-the-transcript","title":"View Conversations in the Transcript","text":"<p>Upon successful upload of the transcript(s), the platform extracts the conversations from the uploaded files. You can view all the conversations, and the chat messages exchanged between the end user and the VA/agent.</p> <p>The platform displays the conversation session summary, which includes the count of the VA messages and user messages. You need to select a Date Filter under Contents to display the details. </p> <p>If a conversation is not useful or is not contributing to the intent, you can delete the specific conversation. Deleting a conversation also impacts the conversation count and average message count in the columns.</p>"},{"location":"automation/tools/intent-discovery/#delete-transcripts","title":"Delete Transcripts","text":"<p>You can delete the uploaded transcript file if the file is not required anymore, in case the upload was incorrect, or if the conversation has been extracted but the file is not useful.</p> <p>On hovering any row, the delete icon is displayed, which is used to delete that specific Transcript. </p>"},{"location":"automation/tools/intent-discovery/#extract-intents","title":"Extract Intents","text":"<p>The next step is intent extraction. </p> <p>Click the Extract Intents button on the Transcripts dialog box. You can see a message about intents being extracted. This process may take a few minutes depending on the number and size of the transcript files. </p> <p>After the intent extraction is completed, you can see the list of extracted intents along with session count, qualified utterances, and actions. </p> <p>You can view the details of the intent action by clicking the View icon under the Actions column next to the text. </p> <p></p>"},{"location":"automation/tools/intent-discovery/#extracted-intent-details","title":"Extracted Intent Details","text":"<p>Clicking anywhere on the extracted Intents row displays a pop-up dialog box to view the details of the extracted Intent. The title of the dialog box is the extracted Intent name. </p> <p>The dialog box shows a table with individual rows for each session. The table has below columns: </p> <ul> <li>Session ID: The session ID and the Date and Time of the Session.</li> <li>Utterances: The list of utterances qualifying the extracted Intent. <ul> <li>The platform shows only 3 utterances per session (row). The remaining count of the utterances is shown as a chip. </li> <li>On clicking the chip, you see all the utterances for the corresponding session.</li> <li>You can bookmark the utterances.</li> </ul> </li> <li>Status: A dropdown that shows whether the session item has been reviewed. By default, it  shows Yet to Review. You can change it to Reviewed.</li> <li>View Transcripts action button: This button is present in the Status column of each row, next to the drop-down. It helps you view the detailed conversion of the Session. On clicking the icon, the Session Details dialog box is displayed.</li> </ul>"},{"location":"automation/tools/intent-discovery/#session-details","title":"Session Details","text":"<p>The Transcript dialog box shows the summary of the session. The detailed chat is displayed below the summary. </p>"},{"location":"automation/tools/intent-discovery/#train-the-utterances","title":"Train the Utterances","text":"<p>In a scenario where the utterances cannot be mapped to the existing intents, you can create a new intent. Once the intents are listed, you can perform the following actions for the intents:</p> <ul> <li>Add a new Dialog Task or FAQ</li> <li>Train them for an existing Dialog Task or FAQ</li> <li>Change the status of utterances</li> </ul>"},{"location":"automation/tools/intent-discovery/#add-a-new-dialog-task-intent","title":"Add a new Dialog Task intent","text":"<ol> <li> <p>Click the Add/Train dropdown across the intent, then select the Dialog Task option under Add. The Add Dialog Task dialog box for the intent is displayed. </p> </li> <li> <p>Provide a name and description for the new intent.</p> </li> <li> <p>All the utterances qualified for the extracted intent are displayed in a table. The bookmark icon appears if you have bookmarked this utterance in the Extracted Intent Details dialog box. </p> </li> <li> <p>Select all the required utterances and click the Add to Bot button. A confirmation message is shown on adding a new Dialog Task. </p> </li> </ol> <p>The Actions column text for the intent will reflect the addition of a dialog task. For example:</p> <ul> <li>If Added \u2018n\u2019 new Dialog Tasks text/tag is existing, then the count increases by 1. For example: Added 1 new Dialog Task will be changed to Added 2 new Dialog Tasks.</li> <li>If there are no intents created so far, then the text becomes Added 1 new Dialog Task. </li> </ul> <p>Additionally, this  change will reflect under the Results column against the project name on the Intent Discovery homepage. For example:</p> <ul> <li>If Added \u2018n\u2019 new Dialog Tasks tag/text is existing, then the count is increased by 1. For example: Added 1 new Dialog Tasks will be changed to Added 2 new Dialog Tasks.</li> <li>If there are no Dialog tasks created so far, then the text becomes  Added 1 new Dialog Task.</li> </ul>"},{"location":"automation/tools/intent-discovery/#train-a-dialog-task","title":"Train a Dialog task","text":"<ol> <li> <p>Click the Add/Train dropdown across the intent, then select the Dialog Task option under Train. The Train Dialog Task dialog box for the intent is displayed. </p> </li> <li> <p>Select the dialog task to be trained from the Intent drop-down and select all the required utterances from the table below. Click Add Utterances. </p> </li> <li> <p>Once the existing Dialog task is trained with the selected Utterances, a confirmation message is shown. </p> </li> </ol> <p>The Actions column text for the intent will reflect the training of a new dialog task. For example:</p> <ul> <li>If Trained \u2018n\u2019 new Dialog Tasks text/tag is existing, then increase the count by 1. For example: Trained 1 new Dialog Task will be changed to Trained 2 new Dialog Tasks.</li> <li>If there are no intents created so far, then append the text with Trained 1 new Dialog Task.</li> </ul> <p>Additionally, this change will reflect under the Results column against the project name on the Intent Discovery homepage. For example:</p> <ul> <li>If Trained \u2018n\u2019 new Dialog Tasks tag/text is existing, then increase the count by 1. For example: Trained 1 new Dialog Tasks will be changed to Trained 2 new Dialog Tasks.</li> <li>If there are no Dialog Tasks trained so far, then append the text with Trained 1 new Dialog Task.</li> </ul>"},{"location":"automation/tools/intent-discovery/#add-a-new-faq-intent","title":"Add a new FAQ intent","text":"<ol> <li> <p>Click the Add/Train dropdown across the intent, then select the FAQ option under Add. The Add FAQ dialog box for the intent is displayed. </p> </li> <li> <p>Provide a name and description for the new intent. </p> </li> <li>All the Utterances qualified for the Extracted Intent are displayed in a table. The bookmark icon appears if the user has bookmarked this utterance in the Session summary dialog box. </li> <li> <p>Select all the required utterances and click Next. </p> </li> <li> <p>On the next dialog box, provide the FAQ question text to be created as an FAQ, along with the required Bot Response to be shown. All the selected utterances from the previous screen are added as alternative questions for this FAQ. </p> </li> <li> <p>Provide or select other features of the FAQ, like Bot response channel, Display name, reference ID, etc. as per your need and preference, and click the Add to Bot button. </p> </li> <li> <p>A confirmation message is shown on adding a new FAQ. </p> </li> </ol> <p>The Actions column text for the intent will reflect the addition of an FAQ. For example:</p> <ul> <li>If Added \u2018n\u2019 new FAQs text/tag is existing, then the count increases by 1. For example: Added 1 new FAQ will be changed to Added 2 new FAQs.</li> <li>If there are no intents created so far, then the text becomes Added 1 new FAQ. </li> </ul> <p>Additionally, the adding will reflect under the Results column against the project name on the Intent Discovery homepage. For example:</p> <ul> <li>If Added \u2018n\u2019 new FAQs tag/text is existing, then the count increases by 1. For example: Added 1 new FAQs will be changed to Added 2 new FAQs.</li> <li>If there are no Dialog tasks created so far, then the text becomes Added 1 new FAQ. </li> </ul>"},{"location":"automation/tools/intent-discovery/#train-an-faq","title":"Train an FAQ","text":"<ol> <li> <p>Click the Add/Train dropdown across the intent, then select the FAQ option under Train. The Train FAQ dialog box for the intent is displayed. </p> </li> <li> <p>Select the FAQ to be trained from the FAQ drop-down. A label box showing the current Bot Response appears. Select all the required utterances from the table below and click Add Utterances. </p> </li> <li> <p>Once the existing FAQ is trained with the selected Utterances, a confirmation message is shown. </p> </li> </ol> <p>The Actions column text for the intent will reflect the training of an FAQ. For example:</p> <ul> <li>If Trained \u2018n\u2019 new FAQs text/tag is existing, then the count increases by 1. For example: Trained 1 new FAQ will be changed to Trained 2 new FAQs.</li> <li>If there are no intents created so far, then the text becomes Trained 1 new FAQ.</li> </ul> <p>Additionally, the training will reflect under the Results column against the project name on the Intent Discovery homepage. For example:</p> <ul> <li>If Trained \u2018n\u2019 new FAQs tag/text is existing, then the count increases by 1. For example: Trained 1 new FAQs will be changed to Trained 2 new FAQs.</li> <li>If there are no Dialog tasks created so far, then the text becomes Trained 1 new FAQ. </li> </ul>"},{"location":"automation/tools/intent-discovery/#change-the-status-of-utterances","title":"Change the status of utterances","text":"<p>You can change the status of utterances between Yet to Review and Reviewed on the  Extracted Intent Details dialog box. You can change the status of one or multiple utterances in a go as per requirement.</p>"},{"location":"automation/tools/intent-discovery/#reusing-an-existing-project","title":"Reusing an existing project","text":"<p>There may be instances where you may need additional intents in an existing project and can achieve the same by adding transcript files to the project. The steps to upload additional transcript files are the same as uploading transcripts to a new project. Intent extraction can be performed multiple times based on need. For example, if, after having extracted intents previously, there is a need to add more intents, you can upload additional transcripts and extract intents again. Also, existing but no longer relevant transcript files can be deleted from a project. These two features ensure that an existing project becomes reusable.</p> <p>The number of files and the file size limitations remain the same.</p> <p>Uploading new transcript files will cause deletion of below data from the project:</p> <ul> <li>Extracted intents</li> <li>Summaries generated</li> <li>Utterances segregated for each session</li> <li>Status flag for each session</li> <li>Bookmarks of the utterances</li> </ul> <p>Please note that the previously loaded transcript files will not be deleted while uploading new ones. Re-extraction of intents will restore the above-deleted project data.</p>"},{"location":"automation/tools/intent-discovery/#deleting-a-project","title":"Deleting a project","text":"<p>You can also delete the project if it is no longer required. Since a maximum of 10 projects can be created within a bot, you may need to delete a past, unwanted project to make a place for a new one.</p> <p> </p> <p> </p> <p>When you delete a project, all the corresponding data in the project is automatically deleted, which includes: </p> <ul> <li>Transcripts </li> <li>Extracted intents</li> <li>Summaries generated</li> <li>Utterances segregated for each session</li> <li>Status flag for each session</li> <li>Bookmarks of the utterances</li> </ul> <p>Note</p> <p>Deletion of a project will have no impact on the Dialog Tasks/FAQ\u2019s that have been trained using the intents extracted from the deleted projects.</p>"},{"location":"automation/use-cases/feedback-surveys/","title":"Feedback Survey","text":"<p>The XO Platform allows you to design and create feedback surveys for products, services, and overall experiences using out-of-the-box templates on the web and mobile channels. </p> <p>You can configure a Virtual Assistant to launch these surveys at a certain point in a conversation or at the end of a conversation (when the end of conversation event is triggered). The NPS, CSAT, and Like/Dislike survey types are currently supported.</p> <p>Key Features</p> <ol> <li>The Feedback Module is use-case and channel-agnostic. But by default, it only shows text messages. You can always add additional channel-specific prompts to collect feedback from voice channels.</li> <li>When a feedback survey is created on the platform, all messages are in text format. The text from the platform gets converted into a voice using the ASR and TTS engines.</li> <li>You can leverage channel-specific configuration to modify the feedback prompts.</li> <li>Feedback flows are fully customizable.</li> <li>The Kore.ai XO Platform lets you configure feedback in two ways:<ul> <li>Using the built-in flows to collect the feedback and the new service type called feedback service to submit the feedback to the bots platform.</li> <li>Collecting feedback from other sources that can be pushed to the platform as part of the conversation execution.</li> </ul> </li> <li>Feedback Surveys get created as dialog tasks with a series of entities, service calls, and message notes. You have complete control of modifying the out-of-the-box messages, adding additional messages to specific channels, such as voice channels, and capturing the feedback on voice.</li> <li>You can use the automatic feedback template that the platform generates or build their flows and submit the feedback to the platform feedback service. Alternatively, it could be a hybrid approach where the feedback flow can emerge from or integrate with another flow.</li> <li>Once a customer responds to a Feedback Survey, the event displays on the chat transcript slider of the Conversations History Dashboard. Learn more.</li> <li>Additionally, you can filter and analyze Conversations (with feedback survey enabled) based on the Feedback Type, Response, and Score using prebuilt and custom filters. Learn more.</li> <li>The feedback response from a customer is captured and pushed to the platform for further analysis in three ways:<ul> <li>By creating a Dialog to capture feedback responses/scores and generate the required analytics to derive actionable insights on the Feedback Analysis Dashboard. Learn more.</li> <li>By pushing feedback data to the platform using the Public API. Learn more.</li> <li>By pushing feedback data via the Botkit. Learn more.</li> </ul> </li> <li>In addition to the primary survey question, you can configure a Follow-up Question for negative feedback to gather specific details and better understand any primary survey issues.</li> <li>Additionally, you can set an Acknowledgement Message to customers after they complete the survey to show appreciation and let them know that it has been received.</li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#navigating-to-feedback-survey","title":"Navigating to Feedback Survey","text":"<p>To navigate to the Feedback Survey feature, follow the steps below:</p> <ol> <li>On the Bot Builder, click the Build tab.</li> <li> <p>Navigate to Configurations &gt; Feedback Survey on the left navigation menu.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#feedback-template-types","title":"Feedback Template Types","text":"<p>The Platform provides the following in-built feedback template types, to create and define a feedback survey:</p>"},{"location":"automation/use-cases/feedback-surveys/#nps-scale-categorization","title":"NPS Scale Categorization","text":"<p>Known as New Promoter Score, this is a standard customer experience metric that measures the experience and loyalty of customers based on their feedback response. For a single-question survey, respondents give a rating between 0 (not at all likely) and 10 (extremely likely), and based on their response, they fall into one of the following NPS score categories:</p> CUSTOMER CATEGORY NPS SCORE DESCRIPTION Promoters 9 &amp; 10     This score indicates a loyal customer who is satisfied with the conversation and is highly likely to return.     Passives 6,7, &amp; 8     This score represents a satisfied customer who may or may not be willing to continue the conversation and return for a service.     Detractors 0,1,2,3,4, &amp; 5     This score indicates that the customer is unsatisfied with the conversation and has given negative feedback. As a result, the customer will mostly not return to the platform and may detract other customers by sharing their experiences."},{"location":"automation/use-cases/feedback-surveys/#csat-score-categorization","title":"CSAT Score Categorization","text":"<p>CSAT or Customer SATisfaction is a customer experience metric that measures or quantifies how happy the customer is with a Virtual Assistant interaction. The customer is asked to rate on a five-point scale, 1 meaning very satisfied and 5 meaning very unsatisfied, for a survey question like \u201cHow satisfied were you with the conversation?\u201d The response score is mapped to the relevant category as shown below:</p> CATEGORY SCORE Very Satisfied 1     Satisfied 2     Neutral 3     Unsatisfied 4     Very Unsatisfied 5"},{"location":"automation/use-cases/feedback-surveys/#likedislike","title":"Like/Dislike","text":"<p>The customer is asked to respond to the feedback survey by clicking a Like or Dislike icon. Like or Extremely Likely denotes the customer\u2019s positive experience and is allocated a score of 1 internally. Dislike or Extremely Unlikely indicates a negative customer experience, and is allocated a score of 0 internally.</p>"},{"location":"automation/use-cases/feedback-surveys/#feedback-survey-creation-and-definition","title":"Feedback Survey Creation and Definition","text":"<p>To create a Feedback Survey on the Bot Builder, follow the steps below:</p> <ol> <li>Navigate to Build &gt; Configurations &gt; Feedback Survey.</li> <li> <p>If this is your first feedback survey, click Add Feedback on the Feedback Survey screen.</p> <p></p> <p>Otherwise, click New Survey.</p> <p></p> <p>In the Add Feedback Survey window, define the survey details and design, and launch the survey to be visible to customers.</p> <p>The Feedback Survey definition and design flow steps are given below:</p> </li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#step-1-define-the-survey-details","title":"Step 1: Define the Survey Details","text":"<p>In this section, you can define a survey name and the type you want to use. To define the survey details, follow the steps below:</p> <ol> <li>Enter the Survey Name in the relevant text area.</li> <li>Select the Survey Type as either NPS, CSAT, or Like/Dislike. Based on your selection, the survey definition changes.</li> <li> <p>Click Next to move to the next step.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#step-2-define-the-survey-design","title":"Step 2: Define the Survey Design","text":"<p>You can define how to present the survey in the Survey Design stage which includes the following:</p> <ul> <li>Gathering the customer\u2019s feedback using one of the out-of-the-box default templates.</li> <li>Defining the primary question that will be posed to the customer when the system triggers the feedback survey.</li> <li>Setting the follow-up questions based on the feedback conditionally.</li> </ul> <p>To define the survey design, follow the steps below:</p> <ol> <li>Select the relevant option in the Add Feedback Survey window based on how you want to create the survey.</li> <li> <p>If you want to create a new Feedback Survey along with a Dialog Task to collect the feedback and capture the analytics, follow the steps below:</p> <ul> <li>Select Create a survey with a New Dialog.</li> <li> <p>Enter the Dialog Name in the text area.   </p> </li> <li> <p>Set the default Primary Question to be posed to the customer for the selected survey type when it\u2019s triggered.</p> <p></p> </li> <li> <p>Alternatively, modify/change the Primary Question in the text area.</p> </li> </ul> </li> </ol> <p>The Primary Question response options the customer will see are displayed below based on the selected survey type:</p> <p>NPS</p> <p></p> <p>CSAT</p> <p>Note</p> <p>The default response names provided for CSAT and the Like/Dislike types are editable; however, the scores set in the system cannot be changed for any survey type.</p> <p>Like/Dislike</p> <p></p> <p>Create the Survey Flow</p> <p>To create your flow, follow the steps below:</p> <ol> <li> <p>Select Create survey without Dialog and click Next.</p> <p></p> </li> <li> <p>(Optional Step): To capture additional details from the customer for a negative feedback, configure the follow-up question with the steps below:</p> </li> <li> <p>Enable the Follow-up Question option (default setting).</p> <p></p> </li> <li> <p>Define when to post the follow-up question by configuring the IF condition, where you must select the conditional option from the list for User Score.</p> <p></p> </li> <li> <p>Next, increment or decrement the feedback score counter for the selected condition to set the validation criterion.</p> <p></p> </li> <li> <p>Either edit the default follow-up question in the text area provided for the THEN clause or keep it unchanged.</p> <p></p> </li> <li> <p>Modify the Acknowledgement Message in the text area or retain the default message to acknowledge the customer\u2019s effort in taking the survey.</p> <p></p> </li> <li> <p>Click Next to move to survey launch configuration.</p> </li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#step-3-define-launch-configuration","title":"Step 3: Define Launch Configuration","text":"<p>After defining the survey, you can choose how and when to launch the survey in one of the following ways with the Launch Configuration:</p> <ul> <li>Associate the survey with the end-of-task (conversation) event.</li> <li>Add the survey task as a sub-dialog to other primary tasks.</li> </ul> <p>To configure the feedback survey launch, follow the steps below:</p> <ol> <li> <p>Select one of the following options:</p> <ul> <li>Launch after End of Task: The dialog task is considered as the \u2018End of Task\u2018 event, and the survey is triggered at the end of every conversation. When selected, End of Task (End of Conversation Event) under Intelligence &gt; Events &gt; End Of Task will be overridden and the feedback survey is launched. Through the survey dialog you\u2019ve created in the previous step.</li> <li> <p>I will decide how to launch the Survey: You can manually initiate the feedback survey at any time by using the associated dialog task in the Kore.ai XO platform. A dialog task will be made available under Build \u2192 Conversational Skills. This allows you to control when the survey is launched and gather feedback at your own convenience.</p> <p></p> </li> </ul> </li> <li> <p>Click Create to launch the feedback survey.</p> <p>A success confirmation message, as shown below, is displayed with your survey details.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/feedback-surveys/#feedback-survey-dialog-flow","title":"Feedback Survey Dialog Flow","text":"<p>After you\u2019ve created the survey, you can view the built-in survey flow as a dialog task under Build &gt; Conversational Skills &gt; Dialog Tasks on the left menu.</p> <p>The Task Flow will include a combination of Entity, Message, and Service nodes to represent the survey flow.</p> <p>You can customize the dialog flow as per your need by changing the dialog flow definition fields.</p> <p>DEFINING CUSTOM FLOWS</p> <ul> <li> <p>Feedback Service is introduced as the new Service Type option under General Settings for the Service Node. You can use this service to submit feedback on the surveys you may have captured using your custom flows.</p> <p></p> </li> <li> <p>You can invoke feedback as a sub-dialog from any other point in the conversation where you would like to capture the feedback.</p> <p></p> </li> </ul>"},{"location":"automation/use-cases/small-talk/","title":"Small Talk","text":"<p>Small Talk refers to the casual conversations that a Virtual Assistant can have with end users. The ability to engage end users in casual conversations helps your assistant socialize better with customers and improves recall rates.</p> <p>The Small Talk conversation is designed as a series of interaction volleys between the assistant and the user. VAs that can answer social inputs like How Are You? are more likely to create a positive impression and help build an invaluable connection with the user.</p> <p>You can find Small Talk on the Unified XO Platform under Build &gt; Conversational Skills &gt; Small Talk.</p> <p></p>"},{"location":"automation/use-cases/small-talk/#benefits","title":"Benefits","text":"<p>Positive interactions are key to businesses today, especially in the context of CRM automation. Even when people know that they are not being assisted by a human, they still appreciate the occasional joke, casual chat or other friendly cues that make human-to-human conversations more engaging. This is why a Virtual Assistant that can handle small talk improves the experience for your users or customers.</p> <p>The Small Talk Engine within the Kore.ai XO Platform lets you configure the conversational elements that are specific to your business context, so that you can create a conversational VA that recognizes when people make small talk and responds accordingly, thus providing a friendly experience, rather than one that feels dry and technical. </p>"},{"location":"automation/use-cases/small-talk/#features","title":"Features","text":"<p>The Small Talk Engine provides the following features:</p> <ul> <li>Custom Small Talk allows you to build a personality and train the VA to conduct casual conversations around your areas of interest.</li> <li>Nested conversations help answer follow-ups during a conversation and make the VA more engaging.</li> <li>Emoji identification: The XO Platform can identify the emojis in user utterances and respond accordingly, using Small Talk.</li> <li>Small Talk works with intent detection. Interjections, such as hello at the start of an utterance will not be considered as small talk. For example, the user\u2019s utterance Hello, I need to book a flight will be matched with the intent: book a flight, so the VA will address the user\u2019s need, rather than use Small Talk.</li> </ul>"},{"location":"automation/use-cases/small-talk/#overview","title":"Overview","text":"<p>Small Talk is a series of User Utterances and Bot Responses. The primary objective of Small Talk is to engage users in casual conversations and in general, functional topics or business transactions are not included in Small Talk.</p> <p>The various user queries in Small Talk are categorized into groups and assigned hierarchical structure. The Greetings category is auto-generated by default for all new assistants. This group contains various questions related to greetings and pleasantries. You can define additional groups or categories and build interaction flows under each group.</p> <ul> <li>Each group can have one or more top-level questions. A top-level question can have one or more child questions.</li> <li>A child question can have one or more subsequent child questions up to three levels. Every question can have one or more alternate questions.</li> <li>Every question can have one or more responses. When multiple responses are present, the Platform will pick one at random.</li> </ul>"},{"location":"automation/use-cases/small-talk/#terminology","title":"Terminology","text":"<p>Following are the various terms associated with Small Talk:</p> <ol> <li>Groups \u2013 Based upon the purpose and content, Small Talk is categorized into groups.</li> <li>User Queries \u2013 For each group, you can add User Queries, Alternate Queries, and Child Queries. Queries are formed using patterns. Know more about patterns</li> <li>Bot Responses \u2013 Each User Query must be associated with a bot response. These can be in plain text format or JavaScript. You can specify channel-specific responses. You can also enter multiple responses, one of which will be picked randomly by the Platform at runtime.</li> </ol>"},{"location":"automation/use-cases/small-talk/#default-small-talk","title":"Default Small Talk","text":"<p>Small Talk is a VA-level task that is configured automatically. When you create a new VA, the Small Talk is generated by default.</p> <p>Note</p> <p>When you open the Small Talk Task in an existing VA, you will be informed of the migration of standard responses related to greetings to the Small Talk feature. You can choose not to Proceed and continue with the Standard Responses.</p> <p>If you proceed with the migration, the Greetings will be permanently deleted from the Standard Responses section and cannot be retrieved.<p> <p>The following are the messages under the Greetings group (these are the Standard Responses of Greeting and other categories that are migrated to Small Talk once you choose to Proceed)</p> GREETINGS Response when User says Hi     Shown when the user says hi, hello, hey, etc, or just enters the VA\u2019s name.     Response to \u2018how are you\u2019?     The user asks \u201chow are you?\u201d <p> NL interprets the following ways in which the user can say that: <p>,  <p> <p> whazzupp whatcha`upto watsup wassup howzit <p> comment`est`vous comment`ca`va ca`va <p> &lt;what`up &lt;what`is`up`today <p> &lt;what`is`up &lt;what`is`the`word&gt; &lt;what`is`the`latest`word&gt; &lt;what`is`new&gt; &lt;what`is`happening&gt; <p> &lt;what`is`going`on&gt; &lt;what\u2019up &lt;is`everything`OK &lt;is`everything`alright &lt;how`you`feeling <p> &lt;how`you`doing &lt;how`is`tricks &lt;how`is`life &lt;how`is`it`going &lt;how`is`everything <p> &lt;how`is`by`you &lt;how`have`you`been`doing&gt; &lt;how`have`you`been&gt; &lt;how`goes&gt; &lt;how`goes`things <p> &lt;how`goes`it &lt;how`is`your`day &lt;how`do`you`do&gt; &lt;how`are`you&gt; &lt;how`are`things&gt; <p> Response to \u2018who are you?\u2019     Shown when the user says \u201cwho are you\u201d     User says \u2018great\u2019, \u2018awesome\u2019, etc. when there is no task in context     Shown when the user says great, awesome, etc. (probably after finishing a task)     User says \u2018that helped\u2019, \u2018that was useful\u2019, etc.     Shown when the user says good, great, awesome, cool, \u201cfair enough\u201d, \u201cthat helped\u201d, \u201cit helps\u201d, \u201cthat was useful\u201d, \u201cthat was handy\u201d etc. (probably after finishing a task)     User says \u2018no\u2019, \u2018nope\u2019, etc. when there is no task in context     This is small talk in the response to when the user utterance is \u2013 \u2018No\u2019, \u2019Nopes\u2019 etc.     User says \u2018I am done\u2019, \u2018That\u2019s it for now\u2019, etc. when there is no task in context     Shown when the user says \u201cI am done\u201d, \u201cthat\u2019s it for now\u201d, \u201cthat\u2019s all\u201d, done, etc. (probably after finishing a task)     User implies to end the conversation (eg. \u2018good night\u2019, \u2018bye\u2019, \u2018ttyl\u2019)     This condition occurs only for Dialog tasks for which the following Follow-up Tasks Setting is configured: \u201cYes, at the end of this dialog ask the user to select and perform a task from \u2018Follow-up task\u2019 list in the Dialog settings.\u201d The VA shows this message when it presents the Follow-Up Intents array to the user at the end of the Dialog.     User says thanks     Shown when the user thanks the VA.     User says \u2018OK\u2019, \u2018fine\u2019, \u2018yes\u2019 etc. when there is no task in context     Shown when the user says OK, fine, got it, etc (probably after finishing a task)     <p></p>"},{"location":"automation/use-cases/small-talk/#customize-small-talk","title":"Customize Small Talk","text":"<p>This section provides step-by-step guidance on the general set up and group configurations to customize Small Talk for your VA.</p>"},{"location":"automation/use-cases/small-talk/#general-setup","title":"General Setup","text":"<p>To add Small Talk to your VA, follow the below steps:</p> <ol> <li>Open the VA to which you want to add Small Talk;</li> <li>From the top menu, go to Build and access the sub-menu Conversational Skills -&gt; Small Talk</li> <li>You need to start by adding a New Group.</li> <li>Next, you need to add User Queries and Bot Responses.</li> </ol>"},{"location":"automation/use-cases/small-talk/#add-groups","title":"Add Groups","text":"<p>You can create a New Group manually by clicking New Group.</p> <p></p> <p>On the New Group dialog box, enter a name in the Group Name field, then click Proceed.</p> <p></p> <p>From the Small Talk editor that opens you can enter User Utterance \u2013 Bot Response pairs and Add to the list.</p> <p></p>"},{"location":"automation/use-cases/small-talk/#group-settings","title":"Group Settings","text":"<p>On hovering over any Small Talk group, you have the option to:</p> <ul> <li>Delete the group.</li> <li>Settings that will allow you to:</li> <li> <p>Manage Variable Namespaces by associating a variable namespace to use with this Small Talk group. This option is visible only when the variable namespace is enabled for the VA. For more information, refer to Managing Namespace.</p> <p></p> </li> </ul>"},{"location":"automation/use-cases/small-talk/#import-small-talk","title":"Import Small Talk","text":"<p>If you have already had Small Talk for your company, you can import it using a JSON or TSV file  </p> <ul> <li>While in Small Talk, click the more (ellipses) icon and select the Import option.</li> </ul> <p></p> <ul> <li>At this point you can download  a sample file to get the formatting details, if you need them. Once your import file is prepared, select it and click Next.  </li> </ul> <p></p> <ul> <li>The import begins instantly.</li> </ul> <p>Warning</p> <p>Existing Small Talk will be replaced with the imported file.</p>"},{"location":"automation/use-cases/small-talk/#modify-the-existing-greetings-group","title":"Modify the Existing Greetings Group","text":"<p>You can click the existing Greetings group to modify it, if the default small talk does not fit your needs. From the Small Talk editor that opens you can now enter User Utterance \u2013 Bot Response pairs and Add to the list.</p>"},{"location":"automation/use-cases/small-talk/#work-with-query-response-pairs","title":"Work with Query \u2013 Response Pairs","text":"<p>Once you create/import a group, you can add/modify the query-response pairs.</p> <ol> <li>Enter the User Query in the User column and the corresponding Bot Response in the Bot column.</li> <li> <p>Press Enter or Add to add the query-response pair to the list.</p> <p></p> </li> <li> <p>Queries are designed using patterns. Know more about patterns.</p> </li> <li> <p>For each User Query, you can enter alternate questions that depict a different way the user might ask the same query.</p> </li> <li> <p>For each bot response, you can enter alternate responses. The Platform picks one response at random during runtime.   </p> </li> <li> <p>Using the handlebar icon that appears in front of the question on hover, you can rearrange the order of the questions.</p> <p></p> </li> <li> <p>Each User Query can have a child query. The child-questions can be asked only when the parent-question is asked and responded to. To add a Child Query, use the + icon that appears next to the question when you hover over it.</p> <p></p> </li> <li> <p>You can delete query or response alternatives by hovering over them and clicking the red x on the top right corner.</p> <p></p> </li> <li> <p>You can also delete the entire Query-Response pair, along with its child pair by hovering over the parent and clicking the bin icon on the far right. You will be asked to confirm your choice.</p> <p></p> </li> <li> <p>Responses are Channel-specific and Java Script formatted. By clicking the Settings (gear icon) that appears next to the response, when you hover over it you will reach the Manage Response window. Here is where you can configure the following:</p> </li> <li>Add a default message to be displayed on all channels.</li> <li>For channel-specific responses:<ul> <li>Click + Add Response.</li> <li>Click the New Prompt Message.</li> <li>Select Channel.</li> <li>Enter the response in standard text or in Java Script using the Advanced Mode. If applicable Select a Template. (see here for more on message formatting).  </li> <li>Click Save.</li> </ul> </li> </ol>"},{"location":"automation/use-cases/small-talk/#small-talk-context","title":"Small Talk Context","text":"<p>You can mark desired information in the user utterance pattern definition and it will be available in the context. A new section called Small Talk is introduced under NLP Analysis which stores the contextual information from the ongoing small talk. You can use this information to personalize the Small Talk messages.</p> <p>Marking a section in the user input pattern by including an underscore \u2018_\u2019 symbol you can indicate the required information. For example, I am from _~location Where are you from? will allow you to capture the location from the user utterance.  This information is stored in the Small Talk context and can be accessed using: <code>context.smallTalk.matchData.0</code></p> <p>The following is the JSON structure:</p> <pre><code>{\n  \"pattern\": \"I am from _~location Where are you from?\",\n  \"matchData\": {\n    \"_0\": \"chicago\"\n  },\n  \"previousMatchData\": []\n}\n</code></pre> <p>You can define and store multiple pattern tokens in the same user input and they can be accessed using the positional count variables \u2013 0, 1, 2 so on, and so forth. Since they capture the positional content, they are not continuous in case the optional token is missing from the user utterance. </p> <p>For example, consider the pattern: how is the [ climate temperature ]  { at _~location } ~time</p> <p>Case1: user utterance: \u201chow is the temperature in London today\u201c</p> <p>context: </p> <pre><code>{\n  \"pattern\": \"how is the _[ climate temperature ]  { at _~location } ~time\",\n  \"matchData\": {\n    \"_0\": \"temperature\"\n    \"_1\": \"London\"\n    \"_2\": \"today\"\n  },\n  \"previousMatchData\": []}\n</code></pre> <p>Case2: user utterance: \u201chow is the climate today\u201c</p> <p>context:  <pre><code>{\n  \"pattern\": \"how is the _[ climate temperature ]  { at _~location } ~time\",\n  \"matchData\": {\n    \"_0\": \"climate\"\n    \"_2\": \"today\"\n  },\n  \"previousMatchData\": []\n}\n</code></pre></p> <p>The context can be accessed from the child nodes under previousMatchedData array using: <code>context.smallTalk.previousMatchData[i].matchData.0</code> with the variable i taking the index value of 0, 1, and 2 based on the parent level.</p> <p>The JSON structure for the parent Small Talk context would be:</p> <p><pre><code>{\n  \"pattern\": \"That is nice\",\n  \"matchData\": {},\n  \"previousMatchData\": [\n    {\n      \"pattern\": \"I am from _~location Where are you from?\",\n      \"matchData\": {\n        \"_0\": \"chicago\"\n      }\n    },\n    {\n      \"pattern\": \"That is far.\",\n      \"matchData\": {}\n    }\n  ]\n}\n</code></pre> The context persists until one of the below scenarios occurs:</p> <ul> <li>End of the session.</li> <li>A new primary Small Talk intent is detected.</li> <li>Any other intent which is not Small Talk is triggered.</li> </ul>"},{"location":"automation/use-cases/small-talk/#training","title":"Training","text":"<p>Once you have made changes to the Small Talk, it needs to be trained for the VA to pick up the Small Talk. Click  Train on the Small Talk editor screen to train the assistant.</p> <p>Note</p> <p>Importing Small Talk file triggers the training automatically.</p> <p></p> <p>Key Considerations</p> <p><ul><li>Only three levels of child nodes are allowed in Small talk. The child questions are identified only if the corresponding parent level question was answered in the previous volley.</li> <li>The questions are evaluated in the order in which they are added to a group. It is advisable to add generic small talk at the end and specific small talk at the beginning (For example, how is your day today? must be added first and then followed by how are you). You can re-order the primary questions after adding them.</li> <li>Groups are also evaluated in the order in which they are added.</li> <li>Duplicate top-level questions, across all categories, are not allowed.</li> <li>Intents and Knowledge Collection will take precedence over Small Talk i.e. when Intents (or FAQs) and Small Talk are detected, preference is given to Intents (or FAQs).</li> <li>Any Small Talk identified is displayed after Ranking &amp; Resolver.</li> <li>Small talk is language-specific. If your assistant is multilingual, then you can design Small Talk in each of the enabled languages.</li> <li>Interruption Behavior for Small Talk is handled using the following options under Build &gt; Intelligence &gt; Manage Interruptions &gt; Interruption Behavior for Small Talk:</li> <ul><li>Respond to Small Talk and resume the on-hold task \u2013 this is the default setting.</li> <li>Execute the Small Talk using Hold &amp; Resume settings. </li></ul> </ul></p> <p></p>"},{"location":"automation/use-cases/using-session-and-context-variables/","title":"Using session and context variables","text":""},{"location":"automation/use-cases/using-session-and-context-variables/#using-session-and-context-variables-in-tasks","title":"Using Session and Context Variables in Tasks","text":"<p>When you define tasks, you can access session variables provided by the Bots Platform, or custom variables that you define, as well as the context object that defines the scope of the variable.</p> <p>For example, some API requests may require you to set session variables before request execution, or a dialog task component may need to access a session variable to transition to the next node. In addition, a dialog task can access the <code>context</code> object with additional system variables. For more information, see the Context Object.</p> <p>You can use session variables where you define JavaScript for the User Prompt editor in tasks under the JavaScript tab.</p>"},{"location":"automation/use-cases/using-session-and-context-variables/#session-variables","title":"Session Variables","text":"<p>This section describes the context variables and the scope of the context variables that you can use in your custom JavaScript code for your tasks.</p> <p>The JavaScript syntax to GET, PUT, or DELETE a key/value pair for each context type is:</p> <pre><code>  \"EnterpriseContext\" : {\n       \"get\" : function(key){...},//get the specified key\n       \"put\" : function(key, value, ttl){...} //put the value at the key for the specified ttl, ttl is in minutes\n       \"delete\" : function(key)//remove the specified key\n   },\n   \"BotContext\" : {\n       \"get\" : function(key){...},//get the specified key\n       \"put\" : function(key, value, ttl){...} //put the value at the key for the specified ttl, ttl is in minutes\n       \"delete\" : function(key)//remove the specified key\n   },\n   \"UserContext\" : {\n       \"get\" : function(key){...},//get the specified key\n   },\n   \"UserSession\" : {\n       \"get\" : function(key){...},//get the specified key\n       \"put\" : function(key, value, ttl){...} //put the value at the key for the specified ttl, ttl is in minutes\n       \"delete\" : function(key)//remove the specified key\n   },\n   \"BotUserSession\" : {\n       \"get\" : function(key){...},//get the specified key\n       \"put\" : function(key, value, ttl){...} //put the value at the key for the specified ttl, ttl is in minutes\n       \"delete\" : function(key)//remove the specified key\n   }\n</code></pre> <p>For example:</p> <pre><code>BotContext.put(\"topicSessionVariable\",\"music\",2000);\nUserSession.put(\"firstName\",\"Mary\",20000);\nUserContext.get(\"firstName\");\n</code></pre> <p>Note</p> <p>put (), get (), and delete () methods support EnterpriseContext, BotContext, UserSession, and BotUserSession object types. UserContext session type is supported only for the get () method.</p>"},{"location":"automation/use-cases/using-session-and-context-variables/#delete-method","title":"delete() method","text":"<p>The delete() method is used to delete only the root-level object.</p> <p>For example,</p> <pre><code>var Company = {\n\n    \"name\":\"Kore.ai\"\n\n}\n\nvar Address = {\n\n    \"location\": \"Hyd\"\n}\n\nBotUserSession.put(\"Company\", Company);\nBotUserSession.delete(\"Company\");\n</code></pre> <p>Note</p> <p>The syntax <code>BotUserSession.delete(\"Company\")</code> is used to delete the root-level object, Company. Using the same syntax, you cannot delete the key-value pairs inside the root-level object. <code>BotUserSession.delete(\"Company.name\")</code> is not supported. If you want to delete the key-value pairs, use the syntax \u2013 <code>delete context.session.BotUserSession.{path to delete the key}</code>.</p> <p>For example, using <code>delete context.session.BotUserSession.Company.name</code>, you can delete the name defined inside the Company. You cannot delete the root-level object using the syntax <code>delete context.session.BotUserSession.Company</code>.</p>"},{"location":"automation/use-cases/using-session-and-context-variables/#put-method","title":"put() method","text":"<p>Using the put () method, you can insert objects at the root-level for EnterpriseContext, BotContext, UserSession, and BotUserSession object types. For example, <code>BotUserSession.put(\"Company\", Company)</code>.</p> <p>Note</p> <p>You cannot insert key-value pairs inside the root level object. The syntax <code>BotUserSession.put(\"Company.Address\", Address)</code> is not supported.</p>"},{"location":"automation/use-cases/using-session-and-context-variables/#get-method","title":"get() method","text":"<p>Using the get () method, you can retrieve the root-level object for EnterpriseContext, BotContext, UserSession, and BotUserSession object types. For example, <code>BotUserSession.get(\"Company\")</code>.</p> <p>Note</p> <p>You cannot retrieve key-value pairs inside the root level object. The syntax <code>BotUserSession.get(\"Company.name\")</code> is not supported.</p>"},{"location":"automation/use-cases/using-session-and-context-variables/#session-variable-types","title":"Session Variable Types","text":"<p>The following types of session variables are available on the XO Platform:</p> <ul> <li> <p>EnterpriseContext \u2013 A key/value pair available to all assistants and all users in an enterprise. For example, with the GitHub bot, a user will need to access one or more enterprise repositories. You can persist the repository data as Gitrepository (Enterprise Context) with the following JavaScript code: </p> <pre><code>var userRepository = {\n\"title\": _labels_[repository],\n\"value\": repository\n};\nEnterpriseContext.put('Gitrepository', userRepository, 200000);\n</code></pre> </li> <li> <p>BotContext \u2013 A key/value pair available to all users of this specific bot. For example, you may want to set up a default currency for financial transactions for a session based on a user\u2019s location. You can persist the default currency data as currency (Bot Context) with the following JavaScript code:</p> <pre><code>var defaultCurrency = { TODO Custom JavaScript for location-based currency }\nBotContext.put('currency', defaultCurrency, 200000);\n</code></pre> </li> <li> <p>UserContext \u2013 A key/value pair available to all assistants for a user. These keys are read-only and provided by the system as user data for:</p> <ul> <li>UserContext.get(\u201c_id\u201d) \u2013 The Kore.ai user ID.</li> <li>UserContext.get(\u201cemailId\u201d) \u2013 The email address associated with the user ID.</li> <li>UserContext.get(\u201clastName\u201d) \u2013 The last name of the user.</li> <li>UserContext.get(\u201cfirstName\u201d) \u2013 The first name of the user.</li> <li>UserContext.get(\u201cprofImage\u201d) \u2013 The image or avatar filename of the user.</li> <li>UserContext.get(\u201cprofColor\u201d) \u2013 The account color for the user.</li> <li>UserContext.get(\u201cactivationStatus\u201d) \u2013 The account status of the user. Can be:<ul> <li><code>active</code> \u2013 The user is active and can interact with other Kore.ai users.</li> <li><code>inactive</code> \u2013 The user is not active, but user data is retained in the system.</li> <li><code>suspended</code> \u2013 The user is suspended by an administrator. The user cannot log on to Kore.ai, however, messages can still be sent to the suspended user.</li> <li><code>locked</code> \u2013 The user exceeded the maximum number of login attempts.</li> </ul> </li> <li>UserContext.get(\u201cjTitle\u201d) \u2013 The title of the user, if defined.</li> <li>UserContext.get(\u201corgId\u201d) \u2013 The organizational ID of the user account, if defined.</li> <li>UserContext.get(\u201ccustomData\u201d) \u2013 Use this to pass user information to web channels, currently only for webSDK. For more information, see Kore.ai Web SDK Tutorial.</li> <li>UserContext.get(\u201cidentities\u201d) \u2013 Alternate user IDs, if defined.<ul> <li><code>val</code> \u2013 The alternate ID</li> <li><code>type</code> \u2013 The type of alternate ID.</li> </ul> </li> </ul> <p>For example, you can PUT a value into the session using the <code>UserSession</code> variable where the key is defined as <code>fullName</code> based on the GET from the two <code>UserContext</code> variables.</p> <pre><code>var name = UserContext.get(\"firstName\")+UserContext.get(\"lastName\");\nUserSession.put(\"fullName\") = name;\n</code></pre> </li> <li> <p>UserSession \u2013 A key/value pair that you can define for this specific user for all assistants in an enterprise. </p> <p>For example, you may want to store a user location to make it available to all assistants, such as a user home address for commerce, transportation, and home delivery services. </p> <p>You can persist default location data as HomeLocation (UserSession) with the following JavaScript code: </p> <pre><code>var location = {\n\"title\": labels[location],\n\"value\": {\n\"latitude\": location.latitude,\n\"longitude\": request.location.longitude\n}\n};\nUserSession.put('HomeLocation', location, '20000');\n</code></pre> </li> <li> <p>BotUserSession \u2013 A key/value pair that you can define to a specific bot based on the inputs by a specific user. For example, you may want to persist a user location for more than one task of a Bot. </p> <p>For a travel bot, the user may be able to book a flight and a hotel based on the same home and destination addresses. </p> <p>For example, you can persist the default home and destination data as HomeLocation (BotUserSession) and DestinationLocation (BotUserSession) with the following JavaScript code:</p> <pre><code>var homelocation = {\n\"title\": labels[request.sourceLocation],\n\"value\": {\n\"latitude\": request.sourceLocation.latitude,\n\"longitude\": request.sourceLocation.longitude\n}\n};\nBotUserSession.put('HomeLocation', homelocation, '20000');\nvar destlocation = {\n\"title\": labels[request.destLocation],\n\"value\": {\n\"latitude\": request.destLocation.latitude,\n\"longitude\": request.destLocation.longitude\n}\n};\nBotUserSession.put('DestinationLocation', destlocation, '20000');\n</code></pre> </li> </ul>"},{"location":"automation/use-cases/using-session-and-context-variables/#standard-keys","title":"Standard Keys","text":"<p>In addition to session and context keys, there are Kore.ai variable placeholders for reusable data. Select one of:</p> <ul><li>_labels_ \u2013 Used to return the friendly label in place of a GUID. For example, when user data is requested from a web service API, the ID of a project or workspace returned is a GUID. You can use the `_labels_` key to show the user-friendly name of the GUID to the end-user instead of the GUID. In Kore.ai, a drop-down control stores the response for the `_labels_` key as, for example:  <pre><code>{\n    \"_labels_\": {\n        \"15379386734832\": \"roadlabs.com\",\n        \"26377329985341\": \"Test Project\",\n        \"workspace\": \"roadlabs.com\",\n        \"project\": \"Test Project\"\n    },\n    \"_fields_\": {\n        \"workspace\": \"15379386734832\",\n        \"project\": \"26377329985341\"\n    }\n}\n</code></pre> </li></ul> <p>To use the <code>_labels_</code> key in a response:</p> <p><code>print('&lt;a href=\"https://app.asana.com/0/' + workspace.id + '/' + id + '/f\" target=\"_blank\"&gt;' + title + '&lt;/a&gt; in workspace '+_labels_[workspace.id]);</code></p> <ul><li>_tenant_ \u2013 Used to return the tenant for the enterprise when defined. For example, JIRA requires a tenant for URLs, such as myteam, in <code>https://myteam.atlassian.net/browse/RTM-1978</code>. You can use the <code>_tenant_</code> key to build a link in a task response such as: <code>var title = request.fields.issuetype.name + ' ' + request.fields.summary + '  has been created.';</code></li> <li>_fields_ \u2013 Used to return an action task field input provided by the end-user that is not part of a payload response. For example, in a JIRA action task, the end-user is prompted to enter a workspace name. You can use the <code>_fields_</code> key to store the end-user input as:  <code>_fields_[\"workspace\"]</code></li> <li>_last_run \u2013 Used to return the UTC date timestamp of a web service poll using ISO 8601 format, for example, 2016-03-05T12:44:38+00:00. For example, if a web service request returns all activity in a payload response, you can use the <code>_last_run</code> key to filter results displayed before or after the value for <code>_last_run</code>.</li></ul>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/","title":"Configure Digital Forms","text":"<p>In this How-To, we will explore a scenario in a Banking Bot, where the user can create an additional account. We will see how Digital Forms can be used to gather all the required information from the user and create the account.</p> <p>For details on what Digital Forms are and how it is implemented in the Kore.ai Bots platform, click here.</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#illustration-with-an-example","title":"Illustration with an Example","text":"<p>Consider a Banking Bot trying to address the following scenarios:</p> <ol> <li>An already registered user wants to open an additional account.</li> <li>There are three types of accounts that are available, each with further options:</li> <li>Savings Account.</li> <li>Checking Account with an option to opt for a Cash Card and set the miniumum balance.</li> <li> <p>Credit Card with an option to choose the type of card to be Platinum, Gold, Silver or Basic.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#prerequisites","title":"Prerequisites","text":"<ul> <li>Bot building knowledge.</li> <li>A configured Banking Bot.</li> </ul>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#configurations","title":"Configurations","text":"<p>Let us consider each of the following scenarios:</p> <ol> <li>Digital Form to gather input from the user;</li> <li>Dialog Task to:<ul> <li>Trigger the above Digital Form.</li> <li>Capture the user-entered account information.</li> </ul> </li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#digital-form-configuration","title":"Digital Form Configuration","text":"<p>Create a form to gather the following information:</p> <ul> <li>Account Name \u2013 pre-populated with the user\u2019s name with an option to change it;</li> <li>Type of Account that the user wants to create, default selection to Savings Account;</li> <li>Based on the type of account selected above the following details to be gathered:<ul> <li>Savings \u2013 No further information required.</li> <li>Checkings \u2013 Whether Cash Card is required, if yes then the maximum withdrawal limit (range between $100 to $1000) to be enforced on that card;</li> <li>Credit Card \u2013 The type of card required<ul> <li>Platinum card (levies additional charge).</li> <li>Gold</li> <li>Silver</li> <li>Basic</li> </ul> </li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#form-creation","title":"Form Creation","text":"<ol> <li>From the Kore.ai Bot Builder platform, open the Banking Bot.</li> <li>Select the Build tab from the top menu.</li> <li>From the left navigation menu, select Digital Skills -&gt; Digital Forms to access the Digital Forms page.</li> <li>Click New Form and enter the following:<ul> <li>Name \u2013 name to the form, say OpenAccount</li> <li>Display Name for the form, say Open an Account</li> <li>Description of the form.     Select form\u2019s Header Style: You can choose a specific header style from the listed illustrations \u2013 the circle indicates the position of logo/icon with respect to the title of the form in the header.      Click the card to select the style. If it has a logo, you can upload an image file (png or jpg) for the logo.      <p>Note</p> <p>During the Export of the Bot, the logo is not exported along with Digital Forms. So, while importing this Bot, you need to separately copy the logo image file and then manually reupload the logo.</p> </li> </ul> </li> <li>Description: Turn on the toggle to show a description of the form in the header.</li> <li> <p>Save &amp; Proceed to the next step.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#form-editor","title":"Form Editor","text":"<ol> <li>Form Editor opens with components on the left, and a blank form. You can drag and drop components to the form as per your requirement.</li> <li>By default, a Submit button is added to the form. This would trigger the submit event which would capture the user input and save in context object.</li> <li>Drag and drop a Text Field component onto the form.</li> <li>As soon as you drag and drop a component, its property settings panel will be displayed.</li> <li> <p>In that panel set the following values:</p> <ul> <li>Display Name say Name.</li> <li>Name used for internal reference, say accountname.</li> <li>Description of the field.</li> <li>Placeholder value to be displayed in the field when blank, say, Enter the name of the account holder.   </li> </ul> </li> <li> <p>Next, a selection box for the type of account to be opened. Drag and drop a Dropdown component onto the form and set the following values:</p> <ul> <li>Display Name say Type.</li> <li>Name used for internal reference, say accounttype.</li> <li>Description of the field.</li> <li>Placeholder value to be displayed in the field when blank, say, Select the type of account you want to open.</li> </ul> </li> <li>Scroll and locate Data Settings, and deselect Multi Select option.</li> <li> <p>Against Dropdown values click Add Values to enter the values \u2013 Checkings, Savings, Credit Card. You can mark one value, Savings, as default. This would be selected by default at the time of execution.</p> <p></p> </li> <li> <p>Next, for the Cash Card option when the account type is selected to be a Checkings account. Drag and drop a Toggle component onto the form and set the following values:</p> <ul> <li>Display Name say Cash Card.</li> <li>Name used for internal reference, say cashcard.</li> <li>Description of the field. In this case, the question, Want a cash card?</li> <li>Value as Yes when selected and No when deselected.</li> </ul> </li> <li>Scroll and locate Visibility Settings. This component should be visible only when the account type is set to Checkings.</li> <li> <p>Add Visibility Rules \u2013 Rule 1 for the field to be Visible, select accounttype field, =(Equal To) operator, Value comparison with, Checkings value.</p> <p></p> </li> <li> <p>If the user opts for cash card, then the withdrawal limit needs to be set on the same. Drag and drop a Range Slider component onto the form and set the following values:</p> <ul> <li>Display Name say Withdrawal Limit.</li> <li>Name used for internal reference, say withdrawallimit.</li> <li>Description of the field.</li> <li>Placeholder value to be displayed in the field when blank, say, Set the withdrawal limit.</li> </ul> </li> <li>Deselect Is Percentage</li> <li>Select Value as 100 for Min and 1000 for Max.</li> <li>Under Data Settings you can set the Default Value to be 150, this would be pre-selected.</li> <li>Visibility Rules would be a compound rule \u2013 account type is checkings and cash card is selected.</li> <li>Scroll and locate Visibility Settings. This component should be visible only when the account type is set to Checkings and the Cash Card is opted.</li> <li>Add Visibility Rules \u2013 Rule 1 field to be visible when, select, accounttype field, =(Equal To) operator, Value comparison with Checkings value  AND selecting cashcard  field, =(Equal To) operator, Value comparison with Yes value.</li> <li> <p>Switch to Advanced Mode to enter the visibility rules.</p> <p></p> </li> <li> <p>For the Credit Card option,you need to further select the type of card. Drag and drop a Radio Button component onto the form and set the following values:</p> <ul> <li>Display Name say Card Type.</li> <li>Name used for internal reference, say cardtype.</li> <li>Description of the field.</li> <li>Placeholder value to be displayed in the field when blank, say, Choose the type of credit card.</li> </ul> </li> <li>Under Data Settings, set the Radio values to be Platinum, Gold, Silver, and _Basic.</li> <li> <p>Scroll and locate Visibility Settings. This component should be visible only when the account type is set to Credit Card.</p> </li> <li> <p>Set Is visible flag to Yes.</p> </li> <li> <p>Add Visibility Rules \u2013 Rule 1 for the filed to be Visible, select accounttype field, _=(Equal To) operator, Value comparison with, Credit Card value.</p> <p></p> </li> <li> <p>Finally, the Pro-Tip, when user selects a Platinum card. Drag and drop a Pro Tip component onto the form and set the following values:</p> </li> <li>Set Display Name as Platinum Tip.</li> <li>Name used for internal reference, mention platinumtip.</li> <li>Description would be the tip you want to display, eg. Additional charges will apply.</li> <li>Scroll and locate Visibility Settings. This component should be visible only when the account type is set to Credit Card.</li> <li>Set Is visible flag to Yes</li> <li> <p>Add Visibility Rules \u2013 Rule 1 for the field to be Visible select accounttype field, =(Equal To) operator, Value comparison with, Credit Card value AND selecting cardtype field, =(Equal To) operator, Value comparison with, Platinum value.</p> <p></p> </li> </ol> <p>Your form is ready. You can toggle between Desktop View and Mobile View to see how it looks in those devices. </p> <p></p> <ol> <li>You can select how the VA handles the conversation when the user cancels the form. You can choose from two options:</li> <li> <p>Discard the task and trigger End of Task Event: This is the default option.</p> <p></p> </li> <li> <p>Continue with this task and transition to this node: In the Select Node drop-down list, you can select any node present in the current dialog task.</p> <p></p> <p> <p>Note</p> <p>The target node has to be in the same dialog, you cannot make a jump to a target node outside the current dialog. The list of target nodes only shows the local nodes. If the target node is not present during runtime, the platform presents the error Error in continuing the conversation, and the task should get discarded.</p> </p> </li> <li> <p>Use the Test button to see a preview.</p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#dialog-task-configuration","title":"Dialog Task Configuration","text":"<p>We will be creating a dialog task and adding a form node to trigger the Digital Form created in the above step and use a service node to make a service call to add the new account from the form data.</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-forms/#create-dialog-task","title":"Create Dialog Task","text":"<ol> <li>Select the Build tab from the top menu</li> <li>From the left navigation menu, select Conversational Skills -&gt; Dialog Tasks.</li> <li>Click the + against the Dialog Tasks to create a new Task<ul> <li>Enter IntentName, say, OpenAccount</li> <li>Click Create &amp; Proceed to open the dialog builder page.</li> </ul> </li> <li>Retain the Intent Node default settings, and close the Intent Node.</li> <li>Click the + next to the intent node and select the Form option.</li> <li> <p>From the dropdown list select the form (OpenAccount) we created earlier.</p> <p></p> </li> <li> <p>You will be prompted to select the Form Experience. Kore.ai Bots platform allows you to gather user input both from the form and through conversation based on the channel.</p> </li> <li>For this use case, select Only Form UI experience.</li> <li>A Form Node would be added, you can customize the form name, etc.</li> <li>We are changing the Name to OpenAccountForm and Display Name to Form to open account.</li> </ol> <p>Capture Form Node Values</p> <p>Next, to capture the values returned by the Form Node using a Script node and displaying the same, follow the steps below:</p> <ol> <li>Add a Message Node to the form node.</li> <li>Set the Name to FormMessage and Display Name to Form Message.</li> <li> <p>Click MANAGE RESPONSES to open the message editor. </p> </li> <li> <p>Select the JavaScript tab and enter the following code. This code would capture from the context object, the data submitted by the user in the Form and display it accordingly.  <code>var message;</code></p> </li> </ol> <p><pre><code>message = 'You have opened a '+context.forms.OpenAccount.accounttype+' account in the name of '+context.forms.OpenAccount.accountname;\nif (context.forms.OpenAccount.accounttype == 'Checkings' &amp;&amp; context.forms.OpenAccount.cashcard == 'Yes')\n  message = message + ' and opted for cash card with withdrawal limit set to '+ context.forms.OpenAccount.withdrawallimit;\nif (context.forms.OpenAccount.accounttype == 'Credit Card')\n  message = message + ' and opted for a '+ context.forms.OpenAccount.cardtype+' card';\nprint(message);\n</code></pre> </p> <p>Your dialog with form is ready! Talk to bot and trigger the above dialog. The form will be displayed, enter the values and click Submit, the message would be displayed. </p> <p></p> <p>You can use the context object as shown above it a Script or Service nodes for further processing.</p> <p>Click here to learn how to add this data to a data table.</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/","title":"Configure Digital Views","text":"<p>In this help document, we will explore how a user can view his/her account details using digital views. We will see how a Digital View can be presented using Panels and Widgets. Widgets can be used to trigger Dialog Tasks and display appropriate messages and Panel can be used to hold these Widgets.</p> <p>We will also see how the Panel can be hosted on Web/Mobile Client using the Widget SDK.</p> <p>For details on what Digital Views are and how it is implemented in the Kore.ai Bots platform, refer here.</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#illustration-with-an-example","title":"Illustration with an Example","text":"<p>Consider a Banking Bot trying to address the following scenarios:</p> <p>This document gives a detailed step-by-step approach to achieving all the above-mentioned scenarios using \u2013 Digital Views (Panels, Widgets), Widget SDK and Web/Mobile Client.</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#prerequisites","title":"Prerequisites","text":"<ul> <li>Bot building knowledge</li> <li>A Banking Bot with a dialog as mentioned below:</li> <li> <p>Get Balance \u2013 Dialog task prompting the user for their Account Number and Account Type and displaying the available balance in the account.</p> <p></p> </li> </ul>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#configurations","title":"Configurations","text":"<p>Let us consider each of the following configuration scenarios:</p> <ol> <li>Dialog Task to display balance in a given account using Widget SDK channel.</li> <li>Widgets to trigger the above dialog task and a Panel set with the widgets.</li> <li>Panel to hold a widget displaying static JSON templace message.</li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#message-template","title":"Message Template","text":"<p>First, the Dialog task which would be triggered from the Widget should have a message definition for the Widget SDK channel.</p> <p></p> <p>We use the following message to display the account details:</p> <pre><code>var output = 'The Balance in your' + context.entities.AccountType + ' account is ' + context.GetAccountBalance.response.body.Balance;\nvar message = {\n    \"elements\": [\n        {\n            \"title\": \"Account View\",\n            \"sub_title\": output,\n            \"icon\": \"https://kore.ai/wp-content/uploads/banking-home.png\",\n        }\n    ]\n};\nprint(JSON.stringify(message));\n</code></pre>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#widgets-configuration","title":"Widgets Configuration","text":"<p>You can configure the following widget types:</p>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#dialog-task-widgets","title":"Dialog Task Widgets","text":"<p>We will be creating two Widgets to trigger a Dialog Task.</p> <p>Current Account:</p> <p>First, let us see how to configure a Widget to display balance from the current account of the user with the steps below:</p> <ol> <li>Ensure that Build is selected from the top menu.</li> <li>From under Digital Skills open Digital Views.</li> <li>Click the Create Widget button.</li> <li>Give a Widget Name and a Display Name.</li> <li>Set the Source, we are triggering Dialog Task, hence select Dialog Task.</li> <li>Select Dialog Task as Get Balance, as per our use case</li> <li> <p>In the Entity Assignment, set the following entities (you can select from the drop box that appears as you type) as per the Dialog Task requirement:</p> <ul> <li>AccountType to current;</li> <li>AccountNumber to 1. </li> </ul> <p>You can use the Open Dialog Task icon, next to the select Dialog Task drop down, to open the dialog and check the entities needed.</p> <p></p> </li> <li> <p>Save the widget.</p> </li> <li>Edit the widget and click Run &amp; Preview to see the widget output.</li> <li>Save as preview will set the output as the thumbnail against the widget.</li> </ol> <p>Savings Account Repeat the above steps for Account View from savings account of the same account number. </p> <p></p>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#panel-configuration","title":"Panel Configuration","text":"<p>The Widgets thus created need to be attached to a Panel for runtime display and execution.</p> <ol> <li>Click the Create Panel button to create a Panel.</li> <li> <p>In the New Panel window, enter Panel Name, Display Name and a URL for Icon.</p> <p></p> </li> <li> <p>Click the Add Widget button to open the Panel Management window.</p> </li> <li> <p>Use the Add Widget to select and add the Widgets that we want to display, in this case Account Balance and Current Account widgets.</p> <p></p> </li> <li> <p>Use the Test button to see the widgets in action. </p> <p></p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#panel-with-json-widgets","title":"Panel with JSON Widgets","text":"<p>We will see how to create Widgets with static JSON content. We will use a JSON to display a pie chart.</p> <ol> <li>Click Create Panel to create a new panel and name it JSON Example.</li> <li> <p>Use the more icon and select Panel Management, there you will find the option to Create Widget. Click on that.</p> <p></p> </li> <li> <p>In the New Widget dialog, enter the Name, and set the source to JSON.</p> <p></p> </li> <li> <p>Enter the following in the JavaScript Editor. This is a message template to display a pie chart with a break up for amounts spent under various heads like travel, food, and accommodation. For more on supported message templates, click here. </p> </li> </ol> <pre><code>{     \"templateType\": \"piechart\",\n      \"pie_type\": \"regular\",\n      \"title\": \"Summary\",\n      \"description\": \"monthly report\",\n      \"elements\": [\n        {\n          \"title\": \"Airlines\",\n          \"value\": \"1264.0\",\n          \"displayValue\": \"$ 1,234\"\n        },\n        {\n          \"title\": \"Hotels\",\n          \"value\": \"568.10\",\n          \"displayValue\": \"$ 568\"\n        },\n        {\n          \"title\": \"Food\",\n          \"value\": \"324.50\",\n          \"displayValue\": \"$ 324\"\n        }\n      ]\n    };\nprint(JSON.stringify(message));\n</code></pre> <ol><li> Test the panel and you will see both the Panel icons.</li> <li>Click on each to see them in action.</li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#publish","title":"Publish","text":"<p>To publish the Bot first enable channels:</p> <ol> <li>From left navigation menu, select Channel for publishing. For our use case we will select both Web/Mobile Client and Widget SDK channels.</li> <li>Select the channels and from Configurations tab, make a note of the Bot Name, Bot Id, Client Id and Client Secret.</li> <li>From left navigation menu, select Publish option. Under Tasks &amp; languages section, ensure that the Widget and Panels we developed are selected for publication.</li> <li>Proceed with the Publish.</li> </ol>"},{"location":"automation/use-cases/digital-skills/configure-digital-views/#hosting","title":"Hosting","text":"<p>We will be hosting the Panels in the web/mobile client. See here for more details on the Widget SDK usage.</p> <ol> <li>Download the Kore.ai Widget SDK, go to https://github.com/Koredotcom/web-kore-sdk, and then click Download.</li> <li>Extract all files to the \u2026/SDKApp/sdk folder.</li> <li>Open the above SDK folder, and traverse to UI folder.</li> <li>Open the <code>kore-config.js</code></li> <li>Configure your <code>botOptions</code> with the \u2018web/mobile client\u2019 channel configurations copied  in  above  section.<ul> <li><code>botOptions.botInfo</code></li> <li><code>botOptions.clientId</code></li> <li><code>botOptions.clientSecret</code></li> </ul> </li> <li> <p>Make other changes as per your requirements.</p> <p></p> </li> <li> <p>Open the <code>kore-widgets-config.js</code></p> </li> <li>Configure your <code>botOptionsWiz</code> with the \u2018Widget SDK\u2019 channel configurations copied  in  above  section.<ul> <li><code>botOptionsWiz.botInfo</code></li> <li><code>botOptionsWiz.clientId</code></li> <li><code>botOptionsWiz.clientSecret</code></li> </ul> </li> <li> <p>Make other changes as per your requirements.</p> <p></p> </li> <li> <p>Open the <code>index_widgets_chat.html</code> file in the browser and see the chat window along with the widgets. </p> <p></p> </li> <li> <p>If you want to host the Panels individually use the <code>index_widgets.html</code> file. See the GitHub for hosting the same in your web site.</p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-forms/","title":"Digital Forms","text":"<p>Virtual Assistants engage end-users primarily using a conversational interface that typically includes an exchange of a series of messages. But oftentimes, there is a need to gather information from the end-user to proceed further. Examples include providing delivery address while interacting with an eCommerce agent, details of an issue while reporting to ITSM agent, opportunity details while creating a CRM opportunity, capturing customer details to book a flight, etc.</p> <p>In a standard Dialog Task, this scenario is designed by placing a series of Entity Nodes connected back-to-back and the user is asked for values for each of these entities sequentially, which is quite tedious and frustrating. Digital Forms mitigate this issue by presenting users with an interactive interface that they can use to provide the information they are asked for in one go.</p> <p>Digital Forms provide a range of input fields that allow your assistant to capture the required details from end-users. After the users complete the form, the input is submitted to the VA to proceed with the task at hand.</p> <p>In this article, we discuss the features and implementation of Digital Forms in the Kore.ai XO Platform. For a use case example and a step-by-step implementation of a Digital Form click here.</p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#features","title":"Features","text":"<ul> <li>Improved user experience with a single interface for input collection.</li> <li>Easy form creation using simple drag and drop actions.</li> <li>Vast component library to cater to all your form requirements.</li> <li>Provision to define rules for input validations and visibility suiting your use case.</li> <li>Automatic dialog task generation from the Form enabling switching between Form or Conversation experience based on the channel of interaction.</li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#general-setup","title":"General Setup","text":"<p>You can access Digital Forms from the Build top menu under Digital Skills &gt; Digital Forms.</p> <p></p> <p>Here is the overall usage process for Digital Forms within the Kore.ai XO Platform</p> <ul> <li>Form Creation: Define a Digital Form by adding components and configuring their properties.</li> <li>Form Invocation: Forms are invoked from inside a task or process:<ul> <li>A form is included as a component in the task. The dialog task offers a Form Experience and Conversation Experience based on the channel of interaction. Learn more by reading about the Form Node.</li> <li>A Digital Form is added to a Digital View with a dialog task triggered when a form is submitted from there.</li> </ul> </li> <li>Form Submission: When it is submitted, the component values are validated and any errors are highlighted. Based on the mode of invocation, post successful validation:<ul> <li>The VA execution proceeds as per dialog flow in case of dialog task invocation.</li> <li>The selected task is triggered.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#create-a-form","title":"Create a Form","text":"<p>A Digital Form includes a definition and various components to capture user input.</p> <p>To create forms, follow the steps below:</p> <ol> <li> <p>Under the Build top menu, select Digital Skills.</p> </li> <li> <p>Click Digital Forms &gt; New Form.</p> </li> <li> <p>On the New Form page, enter the following:</p> <ul> <li>Name of the Form.</li> <li>Display Name for the Form.</li> <li>Description of the Form.</li> </ul> <p></p> </li> <li> <p>Select form\u2019s Header Style: You can choose a specific header style from the listed illustrations \u2013 the circle indicates the position of logo/icon with respect to the title of the form in the header. Click the card to select the style. If it has a logo, you can upload an image file (jpg or png) for the logo.</p> </li> </ol> <p>Note</p> <p>During the Export of the Bot, the logo is not exported along with Digital Forms. So, when importing this Bot, you need to separately copy the logo image file and then manually reupload the logo.</p> <ol><li>Turn on the Description toggle if you want to show a description of the form in the header. </li> <li>Form Security \u2013 Enable Secure Form Data to redact form data from the Bot Context, Debug Logs, Service Calls, Agent Transfer, and the Bot Kit. </li> <p>While enabling, you can also choose whether to display the Secure Form icon to your end users.</p> <p>Once enabled, the Platform will replace the user input with a unique random system-generated alphanumeric value in all the modules. Also, the Secure Form icon and a tip will be displayed, notifying the user that the form is secure.</p> <li>Click Save &amp; Proceed. </li></ol>"},{"location":"automation/use-cases/digital-skills/digital-forms/#add-components","title":"Add Components","text":"<p>Once you configure the basic details for your form, the Platform takes you to the form builder, where you can add the components you require.</p> <p>You can drag and drop the components available on the left pane to the canvas and configure their properties to build the form. For details of the available components &amp; their properties.</p> <p></p> <p>You can search for a given component, or scroll through the list to find what you require.</p> <p></p> <p>You can view the components list in a grid format by clicking the icon on the top right of the list.</p> <p>If you hover in-between components within the form itself, you can find an in-form Add Component button which also allows you to search and add new components without having to navigate to the left-side list.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#add-form-sections","title":"Add Form Sections","text":"<p>If you are working with a longer and more complex form, you can split it into sections. Hover your cursor in-between form components to reveal an Add Section button. Clicking it will add a title and description to your form, which you can use to organize the other fields into sections.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#form-actions","title":"Form Actions","text":"<p>From the Forms Listing page, you can:</p> <ul> <li>Create a New Form, as seen above.</li> <li>Edit the Form.</li> <li>Use the Branding option to customize a form.</li> <li>Test forms.</li> <li>Delete forms.</li> </ul> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#edit","title":"Edit","text":"<p>You can use the Edit option from the form listing to edit the form. The following actions are performed on the Form in edit mode:</p> <p></p> <ul> <li>The Component Listing is used for selecting and adding components to the Form by simple drag and drop action.</li> <li>Use the View Toggler to switch between Desktop View and Mobile View.</li> <li>Use the Move Component Handle Bar against each of the components to change its location by a simple drag and drop action;</li> <li>Use Form Actions to:<ul> <li>Test the form to see the preview of the Digital Form in the XO Platform.</li> <li>Delete the Form. Please keep in mind that deleted forms cannot be restored.</li> <li>Change the Form Settings such as name, display name, and description.</li> </ul> </li> <li>Use the Component Actions to access the Settings, Duplicate, and Delete options for each of the form\u2019s components.</li> <li>You can change the components\u2019 properties from the Component Settings popup:<ul> <li>Use the Component Docker to dock/undock the settings pane to the screen.</li> <li>Use the Component Selector to navigate through the components on the Form.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#branding","title":"Branding","text":"<p>Use the Branding option to change the look and feel of the form to reflect your organization\u2019s standards. An instant preview gives you an idea of how the form would look with the new colors and you have the option to Save or Restore Default scheme.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#test","title":"Test","text":"<p>Test the form to see a preview of what it would look like to the end user. You can do this at any point while you work on the form.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#invoke-a-form","title":"Invoke a Form","text":"<p>A digital form can be invoked as follows:</p> <ol> <li>From a Task: You may include a form as a component in a dialog task for defining the task. The dialog task offers Form Experience and the usual Conversation Experience for filling the form data. You can choose the preference based on the channel of interaction or any other criteria based on your requirements.</li> <li>From a UI flow: You can add a Digital Form to a pane and choose a dialog task to trigger when the form is submitted from the pane.</li> </ol> <p>In the following sections, we discuss each of the above invocation processes.</p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#invocation-from-dialog-tasks","title":"Invocation from Dialog Tasks","text":"<p>Digital Forms are used inside Dialog Tasks for capturing user inputs through a Form Node.</p> <p>To invoke a form from a dialog task, follow the below steps:</p> <ol> <li>Create/open the dialog from where you want to invoke the Digital Form.</li> <li>Click the + icon next to the node where you want to add the Form.</li> <li>Select the Digital Form option and then the form from the list. You can choose to add a Digital Form directly or use an existing Form Node.</li> <li>You are prompted to select the Form Experience, it can be:</li> </ol> <p></p> <ul> <li>Only Form UI \u2013 This creates a Form Node and associates it with the Digital Form selected. This is the default option.</li> </ul> <p></p> <ul> <li>Both Form UI and Conversation Experience \u2013 This further prompts you to choose a channel. When a user is using one of the selected channels they are presented with a Form UI, the rest of the channel users get a conversation experience.  This option creates:</li> <li>A Bot Action Node to determine the transitions to the Form Node and the Sub-dialog Node based on the channels selected.</li> <li>A Form Node for the Digital Form, same as was generated for the Only Form UI above.</li> <li>A Sub-dialog Node to capture the required entities (as defined in the Digital Form using components) for the conversational experience. </li> <li>A Group encompassing the following nodes (see here for details). This grouping can be renamed and/or deleted.</li> </ul> <p></p> <ol> <li>You can set the Properties for each of the nodes added.</li> <li>The Form Node (click here for details).  Of special interest are the following Component Properties:</li> <li>Submit Message \u2013 Message displayed to the end-user on successful submission of the form</li> <li>Web/Mobile SDK Form Behavior \u2013 Using this option you can either have the form displayed inline the chat window or open on a full page. Also, you can either go ahead with the default submit prompt or configure the setting to display a custom and more specific message to be shown in chat. See here to know how to configure.</li> <li> <p>Bot Action Node, in case of the conversation experience flow, can also be configured see here for details) Of special interest is the following:</p> </li> <li> <p>Manage Context Variables is used to create and set values for the context variables. Remember to use the full path of the variable in the key field ie. <code>context.BotUserSession.&amp;lt;variable_name&gt;</code></p> </li> </ol> <p>Note</p> <p>We urge you not to make changes to the connection settings as this affects the V's performance.</p> <ul> <li> <p>Sub-dialog Node is configured as normal (see here for details) Of special interest are the following:</p> </li> <li> <p>Use the Entity Post-assignment to capture the user input.</p> </li> <li>In case you modify the sub-dialog or the source form, you are presented with an option to Regenerate Dialog. This ensures that the changes are reflected in the task without having to rebuild the entire task. Be aware that the changes are reflected in all places this sub-dialog is used.</li> </ul> <p></p> <ol> <li>The user input can be accessed as follows:<ul> <li>Form component values are accessed from the Context Object using <code>{{context.forms.form_name.component_name}}</code></li> <li>In the case of the sub-dialog, the variables used in the post-assignment settings as <code>{{context.&amp;lt;variable_name&gt;}}</code></li> </ul> </li> <li>You can continue with the Dialog Task as per your business needs. For example, you can use the Form Component values as input to a Service Node to update the data or use the Script Node to process it further. If you are using the conversation experience too, remember to connect the auto-generated sub-dialog to the process flow.</li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-forms/#invocation-from-panels","title":"Invocation from Panels","text":"<p>Digital Forms are rendered in Digital Views by configuring Widgets &amp; Panels, Learn more.</p> <p>To invoke a form using Widgets and Panels, follow the below steps:</p> <ol> <li>Create a widget to invoke the Digital Form from Build -&gt; Digital Skills -&gt; Digital Views option.</li> <li>Enter the name.</li> <li>Select Digital Forms as the Source.</li> <li>Add a Form by selecting it from the drop-down list.</li> <li>Select the Dialog to Invoke on Submit from the drop-down list.</li> <li>Click Save.</li> </ol> <p></p> <ol> <li>Add the Widget to an existing panel or create a new panel.  You can add a form directly to a panel, it creates a widget by default.</li> <li>You can Test the panel.</li> <li>Follow the steps provided here to publish and host the panels.</li> </ol> <p>Note</p> <p>While a Digital Form is used to define multiple Widgets and also add to multiple panels, it will be associated with a single Dialog Task across all Widgets and Panels.</p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#the-user-experience","title":"The User Experience","text":"<p>When the end-user initiates the dialog and reaches the node connecting to the Form node, the following events take place. Depending upon the experience selected at design time and the channel of invocation, the flow is the following:</p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#form-experience","title":"Form Experience","text":"<p>A link to the form is presented to the user. Note that for a synchronous WebHook channel, instead of a link the complete form definition is sent click here for more details.</p> <p></p> <p>Clicking the link opens the form in either full-screen or inline mode, based on the selection. Please note the following details about the link:</p> <ul> <li>The link is active only for a certain duration of time, it becomes inactive after that.</li> <li>Even within the active period, it can be used only a limited number of times.</li> </ul> <p>End-users can fill in the values for the components/fields.</p> <p></p> <p>Every form comes with a default Submit button. This validates the form entries, prompts for any missing values. </p> <p></p> <p>Once the form is validated and submitted, the values are available in the context variable and accessed using the following code: <code>context.forms.&amp;lt;form_name&gt;.&amp;lt;component_name&gt;</code></p> <p>Here we are capturing the user entry and displaying it using a message node.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#conversation-experience","title":"Conversation Experience","text":"<p>From the channel of operation, the end-user is prompted to enter values for every component in the form.</p> <p>The values are available in the sub-dialog context and are captured using Entity Post Assignment as mentioned above.</p> <p>Following is the user experience in Conversation mode:</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#exceptions","title":"Exceptions","text":"<p>When exceptions are encountered during the dialog execution with a Form Node, they are handled as follows:</p> EXCEPTION EXCEPTION BEHAVIOR The user tries to continue the conversation without opening the form link.     The Virtual Assistant asks if the user wants to switch to a new task.     The user tries to continue the conversation (in the chat window) without submitting the form responses.     The Virtual Assistant asks if the user wants to switch to a new task.     The user closes the form or browser without submitting responses.     If the bot is configured to cancel the ongoing task, the form displays a warning message that the task will be canceled. If the user accepts, the form will be closed, and a message is displayed saying that the previous task is canceled. <p> Otherwise, the ongoing task goes on, and based on the configuration, the user is taken to the next step of the task.     The user tries to relaunch the form while the form is already open.     The form link will not open the form and a message will be displayed saying that the form link is no longer valid.     The user tries to relaunch the form after moving ahead in the conversation.     The form link will not open the form and a message will be displayed saying that the form link is no longer valid."},{"location":"automation/use-cases/digital-skills/digital-forms/#panel-flow","title":"Panel Flow","text":"<p>Users can access the form using Panels &amp; Widgets. The experience is the same as for the Process Flow with Form experience.</p> <p>Once the form is validated and submitted, the values are available in the context variable and accessed using the following code: context.forms.&lt;form_name&gt;.&lt;component_name&gt;</p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#manage-vas-with-digital-forms","title":"Manage VAs with Digital Forms","text":""},{"location":"automation/use-cases/digital-skills/digital-forms/#publish","title":"Publish","text":"<p>The publishing flow for a VA with Digital Forms has the following special cases:</p> <p>As with any assistant, the Digital Forms exist in the following states:</p> <ul> <li>In-development when a form is created.</li> <li>Awaiting approval when a form is submitted to Publish and the request is waiting for the admin to take action.</li> <li>Rejected when the Publish request is rejected by the admin.</li> <li>Published In the XO Platform, the status of a Digital Form remains In Development even after publishing.</li> </ul> <p></p> <p>On publishing the form, you can see the form listed under Publish Status \u2192 View Publishing Summary, but the status on the Digital Forms main page remains as In Development.</p> <p></p> <p>The In Development and Published versions of the VA can be viewed by toggling between the respective statuses in the top search-bar.</p> <p></p> <p>Note</p> <p>If any edits are done to the Digital Form while it is In Development, the changes would be reflected in the Published version as soon as you publish the form.</p> <ul> <li>Suspended when a published form is suspended by the admin.</li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#pre-publishing-validations","title":"Pre-publishing Validations","text":"<p>The following validations are performed before a Publish request is processed:</p> <p>A Dialog Task that contains a Digital Form can be published only if:</p> <ul> <li>The corresponding Digital Form is already published, or</li> <li>The corresponding Digital Form is also selected for publishing.</li> </ul> <p>A Digital Form that is configured to trigger a Dialog Task is published only if:</p> <ul> <li>The corresponding Dialog Task is already published, or</li> <li>The corresponding Dialog Task is selected for publishing.</li> </ul> <p>While the dependencies are published together, chances are that all the dependencies might not be available at run-time, in such cases:</p> <ul> <li>If the Dialog Task is in a published state, but the Digital Form is not in a published state this triggers:</li> <li>The Task Failure Event and the corresponding behavior is invoked or</li> <li>A relevant Standard Response is displayed and</li> <li>Logged as Failed Task in Analytics.<ul> <li>Digital Form is in a published state, but the Dialog Task is not available then on Form submission, the end-user is presented with the Form\u2019s Error Message.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#import","title":"Import","text":"<p>Digital Forms are included in the full and incremental import of the assistant.</p> <p>For Full Import:</p> <ul> <li>As with all other VA components, the full import replaces the entire Digital Forms and form details.</li> </ul> <p>For Incremental Import:</p> <ul> <li>You can choose to include/exclude the Digital Forms in the import.</li> <li>This import fully replaces the Digital Forms that are common to the import file and the VA.</li> <li>Additional forms in the file are imported into the VA.</li> <li>Additional forms in the VA are retained.</li> <li>Post import, any invalid Digital Form integration details are disassociated with the corresponding forms.</li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#export","title":"Export","text":"<p>The Bot Export option is available for Digital Forms with a status of In Development or Published.</p> <ul> <li>Digital Forms can be selected/deselected from the Bot Export page under the Bot Tasks category.</li> <li>Choose the option to Include dependent dialogs to export Dialog Tasks that are integrated with the selected Digital Forms to define widgets.  Note that this does not include the Sub-dialog Tasks generated using Digital Forms.</li> <li>Complete information for each of the selected forms are available in the export file and this includes:<ul> <li>Fields</li> <li>Field properties</li> <li>Form integrations</li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-forms/#form-component-details","title":"Form Component Details","text":""},{"location":"automation/use-cases/digital-skills/digital-forms/#components-list","title":"Components List","text":"<p>Following is a list of the available components.</p> <p>BASIC</p> <p>Text Field \u2013 used for single-line input.</p> <p></p> <p>Text Area \u2013 used for multi-line entry.</p> <p></p> <p>Number \u2013 used for numerical entries.</p> <p></p> <p>Radio Button \u2013 used as a selection option from a given list.</p> <p></p> <p>Dropdown \u2013 Used as a selection option from a given list; can be multi-select.</p> <p></p> <p>Checkbox \u2013 Used for multi-select option from a given list.</p> <p></p> <p>Date \u2013 Used for date entries, gives a date picker for the user to choose the date.</p> <p></p> <p>Date &amp; Time \u2013 Used for date &amp; time entries. The system displays a date and time picker for the user to choose the date and time. Use the Date component and set the Time option to yes; choose from 12 or 24-hour format.</p> <p></p> <p>Phone Number \u2013 Used for phone number entries, allows the user to choose the country code.</p> <p></p> <p>Email \u2013 Used for email address entries, validates for xxx@uuu.com format.</p> <p></p> <p>Toggle \u2013 Used for switching between two values, ideal for yes/no type of inputs.</p> <p></p> <p>Address \u2013 Used for address entries.</p> <p></p> <p>URL \u2013 Used for web URL entries, validates for xxx.com format.</p> <p></p> <p>Range Slider \u2013 Value selection between specified min and max values; can be represented as a percentage.</p> <p></p> <p>Password - Used to display passwords in their masked form <code>*****</code></p> <p>ADVANCED</p> <p>Button \u2013 Used as a clickable component to submit reset, or open an external URL the form. Choose from Primary, Secondary, Tertiary, Ghost, or Danger.</p> <p></p> <p>Label \u2013 Used to display a static text box, no action required from the user.</p> <p></p> <p>Protip \u2013 Used to mark important information for the end-user, no user action required.</p> <p></p> <p>Note - Used to mark information for the end-user, no user action required.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-forms/#component-properties","title":"Component Properties","text":"<p>The following are the properties that can be set for each of the components.</p> <p>Note</p> <p> Not all the properties are valid for all the components, refer to the Property Matrix for the mapping.</p> PROPERTY DESCRIPTION Display Name This is the text which appears against the component for the end-users.     Name This is the reference name that can be used for referencing the component in the other components of the form and form level operations     Description Help information about a field to be displayed to the end-user.     Placeholder Text A prompt message for the end-user     Button Style For button component, can be: <ul> <li>Primary,  <li>Secondary,  <li>Tertiary,  <li>Ghost, or  <li>Danger </li> Button Action For button component, can be: <ul> <li>Submit,  <li>Reset, or  <li>Go to URL \u2013 in this case, you need to enter a URL in the corresponding field. </li> Read Only To mark the component value is not changeable     Required To define whether input for this field is necessary or optional for the end-user entry.     Tool-tip Additional information about a field to be shown on demand to the end-user. Has three entries: <ul> <li>Tip Text \u2013 text message for the additional information about the component  <li>Tool-tip Type \u2013 whether the tip appears on hover or click  <li>Tool-tip Position \u2013 where the tooltip should be displayed </li> Date Format Time format to be presented to the end-user can be <ul> <li>mm/dd/yyyy \u2013 default  <li>dd/mm/yyyy  <li>yyyy/mm/dd  <li>yyyy/dd/mm </li> Time To enable the end-user to enter Time along with Date     Time Format <p> Used in conjunction with the above Time property     Time format to be presented to the end-user can be 12 hrs or 24 hrs     Default Country Code Choose the desired default country code that should be shown to the end-user. Default is United States +1     Secure Field Data To Secure the user information collected by this field.     Masking Type <p> Available only when Secure Field Data is enabled     Choose how to display the redacted data in the Bot Context, Debug Logs, Service Calls, Agent Transfer and the Bot Kit. Following actions are available: <ul> <li>Redaction \u2013 The platform will replace the user input with a unique random system-generated alphanumeric value. This is the default setting when the Secure Field Data is enabled  <li>Replacement \u2013 The platform will replace the user input with a static value or reference to a context object as entered in the replacement value field.  <li>Mask with Character \u2013 The platform will replace the first few and last few characters of the user input with symbols. You can specify the number and position of characters to mask, symbol for masking (+ or #). </li> Mask Input <p> Available only when Secure Field Data is enabled     Enable this option to mask the end-user\u2019s input for this field in the chat window.     Checkbox Layout Choose the number of columns to present the checkbox values in the grid view. You can select a minimum of 1 and a maximum of 4 columns, with 4 columns being the default selection.     Data Settings Default Value In case the component needs to be pre-populated with a default value     Values For Radio Button, Dropdown and Checkbox, add values to be given for selection by the end-user. You can mark one value as a default value     Multi-Select For Dropdown, if the user can select multiple values.     Validation Settings Default Error Message To be displayed in case user entry fails validation     Validate To define when the validations defined for a field are to be checked. Options are: <ul> <li>On blur \u2013 Validations would be done when the end-user moves away from the component  <li>On change \u2013 Validations would be done when the component value is changed </li> Validation Rule Rules in the following format can be added <ul> <li>Operator \u2013 choose from the list  <li>Comparison Type \u2013 set to either value or field/component or value type  <li>Comparison  With \u2013 the value or component name or type, as per the above selection  <p> Multiple rules added to an existing rule would be taken as an AND condition, whereas a new rule would be an OR condition. You can add multiple Simple rules or a single Advanced rule by toggling between Simple and Advanced Modes  Custom Error Message This would be displayed when a particular validation fails     Visibility Settings Is Visible Whether the given component is visible to the end-user or not     Visibility Rules You can define conditions when a particular component would be visible or hidden <ul> <li>Hide or Visible  <li>Add Visibility Rules by defining the following:  <ul> <li>Component/Field which determines this component behavior- choose from the list  <li>Operator \u2013 choose from the list  <li>Comparison Type \u2013 set to either value or field/component or value type  <li>Comparison  With \u2013 the value or component name or type, as per the above selection  <p> Multiple rules added to an existing rule would be taken as an AND condition, whereas a new rule would be an OR condition. You can add multiple Simple rules or a single Advanced rule by toggling between Simple and Advanced Modes  Auto Populate Auto Population Whether the given component should be auto-populated or not     Auto population rules <ul> <li>Field or Value from which to auto-populate  <li>Field name or the actual value based on the above selection </li>"},{"location":"automation/use-cases/digital-skills/digital-forms/#component-mappings","title":"Component Mappings","text":""},{"location":"automation/use-cases/digital-skills/digital-forms/#properties","title":"Properties","text":""},{"location":"automation/use-cases/digital-skills/digital-forms/#basic","title":"Basic","text":"PROPERTY TEXT FIELD TEXT AREA NUMBER RADIO BUTTON CHECK <p> BOX DROP <p> DOWN DATE PHONE NUMBER EMAIL ADDRESS URL TOGGLE RANGE SLIDER General Settings Display Name Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Name Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Description Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Placeholder Text Yes     Yes     Yes     No     No     Yes     Yes     Yes     Yes     Yes     Yes     No     Yes     Read Only Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Required Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Tool-tip Tip Text Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Tool-tip Type Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Tool-tip Position Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Date Format No     No     No     No     No     No     Yes     No     No     No     No     No     No     Time &amp; <p> Time Format No     No     No     No     No     No     Yes     No     No     No     No     No     No     Default Country Code No     No     No     No     No     No     No     Yes     No     No     No     No     No     Checkbox Layout No     No     No     No     Yes     No     No     No     No     No     No     No     No     Secure Data Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Masking Type Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Mask Input Yes     No     Yes     No     No     No     No     No     No     No     No     No     No     Data Settings Data Source No     No     No     Yes     Yes     Yes     No     No     No     No     No     No     No     Default Value Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Multiselect No     No     No     No     No     Yes     No     No     No     No     No     No     No     Auto Fill Auto Populate Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Auto Populate Settings Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Visibility Settings Is Visible Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Visibility Settings Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Validations Default Error Message Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Validate Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Equals To Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     TBD     Yes     Yes     Yes     Not equal to Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Yes     Contains Yes     Yes     No     No     No     No     No     No     No     No     No     No     No     Does not contain Yes     Yes     No     No     No     No     No     No     No     No     No     No     Regex No     No     No     No     No     No     No     No     No     No     No     No     Max Length Yes     Yes     No     No     No     No     No     Yes     Yes     Yes     No     No     Min Length Yes     Yes     No     No     No     No     No     Yes     Yes     Yes     No     No     Part of Yes     No     No     No     No     No     No     No     No     No     No     No     Not part of Yes     No     No     No     No     No     No     No     No     No     No     No     Greater than No     No     Yes     No     No     No     Yes     No     No     No     No     Yes     Less than No     No     Yes     No     No     No     Yes     No     No     No     No     Yes     Greater than or equal to No     No     Yes     No     No     No     Yes     No     No     No     No     Yes     Less than or equal to No     No     Yes     No     No     No     Yes     No     No     No     No     Yes"},{"location":"automation/use-cases/digital-skills/digital-forms/#advanced","title":"Advanced","text":"PROPERTY BUTTON RICHTEXT PRO-TIP General Settings Display Name Yes     Yes     Yes     Name Yes     Yes     Yes     Description Yes     No     Yes     Placeholder Text No     No     No     Tool-tip Yes     Yes     No     Error Message Yes     No     No     Required No     No     No     Validate Yes     No     No     Read Only Yes     No     No     Action Type (Submit, Reset, Clear)     Yes     No     No     Data Settings Data Source No     No     No     Default Value No     No     No     Auto Fill Auto-Populate No     No     No     Auto-Populate Settings No     No     No     Visibility Settings Is Visible Yes     Yes     Yes     Visibility Settings Yes     Yes     Yes"},{"location":"automation/use-cases/digital-skills/digital-forms/#dialog-node","title":"Dialog Node","text":"<p>The following mapping gives the type of entities included in the sub-dialog when it is auto-generated from a Digital Form.</p> FORM COMPONENT PROPERTY DIALOG TASK NODE PROPERTY Name     Name     Display Name     Display Name     Placeholder Text     Entity Prompt     Error Message     Error Prompt     DIGITAL FORM COMPONENT TYPE DIALOG TASK <p> NODE TYPE Text Field     String     Text Area     Description     Number     Number     Radio Button     LoI (Enum) with each of the options in the radio button group copied as list items     Dropdown     LoI (Enum) with each of the values in the dropdown list copied as list items. <p> Multi-select would be enabled based on the \u2018is multi-select\u2019 option of the Form Component     Checkbox     LoI (Enum) with each of the options in the checkbox group copied as list items <p> Multi-select is enabled by default     Date     Date     Phone Number     Phone Number     Email     Email     Address     Address     URL     URL     Toggle     LoI (Enum) with each of the options in the toggle copied as list items     Advanced Button     Not Applicable     Label     Not Applicable     Protip     Not Applicable     &lt; Note     Not Applicable"},{"location":"automation/use-cases/digital-skills/digital-forms/#context-object","title":"Context Object","text":"<p>The following mapping gives the context object to capture the component value along with a sample context object.</p> COMPONENT TYPE CONTEXT OBJECT Text Field     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Text Area     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Number     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Radio Button     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Dropdown     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;[&lt;index&gt;]</code> Checkbox     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;[&lt;index&gt;]</code> Date     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> <p> In mm/dd/yyyy format     Date &amp; Time     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> <p> In mm/dd/yyyy hh:mm AM/PM format     Phone Number     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> <p> prefixed with the area code of the country selected by the user     Email     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Address     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> URL     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> Toggle     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> <p> Yes/No values     Range Slider     <code>context.forms.&lt;form_name&gt;.&lt;component_name&gt;</code> <p>SAMPLE CONTEXT OBJECT</p> <pre><code>\"forms\": {\n    \"basicpropertieslist\": {\n      \"TextField\": \"text\",\n      \"Textarea\": \"text area\",\n      \"Number\": 123,\n      \"Radio\": \"Male\",\n      \"Dropbox\": [\n        \"UnderGrad\",\n        \"Other\"\n      ],\n      \"Checkbox\": [\n        \"Education\",\n        \"Technology\"\n      ],\n      \"Date\": \"07/08/2020\",\n      \"Date&amp;Time\": \"07/08/2020 19:00 PM\",\n      \"PhoneNumber\": \"+919999999999\",\n      \"Email\": \"test@gmail.com\",\n      \"toggle\": \"Yes\",\n      \"Adress\": \"Address\",\n      \"Url\": \"test.com\",\n      \"rangeSlider\": 26.1\n    }\n  }\n</code></pre>"},{"location":"automation/use-cases/digital-skills/digital-forms/#prefill-form","title":"Prefill Form","text":"<p>You can specify data that can be used to pre-populate the form fields. Platform will check for the availability of any form prefill information before lauching the form. If any information is available, then the corresponding fields in the form are pre-populated before presenting the form to the user. The values can be static or from a context object.</p> <p>You can specify pre-fill form data using the following context object: <code>context.prefillForms</code>.</p> <p>You can use the following in Javascript to populate the above-mentioned context object:</p> <pre><code>context.prefillForms = {\n  &lt;form_name&gt;: {\n     fields: {\n        &lt;form_field1&gt;: \"&lt;value1&gt;\",\n        &lt;form_field2&gt;: &lt;context.session.....&gt;,\n        &lt;form_array_field2&gt;: [\n             &lt;array_value1&amp;gt,\n             &lt;array_value2&amp;gt,\n        ],\n     },\n  },\n};\n</code></pre>"},{"location":"automation/use-cases/digital-skills/digital-forms/#limitations","title":"Limitations","text":"<ul> <li>Digital Forms will not work as expected on the following channels:<ul> <li>Amazon Alexa</li> <li>Cisco Jabber</li> <li>Google Assistant</li> <li>IVR Voice</li> <li>Twilio Voice</li> </ul> </li> <li>You are advised to choose the Conversation Experience for these channels.</li> <li>Digital Forms created in the parent bot are not inherited into Smart Bots.</li> <li>The Digital Forms functionality is not applicable for Universal Bots.</li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-skills-overview/","title":"Digital Skills","text":"<p>Improving the user experience is a crucial aspect of developing a virtual assistant or any digital application. Digital skills are essential for efficiently handling and presenting information to users in a user-friendly and visually appealing manner.</p>"},{"location":"automation/use-cases/digital-skills/digital-skills-overview/#what-are-digital-skills","title":"What are Digital Skills?","text":"<p>Digital Skills are a set of features within the Kore.ai XO Platform which allow you to create interactive user interfaces that can either retrieve or present information to/from the user. These interfaces take the shape of either of the following:</p> <ul> <li> <p>Digital Forms: These allow you to retrieve information from end users by showing them a form rather than configuring the assistant to ask them for each piece of information individually.</p> </li> <li> <p>Digital Views: There are two components to Digital Views:</p> <ul> <li>Widgets: These can be set up to retrieve information from a Dialog Task, JSON file or Digital Form and present it to the user.</li> <li>Panels: A Panel is a collection of widgets. You can use Panels to present end users with the same type of information in an organized manner in one place. For example, you might have a My Trips Panel, which could include widgets for Upcoming Trips, Completed Trips and Canceled Trips.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-skills-overview/#digital-skills-implementation","title":"Digital Skills Implementation","text":"<ul> <li> <p>You can implement Digital Forms within the Kore.ai XO Platform, by following this article. </p> </li> <li> <p>You can also implement Digital Views by following the process described here. </p> </li> <li> <p>Digital Views can be further enhanced using the Kore.ai Widget SDK, which you can learn more about here. </p> </li> <li> <p>You can download the Widget SDK from Kore.ai\u2019s GitHub profile.</p> </li> </ul>"},{"location":"automation/use-cases/digital-skills/digital-views/","title":"Digital Views","text":"<p>Interactions with Virtual Assistants are typically conducted using chat/messaging tools, voice channels, or other types of assistants. In the majority of the cases, the Virtual Assistants respond to the user queries only when the users have requested some information. This works well for conducting on-demand tasks that need user input for execution and the result is usually a short response, confirmation, or acknowledgment. But the need for more proactive user updates and less user input through an engaging interface has become a key requirement. </p> <p>Using Digital Views from the Kore.ai XO Platform, you can design and launch rich visual experiences through interactive components, panels, and widgets, to proactively present relevant information to your users or customers. Panels are the placeholders that hold one or more widgets. Widgets are individual components that display information to the end-users. Your users or customers can interact with your VA either in conversation mode or directly get the required information from the widgets.</p> <p>This article gives an overview on the working and implementation of Panels &amp; Widgets. For step-by-step usage instructions, refer to this article.</p>"},{"location":"automation/use-cases/digital-skills/digital-views/#how-it-works","title":"How It Works","text":"<ol> <li>Using Digital Views, an organization offers to its VA end-users a single interface for various activities.</li> <li>Multiple panels constitute a Digital View.</li> <li>Each of the panels gives access to various functions.</li> <li>The end-user accesses these panels for information pertaining to each of the functions and performs follow-up actions.</li> <li>As an example, a Panel within a travel VA  could have multiple widgets showing:<ul> <li>Upcoming Trips</li> <li>Completed Bookings</li> <li>Canceled Bookings </li> </ul> </li> </ol> <p>You can access Digital Views by selecting the VA you want to work with then going to Build &gt; Digital Skills &gt; Digital Views. </p>"},{"location":"automation/use-cases/digital-skills/digital-views/#how-to-use-digital-views","title":"How to use Digital Views?","text":"<p>You can enable Digital Views for your Virtual Assistant by designing the required widgets, adding them to the relevant panels and publishing them on the WidgetSDK channel.</p> <p>Here are the steps we recommend for efficient design of Digital Views: </p> <ol> <li>Set up: Panels are containers to host one or more widgets. You may create multiple panels and each panel can host widgets that present relevant information. Widgets are the interactive components that can contain information to be presented to the end-users and allow them to perform actions and follow-ups.</li> <li>Configure: Define widgets by connecting them either to your tasks or by directly defining the widget. If you have connected your widget to a Dialog Task, make sure to use a Message node to present the required information in the widget using any of the supported widget templates.</li> <li>Preview &amp; Publish: Preview your widgets from the XO Platform to review the visual representation of the information. Enable the WidgetSDK channel and publish your panels and widgets to make them available for your end-users.</li> <li>Host with Kore.ai SDK / Host Independently: You can choose to host your widgets independently or co-host them along with the WebSDK. You can download the SDKs from the Kore.ai GitHub page.</li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#general-setup","title":"General Setup","text":"<p>Here is the general setup process to follow when you want to configure Panels and Widgets for Digital Views: </p> <ol> <li>Configure Widgets: Define widgets by connecting them either to your tasks or any other source like JavaScript generating JSON file. In cases where you are using a task as a source, ensure that the message is formatted properly for the Widget SDK channel.</li> <li>Preview the Widgets: Preview your widgets from the XO Platform.</li> <li>Set up Panels: You may create multiple panels and each panel can host widgets that present relevant information. You can use the predefined widgets or create new ones.</li> <li>Test the Panels to see how the Panels and Widgets are rendered in the chat window.</li> <li>Publish the VA: Publish the VAso that the panels and widgets are made available for your end-users.</li> <li>Host the Panel: You can choose to host your widgets independently or co-host them along with the web SDK. You can download the SDKs from the Kore.ai GitHub page. Do ensure to enable WidgetSDK as a channel.</li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#configure-widgets","title":"Configure Widgets","text":"<p>Widgets are individual components that can communicate with the VA for presenting information to the end-users. The source of information for widgets is from a Dialog Task or a JSON using any of the predefined widget templates.</p> <p>To configure widgets, follow the below steps:</p> <ol> <li> <p>Click Create Widget to create a widget.     </p> </li> <li> <p>The New Widget dialog opens.     </p> </li> <li> <p>On the New Widget window, enter the following details:</p> <ul> <li>Name of the widget</li> <li>Display Name for the widget</li> <li>Auto Refresh to set the frequency with which this widget needs a poll for fresh data. The refresh is applicable only when the panel containing the widget is active.</li> <li>Source for a widget can be set either from the execution of Dialog Task, from JavaScript by defining a JSON, or by linking an existing Digital Form.</li> </ul> </li> <li>Click Save.</li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#configure-widget-sources","title":"Configure Widget Sources","text":"<p>For the widget input data, you must configure one of the following sources and complete the configuration.</p>"},{"location":"automation/use-cases/digital-skills/digital-views/#dialog-task","title":"Dialog Task","text":"<p>The Dialog Task option allows you to trigger a task and present the output in the widget.</p> <p>The Select Dialog Task drop-down will list all available tasks in the current VA. Select the task you want to trigger using this widget.</p> <p>Note</p> <p>In the connected Dialog Task make sure to use a Message node to present the required information in the widget using any of the supported widget templates.</p> <p>You can use the icon next to the Dialog Task to open the Dialog Task for checking the task details like entity names etc.</p> <p>Any entities used by the selected Dialog Task need to be pre-populated with values by mapping Entity Name with Entity Values.</p> <p>If the selected Dialog Task has any Authorization Profile defined, it is displayed here. </p>"},{"location":"automation/use-cases/digital-skills/digital-views/#json","title":"JSON","text":"<p>When selecting JSON as the source, you will be presented with a Javascript editor, where you can add your code, as shown below:</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-views/#digital-form","title":"Digital Form","text":"<p>When selecting Digital Form as a widget source, you  can select the Digital Form, and the Dialog Task to trigger on submission.</p> <p>Note</p> <p>A Digital Form can be used to define multiple Widgets and can also be added to multiple Panels. However, it will be associated with the same Dialog Task across all Widgets and Panels.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-views/#edit-run-preview-a-widget","title":"Edit, Run &amp; Preview a Widget","text":"<p>After you save, the widget will be In Development state. You can Edit or Delete the widget. </p> <p>When you select Edit widget, apart from being able to modify any of the above fields, you will have the option to Run &amp; Preview the widget. You can save the preview as the thumbnail display for the widget. </p>"},{"location":"automation/use-cases/digital-skills/digital-views/#configure-panels","title":"Configure Panels","text":"<p>Panel refers to containers that hold one or more widgets. You can add an existing widget to the panel or create new widgets within it.</p>"},{"location":"automation/use-cases/digital-skills/digital-views/#create-a-panel","title":"Create a Panel","text":"<p>To create a panel, follow the steps below:</p> <ol> <li>Click Create Panel to create a panel.</li> <li> <p>On the New Panel window, enter the following details:</p> <ul> <li>Name of the Panel.</li> <li>Display Name for the Panel.</li> <li>Panel Icon to display in the chat window (URL to the location).</li> <li>Save the Panel. </li> </ul> </li> <li> <p>After you save, the panel will be In Development and will be displayed on your Digital Views screen. </p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#add-widgets","title":"Add Widgets","text":"<ol> <li>Click Add Widget to add widgets to the panel.    </li> <li> <p>Select widgets from the drop-down list and click Add. You can add multiple widgets to the same panel.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#panel-options","title":"Panel Options","text":"<p>You have the following options for a given panel:</p> <ol> <li>Edit the panel details;</li> <li>Add Form to add existing forms to the Panel. Once added, forms will behave as a widget with the source set to Digital Form;</li> <li>Add Widget to add existing widgets;</li> <li>Panel Management to add existing forms/widgets, or remove already added forms/widgets from the panel.</li> <li>Test the individual panel \u2013 this opens the Talk to Bot window along with the panel listing with the current panel active and data presented. You can interact with the VA and test the panel.</li> <li>Delete the Panel. </li> </ol>"},{"location":"automation/use-cases/digital-skills/digital-views/#publish","title":"Publish","text":"<p>When you publish your Virtual Assistant,  please ensure that the panels and widgets you want to include are selected.</p> <p>Learn more about publishing a Virtual Assistant.</p> <p></p>"},{"location":"automation/use-cases/digital-skills/digital-views/#host","title":"Host","text":"<p>The XO Platform provides the Widget SDK for hosting and managing panels and widgets. You can choose to host your widgets independently or co-host them along with the WebSDK. You can download the SDKs from the Kore.ai GitHub page. Do ensure to enable WidgetSDK as a channel. Learn more.</p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/","title":"Build a Knowledge Graph","text":"<p>The XO Platform\u2019s Knowledge Graph (KG) helps you turn your static FAQ text into an intelligent, personalized conversational experience. It goes beyond the usual practice of capturing FAQs as flat question-answer pairs. Instead, the Knowledge Graph enables you to create a hierarchical structure of key domain terms and associate them with context-specific questions and their alternatives, synonyms, traits, and more. </p> <p>Additionally, you can opt for the LLM-based Few-Shot Knowledge Graph, which requires no ontology and reduces maintenance and training requirements. Learn more.</p> <p>To generate a Knowledge Graph, you need to add FAQs to an existing or new VA. If you have not created a VA, refer to Building a Virtual Assistant.</p> <p>To open the Knowledge Graph builder, follow the below steps:</p> <ol> <li>Log in to the XO Platform and open the VA to which you want to add the Knowledge Graph.</li> <li>Select the Build tab from the top menu.</li> <li>On the left menu, select Conversation Skills and click Knowledge Graph.</li> <li> <p>You will notice that there is already a Knowledge Graph with the name of your assistant.</p> <p></p> <p> <p>Note</p> <p>All features explained here are supported by the Few-Shot Knowledge Graph, except for the following: <ul><li>Few-Shot Knowledge Graphs do not require an ontology structure, but you can create one to  improve intent detection.</li> <li>Default terms are not available in Few-Shot Knowledge Graphs. The only exception is when you switch from an Ontology Graph, in which case existing Default terms are stored as such until updated. Afterward, Default terms become Organizer terms and can be set as Mandatory.</li> <li>Lemmatization using Parts of Speech, Search in Answer, and Contextual Paths Qualification are not supported by Few-Shot Graphs. Please see the Knowledge Graph Types Comparison Table for a detailed list of supported features.</li> <li>Path Level and Knowledge Graph Synonyms are only supported for Mandatory Terms and for Tags.</li></ul></p> </p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#create-the-knowledge-graph-node-structure","title":"Create the Knowledge Graph Node Structure","text":"<p>By default, the name of the VA becomes the root node of the hierarchy and you can edit this. Create the rest of the nodes below the root node.</p> <p>To create nodes, follow the below steps:</p> <ol> <li>Open the Knowledge Graph.</li> <li>On the top left of the Knowledge Graph window, hover over the root node.</li> <li>Click the + icon. A text box appears below to Add Node. For better performance, there is a restriction of 50k FAQs spread across 20k maximum allowed number of nodes.</li> <li>Type the name of the node in the text box and press Enter. A warning would be displayed in case you enter a duplicate node name, i.e. if a child node with the same name already exists under the parent node.      <p>Note</p> <p>This node becomes a child for the root node and can be referred to as a First-level node.</p></li> </ol> <ol><li>Repeat steps 1 to 3 in this section to create other First-level nodes.</li> <li>After you create First-level nodes, create child nodes as follows:</li> <ul><li>Hover over any First-level node, and click the plus icon to create its child node.</li> <li>You can create a child node for any level node by hovering over it and clicking the + icon.</li></ul></ol> <p>Follow the same process to create multiple node levels. </p> <p>The demo below shows you how to create nodes.</p> <p></p> <p>You can delete nodes by clicking the Delete icon on the right.</p> <p></p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#build-the-knowledge-graph","title":"Build the Knowledge Graph","text":"<p>The next step is to add Knowledge Graph Intents which can be either:</p> <ul> <li>FAQ to answer user queries</li> <li>Task to execute a dialog task.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#add-faqs","title":"Add FAQs","text":"<p>Using this option, you can add relevant question-answer sets to the nodes in the hierarchy. Note that there is a limit  of 50k FAQs over 20k nodes to avoid performance issues. Learn more.</p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#run-a-task","title":"Run a Task","text":"<p>To leverage the capabilities of the Knowledge Graph and dialog tasks, and handle FAQs that involve complex conversations, you must link a dialog task to a Knowledge Graph Intent </p> <ol> <li>On the Intent window, under the Intent section, select Task.</li> <li>Optionally, enter a Display Name. This name will be used for presenting the FAQ to the end-users in case of ambiguity.</li> <li>Select a task from the drop-down list. You can Add Utterance that triggers this task.</li> <li>If multiple utterances mean the same, Add Alternate Utterance.</li> <li>You can also add a Reference Id. This field can be used to add a reference to any external content used as a source for this FAQ.</li> <li> <p>Click Save.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#manage-traits-synonyms-and-stop-words","title":"Manage Traits, Synonyms, and Stop Words","text":"<p>You can improve the performance of your Knowledge Graph by adding tags, synonyms, traits, and more. Refer here to know more.</p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#manage-variable-namespaces","title":"Manage Variable Namespaces","text":"<p>Manage Variable Namespaces section (introduced in v8.0) allows you to associate the Variable Namespaces to use with this Knowledge Graph. This option is visible only when the Variable Namespace is enabled for the VA. For more information, refer to Managing Namespace.</p> <p></p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#update-a-knowledge-graph","title":"Update a Knowledge Graph","text":"<p>Once created, there will be times when you want to make changes to the Knowledge Graph for better organization and presentation.</p> <p>Note</p> <p>Once you make any changes to the Knowledge Graph, make sure to click Train on the top-right to send the updates to the Knowledge Graph engine. If you do not train the VA, the changes are not reflected in its responses.</p> <p>By default, intents added to a child node are visible for all its parent nodes in the path, up to the root node. </p> <p>If you do not want the intents from child nodes to be seen beyond a certain parent node, click the following icon on the Questions pane of the selected parent.</p> <p></p> <p>The intents from all its child nodes are visible to the selected parent node and not to all its parent nodes.</p>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#move-intents-between-nodes","title":"Move Intents Between Nodes","text":"<p>You can move one or more Intent and Response sets between nodes in your Knowledge Graph, as follows.</p> <ol> <li>On the Knowledge Graph, click the name of the node from which you want to move the intent. The intents associated to the node display on the right pane.</li> <li>Identify the intent that you want to move, and select the checkbox next to it. You can select multiple items.</li> <li> <p>Drag the intent and drop it on the relevant node. The node is highlighted and the intent displays on the right pane of the node.</p> <p>The demo below shows you how this works.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#edit-and-delete-terms","title":"Edit and Delete Terms","text":"<ol> <li>On the nodes hierarchy from the left pane, hover over the term/node you want to edit.</li> <li>Click the Settings (gear) icon. The settings window opens.</li> <li> <p>You can change the name of the term, set the term types, set the term status, add traits, add or remove synonyms, and manage context. Learn more. </p> <p></p> </li> </ol> <p>To delete a term, follow the steps below:</p> <ol> <li>On the nodes hierarchy, hover over the term you want to delete.</li> <li>Click the Delete icon.</li> <li> <p>On the confirmation dialog box, you can find the following options:</p> <ul> <li>Delete the FAQs along with the term \u2013 Choosing this option deletes the term and FAQs under it.</li> <li>Delete the term and move FAQs to root term - Choosing this option deletes the term and moves the FAQs under it to the root term.</li> </ul> <p> <p>Warning</p> <p>If the term has child nodes, all those nodes will be deleted. A warning message like the one shown below is displayed before you confirm.</p> </p> <p></p> <p> <p>Note</p> <p><ul><li>If your VA is already published, you must train it  for the deletions to be effective.</li> <li>If you have deleted the first level term you can selectively train to remove the related terms from the published copy.</li> <li>If you have deleted, say, the nth level child term, then you need to select the entire parent term for training.</li></ul></p> </p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#edit-intents-and-responses","title":"Edit Intents and Responses","text":"<ol> <li>From the nodes hierarchy, select the relevant term.</li> <li>Intents associated with the term appear on the right pane.</li> <li>Hover over the intent or response to edit it and click the Edit icon.</li> <li>Make changes to the intent or response and click Save.</li> <li> <p>You can delete the intent using the Delete icon.</p> <p></p> </li> <li> <p>Selecting multiple intents lets you delete them in bulk.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/build-a-knowledge-graph/#improve-performance","title":"Improve Performance","text":"<p>The Knowledge Graph engine works well with the default settings, but you can fine-tune the KG engine performance. Here are a few guidelines:</p> <ol> <li>Configure the Knowledge Graph by defining terms, synonyms, primary and alternative questions, or user utterances. Though hierarchy does not affect the KG engine performance, it does help organize and guide your knowledge implementation.</li> <li> <p>Set the following parameters:</p> <ul> <li>Path Coverage \u2013 For Ontology-based graphs, you can define the minimum percentage of terms in the user\u2019s utterance to be present in a path to qualify it for further scoring.</li> <li>Definite Score for KG \u2013 Define the minimum score for a KG intent match to consider as a definite match and discard any other intent matches found.</li> <li>Minimum and Definitive Level for Knowledge Tasks \u2013 Define minimum and definitive threshold to identify and respond in case of a knowledge task.</li> <li>KG Suggestions Count \u2013 Define the maximum number of KG/FAQ suggestions to present when a definite KG intent match is unavailable.</li> <li>The proximity of Suggested Matches \u2013 Define the maximum difference to allow between top-scoring and immediate next suggested questions to consider as equally important. </li> <li>Qualify Contextual Paths \u2013 This ensures that the bot context is populated and retained with the terms/nodes of the matched intent. This further enhances the user experience.</li> </ul> <p> <p>Note</p> <p> You can customize these settings in Natural Language &gt; Thresholds &amp; Configurations. See Knowledge Graph Training for details.</p> </p> </li> <li> <p>Traits \u2013 Traits qualify nodes/terms even if the user utterance does not contain the term/node. Traits are also helpful in filtering the suggested intent list.</p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/","title":"Creating a Knowledge Graph from CSV or JSON Files","text":"<p>The XO Platform gives you the option to create a Knowledge Graph in a spreadsheet or JSON and then  import it into the VA instead of creating the Knowledge Graph from scratch. Learn more. </p> <p>The process to create a Knowledge Graph using an editor is summarized below:</p> <ol> <li>Download the sample CSV or a JSON file. You can download these sample files from a blank Knowledge Graph too.</li> <li>Edit the file by adding rows corresponding to the questions, responses, synonyms, etc.</li> <li>Import the file to your VA.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#csv-file","title":"CSV File","text":"<p>You can create the Knowledge Graph using a sample spreadsheet that you can download from the VA. If you anticipate frequent changes to the Knowledge Graph, we recommend that you create it in a spreadsheet as it is easier to perform bulk updates compared to the application UI.</p> <p>Follow the instructions below to build your Knowledge Graph in a spreadsheet.</p>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#download-the-sample-file","title":"Download the Sample File","text":"<ol> <li>Select the VA to work with and go to Build.</li> <li>On the left pane, click Conversation Skills&gt; Knowledge Graph.</li> <li>You can find the Import option on the respective Knowledge Graph.</li> <li>You are prompted to back up the Knowledge Graph before proceeding. Choose the CSV or JSON format for the backup.</li> <li>After backup, click Proceed.</li> <li> <p>On the corresponding dialog box, click Sample CSV. The CSV file is downloaded to your local computer.</p> <p></p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#build-the-knowledge-graph","title":"Build the Knowledge Graph","text":"<p>The format for the CSV file includes details regarding alternate answers, extended responses, and advanced responses.</p> <p>The following types of entries are supported:</p> <ul> <li>Faq \u2013 The leaf level nodes with questions and answers.</li> <li>Node \u2013 For node/tags, traits, preconditions, and output context.</li> <li>Synonyms</li> <li>KG Params</li> <li>Traits</li> </ul> <p>Each of the above categories needs to be preceded by the appropriate header. The header helps identify the new vs old versions of the JSON file by the platform.</p> <p>Moving forward, this article discusses detailed information for each section and the content expected for each.</p>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#faq","title":"FAQ","text":"<p>This contains the actual questions and answers along with the alternate questions, answers, and extended answers.</p> <p></p> <p>The following column details can be used:</p> <ul> <li>Faq: Mandatory entry in the header, must be left blank in the following rows.</li> <li>Que ID: The Question ID is auto-generated by the Platform. This field uniquely identifies the FAQs and it should not be added or edited manually. Leave this field blank if you are adding a new FAQ. Do not alter the value of this field if you are updating an existing FAQ. Do not manually add any data in this field.</li> <li>Path: To which the FAQ belongs. The mandatory node names must be prefixed with <code>**</code> and organizer nodes with <code>!!</code></li> <li>Primary Question: The actual question users might ask: When left blank, the entry in the Answer column is considered as the alternative answer to the previous primary question.</li> <li>Alternate Question: Optional: Alternate question to the primary question if there are multiple alternate questions, they must be given in multiple rows.</li> <li>Tags: For each question or alternate question.</li> <li>Answer: Answer to the question serves as an alternate answer when the primary question field is left blank. The Answer format can be:<ul> <li>Plain text</li> <li>Script with SYS_SCRIPT prefix i.e. <code>SYS_SCRIPT;   &lt;answer in javascript format&gt;</code></li> <li>Channel-specific formatted response when prefixed with SYS_CHANNEL_&lt;channel-name&gt;, the answer can be simple or in script format:<ul> <li><code>SYS_CHANNEL_&lt;channel-name&gt; SYS_TEXT; &lt;answer&gt;</code></li> <li><code>SYS_CHANNEL_&lt;channel-name&gt; SYS_SCRIPT; &lt;answer in javascript format&gt;</code></li> </ul> </li> <li>Trigger a dialog then prefix with <code>SYS_INTENT i.e.&lt;SYS_INTENT&gt; &lt;dialog ref id&gt;</code></li> </ul> </li> <li>Extended Answer-1: Optional to be used in case the response is lengthy.</li> <li>Extended Answer-2: Optional to be used in case the response is lengthy.</li> <li>ReferenceId: reference to any external content used as a source for this FAQ</li> <li>Display Name: The name that would be used for presenting the FAQ to the end-users in case of ambiguity.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#nodes","title":"Nodes","text":"<p>This section includes settings for both nodes and tags.</p> <p></p> <p>Key Terms and Definitions</p> <p> <p><ul><li>Node: Mandatory entry in the header must be blank in the following rows.</li> <li>Que ID: The Question ID is auto-generated by the Platform. This field uniquely identifies the FAQs and it should not be added or edited manually. Leave this field blank if you are adding a new FAQ. Do not alter the value of this field if you are updating an existing FAQ. Do not manually add any data in this field.</li> <li>Nodepath: Path for reaching the node/tag.</li> <li>Tag: Mandatory for tag settings, leave blank for node.</li> <li>Precondition: Conditions to be satisfied for qualifying this node/tag.</li> <li>outputcontext: Context to be populated by this node/tag.</li> <li>Traits: Traits for this node/tag.</li>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#synonyms","title":"Synonyms","text":"<p>Use this section to enter the synonyms as key-value pairs.</p> <p></p> <ul> <li>Synonyms: Mandatory entry in the header, must be blank in the following rows.</li> <li>Phrase: for which the synonym needs to be entered.</li> <li>Synonyms: Comma-separated values.</li> </ul> <p>Use of synonyms in KG term identification can be enabled using the following:</p> <ul> <li>confidenceConfigs: Mandatory entry in the header, must be blank in the following rows.<ul> <li>parameter: useBotSynonyms in this case.</li> <li>value: Set to true or false.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#kg-params","title":"KG Params","text":"<ul> <li>KG Params: mandatory entry in the header, must be blank in the following rows.</li> <li>lang: VA language code. For example, \u201cen\u201d for English.</li> <li>stopwords: Comma-separated values. </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#traits","title":"Traits","text":"<p>Trait related information can be specified as follows:</p> <p></p> <ul> <li>Traits: Mandatory entry in the header, must be blank in the following rows.</li> <li>lang: VA language code. For example, \u201cen\u201d for English.</li> <li>GroupName: Trait group name.</li> <li>matchStrategy: Pattern or probability (for ML-based).</li> <li>scoreThreshold: Threshold value (between 0 and 1) when the matchStrategy above is set to ML-based.</li> <li>TraitName: The name of the trait.</li> <li>Training data: Utterances for the trait.</li> </ul> <p>For Taxonomy Based KG, the following fields can be included if there are one or more faqs linked to another faq in the KG:</p> <ul> <li>faqLinkedTo: The faqLinkedto field identifies the source FAQ to which another FAQ is linked to. The faqLinkedTo field must contain a single, valid \u2018Que ID\u2019 of the source FAQ. \u2018Que Id\u2019 should be a valid identity generated by the platform. Do not give a reference to an FAQ that is already linked to another FAQ.</li> <li>faqLinkedBy: The faqLinkedBy field contains the list of \u2018Que Ids\u2019 of the FAQs that are linked to a particular FAQ. \u2018Que Id\u2019 should be a valid identity generated by the platform..</li> <li>isSoftDeleted: The isSoftDeleted field is used to identify the FAQs that are deleted but it has one or more FAQs linked to it.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#json-file","title":"JSON file","text":"<p>The XO Platform allows you to create the Knowledge Graph in JSON and upload it. You can download a sample JSON from the VA to understand its structure.</p> <p>Follow the instructions below to build your Knowledge Graph using JSON:</p>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#download-the-sample-file_1","title":"Download the Sample File","text":"<ol> <li>On the left pane, click Conversational Skills &gt; Knowledge Graph.</li> <li>You can find the Import option on the respective Knowledge Graph.</li> <li>You are prompted to back up the Knowledge Graph before proceeding. Choose the CSV or JSON format for the backup.</li> <li>After backup, click Proceed.</li> <li>On the corresponding dialog box, click Sample JSON. The JSON file is downloaded to your local computer.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/create-knowledge-graph-from-csv-and-json/#json-reference","title":"JSON Reference","text":"PROPERTY NAME TYPE DESCRIPTION FAQ     Array     Consists of the following: <ul> <li>Question  <li>Answer  <li>Leaf and parent terms up to the First-level node in the path  <li>Alternative question </li> Question     String     Primary question; included in the FAQ array.     Answer     String     VA response; included in the FAQ array.     Terms Array Includes the leaf node to which the question is added, and its parents up to the First-level node. refId String Optional reference to any external content used as a source for this FAQ. Alternate Questions     Array     Consists of alternative questions and terms. Include terms from leaf to the First-level node.     Synonyms     Object     Consists of arrays of terms and their synonyms.     Unmappedpath Array Consists of arrays of nodes that do not have any questions, and all their parents up to the First-level node. Traits     Object     Consists of trait names as keys and an array of utterances as values.     <p>For a Taxonomy Based KG, the following fields can be included if there are one or more faqs linked to another faq in the KG. :</p> <ul> <li>faqLinkedTo: To identify the source faq.</li> <li>faqLinkedBy: To identify the linked faqs.</li> <li>isSoftDeleted: To identify if the faq is deleted but has some linked faqs.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/generate-a-knowledge-graph/","title":"Generate a Knowledge Graph","text":"<p>The performance of the  Knowledge Graph is based on its organization which is influenced by the key domain terms, and the established hierarchy.</p> <p>Building the FAQ is easy when you start fresh with the Knowledge Graph, but in case you have a list of questions-answer pairs, converting them into a fully-functional Knowledge Graph is tedious.</p> <p>The XO Platform provides a Knowledge Graph Generator that automatically extracts terms from FAQ, defines the hierarchy between these terms, and also associates the FAQ to the right terms. You can then import the output file from the generator to your VA\u2019s Knowledge Graph without worrying about the hierarchy. </p> <p>You can also edit the hierarchy after import to suit your needs. It is highly recommended to review and make changes as the Knowledge Graph generated is only a suggestion.</p> <p>Note</p> <p>The Knowledge Graph Generator is available from v7.1 of the Platform.</p> <p>The Kore.ai Knowledge Graph Generator is hosted on the Kore GitHub repository. This document provides the steps needed to install and use the generator.</p>"},{"location":"automation/use-cases/knowledge-ai/generate-a-knowledge-graph/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.6: The Knowledge Graph Generator requires python v3.6. You can download it here.</li> <li>Virtual Environment: It is advised to use a virtual environment, instead of installing requirements in the system directly. Follow the steps mentioned here to set up a virtual environment.</li> <li>For Windows Developers:<ul> <li>Microsoft Visual C++ Build Tools \u2013 tested with v14.0.</li> <li>Windows 10 users must install Windows 10 SDK. You can download it here.</li> <li>The operating system must be up to date for a seamless installation of requirements. Some libraries like SpiCy (internal dependency) need specific DLLs that are available in the latest updates.</li> </ul> </li> <li>A file containing the FAQs in JSON or CSV format. You can obtain this file in two ways:<ul> <li>Export the Knowledge Graph from Kore.ai XO Platform, see here for how.</li> <li>Build the Knowledge Graph in a tabular form with questions in the first column and answers in the corresponding second column and save the file in CSV format.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/generate-a-knowledge-graph/#configuration","title":"Configuration","text":"<ol> <li>Download the Knowledge Graph Generator from Kore.ai GitHub: https://github.com/Koredotcom/KnowledgeGraphGenerator.</li> <li>Extract the zip file into a folder and open the command prompt from that generator folder.</li> <li>Activate the virtual environment: Execute the following command replacing the placeholders with actual values to activate the virtual environment:<ol> <li>For Windows:  <code>&amp;lt;virtual_environments_folder_location&gt;/&amp;lt;virtualenv_name&gt;/Scripts/activate</code></li> <li>For Unix/macOS:  <code>&amp;lt;virtual_environments_folder_location&gt;/&amp;lt;virtualenv_name&gt;/bin/activate</code>.</li> </ol> </li> <li>Once the virtual environment is activated, you can see the virtual environment name at the start of every command in the console.</li> <li>Install the requirements: Run the following command from your project root directory (KnowledgeGraphGenerator) in the virtual environment to install the requirements  <code>pip install -r requirements.txt</code>You can verify the installation by running the following command and ensuring that the list contains all the components mentioned in the requirement.txt file.  <code>pip list</code></li> <li>Download spacy English model: Run the following command to download spaCy, the NLP model.  <code>python -m spacy download en</code></li> </ol>"},{"location":"automation/use-cases/knowledge-ai/generate-a-knowledge-graph/#execution","title":"Execution","text":"<p>Now that you have the prerequisites and have configured the Knowledge Graph Generator, let us see how to generate the Knowledge Graph.</p> <p>The following command executes the generator:</p> <pre><code>python KnowledgeGraphGenerator.py --file_path &lt;INPUT_FILE_PATH&gt; --type &lt;INPUT_FILE_TYPE&gt; --language &lt;LANGUAGE_CODE&gt; --v &lt;true/false&gt;\n</code></pre> <p>Let us look at each of the options:</p> OPTION DESCRIPTION MANDATORY/OPTIONAL DEFAULT VALUE Input File Path     Input file name along with the location     Mandatory     Input File Type     The type of input file: <ul> <li>json_export \u2013 for files exported from Kore.ai Bot Builder using JSON Export option  <li>csv_export \u2013 for files exported from Kore.ai Bot Builder using CSV Export option  <li>CSV \u2013 for files with questions in the first column and answers in the respective second column </li> Mandatory     Language Code     The language code for the language in which input data exist     Optional     en (English)     Verbose Mode     Running a command in verbose mode to see intermediate progress steps     Optional     false"},{"location":"automation/use-cases/knowledge-ai/generate-a-knowledge-graph/#output","title":"Output","text":"<p>The output JSON file is generated and placed under the project root directory with the name <code>ao_output.json</code></p> <p>The output JSON file can directly be imported to Knowledge Graph in the bot. </p> <p>Please refer to this link for steps to import Knowledge Graph.</p> <p>Note</p> <p>When you try to import the Knowledge Graph it replaces the existing one. We recommend you take a back up before importing.</p>"},{"location":"automation/use-cases/knowledge-ai/import-and-export-knowledge-graph/","title":"Import and Export a Knowledge Graph","text":"<p>You can build a Knowledge Graph in a CSV or JSON file and upload it to a VA. Similarly, you can export the existing Knowledge Graph to CSV or JSON. Exporting a Knowledge Graph helps you edit it in a spreadsheet or import it to another VA.</p> <p>The allowed limit is a maximum of 50k FAQs spread across a maximum of 20k nodes.</p> <p>The XO Platform allows you to import any VA with a file size up to 50MB. If you try to import a bot with more than 50MB size, the import process fails.</p>"},{"location":"automation/use-cases/knowledge-ai/import-and-export-knowledge-graph/#import","title":"Import","text":"<p>Caution</p> <p>Importing a Knowledge Graph replaces the existing one. Please proceed with caution and follow the steps below carefully.</p> <p>To import a Knowledge Graph, follow the steps below:</p> <ol> <li>Open the VA to import the KG and select the Build tab.</li> <li>On the left pane, click Conversational Skills &gt; Knowledge Graph.</li> <li> <p>You can find the Import option on the respective Knowledge Graph. </p> </li> <li> <p>Click Import.</p> </li> <li> <p>In the Import dialog, do one of the following based on the scenario:</p> <ul> <li>For a new Knowledge Graph, click Proceed.</li> <li>For an existing Knowledge Graph, take a backup CSV or JSON file, and then click Proceed. </li> </ul> </li> <li> <p>Drag and drop the file to the Import window or click Browse to locate the file.</p> </li> <li>Click Next to begin the import. </li> </ol> <p>After the import is complete, the success message appears in a dialog box.  8. Click Done.</p> <p>The hierarchy is displayed in the Knowledge Graph which you can edit and use to train your VA.</p>"},{"location":"automation/use-cases/knowledge-ai/import-and-export-knowledge-graph/#export","title":"Export","text":"<p>To export a Knowledge Graph, follow the below steps:</p> <ol> <li>On the left pane, click Conversational Skills &gt; Knowledge Graph.</li> <li> <p>You can find the Export option on the respective Knowledge Graph.</p> <p></p> </li> <li> <p>Based on the preferred format: click Export JSON or Export CSV.</p> <p> <p>Note</p> <p>Please read the warning message shown below before clicking Confirm. To learn more about caching challenges and strategies, click here.</p> </p> <p></p> <p>When these steps are completed, the Knowledge Graph file is downloaded to your machine.</p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/","title":"Knowledge Graph Extraction","text":"<p>The Knowledge Graph Extraction service enables you to effortlessly move your enterprise\u2019s Frequently Asked Questions (FAQ) content into a Knowledge Graph that trains your assistant based on these questions.</p> <p>The feature supports the extraction of knowledge from unstructured content such as web pages and PDF documents, and structured content like CSV files.</p> <p>After completing the extraction, you can edit the question and answers using an easy-to-use interface and organize them under the relevant Knowledge Graph nodes.</p> <p></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#the-extraction-process","title":"The Extraction Process","text":"<p>To move data using the Knowledge Extraction service to the Knowledge Graph, follow the process below:</p> <ol> <li>Extracting: Extract the existing FAQ content from structured or unstructured sources of question-answer data such as PDF, web pages, and CSV files. This extraction can be done before or after creating a Knowledge Graph for the assistant you are working with.       <p>Note</p> <p>The Knowledge Extraction service supports a specific content structure for each source type. Refer to the Supported formats section below for details</p> </li> </ol> <ol><li>Editing: Upon successful data extraction, you can edit the questions and answer text before moving it to the Knowledge Graph.</li> <li>Moving: You can add data to a VA before or after creating a Knowledge Graph (KG). If you try to add the extracted content to a KG before it exists, the VA automatically creates a KG with the VA\u2019s name.</li></ol> <p>The Knowledge Extractor allows you to add the extracted content to the Knowledge Graph as follows:</p> <ul> <li>Add to Knowledge Graph moves the selected questions to the root node of the Knowledge Graph. You can use this option when the required term is not yet added to the KG or when the VA does not have a Knowledge Graph.</li> <li>Add to Specific Term: If the VA already consists of a Knowledge Graph, you drag-drop the selected content to the required nodes.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#extract-from-a-website","title":"Extract from a Website","text":"<ol> <li>Open the VA to which you want to extract the content.</li> <li>Select the Build top menu item.</li> <li>From the left menu, click Conversational Skills &gt; Knowledge Graph.</li> <li>Under the Extracts section, click Extract from URL.</li> <li>Enter a Name for the extraction.</li> <li>Enter the URL of the page, and then click Proceed. </li> <li>Once the extraction is completed successfully, a success status page appears.</li> <li>Review &amp; Add the relevant questions to your Knowledge Graph,</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#extract-from-a-file","title":"Extract from a File","text":"<p>Note</p> <p>The file size should not exceed 5MB.</p> <p>To extract content from a file, please follow the steps below. For file format details, refer to the Supported formats section of this article.</p> <ol> <li>Open the VA to which you want to extract the content.</li> <li>Select the Build top menu item.</li> <li>From the left menu, click Conversational Skills &gt; Knowledge Graph.</li> <li>Under the Extracts section, click Extract from URL.</li> <li> <p>Click Browse to locate the file (PDF or CSV).</p> <p></p> </li> <li> <p>Click Proceed.</p> </li> <li>For PDF files you have an option to annotate the document before extraction.</li> <li>After the extraction is completed successfully, a success status page is displayed.</li> <li>Review &amp; Add the relevant questions to your Knowledge Graph, .</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#annotate-extract","title":"Annotate &amp; Extract","text":"<p>Note</p> <p>This feature has been introduced in v8.0 of the Platform.</p> <p>You might have all the FAQs related to your business in a PDF file but not in the XO Platform compatible format. Versions prior to 8.0 of the XO Platform did not allow incompatible files. The introduction of the Annotation tool helps annotate documents, identifying the key sections of the content. The Knowledge Extraction engine uses this information to extract the FAQs from the document.</p> <p>Note</p> <p>This is only applicable to PDF documents.</p> <ol> <li>Select a new or previously extracted PDF file. Note that you can use a previously extracted file provided no questions from that file are added to the Knowledge Graph.</li> <li> <p>Click Annotate &amp; Extract to make annotation on a newly uploaded file.</p> <p>&lt;img src=\"&lt;../../images/annotate-and extract-pdf.png&gt;\" alt=\"annotate and extract\" title=\"annotate and extract\" style=\"border: 1px solid gray; zoom:75%;\"&gt;</p> </li> <li> <p>The PDF document is loaded into the Annotation Tool allowing you to annotate the various sections in the document.</p> </li> <li>To annotate, select the text and tag it as follows:<ul> <li>Heading tags are used to identify questions. Headings are used to train the model to identify the questions and the content between two consecutive headings is treated as the answer for the preceding heading.</li> <li>Header \u2013 Text thus marked is ignored. Text marked as Headers is used to train the model to identify and ignore such text. Random marking of texts as headers must be avoided as marking texts as headers or paragraphs as the header invalidates the backend ML model, and will not produce optimal results.</li> <li>Footer \u2013 Text thus marked is ignored. Text marked as Footers is used to train the model to identify and ignore such text. Same as the Header, random marking of texts as footers must be avoided as marking text such as header or paragraphs as the footer invalidates the backend ML model, and will not produce optimal results.</li> <li>Exclude \u2013 This text is not used for extraction.</li> <li>Ignore Page \u2013 Pages marked as ignored are not used for extraction.</li> </ul> </li> <li>You can use Remove Annotation to rectify any incorrect annotations.</li> <li>The Knowledge Graph Engine uses the headings, headers, and footers in the extraction process. Since the model is trained by the KG Engine, annotating the entire document is not necessary. You can annotate a couple of pages with headings, headers, and footers, extract and review the questions. If satisfied, you can proceed with adding questions to the Knowledge Graph, else repeat the annotation process till you get satisfactory results.</li> <li>Additional document information is provided:<ul> <li>Document Info \u2013 Name, Size, and the Number of Pages of the document.</li> <li>Annotation Summary \u2013 Number of annotations marked for each category for the particular page and entire document.</li> </ul> </li> <li> <p>After you annotate, you can Extract the document. </p> </li> <li> <p>Once the content is extracted, you will see a message showing you how many questions have been found and allowing you to review and add them to the Knowledge Graph.</p> <p></p> </li> <li> <p>Choosing to Review the questions will take you to a screen where you can review extracted FAQs. This screen splits your FAQs into: All Questions, Added to KG and Not Added to the KG.  </p> </li> <li> <p>The All Questions tab gives the questions extracted by the KG Engine as per the annotations and training. Click the name of a question or check the checkbox to select multiple ones to add to the Knowledge Graph then drag and drop them to the appropriate node..</p> </li> <li>If you are not satisfied with the extracted content, you can always re-annotate the document. Just click on the Annotate tab to return to the annotation tool.</li> <li>The same procedure mentioned above is followed for re-annotation. The following points need to be kept in mind for re-annotation:<ul> <li>You can re-annotate the document provided no questions from this file are added to the Knowledge Graph.</li> <li>In case questions are already added, you can choose to create a copy of the annotated document and work with it. The copy will have all the annotations intact.</li> </ul> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#edit-the-extracted-content","title":"Edit the Extracted Content","text":"<ol> <li>Open the VA.</li> <li>Select the Build top menu item.</li> <li>From the left pane, click Conversational Skills &gt; Knowledge Graph.</li> <li> <p>The Knowledge Extraction section displays the list of all extractions.</p> <p></p> </li> <li> <p>Click the name of a successful extract you want to edit.</p> </li> <li> <p>Hover over the question-answer pair to modify it and click the Edit icon.</p> <p></p> </li> <li> <p>Make the necessary changes and click Save.</p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#add-the-extracted-content-to-the-knowledge-graph","title":"Add the Extracted Content to the Knowledge Graph","text":"<p>There are two ways to add the extracted content to the Knowledge Graph.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#from-the-extracts-section","title":"From the Extracts Section","text":"<p>To add the content from the Extracts section, follow the steps below:</p> <ol> <li>Open the VA.</li> <li>Select the Build top menu item.</li> <li>From the left menu, click Conversational Skills &gt; Knowledge Graph.</li> <li>From the Knowledge Extraction section, select the name of a successful extract you want to add.</li> <li>Drag and drop the required Q&amp;A to the node/term you want to add. As you drag and drop, the child nodes will be expanded.</li> <li>You can select multiple Q&amp;As and perform a bulk move.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#from-knowledge-graph","title":"From Knowledge Graph","text":"<p>To add the content from the KG, follow the steps below:</p> <ol> <li>Open the VA.</li> <li>Select the Build top menu item.</li> <li>From the left pane, click Conversational Skills &gt; Knowledge Graph.</li> <li>Select the node you want to add these Question-Answers.</li> <li>Click Add from Extraction. It opens the list of successful and failed extractions.</li> <li>Click the name of a successful extract you want to move.</li> <li> <p>Select the checkboxes next to the question-answer pairs that you want to move and then click Add.</p> <p></p> <p> <p>Note</p> <p>Once you move a question-answer pair from the extract to the knowledge graph, you cannot move it again. The platform shows a duplicate error when you try to move a question from the extract that is already present in the collection.</p> <p>You can make any changes to the moved content from the knowledge graph. However, if the question is modified or removed from the knowledge graph, then the developer is allowed to add it again.</p> </p> </li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#supported-formats-and-requirements","title":"Supported Formats and Requirements","text":"<p>The Knowledge Extraction service supports extracting FAQs only from supported CSV, PDF, and URL formats.</p> <p>Note that the file size must not exceed 5MB.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#csv","title":"CSV","text":"<ul> <li>The Knowledge Extraction service interprets the text in the first column as a question and that in the second column as an answer.</li> <li>The file must not have any headers.</li> <li>The Knowledge Extraction service ignores any headers and the text present in the other columns.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#pdf","title":"PDF","text":"<ul> <li>The Knowledge Extraction service processes the content from a PDF and converts it into question-answer pairs.</li> <li>Documents with the table of contents: Ideally a document with a table of contents is preferred. In such cases, the Knowledge Extraction service extracts the table of contents first and then uses it to parse the document and identify headings. The information present in the table of contents is used to derive the hierarchy of headings (headings, subheadings, sub-sub headings, etc.). These levels are separated by a vertical line as a delimiter (heading | subheading | sub-sub heading) as part of the extraction process.</li> <li>Documents with no table of contents: In such cases, the Knowledge Extraction service uses a pre-trained machine learning model that identifies headings based on either font style or font size. In the case of using font size, the heading hierarchy can also be derived.</li> <li>The text is then formatted with a uniform header and paragraph blocks.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-extraction/#web-pages","title":"Web Pages","text":"<p>The Knowledge Extraction service supports the following three different formats of FAQ web pages:</p> <ul> <li>Plain FAQ pages with linear question-answer pairs.</li> <li>Pages with question hyperlinks that point to answers on the same page.</li> <li>Pages with question hyperlinks that point to answers on a different page.</li> </ul> <p>Extraction of certain FAQs on the webpage fails under the following conditions:</p> <ul> <li>The question text is split between multiple HTML tags on the FAQ page.</li> <li>The tag applied to the answer is neither the child nor the sibling of the extracted question as per the HTML DOM structure.</li> <li>The question does not have a hyperlink to the answer (applies to FAQs with hyperlinks).</li> <li>When the questions hyperlink to the answer, but the question statement is not repeated above the answer (applies to FAQs with hyperlinks).</li> </ul> <p>The extraction of the entire FAQ page also fails if the page consists of more than one FAQ page type mentioned above.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-analysis/","title":"Knowledge Graph Analysis","text":"<p>A careful analysis of the Knowledge Graph helps in detecting errors in your questions and the path associated with them that hamper the user experience.</p> <p>The Knowledge Graph (KG) Diagnosis tool helps you identify any inefficiencies in your KGs and suggests possible corrective actions. These are just guidelines and you need to further analyze the recommendations before going ahead with any changes.</p> <p>The KG provides an option to initiate an inspection, as follows:</p> <ul> <li>This option is available only for the in-development version of the KG where there are one or more FAQs added.</li> <li>The analysis considers the thresholds and other configurations of the KG.</li> <li>The analysis issues a warning if any node contains more than 25 questions and an advisory to the effect that the training fails if there are more than 100 questions in any node.</li> <li>You can invoke the diagnosis, by clicking Inspect on the KG screen.</li> </ul> <p></p> <ul> <li> <p>You can also add patterns as alternate questions for an FAQ to provide better coverage, which helps in detecting the right FAQs for a user question. KG Inspect helps in identifying any syntax errors that occur knowingly or unknowingly while defining patterns.  The platform analyzes the KG and provides a report of the analysis. The identified incorrect patterns in KG are displayed in the report.</p> </li> <li> <p>You have an option to Re-run the analysis or Export the report. The export option downloads the report in JSON format.</p> </li> </ul> <p></p> <ul> <li>The inspect report shows an overview of the number of issues found under various categories. Please read below to learn more.</li> <li>The various categories are grouped as:<ul> <li>Error \u2013 Errors are incorrect graph definitions that need an immediate fix.</li> <li>Warnings \u2013 When rectified, it help improves intent detection. A maximum of 50 warnings are displayed.</li> <li>Suggestions \u2013 When implemented, it helps in the better organization of your KG. A maximum of 10 suggestions are displayed.</li> </ul> </li> <li>Click each category to view the detailed report</li> </ul> <p>In the example below, the details of all the patterns with invalid syntaxes are shown:</p> <p></p> <p>Note</p> <p>There can be more than 50 warnings or 10 suggestions, but only the first 50/10 occurrences of the issue are listed. You must fix the same and re-run the analysis to view the next set.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-analysis/#report-fields-for-ontology-knowledge-graphs","title":"Report Fields for Ontology Knowledge Graphs","text":"<p>The following table details the fields that are displayed in the report:</p> ISSUE TYPE CATEGORY DETAILS SUGGESTION Patterns with Invalid Syntax     Error     <ul> <li>Current Path  <li>Pattern  <li>Error  <li>Question </li> Rectify the incorrect patterns for better FAQ detection.     Questions added to incorrect paths     Error     <ul> <li>Question  <li>Path </li> Modify the path to include the terms in the question.     Long-chain of terms with the questions present only at the last term in the chain     Suggestion     <ul> <li>Question  <li>Path </li> Reduce the path by avoiding unimportant terms or merge relevant terms.     Identical terms with a common ancestor     Suggestion     <ul> <li>Common Parent  <li>Child Paths (only for the largest repeated child trees) </li> Move the child terms above their parent terms to avoid duplication     Paths without any questions     Suggestion     <ul> <li>Path </li> </ul> Remove the path if you do not intend to add any questions to this path     Redundant alternate questions     Suggestion     <ul> <li>Question  <li>Alternate Question (multiple)  <li>Path </li> Rephrase alternate questions to include wider coverage     A large number of questions added to the root term     Suggestion     <ul> <li>Question  <li>Path </li> Move the questions to the appropriate paths     Unusually long paths     Warning     <ul> <li>Path </li> </ul> Reduce the path by avoiding unnecessary terms or merging relevant terms.     Questions at the root node that can be moved to better paths     Warning     <ul> <li>Question  <li>Current Path  <li>Suggested Path </li> Move the question to the suggested path     Questions with common words that are not used as terms     Warning     <ul> <li>Question (multiple)  <li>Path  <li>Suggested Extension </li> Extend the current path using the suggested extension     Questions that match multiple paths     Warning     <ul> <li>Question  <li>Current path  <li>Other Paths (multiple) </li> Review the paths to avoid possible ambiguity scenarios     Identical sibling nodes     Warning     <ul> <li>Path  <li>Identical Term </li> Merge the identical terms"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-analysis/#report-fields-for-few-shot-knowledge-graphs","title":"Report Fields for Few-Shot Knowledge Graphs","text":"<p>For Few-Shot Knowledge Graphs, nothing regarding paths and keywords requires analysis; since these are not used by the model to detect intent. The only report fields you will see when inspecting such a graph are the following: </p> ISSUE TYPE CATEGORY  DETAILS SUGGESTION Patterns with Invalid Syntax     Error     <ul> <li>Current Path  <li>Pattern  <li>Error  <li>Question </li> Rectify the incorrect patterns for better FAQ detection.     Paths without any questions     Suggestion     <ul> <li>Path </li> </ul> Remove the path if you do not intend to add any questions to this path.     Redundant alternate questions     Suggestion     <ul> <li>Question  <li>Alternate Question (multiple)  <li>Path </li> Rephrase alternate questions to include wider coverage.     <p>Note</p> <p>Every time a KG is inspected, the following details get updated in a scenario where any FAQs are modified or any new FAQs are added: <ul><li>Total checks</li> <li>Count of errors, warnings, suggestions</li> <li>Count and the list of various checkpoints.</li></ul></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/","title":"Knowledge Graph","text":"<p>A Knowledge Graph (KG) component helps convert static FAQ text into an intelligent, personalized conversational experience. It goes beyond the usual practice of capturing FAQs as flat question-answer pairs, allowing you to either build an ontology structure or leverage LLM and Generative AI to simplify knowledge organization, maintenance, and training.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#why-a-knowledge-graph","title":"Why a Knowledge Graph?","text":"<p>People express a query in multiple ways, so identifying all the options is complex. The XO Platform Knowledge Graph simplifies this process by either building an ontology structure or using an LLM model that does not require such an ontology.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#knowledge-graph-types","title":"Knowledge Graph Types","text":"<p>There are two types of Knowledge Graphs:</p> <ol> <li>The Ontology Knowledge Graph lets you create an ontological structure of key domain terms and associate them with context-specific questions and their alternatives, synonyms, and Machine-Learning-enabled Traits.</li> <li>The Few-Shot Knowledge Graph leverages a Large Language Model (LLM) to simplify knowledge organization. Using this model, you are not required to build an ontology. All you need to do is add all FAQs to the root node/term. This significantly reduces the complexity of building and maintaining an ontology structure.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#choosing-your-knowledge-graph-type","title":"Choosing Your Knowledge Graph Type","text":"<p>Starting with v10.1 of the XO Platform, the Few-Shot Model is the default for all new Knowledge Graphs created under NLP V3 and in English.</p> <p>If you have built your Ontology-based graph before this release, you can migrate to the new model anytime. You must upgrade to NLP V3 to use the Few-Shot Model. You can return to the Ontology model if you change your mind later.</p> <p>You can select your desired Knowledge Graph Type by going to Build &gt; Natural Language &gt; Thresholds and Configurations &gt; Knowledge Graph.</p> <p></p> <p>Changing Knowledge Graph Types is captured in the Change Logs, which you can access by going to Deploy &gt; Change Logs.</p> <p>Note</p> <p>Before changing your Knowledge Graph Type, we recommend backing up your existing knowledge graph by either creating a new bot version or by exporting a copy of your knowledge graph as a JSON or CSV.</p> <p>Please continue reading to learn more about each type of knowledge graph. See Knowledge Graph Terminology for in-depth information about Knowledge Graph features and components.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#the-ontology-knowledge-graph","title":"The Ontology Knowledge Graph","text":"<p>This type lets you organize FAQs using Default, Mandatory, and Organizer Terms/Nodes, tags, synonyms, context, traits, and more.</p> <p>Whenever someone asks your VA a question, the terms (node names) in the Knowledge Graph are checked and matched with keywords from the utterance. We call this process path qualification. Tags and synonyms are also checked, and based on the score they receive, questions are shortlisted as likely matches or intents. These shortlisted questions are then compared with the actual utterance to identify the response, which can be either a simple response or the execution of a dialog task.</p> <p>You can also add completely different alternative questions to the FAQ and provide tags, synonyms, and terms appropriately such that any untrained question can also be matched. The performance and intelligence of the Knowledge Graph depend on the way you train it with the appropriate terms, tags, synonyms, etc.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#enable-the-ontology-knowledge-graph","title":"Enable the Ontology Knowledge Graph","text":"<p>To enable this Knowledge Graph type, go to Build &gt; Natural Language &gt; Thresholds and Configurations &gt; Knowledge Graph, and select Ontology Model as the Knowledge Graph Type.</p> <p>Before enabling the Ontology Knowledge Graph model, please consider the following:</p> <ol> <li>You must build a Graph Ontology structure so the engine can qualify paths and compare them with query input. Each relevant term/node is considered while identifying the appropriate FAQ, so you must regularly maintain the node structure to facilitate optimum performance.</li> <li>The model supports three types of terms: Default, Mandatory, and Organizer.</li> <li>The Ontology Model also supports other features such as Traits, Patterns, Path Synonyms, KG Synonyms, Bot Synonyms, Preconditions, and more. Please see the Comparison Table below for a detailed list of supported features. Also, see Knowledge Graph Training for configuration details.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#how-it-works","title":"How It Works","text":"<p>The Ontology Knowledge Graph engine uses a two-step approach while extracting a response. It combines a search-driven intent detection process with rule-based filtering. The settings for path coverage (percentage of terms needed) and term usage (mandatory or optional) in the user utterance help in the initial filtering of the FAQ intents. Tokenization and the n-gram-based cosine scoring model help fulfill the final search criteria.</p> <p>When a new utterance reaches the Ontology Knowledge Graph:</p> <ul> <li>The user utterance and KG nodes/terms are tokenized, and n-gram is extracted (The Knowledge Graph Engine supports a maximum of a quad-gram).</li> <li>The tokens are mapped with the KG nodes/terms to obtain their respective indices.</li> <li>Path comparison between the user utterance and KG nodes/terms establishes the qualified path for that utterance. This step considers the path coverage and term usage mentioned above.</li> <li>From the list of questions in the qualified path, the best match is selected based on cosine scoring.</li> </ul> <p>Training the Ontology Knowledge Graph Model involves the following steps:</p> <ul> <li>All the terms/nodes, along with synonyms, are identified and indexed.</li> <li>Using these indices, a flattened path is established for each KG Intent.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#the-few-shot-knowledge-graph","title":"The Few-Shot Knowledge Graph","text":"<p>This Knowledge Graph type uses Kore.ai\u2019s Large Language Model (LLM) to identify the appropriate FAQ for a query based on semantic similarity and pattern recognition. This model only uses Mandatory and Organizer terms and does not perform path qualification, so you are not required to build an ontology. All you need to do is add all FAQs to the root node/term. It significantly reduces the complexity of building and maintaining an ontology structure.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#enable-the-few-shot-knowledge-graph","title":"Enable the Few-Shot Knowledge Graph","text":"<p>To enable the Few-Shot Knowledge Graph, go to Build &gt; Natural Language &gt; Thresholds and Configurations &gt; Knowledge Graph, and select Few-Shot Model as the Knowledge Graph Type.</p> <p>Before enabling the Few-Shot Knowledge Graph, please consider the following:</p> <ol> <li>When switching from an Ontology-based Knowledge Graph to the Few-Shot model, Default terms/odes are still stored until you update them. From this point onwards, the terms are stored as Organizer unless you make them Mandatory.</li> <li>Only Mandatory terms support path-level synonyms.</li> <li>The Few-Shot model works with Ranking &amp; Resolver V2 and NLP V3. When you enable this model, the Ranking &amp; Resolver version will be updated automatically. If you are not using NLP V3, you will be asked to upgrade before enabling it.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#how-it-works_1","title":"How It Works","text":"<p>When a new utterance reaches the Few-Shot Knowledge Graph, the Large Language Model determines possible and definitive intent matches. The model uses semantic similarity, and when similarity crosses the threshold, then pattern recognition is used. The identified intents are sent to Ranking and Resolver, where the winning intent is identified. Once this process completes, the assistant responds to the query.</p> <p>Training this model mainly involves adding tags and alternative questions to FAQs. Other training features, such as term synonyms, traits, context, etc., are optional but still recommended to improve performance for specific use cases where the LLM cannot identify the intent.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-overview/#compare-knowledge-graph-types","title":"Compare Knowledge Graph Types","text":"FEATURE FEW-SHOT KG MODEL  ONTOLOGY KG MODEL Ontology Structure     Yes, Optional.     Yes, Mandatory.     Default Terms     No, unless you switch from an Ontology KG and don\u2019t update the term. After updating, the term becomes an Organizer and can be set as Mandatory.      Yes     Mandatory Terms     Yes     Yes     Organizer Terms     Yes     Yes     Path Qualification     No     Yes, always performed.     Tags     Yes     Yes     Synonyms     Yes, for Mandatory Terms and Tags.     Yes     Path-Level Synonyms     Yes, for Mandatory Terms     Yes     Knowledge Graph Synonyms     Yes, for Mandatory Terms     Yes     Traits     Yes     Yes     Context     Yes     Yes     Stop Words     Yes     Yes     KG Import/Export     Yes     Yes     Auto-Generate KG     Yes     Yes     Bot Synonyms     Yes     Yes     Lemmatization using Parts of Speech     No     Yes     Path Coverage     No     Yes     Search in answer     No     Yes     Qualify Contextual Paths     No     Yes     Auto-Correction     Yes     Yes     Minimum and Definitive Level for Knowledge Graph Intent     Yes     Yes     KG Suggestions Count     Yes     Yes     Proximity of Suggested Matches     Yes     Yes     Manage Long Responses     Yes     Yes     Intent Preconditions     Yes     Yes     Context Output     Yes     Yes     Supports All Platform Languages     Yes     Yes"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/","title":"Knowledge Graph Terminology","text":"<p>This article explains the terminology for building a Knowledge Graph within the XO Platform. This terminology applies to both the Few-Shot and the Ontology KG Models unless otherwise specified. Learn more.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#terms-or-nodes","title":"Terms or Nodes","text":"<p>Terms or Nodes are the building blocks of an ontology and are used to define the fundamental concepts and categories of a Knowledge Graph.</p> <p>You can organize the terms in a hierarchical order to represent the flow of information in your graph. You can create, organize, edit, and delete terms and set term types to facilitate intent identification </p> <p>Important</p> <p>The Knowledge graph is limited to 20 thousand nodes/terms and 50 thousand FAQs.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#nodeterm-hierarchy","title":"Node/Term Hierarchy","text":"<p>For easier representation, we identify node/term hierarchy using the following names:</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#root-termnode","title":"Root Term/Node","text":"<p>The Root Term/Node forms the topmost term of your Ontology. A Knowledge Graph contains only one root node, and all other nodes in the ontology become its child nodes. The Root node takes the name of the VA by default, but you can change it as needed. In an Ontology-based KG, this node is not used for path qualification or processing. Path qualification starts from first-level nodes. </p> <p>For Ontology-Based graphs, it is best to organize your FAQs into a clear structure, so we don\u2019t recommend adding them at the Root node. However, you can add a maximum of 100 FAQs, if required. </p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#first-level-termnode","title":"First-level Term/Node","text":"<p>The immediate next-level nodes after the Root node are known as First-Level Term/Node. There can be any number of first-level nodes in a graph. </p> <p>We recommend using first-level nodes to represent high-level terms, such as the names of departments, functionalities, etc. </p> <p>For example, in a Travel Assistant, you might have a first-level node called Reservation, which can be structured by functionality into subnodes such as: Cancel and Update.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#leaf-termnode","title":"Leaf Term/Node","text":"<p>Any node at any level starting with the 2nd is called a Leaf Term/Node.</p> <p>Note</p> <p><ul><li>This hierarchical organization of nodes is for your convenience to keep related questions together.</li> <li>The Knowledge Graph Engine does not consider any parent-child relation while evaluating the questions for a match.</li> <li>The hierarchy does not influence the FAQ matching process since all the nodes are considered the same way, irrespective of their position.</li> </ul></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#termnode-types","title":"Term/Node Types","text":"<p>Functionally, there are three types of Terms/Nodes.</p> <ul> <li>Default: Default terms do not have any particular considerations in shortlisting qualified paths in Ontology-based KGs. </li> <li>Mandatory: When you mark a term as Mandatory, paths associated with it are shortlisted for ranking only if the user\u2019s utterance includes the mandatory term or its synonyms.</li> <li> <p>Organizer: This term type can be marked as part of the Knowledge Graph to organize the ontology and help qualify FAQs even when they don\u2019t contain the specific terms.</p> <p></p> </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#tags","title":"Tags","text":"<p>For each term/node, you can add custom tags. Tags work exactly like terms but are not displayed in the Knowledge Graph ontology to avoid clutter. You can add synonyms and traits to tags as you do to terms.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#synonyms","title":"Synonyms","text":"<p>The Knowledge Graph allows you to add Synonyms for terms to include all possible alternative forms. Adding synonyms reduces the need for training the VA with alternative questions.</p> <p>For example, the reservation node in our previously-mentioned Travel Assistant may have the following synonyms added to it: booking, order, purchase, etc. </p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#synonym-types","title":"Synonym Types","text":"<p>When you add a synonym for a term or a tag in the Knowledge Graph, you can add it as a local or global synonym. Local synonyms (or Path Level Synonyms) apply to the term only in that particular path, whereas global synonyms (or Knowledge Graph Synonyms) apply to the term even if it appears on any other path in the ontology.</p> <p>After v. 7.2 of the XO Platform, you can also use Bot Synonyms inside the Knowledge Graph engine for path qualification and question matching. With this setting, you need not recreate the same synonyms in Bot Synonyms and KG Synonyms.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#traits","title":"Traits","text":"<p>A trait is a collection of typical end-user utterances that define the nature of a question. Learn more.</p> <p>A trait is applied to multiple terms across your Bot Ontology.</p> <p>Note</p> <p><ul><li>Traits also help you filter nodes based on associated user utterances. Thus, if the user types an utterance that is present in a trait, the assistant only searches the nodes to which the trait is applied.</li> <li>If the utterance is present in any other node to which the trait is not applied, the node is ignored.</li></ul></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-terminology/#intents","title":"Intents","text":"<p>A VA can respond to a given question with an FAQ or the execution of a Dialog Task.</p> <ul> <li> <p>FAQ: The question-answer pairs must be added to relevant nodes in your ontology. A maximum of 50k FAQs is permissible. A question is asked differently by different users, and to support this, you must associate multiple alternate forms for each question. Preceding an alternate question with || will allow you to enter patterns for FAQs (after the v.7.2 release).</p> <p></p> </li> <li> <p>Task: Linking a Dialog task to a KG Intent helps leverage the capabilities of the Knowledge Graph and Dialog tasks to handle FAQs that involve complex conversations.</p> <p></p> </li> </ul> <p>Important</p> <p><ul><li>For Few-shot graphs, you can add all your FAQs to the Root node because the LLM does not require an ontology.</li> <li>Default terms are not available in Few-Shot Knowledge Graphs. The only exception is when you switch from an Ontology Graph, in which case existing Default terms are stored as such until updated. Afterward, Default terms become Organizer terms and can be set as Mandatory.</li> <li>Path Level Synonyms are only supported for Mandatory Terms and for Tags.</li></ul></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/","title":"Knowledge Graph Training","text":"<p>Training your Assistant is not restricted to the Machine Learning and Fundamental Meaning engines. You must also train the Knowledge Graph (KG) engine, too.</p> <p>The Ontology-based Knowledge Graph turns static FAQ text into an intelligent, personalized conversational experience. It uses domain terms and relationships thus reducing the training needs. It also has the capability to enable the ontology weighted features whenever ML gets confused and to automate conversational dialog for resolving appropriate answers.</p> <p>The Few-Shot Knowledge Graph leverages Kore.ai\u2019s LLM and lets you add FAQs without building an ontology. Less training and maintenance are required since you do not need to configure the graph term-by-term. Learn more about Knowledge Graph Types.</p> <p>The Knowledge Graph engine thus responds to users\u2019 intents by identifying the appropriate questions within the Knowledge Graph, and then presenting the user with the appropriate response.</p> <p>You can find the Knowledge Graph by selecting your desired VA, then going to Build &gt; Conversation Skills &gt; Knowledge Graph.</p> <p>Training a Few-Shot Knowledge Graph</p> <p>Few-Shot Knowledge Graphs do not require an ontology and do not perform path qualification. Instead, they identify intents using semantic similarity and pattern recognition. However, if you want to train the VA on a specific use case for which the appropriate FAQ is not identified, you can map FAQs to an ontology, similar to what you would do with an Ontology-based Graph.</p> <p>The main difference concerning training is that in the Few-Shot KG, Terms don't require some of the training configurations needed in an Ontology Graph. Here are some key pointers:</p> <p><ul><li>Default Terms are not available. The only exception is when you switch from an Ontology Graph, in which case existing Default terms are stored as such until updated. Afterward, Default terms become Organizer terms and can be set as Mandatory.</li> <li>Organizer Terms do not support Path-Level and Knowledge Graph Synonyms. They support Intent Preconditions and Context Output.</li> <li>Mandatory Terms support Traits, Path-Level and Knowledge Graph Synonyms, Intent Preconditions, and Context Output, just like in an Ontology-based Graph.</li> <li>You can set all Thresholds and Configurations except Path Coverage and Lemmatization using Parts of Speech, Search in Answer, and Qualify Contextual Paths, which are not supported by Few-Shot Graphs.</li>  See the Knowledge Graph Types Comparison Table for a detailed list of supported features.  Also, see Training Configuration below for training setup details."},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#knowledge-graph-engine-capabilities","title":"Knowledge Graph Engine Capabilities","text":"<p>The following are the overall capabilities of the Knowledge Graph Engine:</p> <ul> <li>Ease of Training using Synonyms: Kore.ai\u2019s Knowledge Graph has a provision to associate synonyms against a graph node. This helps capture the variation in a question. For example, flight can be used as a synonym for plane in an FAQ such as How can I buy a plane ticket?</li> <li>Better Coverage with Alternate Questions: The Knowledge Graph has a provision to add alternate questions. This helps us to capture the various ways a user might ask the same question. For example, in How do I change my flight? we can add an alternate question as Can I change my flight?</li> <li>Improved Accuracy: Ontology-driven question-answers reduce the possibility of false positives.</li> <li>Weighing Phrases using Traits: Kore.ai\u2019s Knowledge Graph engine includes a concept of traits for filtering out irrelevant suggestions. Learn More.</li> <li>Ability to Mark Term Importance: The Knowledge Graph has a provision to mark that an ontology term is important. For example, in the question, How to book a flight?, the word flight is an important term. If the flight keyword is not present in the user utterance, then it makes little sense.</li> <li>Ability to Group Relevant Nodes: As the graph grows in size, managing graph nodes can become a challenging task. Using the organizer node construct of the ontology engine, developers can group relevant child nodes under a parent node.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#faq-detection-steps","title":"FAQ Detection Steps","text":"<p>Here are the steps that the Knowledge Graph Engine takes when detecting FAQs:</p> <ul> <li>Step 1: Extract Nodes: The KG engine processes the user utterance to extract the term (ontology nodes) present in the graph. It also takes into consideration the synonyms, traits, and tags associated with the terms.</li> <li>Step 2: Query Graph: The KG engine fetches all the paths that consist of the extracted nodes.</li> <li>Step 3: Shortlist Paths: All the paths consisting of 50% or more matching terms with the user utterance are shortlisted for further processing.</li> </ul> <p>Note</p> <p>Patch coverage computation doesn't consider the root node.</p> <ul> <li>Step 4: Filter with Traits: If traits are defined in the Knowledge Graph, paths shortlisted in the above step are further filtered based on the confidence score of a classification algorithm in user utterance. </li> <li>Step 5: Send to Ranker: The KG engine then sends the shortlisted paths to the Ontology Ranker Program.</li> <li>Step 6: Score based on Cosine Similarity: The Ontology Ranker makes use of user-defined synonyms, lemma forms of word, n-grams, stop words, to compute the cosine similarity between the user utterance and the shortlisted questions. Paths are ranked in non-increasing order of cosine similarity score.</li> <li>Step 7: Qualify Matches: The Ontology Ranker then qualifies the paths as follows:<ul> <li>Paths with score &gt;= upper_threshold are qualified as an answer (definitive match).</li> <li>Paths with lower_threshold &gt; score &gt; upper_threshold are marked as suggestions (probable match).</li> <li>Paths with a score &gt; lower_threshold are ignored.</li> </ul> </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#training-guidelines","title":"Training Guidelines","text":"<p>From the Knowledge Graph, follow these steps to build and train the corresponding Knowledge Graph:</p> <ol> <li>Identify terms by grouping the unique words in each FAQ question. Build a hierarchy based on all such unique words.</li> <li>Ensure that each node has not more than 25 questions.</li> <li>Associate traits with terms to enable filtering FAQs from multiple identified results.</li> <li>Define synonyms for each term/node in the hierarchy. Ensure that all the different ways to call the term are defined.</li> <li>Depending on the importance of each term in a path, mark them as either mandatory or regular.</li> <li>Define alternative questions for each FAQ to ensure better coverage.</li> <li>Manage context for accurate response.</li> <li>Use Stop Words to filter unwanted utterances.</li> </ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#training-configuration","title":"Training Configuration","text":"<p>This article presupposes that you already know the basics of building your Knowledge Graph. If not, please read this article.</p> <p>In order to configure the training of your Knowledge Graph for improved VA performance, we recommend that you go through as many of the following parameters as possible. These parameters involve:</p> <ul> <li>Adjusting the Term Type to your VA\u2019s needs when adding terms to your graph,</li> <li>Setting tags for FAQs to improve detection,</li> <li>Configuring synonyms for Knowledge Graph terms to enhance path detection and help the VA find the appropriate questions to answer by widening the spectrum of words that can be used to find a specific question,</li> <li>Adding Traits to detect relevant information that improves intent or scenario detection.</li> <li>Manage Context to help users complete tasks faster and create more natural, human-like back and forth conversations.</li> <li>Add Stop Words which will be discarded from intent scoring, even when they are a node term. </li> </ul> <p>We will discuss these parameters in detail in the following sections.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#term-type","title":"Term Type","text":"<p>Designate the terms and tags in the Knowledge Graph as Default, or Mandatory, or Organizer depending on their importance in qualifying matching paths: You can configure term types by accessing the term/node settings.</p> <p></p> <p>The available term types are: </p> <ul> <li>Default: Default terms do not have any particular considerations in shortlisting qualified paths.</li> <li>Mandatory: When you mark a term as Mandatory, all paths associated with the term are shortlisted for ranking only if the user\u2019s utterance includes the mandatory term or its synonyms.</li> <li>Organizer: Term can be marked as being a part of the Knowledge Graph only for organizing questions (this option is available only for terms, not tags). </li> </ul> <p></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#tags","title":"Tags","text":"<p>When you type a question in the Intent Name Add Question field, the Knowledge Graph suggests some tags that you can add to the graph based on the text. To include a suggested term to the path, select the tag from the drop-down list that appears when the cursor is in the Add Term field. You can also add custom tags by typing them in the add term field and hitting the Enter/Return key.</p> <p></p> <p>After you add a tag, it is visible below the question like a tag everywhere the question appears. Tags work exactly like terms but are not displayed in the Knowledge Graph to avoid clutter. </p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#synonyms","title":"Synonyms","text":"<p>You can add multiple synonyms for each term in your Knowledge Graph, making the path discoverable for varied user utterances. You can add synonyms for a term from the term\u2019s  Settings window.</p> <p>When you add a synonym for a term in the Knowledge Graph, you can add them as local (Path Level) or global (Knowledge Graph level) synonyms.</p> <p>Local Synonyms apply to the term only in that particular path, whereas Global Synonyms apply to the term even if it appears on any other path in the hierarchy.</p> <p>To add synonyms for a term, follow the below steps:</p> <ol> <li>On the top left of the VA\u2019s Knowledge Graph, hover over the node/term for which you want to add synonyms.</li> <li>Click the gear icon to open the Settings window.</li> <li> <p>To add synonyms,  do the following:</p> <ul> <li>To add local synonyms, type them in the box under Path Level Synonyms.</li> </ul> <p></p> <ul> <li>To add Global synonyms, click Edit then Add under Knowledge Graph Synonyms and enter them.  <p>Note</p> <p>Press Enter after typing each synonym in the Synonyms box. If you type multiple synonyms without pressing Enter after each synonym, all the synonyms are considered as a single entity, even if they are separated by spaces.</p> <p></p> <p>Note</p> <p>These Knowledge Graph Synonyms can also be accessed from the Manage Synonyms option under the more options icon on the top-right of the Knowledge Graph page.</p> <ol><li>You can use Bot Synonyms in the identification of KG terms. This option can be enabled either from the Threshold and Configurations or from More Options &gt; Manage Synonyms. <p>Once enabled, the bot-level synonyms that match with KG terms (or tags) are automatically displayed under the Bot Synonyms heading in the Synonyms section and are used by the KG engine. The Bot Synonyms are used similar to that of KG graph level synonyms, for path qualification and for question matching. When a node matches both with a bot synonym and a bot concept, the bot concept takes priority.</p></li> <li>To add synonyms for a child node, enter them in the Synonyms box next to the Child Terms listed at the bottom of the settings window.  </li></ol>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#traits","title":"Traits","text":"<p>You can create traits with common user utterances and then add them to the relevant terms in your Knowledge Graph. To know more about Traits, click here.</p> <p>Traits are common across the XO Platform. If you have created Traits from the Natural Language section they are available for use here as well.</p> <p>To create a trait, follow the below steps:</p> <ol> <li>On the top-right of the Knowledge Graph window, click the more options icon and then select Manage Traits.</li> </ol> <p></p> <ol> <li>On the Manage Traits window, click New Trait.</li> <li>In the Trait Type and Trait Name field, enter a relevant name for the trait. For example, Flight Fare.</li> <li>In the Utterances field, enter all the utterances that you want to include in the trait. Examples of the Issues trait: First Class, Premium Economy, Economy, etc.</li> <li>Click Save &amp; Add Rule or Save &amp; Exit.</li> </ol> <p></p> <p>After you create a trait, you can assign it to multiple nodes in the Knowledge Graph.</p> <p>To add a trait to a node/term, follow the below steps:</p> <ol> <li>On the top-left of your Knowledge Graph, hover over the terms to which you want to add the trait.</li> <li>Click the gear icon to open the Settings window.</li> <li>Select the name of a trait from the Trait dropdown list and click Save.</li> </ol> <p>Note</p> <p>Adding a trait to a node doesn't add it to other nodes with the same name. You must add traits to each relevant node separately. </p> <p></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#context","title":"Context","text":"<p>You can Manage Context for the terms and tags by setting:</p> <ul> <li>Intent Precondition \u2013 the context that should be present as a qualifier for this node or tag.</li> <li>Context Output \u2013 the context that should be populated to signify the execution of this task.</li> </ul> <p>Post the release of v8.0 of the Platform, context can be enabled for Organizer nodes as well. Enabling the Manage Context option allows you to set the context precondition and context output mentioned above. Click here for more on Context Management.</p> <p>Note</p> <p>Enabling the Manage Context option will not emit the term/node name by default.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#stop-words","title":"Stop Words","text":"<p>Stop words present in the user utterance are discarded for scoring even if the stop word is used to define a node (or node synonyms).</p> <p>The Knowledge Graph has a language-specific predefined set of stop words. This list can be customized to suit your requirements.</p> <p>To edit the stop words list, follow the below steps:</p> <ol> <li>From the Knowledge Graph page, click on the more options icon and select Manage Stop Words.</li> <li>From the Manage Stop Words window, delete or add stop words.</li> </ol> <p></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#training-process","title":"Training Process","text":"<p>After you complete creating/editing the Knowledge Graph, click the Train button on the top-right of the Knowledge Graph window. When you perform this action, all the paths, synonyms, and question-answer sets are sent to the Graph DB engine.</p> <p>Note</p> <p>After every change that you make to the Knowledge Graph such as adding synonyms to a term or editing the name of a term, you must click the Train button for the changes to reflect in the bot responses.</p> <p>The training fails if any single node has more than 100 questions. This limit was introduced in v7.3 to make the Knowledge Graph more efficient by improving the response times. In such failure cases, you can Download Errors CSV file which lists the path with more than 100 questions. You can use this file to rectify your Knowledge Graph.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#testing","title":"Testing","text":"<p>When you complete creating the Knowledge Graph and training it, we recommend that you interact with the assistant and ask questions connected to the Knowledge Graph. Test the responses by using a variety of utterances so that you can identify missing terms, questions, alternative questions, synonyms, and traits. Learn more about utterance testing.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#thresholds-configurations","title":"Thresholds &amp; Configurations","text":"<p>To train and improve the performance, Thresholds and Configurations can be specified for all three NLP engines \u2013 FM, KG, and ML. You can access these settings from Natural Language &gt; Training &gt; Thresholds &amp; Configurations.</p> <p>Note</p> <p>If your VA is multilingual, you can set the Thresholds differently for different languages. If not set, the Default Settings will be used for all languages. This feature is available from v7.0 onwards.</p> <p>The settings for the Knowledge Graph engine are discussed in detail in the following sections.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#explore-thresholds-and-configurations","title":"Explore Thresholds and Configurations","text":"<p>To navigate to Thresholds and Configuration, please follow the steps below: </p> <ol> <li>Open the VA for which you want to configure Knowledge Graph settings.</li> <li>Hover over the left pane and click Natural Language &gt; Training.</li> <li>Click the Thresholds &amp; Configurations tab.</li> <li>Below is a detailed discussion about the Knowledge Graph section on this page.</li> </ol> <p></p> <p>Here are the features that you will find in this section of the Platform:</p> <ul> <li>Auto-Correction will spell correct the words in the user input to the closest matching word from the VA\u2019s Knowledge Graph domain dictionary. Knowledge Graph domain dictionary comprises the words extracted from Knowledge Graph\u2019s questions, alternate questions, nodes, and synonyms.</li> <li>Bot Synonyms will enable the XO Platform to use the Bot Synonyms in Knowledge Graph as well. Inclusion of Bot Synonyms for intent detection by the KG engine requires training. Click Proceed when prompted to enable this setting and initiate training.</li> <li>Lemmatization using Parts of Speech will enable the use of parts of speech associated with the words in the utterance to lemmatize.</li> <li>Path Coverage can be used to define the minimum percentage of terms in the user\u2019s utterance to be present in a path to qualify it for further scoring. The default setting is 50% i.e. at least half of the terms in the user utterance should match the node names and terms.</li> <li>Minimum and Definitive Level for Knowledge Graph Intent allows you to set the confidence levels for a Knowledge Graph intent. You can view and adjust the confidence level percentages for the graph in one of three ranges:<ul> <li>Definitive Range \u2013 Matches in this range (green area) are picked and any other probable matches are discarded, default set to 93-100%.</li> <li>Probable Range \u2013 Matches in this range (dark gray area) are considered for re-scoring and ranking, by default set to 80-93%</li> <li>Low Confidence Range \u2013 If no other intents have matched, low confidence matches (orange area) are presented to end-user for intent confirmation, by default set to 60-80%</li> <li>Not Matching an Intent \u2013 The light gray area represents the knowledge graph intent NLP interpreter confidence levels as too low to match the knowledge graph intent, default set to 60%.</li> </ul> </li> <li>KG Suggestions Count: Define the maximum number of KG/FAQ suggestions (up to 5) to be presented when a definite KG intent match is not available. Default set to 3.</li> <li>Proximity of Suggested Matches: Define the maximum difference (up to 50%) to be allowed between top-scoring and immediate next suggested questions to consider them as equally important. Default set to 5%. This applies to the matches in the probable range.</li> <li>Manage Long Responses when the response size exceeds channel-specific limitations. You can choose to truncate the response or display the full response with a read more link. Read More link is included at the end of the message. On selecting this link, the full response is opened as an answer in the browser. The URL to open the long response in a web browser is set by default by the Platform. But you can provide a custom URL, too.</li> <li>Search in Answer for the qualifying FAQs.</li> <li>Qualify Contextual Paths in the Knowledge Graph using the context tags available in the context. Enabling this option will ensure that the paths are shortlisted using terms or tags from the context. These tags can come from previous matched paths or intent or custom-defined tags.</li> </ul> <p>The Platform also offers some advanced configurations. Learn more.</p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#search-in-answer","title":"Search in Answer","text":"<p>This feature enables identifying FAQs by searching the user input against the answer section, instead of only matching with questions. This is a fallback mechanism only i.e. search in the answer section will be done only if no FAQs are identified from questions.</p> <p>Note</p> <p>This feature is not supported in all languages, refer here for details.</p> <p>When the Search in Answer flag is enabled, the Knowledge Graph engine considers the answer text for identifying the intents also.</p> <p>Once this option is enabled, you can specify whether to Inform the end-user that the answer is a probable answer. If selected a Standard Message to the effect is displayed, which can be customized using the Manage Response link. Learn more.</p> <p>There are three ways in which you can render the response:</p> <ol> <li>Show Complete Response: Full response is sent as the answer to the user.</li> <li>Show only the Relevant Paragraph: Only the relevant paragraph from which the question was identified is sent as the response.</li> <li>Show only the Relevant Paragraph with Read More link: Only the relevant paragraph from which the question was identified is sent as the response.</li> </ol> <p>An additional Read More link is included at the end of the message. On selecting this link, the full response is opened as an answer in the browser. The URL to open the long response in a web browser is set by default by the Platform. But you can provide a custom URL (see below for details).</p> <p></p>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#custom-url-configuration","title":"Custom URL Configuration","text":"<p>By default, the URL to open the long response in the web browser is set by the Platform. You have an option to provide a custom URL for rendering the FAQ answers.</p> <p>The Platform will call the provided URL with details of the relevant message template (template id) and other necessary information.</p> <p>The following API gives the full information of the FAQ:</p> <p>URL: <code>https://{{host-name}}/api/1.1/public/users/{{userId}}/faqs/resolvedResponse/{{respId}}</code></p> <p>Method: <code>get</code></p> <p>Headers: <code>{auth : JWT}</code></p> <p>Sample Response:</p> <pre><code>{\n\"response\": \"You can contact our Branch officials wherein you have submitted your documents.If the documents are in order, the account will be opened within 2 working days.\",\n\"primaryQuestion\": \"How to check the status of my account opening?\"\n}\n</code></pre>"},{"location":"automation/use-cases/knowledge-ai/knowledge-graph-training/#lemmatization","title":"Lemmatization","text":"<p>Lemmatization in linguistics is the process of grouping together the inflected forms of a word so they can be analyzed as a single item, identified by the word\u2019s lemma, or dictionary form. Using Parts of Speech information from the user utterance in the process of lemmatization can improve identifying a more accurate FAQ.</p> <p>Following are some examples of the phrases as recognized by the KG engine with and without using parts of speech:</p> USER UTTERANCE NOT USING POS USING POS What is my outstanding booking invoice balance     outstand <p> book     outstanding <p> booking     I am filing for a visa so that I can travel     file     filing     What happens if my luggage exceeds the maximum weight? ?     , happen <p> exceed     happens <p> exceeds"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/","title":"Manage FAQs","text":"<p>FAQs allow you to add question-answer sets to your Knowledge Graph and map them to related ontology terms. This feature improves intent recognition and increases the performance of your VA.</p> <p>Important</p> <p>There is a limit of 50k FAQs over 20k nodes to avoid performance issues.</p> <p>All features explained here are supported by the Few-Shot Knowledge Graph, except for the following:</p> <ul> <li>Adding the Root Term/Node without an ontology structure. However, you can create one to improve intent detection.</li> <li>Default terms. The only exception is when you switch from an Ontology Graph, in which case existing Default terms are stored as such until updated. Afterward, Default terms become Organizer terms and can be set as Mandatory.</li> <li>Lemmatization using Parts of Speech Search in Answer and Contextual Paths Qualification. Please see the Knowledge Graph Types Comparison Table for a detailed list of supported features.</li> <li>Path Level and Knowledge Graph Synonyms are only supported for Mandatory Terms and for Tags.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/#add-faqs","title":"Add FAQs","text":"<p>To add an FAQ, follow the below steps:</p> <ol> <li>On the left pane of the Knowledge Graph window, click the node to which you want to add questions.</li> <li> <p>Click Add Intent on the top-right. </p> </li> <li> <p>On the Intent window, under the Intent section, select FAQ.</p> </li> <li>(Optional) Enter a Display Name to represent the FAQ to the end-users.</li> <li>In the Add Question field, enter the question that describes the user\u2019s query.</li> <li>(Optional) If there are alternatives to the same question, add them in the Add Alternate FAQ field. Repeat the step for all the alternative questions you want to add.</li> <li>(Optional) Use patterns to define the FAQs. This can be done by preceding the pattern with || (two vertical bars) in the alternate question field. The Platform marks these as patterns and evaluates them accordingly. Learn More.</li> <li>(Optional) Add terms that enable the Knowledge Graph Engine to identify questions more effectively.</li> <li>(Optional) Enable or disable the Intent Status for the FAQ intents. The Knowledge Graph does not use the FAQs intents that are enabled. These intents do not participate in the intent recognition process during testing and end-user interaction.</li> <li>(Optional) Enable or disable the Term Status. The Knowledge Graph uses only the enabled terms. The disabled terms and all their FAQ intents do not participate in the intent recognition process during testing and end-user interaction.</li> <li>(Optional) Add a Reference Id. This field is used to reference any external content used as a source for this FAQ. </li> </ol> <p>As you enter these questions, pay attention to terms that you can further add to your FAQ hierarchy. Learn more.</p>"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/#manage-bot-responses","title":"Manage Bot Responses","text":"<p>For the FAQ Response, you can compose a simple or complex channel-specific reply. The editor is like any other prompt editor on the Platform, for example, messages for dialog nodes. Learn more. </p> <p>You can add channel-specific responses to questions in your Knowledge Graph. By creating varying responses with different language and formatting options, you can leverage the dynamic responses on the selected channels. </p> <p>To add a channel-specific response, select the channel from the channels list before typing the response.</p> <p>Note</p> <p>We recommend adding one response for All Channels so that it is triggered in the absence of a channel-specific response.</p> <p>Handling Lengthy Reponses and Improving Readability</p> <p>Sometimes the FAQ responses are quite lengthy or may include nice-to-have information along with the primary response. To improve the readability of such responses, you can do one of the following:</p> <ul> <li> <p>Split information into easy-to-read chunks that go as separate messages in a sequence by clicking Add Extended Response on the top-right of the Bot Response window.</p> </li> <li> <p>Select Add Alternate Response if your question can have more than one answer. Repeat the step for all the alternative responses you want to add. At runtime, the platform picks one response at random.</p> </li> </ul>"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/#add-faqs-from-an-existing-source","title":"Add FAQs from an Existing Source","text":"<p>When the Knowledge Graph you are trying to build is large and complex, it's important to have all the FAQs in one place and Import or Extract them as required. </p> <p>Adding FAQs from an existing source is the most effective method to implement in this case. The different ways to accomplish this include the following:</p> <ul> <li>Use the Knowledge Graph Generator to generate Knowledge Graph from a FAQ list and import it to your VA. See here for the steps.</li> <li>Select the Import option to import a Knowledge Graph exported from another VA. See here for more.</li> <li>Leverage an existing list of Q&amp;As from Knowledge Extraction to populate the Questions and Responses. See here for more.</li> </ul>"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/#move-faqs-between-nodes","title":"Move FAQs Between Nodes","text":"<p>You can move one or more Questions and Response sets between nodes in your Knowledge Graph, with the steps below:</p> <ol> <li>On the Knowledge Graph, click the name of the node from which you want to move the FAQ. The intents associated to the node display on the right pane.</li> <li>Identify the FAQ that you want to move, and select the checkbox next to it. You can select multiple items.</li> <li>Drag the FAQ and drop it on the relevant node. The node is highlighted and the FAQ displays on the right pane of the node.</li> </ol> <p>The demo below shows you how this works. </p>"},{"location":"automation/use-cases/knowledge-ai/manage-faqs/#edit-faqs-and-responses","title":"Edit FAQs and Responses","text":"<ol> <li>From the nodes hierarchy, select the relevant term.</li> <li>FAQs associated with the term appear on the right pane.</li> <li>Hover over the Question or Response to edit it and click the edit icon.</li> <li>Make changes to the Question or Response and click Save.</li> <li>You can delete the Question using the bin icon.  Selecting multiple intents lets you delete them in bulk. </li> </ol>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/posts/blog-support-just-landed/","title":"Blog support just landed","text":"<p>Hey there! You're looking at our new blog, built with the brand new built-in blog plugin. With this plugin, you can easily build a blog alongside your documentation or standalone.</p> <p>Proper support for blogging, as requested by many users over the past few years, was something that was desperately missing from Material for MkDocs' feature set. While everybody agreed that blogging support was a blind spot, it was not obvious whether MkDocs could be extended in a way to allow for blogging as we know it from Jekyll and friends. The built-in blog plugin proves that it is, after all, possible to build a blogging engine on top of MkDocs, in order to create a technical blog alongside your documentation, or as the main thing.</p> <p>This article explains how to build a standalone blog with Material for MkDocs. If you want to build a blog alongside your documentation, please refer to the plugin's documentation.</p>"},{"location":"blog/posts/blog-support-just-landed/#quick-start","title":"Quick start","text":""},{"location":"blog/posts/blog-support-just-landed/#setting-up-insiders","title":"Setting up Insiders","text":"<p>Before we can start bootstrapping a blog and write our first post, we need to set up Insiders, since the built-in blog plugin is currently reserved to sponsors. Without the funds this project receives through sponsorships, this plugin wouldn't exist. Three steps are necessary:</p> <ol> <li>Subscribe to a monthly sponsorship</li> <li>Create a personal access token</li> <li>Install Insiders</li> </ol>"},{"location":"blog/posts/blog-support-just-landed/#creating-a-standalone-blog","title":"Creating a standalone blog","text":"<p>After Insiders is installed, you can bootstrap a new project using the <code>mkdocs</code> executable:</p> <pre><code>mkdocs new .\n</code></pre> <p>This will create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre>"},{"location":"blog/posts/blog-support-just-landed/#configuration","title":"Configuration","text":"<p>In this article, we're going to build a standalone blog, which means that the blog lives at the root of your project. For this reason, open <code>mkdocs.yml</code>, and replace its contents with:</p> <pre><code>site_name: My Blog\ntheme:\nname: material\nfeatures:\n- navigation.sections\nplugins:\n- meta\n- blog:\nblog_dir: . # (1)!\n- search\n- tags\nnav:\n- index.md\n</code></pre> <ol> <li>This is the important part \u2013 we're hosting the blog at the root of the     project, and not in a subdirectory. For more information, see the     <code>blog_dir</code> configuration option.</li> </ol>"},{"location":"blog/posts/blog-support-just-landed/#blog-setup","title":"Blog setup","text":"<p>The blog index page lives in <code>docs/index.md</code>. This page was pre-filled by MkDocs with some content, so we're going to replace it with what we need to bootstrap the blog:</p> <pre><code># Blog\n</code></pre> <p>That's it.</p>"},{"location":"blog/posts/blog-support-just-landed/#writing-your-first-post","title":"Writing your first post","text":"<p>Now that we have set up the built-in blog plugin, we can start writing our first post. All blog posts are written with the exact same Markdown flavor as already included with Material for MkDocs. First, create a folder called <code>posts</code> with a file called <code>hello-world.md</code>:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u251c\u2500 posts/\n\u2502  \u2502  \u2514\u2500 hello-world.md # (1)!\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li>If you'd like to arrange posts differently, you're free to do so. The URLs     are built from the format specified in <code>post_url_format</code> and     the titles and dates of posts, no matter how they are organized     inside the <code>posts</code> directory.</li> </ol> <p>Then, open up <code>hello-world.md</code>, and add the following lines:</p> <pre><code>---\ndraft: true # (1)!\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque nec\nmaximus ex. Sed consequat, nulla quis malesuada dapibus, elit metus vehicula\nerat, ut egestas tellus eros at risus. In hac habitasse platea dictumst.\nPhasellus id lacus pulvinar erat consequat pretium. Morbi malesuada arcu mauris\nNam vel justo sem. Nam placerat purus non varius luctus. Integer pretium leo in\nsem rhoncus, quis gravida orci mollis. Proin id aliquam est. Vivamus in nunc ac\nmetus tristique pellentesque. Suspendisse viverra urna in accumsan aliquet.\n&lt;!-- more --&gt;\nDonec volutpat, elit ac volutpat laoreet, turpis dolor semper nibh, et dictum\nmassa ex pulvinar elit. Curabitur commodo sit amet dolor sed mattis. Etiam\ntempor odio eu nisi gravida cursus. Maecenas ante enim, fermentum sit amet\nmolestie nec, mollis ac libero. Vivamus sagittis suscipit eros ut luctus.\nNunc vehicula sagittis condimentum. Cras facilisis bibendum lorem et feugiat.\nIn auctor accumsan ligula, at consectetur erat commodo quis. Morbi ac nunc\npharetra, pellentesque risus in, consectetur urna. Nulla id enim facilisis\narcu tincidunt pulvinar. Vestibulum laoreet risus scelerisque porta congue.\nIn velit purus, dictum quis neque nec, molestie viverra risus. Nam pellentesque\ntellus id elit ultricies, vel finibus erat cursus.\n</code></pre> <ol> <li>If you mark a post as a draft, a red marker appears next to the post date      on index pages. When the site is built, drafts are not included in the      output. This behavior can be changed, e.g. for rendering drafts when      building deploy previews.</li> </ol> <p>When you spin up the live preview server, you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you:</p> <p></p> <p>However, this is just the start. The built-in blog plugin packs a lot of functionality needed in day-to-day blogging. Visit the documentation of the plugin to learn about the following topics:</p> <ul> <li>Adding an excerpt</li> <li>Adding authors</li> <li>Adding categories</li> <li>Adding tags</li> <li>Adding related links</li> <li>Linking from and to posts</li> <li>Setting the reading time</li> <li>Setting defaults</li> </ul> <p>Additionally, the built-in blog plugin has dozens of configuration options which allow for fine-tuning the output. You can configure post slugs, general behavior and much more.</p>"},{"location":"blog/posts/blog-support-just-landed/#whats-next","title":"What's next?","text":"<p>Getting basic blogging support out the door was quite a challenge \u2013 the built-in blog plugin is probably the biggest release this year and already packs a lot of functionality. However, Material for MkDocs is used in many different contexts, which is why we'd expect to iterate, as always.</p> <p>Some ideas already proposed by users:</p> <ul> <li> <p>Blog series: Authors should be able to create so called blog series and   assign posts to a blog series using simple identifiers. For each post that is   part of a series, a list with links to all other posts should be included in   the post's content.</p> </li> <li> <p>Author indexes: Besides archive and category indexes, authors should    be able to create per-author indexes, which list all posts linked to an   author. Additionally, a profile should be created for each author and linked   from posts.</p> </li> <li> <p>Social share buttons: It should be easy to share blog posts via social   media or other ways. For this reason, it should be possible to automatically   include social sharing buttons with each post.</p> </li> </ul> <p>What's still missing from the brand new built-in blog plugin? Feel free to share your ideas in the comments. Together, we can build one of the best modern engines for technical blogging!</p>"},{"location":"blog/posts/chinese-search-support/","title":"Chinese search support \u2013 \u4e2d\u6587\u641c\u7d22\u200b\u652f\u6301","text":"<p>Insiders adds experimental Chinese language support for the built-in search  plugin \u2013 a feature that has been requested for a long time given the large number of Chinese users.</p> <p>After the United States and Germany, the third-largest country of origin of Material for MkDocs users is China. For a long time, the built-in search plugin didn't allow for proper segmentation of Chinese characters, mainly due to  missing support in lunr-languages which is used for search tokenization and stemming. The latest Insiders release adds long-awaited Chinese language support for the built-in search plugin, something that has been requested by many users.</p> <p>Material for MkDocs\u7d42\u65bc\u200b\u652f\u6301\u200b\u4e2d\u6587\u200b\u4e86\uff01\u6587\u672c\u200b\u88ab\u200b\u6b63\u78ba\u200b\u5206\u5272\u200b\u4e26\u4e14\u200b\u66f4\u200b\u5bb9\u6613\u200b\u627e\u5230\u3002</p> <p>This article explains how to set up Chinese language support for the built-in search plugin in a few minutes.</p>"},{"location":"blog/posts/chinese-search-support/#configuration","title":"Configuration","text":"<p>Chinese language support for Material for MkDocs is provided by jieba, an excellent Chinese text segmentation library. If jieba is installed, the built-in search plugin automatically detects Chinese characters and runs them through the segmenter. You can install jieba with:</p> <pre><code>pip install jieba\n</code></pre> <p>The next step is only required if you specified the <code>separator</code>  configuration in <code>mkdocs.yml</code>. Text is segmented with zero-width whitespace  characters, so it renders exactly the same in the search modal. Adjust <code>mkdocs.yml</code> so that the <code>separator</code> includes the <code>\\u200b</code> character:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\u200b\\-]'\n</code></pre> <p>That's all that is necessary.</p>"},{"location":"blog/posts/chinese-search-support/#usage","title":"Usage","text":"<p>If you followed the instructions in the configuration guide, Chinese words will  now be tokenized using jieba. Try searching for  \u652f\u6301 to see how it integrates with the  built-in search plugin.</p> <p>Note that this is an experimental feature, and I, @squidfunk, am not  proficient in Chinese (yet?). If you find a bug or think something can be improved, please open an issue.</p>"},{"location":"blog/posts/excluding-content-from-search/","title":"Excluding content from search","text":"<p>The latest Insiders release brings three new simple ways to exclude dedicated parts of a document from the search index, allowing for more fine-grained control.</p> <p>Two weeks ago, Material for MkDocs Insiders shipped a brand new search plugin, yielding massive improvements in usability, but also in speed and size of the search index. Interestingly, as discussed in the previous blog article, we only scratched the surface of what's now possible. This release brings some useful features that enhance the writing experience, allowing for more fine-grained control of what pages, sections and blocks of a Markdown file should be indexed by the built-in search functionality.</p> <p>The following section discusses existing solutions for excluding pages and sections from the search index. If you immediately want to learn what's new, skip to the section just after that.</p>"},{"location":"blog/posts/excluding-content-from-search/#prior-art","title":"Prior art","text":"<p>MkDocs has a rich and thriving ecosystem of plugins, and it comes as no surprise that there's already a fantastic plugin by @chrieke to exclude specific sections of a Markdown file \u2013 the mkdocs-exclude-search plugin. It can be installed with:</p> <pre><code>pip install mkdocs-exclude-search\n</code></pre> <p>How it works: the plugin post-processes the <code>search_index.json</code> file that is generated by the built-in search plugin, giving the author the ability to exclude certain pages and sections by adding a few lines of configuration to <code>mkdocs.yml</code>. An example:</p> <pre><code>plugins:\n- search\n- exclude-search:\nexclude:\n- page.md\n- page.md#section\n- directory/*\n- /*/page.md\n</code></pre> <p>It's easy to see that the plugin follows a configuration-centric approach, which adds support for advanced filtering techniques like infix- and suffix-filtering using wildcards. While this is a very powerful idea, it comes with some downsides:</p> <ol> <li> <p>Exclusion patterns and content are not co-located: exclusion patterns     need to be defined in <code>mkdocs.yml</code>, and not as part of the respective     document or section to be excluded. This might result in stale exclusion     patterns, leading to unintended behavior:</p> <ul> <li> <p>When a headline is changed, its slug (permalink) also changes, which might   suddenly match (or unmatch) a pattern, e.g., when an author fixes a typo   in a headline.</p> </li> <li> <p>As exclusion patterns support the use of wildcards, different authors   might overwrite each other's patterns without any immediate feedback since   the plugin does only report the number of excluded documents \u2013 not what   has been excluded.1</p> </li> </ul> </li> <li> <p>Exclusion control might be too coarse: The mkdocs-exclude-search     plugin only allows for the exclusion of pages and sections. It's not     possible to exclude parts of a section, e.g., content that is irrelevant     to search but must be included as part of the documentation.</p> </li> </ol>"},{"location":"blog/posts/excluding-content-from-search/#whats-new","title":"What's new?","text":"<p>The latest Insiders release brings fine-grained control for excluding pages, sections, and blocks from the search index, implemented through front matter, as well as the Attribute Lists. Note that it doesn't replace the mkdocs-exclude-search plugin but complements it.</p>"},{"location":"blog/posts/excluding-content-from-search/#excluding-pages","title":"Excluding pages","text":"<p>An entire page can be excluded from the search index by adding a simple directive to the front matter of the respective Markdown file. The good thing is that the author now only has to check the top of the document to learn whether it is excluded or not:</p> <pre><code>---\nsearch:\nexclude: true\n---\n# Document title\n...\n</code></pre>"},{"location":"blog/posts/excluding-content-from-search/#excluding-sections","title":"Excluding sections","text":"<p>If a section should be excluded, the author can use the Attribute Lists extension to add a pragma called <code>data-search-exclude</code> at the end of a heading. The pragma is not included in the final HTML, as search pragmas are filtered by the search plugin before the page is rendered:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\n## Section 1\nThe content of this section is included\n\n## Section 2 { data-search-exclude }\nThe content of this section is excluded\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"\",\n\"title\":\"Document title\"\n},\n{\n\"location\":\"page/#section-1\",\n\"text\":\"&lt;p&gt;The content of this section is included&lt;/p&gt;\",\n\"title\":\"Section 1\"\n}\n]\n}\n</code></pre>"},{"location":"blog/posts/excluding-content-from-search/#excluding-blocks","title":"Excluding blocks","text":"<p>If even more fine-grained control is desired, the pragma can be added to any block-level element or inline-level element that is officially supported by the Attribute Lists extension:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\nThe content of this block is included\n\nThe content of this block is excluded\n{ data-search-exclude }\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"&lt;p&gt;The content of this block is included&lt;/p&gt;\",\n\"title\":\"Document title\"\n},\n]\n}\n</code></pre>"},{"location":"blog/posts/excluding-content-from-search/#conclusion","title":"Conclusion","text":"<p>The latest release brings three simple ways to control more precisely what goes into the search index and what doesn't. It complements the already very powerful mkdocs-exclude-search plugin, allowing for new methods of shaping the structure, size and content of the search index.</p> <ol> <li> <p>When the log level is set to <code>DEBUG</code>, the plugin will report exactly which pages and sections have been excluded from the search index, but MkDocs will now flood the terminal with debug output from its core and other plugins.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/posts/search-better-faster-smaller/","title":"Search: better, faster, smaller","text":"<p>This is the story of how we managed to completely rebuild client-side search, delivering a significantly better user experience while making it faster and smaller at the same time.</p> <p>The search of Material for MkDocs is by far one of its best and most-loved assets: multilingual, offline-capable, and most importantly: all client-side. It provides a solution to empower the users of your documentation to find what they're searching for instantly without the headache of managing additional servers. However, even though several iterations have been made, there's still some room for improvement, which is why we rebuilt the search plugin and integration from the ground up. This article shines some light on the internals of the new search, why it's much more powerful than the previous version, and what's about to come.</p> <p>The next section discusses the architecture and issues of the current search implementation. If you immediately want to learn what's new, skip to the section just after that.</p>"},{"location":"blog/posts/search-better-faster-smaller/#architecture","title":"Architecture","text":"<p>Material for MkDocs uses lunr together with lunr-languages to implement its client-side search capabilities. When a documentation page is loaded and JavaScript is available, the search index as generated by the built-in search plugin during the build process is requested from the server:</p> <pre><code>const index$ = document.forms.namedItem(\"search\")\n? __search?.index || requestJSON&lt;SearchIndex&gt;(\nnew URL(\"search/search_index.json\", config.base)\n)\n: NEVER\n</code></pre>"},{"location":"blog/posts/search-better-faster-smaller/#search-index","title":"Search index","text":"<p>The search index includes a stripped-down version of all pages. Let's take a look at an example to understand precisely what the search index contains from the original Markdown file:</p> Expand to inspect example <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Example\n## Text\nIt's very easy to make some words **bold** and other words *italic*\nwith Markdown. You can even add [links](#), or even `code`:\n\n```\nif (isAwesome) {\n  return true\n}\n```\n## Lists\nSometimes you want numbered lists:\n\n1. One\n2. Two\n3. Three\n\nSometimes you want bullet points:\n\n* Start a line with a star\n* Profit!\n</code></pre> <pre><code>{\n\"config\": {\n\"indexing\": \"full\",\n\"lang\": [\n\"en\"\n],\n\"min_search_length\": 3,\n\"prebuild_index\": false,\n\"separator\": \"[\\\\s\\\\-]+\"\n},\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"Example Text It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true } Lists Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n},\n{\n\"location\": \"page/#example\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true }\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n}\n]\n}\n</code></pre> <p>If we inspect the search index, we immediately see several problems:</p> <ol> <li> <p>All content is included twice: the search index contains one entry       with the entire contents of the page, and one entry for each section of       the page, i.e., each block preceded by a headline or subheadline. This       significantly contributes to the size of the search index.</p> </li> <li> <p>All structure is lost: when the search index is built, all structural       information like HTML tags and attributes are stripped from the content.       While this approach works well for paragraphs and inline formatting, it       might be problematic for lists and code blocks. An excerpt:</p> <pre><code>\u2026 links , or even code : if (isAwesome) { \u2026 } Lists Sometimes you want \u2026\n</code></pre> <ul> <li> <p>Context: for an untrained eye, the result can look like gibberish, as   it's not immediately apparent what classifies as text and what as code.   Furthermore, it's not clear that <code>Lists</code> is a headline as it's merged   with the code block before and the paragraph after it.</p> </li> <li> <p>Punctuation: inline elements like links that are immediately followed   by punctuation are separated by whitespace (see <code>,</code> and <code>:</code> in the   excerpt). This is because all extracted text is joined with a whitespace   character during the construction of the search index.</p> </li> </ul> </li> </ol> <p>It's not difficult to see that it can be quite challenging to implement a good search experience for theme authors, which is why Material for MkDocs (up to now) did some monkey patching to be able to render slightly more meaningful search previews.</p>"},{"location":"blog/posts/search-better-faster-smaller/#search-worker","title":"Search worker","text":"<p>The actual search functionality is implemented as part of a web worker1, which creates and manages the lunr search index. When search is initialized, the following steps are taken:</p> <ol> <li> <p>Linking sections with pages: The search index is parsed, and each     section is linked to its parent page. The parent page itself is not     indexed, as it would lead to duplicate results, so only the sections     remain. Linking is necessary, as search results are grouped by page.</p> </li> <li> <p>Tokenization: The <code>title</code> and <code>text</code> values of each section are split     into tokens by using the <code>separator</code> as configured in     <code>mkdocs.yml</code>. Tokenization itself is carried out by     lunr's default tokenizer, which doesn't allow for     lookahead or separators spanning multiple characters.</p> <p>Why is this important and a big deal? We will see later how much more we can achieve with a tokenizer that is capable of separating strings with lookahead.</p> </li> <li> <p>Indexing: As a final step, each section is indexed. When querying the     index, if a search query includes one of the tokens as returned by step 2.,     the section is considered to be part of the search result and passed to the     main thread.</p> </li> </ol> <p>Now, that's basically how the search worker operates. Sure, there's a little more magic involved, e.g., search results are post-processed and rescored to account for some shortcomings of lunr, but in general, this is how data gets into and out of the index.</p>"},{"location":"blog/posts/search-better-faster-smaller/#search-previews","title":"Search previews","text":"<p>Users should be able to quickly scan and evaluate the relevance of a search result in the given context, which is why a concise summary with highlighted occurrences of the search terms found is an essential part of a great search experience.</p> <p>This is where the current search preview generation falls short, as some of the search previews appear not to include any occurrence of any of the search terms. This was due to the fact that search previews were truncated after a maximum of 320 characters, as can be seen here:</p> <p></p> <p>The first two results look like they're not relevant, as they don't seem to include the query string the user just searched for. Yet, they are.</p> <p>A better solution to this problem has been on the roadmap for a very, very long time, but in order to solve this once and for all, several factors need to be carefully considered:</p> <ol> <li> <p>Word boundaries: some themes2 for static site generators generate    search previews by expanding the text left and right next to an occurrence,    stopping at a whitespace character when enough words have been consumed. A    preview might look like this:</p> <pre><code>\u2026 channels, e.g., or which can be configured via mkdocs.yml \u2026\n</code></pre> <p>While this may work for languages that use whitespace as a separator between words, it breaks down for languages like Japanese or Chinese3, as they have non-whitespace word boundaries and use dedicated segmenters to split strings into tokens.</p> </li> <li> <p>Context-awareness: Although whitespace doesn't work for all languages,     one could argue that it could be a good enough solution. Unfortunately, this     is not necessarily true for code blocks, as the removal of whitespace might     change meaning in some languages.</p> </li> <li> <p>Structure: Preserving structural information is not a must, but     apparently beneficial to build more meaningful search previews which allow     for a quick evaluation of relevance. If a word occurrence is part of a code     block, it should be rendered as a code block.</p> </li> </ol>"},{"location":"blog/posts/search-better-faster-smaller/#whats-new","title":"What's new?","text":"<p>After we built a solid understanding of the problem space and before we dive into the internals of our new search implementation to see which of the problems it already solves, a quick overview of what features and improvements it brings:</p> <ul> <li>Better: support for rich search previews, preserving the structural   information of code blocks, inline code, and lists, so they are rendered   as-is, as well as lookahead tokenization, more accurate highlighting, and    improved stability of typeahead. Also, a slightly better UX.</li> <li>Faster and smaller: significant decrease in search index size of up   to 48% due to improved extraction and construction techniques, resulting in a   search experience that is up to 95% faster, which is particularly helpful for   large documentation projects.</li> </ul>"},{"location":"blog/posts/search-better-faster-smaller/#rich-search-previews","title":"Rich search previews","text":"<p>As we rebuilt the search plugin from scratch, we reworked the construction of the search index to preserve the structural information of code blocks, inline code, as well as unordered and ordered lists. Using the example from the search index section, here's how it looks:</p> NowBefore <p></p> <p></p> <p>Now, code blocks are first-class citizens of search previews, and even inline code formatting is preserved. Let's take a look at the new structure of the search index to understand why:</p> Expand to inspect search index NowBefore <pre><code>{\n...\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"&lt;p&gt;It's very easy to make some words bold and other words italic with Markdown. You can even add links, or even &lt;code&gt;code&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;if (isAwesome){\\n  return true\\n}\\n&lt;/code&gt;&lt;/pre&gt;\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"&lt;p&gt;Sometimes you want numbered lists:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;One&lt;/li&gt; &lt;li&gt;Two&lt;/li&gt; &lt;li&gt;Three&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Sometimes you want bullet points:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Start a line with a star&lt;/li&gt; &lt;li&gt;Profit!&lt;/li&gt; &lt;/ul&gt;\"\n}\n]\n}\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"Example Text It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true } Lists Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n},\n{\n\"location\": \"page/#example\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true }\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n}\n]\n}\n</code></pre> <p>If we inspect the search index again, we can see how the situation improved:</p> <ol> <li> <p>Content is included only once: the search index does not include the     content of the page twice, as only the sections of a page are part of the     search index. This leads to a significant reduction in size, fewer bytes to     transfer, and a smaller search index.</p> </li> <li> <p>Some structure is preserved: each section of the search index includes     a small subset of HTML to provide the necessary structure to allow for more     sophisticated search previews. Revisiting our example from before, let's     look at an excerpt:</p> NowBefore <pre><code>\u2026 links, or even &lt;code&gt;code&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;if (isAwesome){ \u2026 }\\n&lt;/code&gt;&lt;/pre&gt;\n</code></pre> <pre><code>\u2026 links , or even code : if (isAwesome) { \u2026 }\n</code></pre> <p>The punctuation issue is gone, as no additional whitespace is inserted, and the preserved markup yields additional context to make scanning search results more effective.</p> </li> </ol> <p>On to the next step in the process: tokenization.</p>"},{"location":"blog/posts/search-better-faster-smaller/#tokenizer-lookahead","title":"Tokenizer lookahead","text":"<p>The default tokenizer of lunr uses a regular expression to split a given string by matching each character against the <code>separator</code> as defined in <code>mkdocs.yml</code>. This doesn't allow for more complex separators based on lookahead or multiple characters.</p> <p>Fortunately, our new search implementation provides an advanced tokenizer that doesn't have these shortcomings and supports more complex regular expressions. As a result, Material for MkDocs just changed its own separator configuration to the following value:</p> <pre><code>[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&amp;[lg]t;\n</code></pre> <p>While the first part up to the first <code>|</code> contains a list of single control characters at which the string should be split, the following three sections explain the remainder of the regular expression.4</p>"},{"location":"blog/posts/search-better-faster-smaller/#case-changes","title":"Case changes","text":"<p>Many programming languages use <code>PascalCase</code> or <code>camelCase</code> naming conventions. When a user searches for the term <code>case</code>, it's quite natural to expect for <code>PascalCase</code> and <code>camelCase</code> to show up. By adding the following match group to the separator, this can now be achieved with ease:</p> <pre><code>(?!\\b)(?=[A-Z][a-z])\n</code></pre> <p>This regular expression is a combination of a negative lookahead (<code>\\b</code>, i.e., not a word boundary) and a positive lookahead (<code>[A-Z][a-z]</code>, i.e., an uppercase character followed by a lowercase character), and has the following behavior:</p> <ul> <li><code>PascalCase</code> <code>Pascal</code>, <code>Case</code></li> <li><code>camelCase</code> <code>camel</code>, <code>Case</code></li> <li><code>UPPERCASE</code> <code>UPPERCASE</code></li> </ul> <p>Searching for  searchHighlight now brings up the section discussing the <code>search.highlight</code> feature flag, which also demonstrates that this now even works properly for search queries.5</p>"},{"location":"blog/posts/search-better-faster-smaller/#version-numbers","title":"Version numbers","text":"<p>Indexing version numbers is another problem that can be solved with a small lookahead. Usually, <code>.</code> should be considered a separator to split words like <code>search.highlight</code>. However, splitting version numbers at <code>.</code> will make them undiscoverable. Thus, the following expression:</p> <pre><code>\\.(?!\\d)\n</code></pre> <p>This regular expression matches a <code>.</code> only if not immediately followed by a digit <code>\\d</code>, which leaves version numbers discoverable. Searching for  7.2.6 brings up the 7.2.6 release notes.</p>"},{"location":"blog/posts/search-better-faster-smaller/#htmlxml-tags","title":"HTML/XML tags","text":"<p>If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the <code>&lt;</code> and <code>&gt;</code> control characters are encoded in code blocks as <code>&amp;lt;</code> and <code>&amp;gt;</code>. Now, adding the following expression to the separator allows for just that:</p> <pre><code>&amp;[lg]t;\n</code></pre> <p>Searching for  custom search worker script  brings up the section on custom search and matches the <code>script</code> tag among the other search terms discovered.</p> <p>We've only just begun to scratch the surface of the new possibilities tokenizer lookahead brings. If you found other useful expressions, you're invited to share them in the comment section.</p>"},{"location":"blog/posts/search-better-faster-smaller/#accurate-highlighting","title":"Accurate highlighting","text":"<p>Highlighting is the last step in the process of search and involves the highlighting of all search term occurrences in a given search result. For a long time, highlighting was implemented through dynamically generated regular expressions.6</p> <p>This approach has some problems with non-whitespace languages like Japanese or Chinese3 since it only works if the highlighted term is at a word boundary. However, Asian languages are tokenized using a dedicated segmenter, which cannot be modeled with regular expressions.</p> <p>Now, as a direct result of the new tokenization approach, our new search implementation uses token positions for highlighting, making it exactly as powerful as tokenization:</p> <ol> <li> <p>Word boundaries: as the new highlighter uses token positions, word     boundaries are equal to token boundaries. This means that more complex cases     of tokenization (e.g., case changes, version numbers, HTML/XML tags),     are now all highlighted accurately.</p> </li> <li> <p>Context-awareness: as the new search index preserves some of the     structural information of the original document, the content of a section     is now divided into separate content blocks \u2013 paragraphs, code blocks, and     lists.</p> <p>Now, only the content blocks that actually contain occurrences of one of the search terms are considered for inclusion into the search preview. If a term only occurs in a code block, it's the code block that gets rendered, see, for example, the results of   twitter.</p> </li> </ol>"},{"location":"blog/posts/search-better-faster-smaller/#benchmarks","title":"Benchmarks","text":"<p>We conducted two benchmarks \u2013 one with the documentation of Material for MkDocs itself, and one with a very massive corpus of Markdown files with more than 800,000 words \u2013 a size most documentation projects will likely never reach:</p> Before Now Relative Material for MkDocs Index size 573 kB 335 kB \u201342% Index size (<code>gzip</code>) 105 kB 78 kB \u201327% Indexing time7 265 ms 177 ms \u201334% KJV Markdown8 Index size 8.2 MB 4.4 MB \u201347% Index size (<code>gzip</code>) 2.3 MB 1.2 MB \u201348% Indexing time 2,700 ms 1,390 ms \u201348% <p>Benchmark results</p> <p>The results show that indexing time, which is the time that it takes to set up the search when the page is loaded, has dropped by up to 48%, which means the new search is up to 95% faster. This is a significant improvement, particularly relevant for large documentation projects.</p> <p>While 1,3s still may sound like a long time, using the new client-side search together with instant loading only creates the search index on the initial page load. When navigating, the search index is preserved across pages, so the cost does only have to be paid once.</p>"},{"location":"blog/posts/search-better-faster-smaller/#user-interface","title":"User interface","text":"<p>Additionally, some small improvements have been made, most prominently the more results on this page button, which now sticks to the top of the search result list when open. This enables the user to jump out of the list more quickly.</p>"},{"location":"blog/posts/search-better-faster-smaller/#whats-next","title":"What's next?","text":"<p>Our new search implementation is a big improvement to Material for MkDocs. It solves some long-standing issues which needed to be tackled for years. Yet, it's only the start of a search experience that is going to get better and better. Next up:</p> <ul> <li> <p>Context-aware search summarization: currently, the first two matching   content blocks are rendered as a search preview. With the new tokenization   technique, we laid the groundwork for more sophisticated shortening and   summarization methods, which we're tackling next.</p> </li> <li> <p>User interface improvements: as we now gained full control over the   search plugin, we can now add meaningful metadata to provide more context and   a better experience. We'll explore some of those paths in the future.</p> </li> </ul> <p>If you've made it this far, thank you for your time and interest in Material for MkDocs! This is the first blog article that I decided to write after a short Twitter survey made me to. You're invited to leave a comment to share your experiences with the new search implementation.</p> <ol> <li> <p>Prior to  5.0.0, search was carried out in the main thread  which locked up the browser, rendering it unusable. This problem was first reported in #904 and, after some back and forth, fixed and released in  5.0.0.\u00a0\u21a9</p> </li> <li> <p>At the time of writing, Just the Docs and Docusaurus use this method for generating search previews. Note that the latter also integrates with Algolia, which is a fully managed server-based solution.\u00a0\u21a9</p> </li> <li> <p>China and Japan are both within the top 5 countries of origin of users of Material for MkDocs.\u00a0\u21a9\u21a9</p> </li> <li> <p>As a fun fact: the <code>separator</code> default value of the search plugin being <code>[\\s\\-]+</code> always has been kind of irritating, as it suggests that multiple characters can be considered being a separator. However, the <code>+</code> is completely irrelevant, as regular expression groups involving multiple characters were never supported by lunr's default tokenizer.\u00a0\u21a9</p> </li> <li> <p>Previously, the search query was not correctly tokenized due to the way lunr treats wildcards, as it disables the pipeline for search terms that  contain wildcards. In order to provide a good typeahead experience, Material for MkDocs adds wildcards to the end of each search term not explicitly preceded with <code>+</code> or <code>-</code>, effectively disabling tokenization.\u00a0\u21a9</p> </li> <li> <p>Using the separator as defined in <code>mkdocs.yml</code>, a regular expression was constructed that was trying to mimic the tokenizer. As an example, the search query <code>search highlight</code> was transformed into the rather cumbersome regular expression <code>(^|&lt;separator&gt;)(search|highlight)</code>, which only matches at word boundaries.\u00a0\u21a9</p> </li> <li> <p>Smallest value of ten distinct runs.\u00a0\u21a9</p> </li> <li> <p>We agnostically use KJV Markdown as a tool for testing to learn how Material for MkDocs behaves on large corpora, as it's a very large set of Markdown files with over 800k words.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/posts/the-past-present-and-future/","title":"The past, present and future","text":"<p>2021 was a fantastic year for this project as we shipped many new awesome features, saw significant user growth and leveraged GitHub Sponsors to make the project sustainable.</p> <p>Today, together, MkDocs and Material for MkDocs are among the most popular options when it comes to choosing a static site generator and theme for your technical documentation project. Material for MkDocs ensures that your content is always perfectly presented to your audience, regardless of screen resolution or device capabilities. It has evolved to a framework for technical writing, offering many features, some of which are yet to be found in other static site generators. However, we're far from the end, as 2022 is going to bring some interesting new capabilities.</p> <p>This article showcases all features that were added in 2021 and gives an outlook on what's going to drop in 2022. Additionally, it provides some context on the history of the project.</p>"},{"location":"blog/posts/the-past-present-and-future/#a-little-history","title":"A little history","text":"<p>In 2015, albeit 10 years in the industry, I was still quite new in Open Source. I wanted to release my latest Open Source project protobluff, a zero-copy Protocol Buffers implementation for C, which I've created as part of my former startup. As the project has a significant degree of complexity, I quickly realized that I was in need of good user documentation.</p> <p>After evaluating static site generators in general and Hugo, Sphinx and MkDocs in particular, I quickly decided that MkDocs seemed a good choice, as it was specifically aimed at technical project documentation and easy to use. Unfortunately, all of the available themes looked dated and given that I'm a very visual person, I just couldn't convince myself to call it a day.</p> <p>I had to build a theme.</p> <p>Months later, in February 2016, I released the first version of Material for MkDocs (and with it, protobluff, the project I wanted to release in the first place), and it looked like this:</p> <p></p> <p>It was already fully responsive and overall, well, quite okayish, but barely customizable, as only the logo could be changed. Beyond that, it had no options: No color or navigation options, no instant loading, etc. The search was very rudimentary and only supported section titles:</p> <p></p> <p>It's important to know that at this point in time I've built Material for MkDocs for protobluff, the project I was really caring about. Almost 6 years later, nobody knows protobluff, but this little side project has taken off. If back in those days, you would've told me big organizations like AWS, Microsoft and CERN, as well as extremely popular Open Source projects like FastAPI and Kubernetes will be using this project in the future \u2013 I would've declared you insane.</p> <p>I still find the success of this project quite surprising, as I thought that themes exist in abundance and are very much a solved problem. There's no glory in themes, no stars to earn (remember that I was new in Open Source, so this was the metric I was optimizing for), as there are thousands and thousands of options. However, as the years progressed, I learned that execution matters: although Material for MkDocs solves a problem for which thousands of solutions exist, it excels in a specific niche, and that niche is to be known as technical project documentation.</p> <p>Today, this project is not only popular but funded by almost 300 individuals and organizations, resulting in a yearly budget of more than $50,000. This allows me to set aside enough time for the development of new features, bug fixing, stability improvement, issue triage and general support and still feels like a dream to me, as there are many failed stories of Open Source funding and people telling you: don't do Open Source, you'll be working for free.</p> <p>Making Open Source sustainable is, after all, possible in 2021.</p>"},{"location":"blog/posts/the-past-present-and-future/#2021-in-numbers","title":"2021 in numbers","text":"<p>2021 was an exciting year, as the project has seen significant growth.</p> <p>166k people visited the official documentation in 2021, totalling in 1,6m page views which is an increase of 83% when compared to 2020. The average visitor spends 1,5min on the site. While mobile phones make up 12% of visits, tablets only account for 0.6%. Visitors come from as many as 213 countries, which covers almost the whole world.</p>"},{"location":"blog/posts/the-past-present-and-future/#features","title":"Features","text":"<p>It's absolutely mind-blowing that 38 new features were added to Material for MkDocs throughout 2021 \u2013 that's a new feature every 9,6 days \u2013 which was only possible because of the constantly improving funding situation. Following is a list of all features shipped in alphabetical order, some of which are still exclusively available to sponsors as part of Insiders:</p> <ul> <li>Admonition inline blocks</li> <li>Advanced search highlighting</li> <li>Anchor tracking</li> <li>Back-to-top button</li> <li>Boosting pages in search</li> <li>Brand new search plugin</li> <li>Code annotations</li> <li>Code annotations: anchor links</li> <li>Code annotations: strip comments</li> <li>Code block titles</li> <li>Code block line anchors</li> <li>Color palette toggle</li> <li>Content tabs: improved support</li> <li>Content tabs: auto-linking</li> <li>Content tabs: animated indicator</li> <li>Cookie consent</li> <li>Custom admonition icons</li> <li>Dark mode support for images</li> <li>Dismissable announcement bar</li> <li>Excluding content from search</li> <li>Latest release tag</li> <li>Mermaid.js integration</li> <li>Navigation icons</li> <li>Remove generator notice</li> <li>Rich search previews</li> <li>Stay on page when switching versions</li> <li>Search highlighting</li> <li>Search sharing</li> <li>Search suggestions</li> <li>Section index pages</li> <li>Site language selection</li> <li>Social cards</li> <li>Sticky navigation tabs</li> <li>Tags with search integration</li> <li>Tokenizer with lookahead</li> <li>Versioning</li> <li>Version warning</li> <li>Was this page helpful?</li> </ul> <p>Additionally, a lot of bugs were fixed in the 1,000 commits that were pushed to the repository this year. The changelog includes a list of all fixes. Furthermore, a large amount of time was invested into refactoring the code base to keep it in good shape. While the <code>mkdocs-material</code> package was released 55 times, <code>mkdocs-material-insiders</code> was shipped 72 times.</p>"},{"location":"blog/posts/the-past-present-and-future/#funding","title":"Funding","text":"<p>In 2021, monthly funding increased from $1,050 in the beginning of January to more than $4,300 (Dec 27, 2021), totaling in a yearly budget of more than $50,000. Compared to last year, revenue from funding has increased by 617% \u2013 which is absolutely unbelievable:</p> <p></p> <p>I'm solely providing these numbers to fulfill the transparency pledge I'm giving to my awesome sponsors, and to show that it's possible to make existing Open Source projects sustainable by following a well-designed release strategy.</p> <p>You can learn about the strategy in the Insiders guide.</p>"},{"location":"blog/posts/the-past-present-and-future/#2022","title":"2022","text":"<p>Standing at the verge of the next year, it's safe to say that the project will continue to prosper and evolve, yielding many awesome features that will make technical writing more comfortable and flexible. Here's an excerpt of the features that will see the light of day in 2022:</p> <ul> <li> <p>Instant previews: instant previews will render a specific page section   inside a tooltip when hovering an internal link, which will allow to implement   things like glossaries. Further support for improving glossary functionality   will also be investigated.</p> </li> <li> <p>Text annotations: as a logical progression of code annotations which   were added in 2021, authors will be able to add annotations to plain text,   yielding excellent opportunities for side content. Of course, text annotations   will be as easy to use as code annotations.</p> </li> <li> <p>Navigation pruning: to optimize large documentation projects, Material   for MkDocs will introduce a new feature flag called <code>navigation.prune</code> that   will lead to significantly smaller HTML files for documentation projects with   huge navigation hierarchies.</p> </li> <li> <p>Navigation status badge: as an addition to the recently added   navigation icon support, a status will be attributable to   each page, allowing to mark a page in the navigation tree with an icon as    new or  deprecated.   Custom status types will also be supported.</p> </li> <li> <p>Card grids: as a further component in the toolkit of technical writing,   card grids will allow arranging content in grids, which is especially   useful for overview pages. They will allow to arrange arbitrary content,   including code blocks, admonitions, etc.</p> </li> <li> <p>Blog support: blogging support is still under investigation and expected   to be one of the major additions in 2022. Blogging will perfectly integrate   with writing documentation, allowing to use all components available in   Material for MkDocs.</p> </li> </ul> <p>This list is incomplete. Additionally, many new smaller features will be added next year, just as in 2021. You can follow @squidfunk on Twitter to stay updated.</p> <p>Happy new year! </p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#material-for-mkdocs","title":"Material for MkDocs","text":""},{"location":"changelog/#9.1.20","title":"9.1.21 July 27, 2023","text":"<ul> <li>Fixed MkDocs 1.4 compat issue in social plugin (9.1.20 regression)</li> </ul>"},{"location":"changelog/#9.1.20","title":"9.1.20 July 27, 2023","text":"<ul> <li>Updated Sanskrit translations</li> <li>Fixed deprecation warnings for social plugin</li> </ul>"},{"location":"changelog/#9.1.19","title":"9.1.19 July 18, 2023","text":"<ul> <li>Added support for MkDocs 1.5+</li> <li>Fixed #5699: Improve error reporting in social plugin</li> </ul>"},{"location":"changelog/#9.1.18","title":"9.1.18 July 3, 2023","text":"<ul> <li>Updated Danish translations</li> <li>Added support for installing user requirements in Docker image</li> <li>Fixed #5655: Search separator with lookbehind breaks highlighting</li> </ul>"},{"location":"changelog/#9.1.17","title":"9.1.17 June 23, 2023","text":"<ul> <li>Fixed #5633: Code annotations with nested lists incorrectly mounted</li> <li>Fixed #5628: Regression in new social plugin configuration scheme</li> </ul>"},{"location":"changelog/#9.1.16","title":"9.1.16 June 15, 2023","text":"<ul> <li>Updated Indonesian translations</li> <li>Ensure scroll bar follows color scheme of operating system</li> </ul>"},{"location":"changelog/#9.1.15","title":"9.1.15 May 29, 2023","text":"<ul> <li>Fixed #5566: Indicate color scheme to operating system</li> <li>Fixed #5565: Update <code>Dockerfile</code> to latest version of base image</li> <li>Fixed #5554: Add additional version tags (<code>9</code>, <code>9.1</code>) to Docker image</li> <li>Fixed #5536: Strip tags of ARIA labels in table of contents</li> </ul>"},{"location":"changelog/#9.1.14","title":"9.1.14 May 20, 2023","text":"<ul> <li>Updated Armenian and Greek translations</li> </ul>"},{"location":"changelog/#9.1.13","title":"9.1.13 May 16, 2023","text":"<ul> <li>Fixed #5517: Social plugin crashes for some fonts (e.g. Open Sans)</li> </ul>"},{"location":"changelog/#9.1.12","title":"9.1.12 May 12, 2023","text":"<ul> <li>Updated Bengali (Bangla) translations</li> <li>Fixed #5503: Docker image publish errors on uppercase characters</li> <li>Fixed #5407: Auto-pause media when in hidden content tabs</li> </ul>"},{"location":"changelog/#9.1.11","title":"9.1.11 May 8, 2023","text":"<ul> <li>Fixed #5487: Social plugin crashes without options (9.1.10 regression)</li> </ul>"},{"location":"changelog/#9.1.10","title":"9.1.10 May 8, 2023","text":"<ul> <li>Added <code>cards_layout_options</code> setting for social cards</li> <li>Deprecated <code>cards_color</code> and <code>cards_font</code> setting for social cards</li> </ul>"},{"location":"changelog/#9.1.9","title":"9.1.9 May 2, 2023","text":"<ul> <li>Added Telugu, Kannada and Sanskrit translations</li> <li>Fixed #5428: Fixed margins for light/dark mode images in figures</li> <li>Fixed #5420: Social plugin crashing for some specific Google Fonts</li> <li>Fixed #5160: Instant loading makes code annotations jump (9.1.1 regression)</li> <li>Fixed #4920: Social plugin not loading logo from custom icon set</li> <li>Fixed social plugin crashing when only code font is specified</li> </ul>"},{"location":"changelog/#9.1.8","title":"9.1.8 April 24, 2023","text":"<ul> <li>Fixed #5417: Theme breaks when <code>palette</code> is not defined (9.1.7 regression)</li> </ul>"},{"location":"changelog/#9.1.7","title":"9.1.7 April 22, 2023","text":"<ul> <li>Updated Persian (Farsi) and Turkish translations</li> <li>Fixed #5401: Added missing flag to disable built-in tags plugin</li> <li>Fixed #5206: Ensure defaults are set for primary and accent colors</li> <li>Fixed unnecessary inclusion of palette CSS when unused</li> </ul>"},{"location":"changelog/#9.1.6","title":"9.1.6 April 7, 2023","text":"<ul> <li>Updated Persian (Farsi) translations</li> <li>Fixed #5300: Boxes in Mermaid sequence diagrams not color-abiding</li> </ul>"},{"location":"changelog/#9.1.5","title":"9.1.5 March 31, 2023","text":"<ul> <li>Updated Lithuanian and Japanese translations</li> <li>Updated Mermaid.js to version 9.4.3</li> <li>Fixed #5290: Footer previous/next labels cut-off for short page titles</li> </ul>"},{"location":"changelog/#9.1.4","title":"9.1.4 March 24, 2023","text":"<ul> <li>Fixed #5239: Instant loading breaks anchors in details (9.1.1 regression)</li> <li>Fixed #5211: Anchor following not working for Chinese (9.1.2 regression)</li> </ul>"},{"location":"changelog/#9.1.3","title":"9.1.3 March 14, 2023","text":"<ul> <li>Added Kurdish (Soran\u00ee) translations</li> <li>Updated Norwegian (Bokm\u00e5l), Portuguese and Romanian translations</li> <li>Improved compatibility with <code>mkdocs-jupyter</code> plugin</li> <li>Fixed #5198: Built-in search plugin not filtering <code>script</code> and <code>style</code> tags</li> <li>Fixed #5176: Back-to-top + instant loading not working (9.1.1 regression)</li> </ul>"},{"location":"changelog/#9.1.2","title":"9.1.2 March 9, 2023","text":"<ul> <li>Updated Icelandic, Korean and Swedish translations</li> <li>Fixed #5168: Mermaid text boxes overflow (9.0.13 regression)</li> <li>Fixed #5155: Table of contents not highlighting percent-encoded URLs</li> </ul>"},{"location":"changelog/#9.1.1","title":"9.1.1 March 5, 2023","text":"<ul> <li>Updated Czech and Thai translations</li> <li>Improved instant loading (scroll restoration, slow connections)</li> <li>Fixed #5023: Instant loading not allowing to go back to initial page</li> <li>Fixed #3797: Instant loading does not work with section anchors in Safari</li> </ul>"},{"location":"changelog/#9.1.0","title":"9.1.0 March 2, 2023","text":"<ul> <li>Docker image now available for <code>amd64</code>, <code>arm64</code> and <code>arm/v7</code></li> <li>Updated Chinese (Taiwanese) translations</li> <li>Generalized tag identifier implementation</li> <li>Fixed flickering of header shadow on load</li> <li>Fixed occasional flickering of announcement bar</li> </ul>"},{"location":"changelog/#9.0.15","title":"9.0.15 February 26, 2023","text":"<ul> <li>Updated Chinese (Traditional) translations</li> <li>Updated Hebrew translations</li> </ul>"},{"location":"changelog/#9.0.14","title":"9.0.14 February 23, 2023","text":"<ul> <li>Fixed #5072: Rendering bug on navigation expand button in Firefox</li> </ul>"},{"location":"changelog/#9.0.13","title":"9.0.13 February 18, 2023","text":"<ul> <li>Updated Uzbek translations</li> <li>Switched back to pre-9.0.0 headline detection in <code>content</code> partial</li> <li>Fixed #5062: Version warning not readable when using slate scheme</li> <li>Fixed #5061: Improved discernibility of table row hover color</li> <li>Fixed #5034: Sequence actors in Mermaid diagrams not color-abiding</li> <li>Fixed #4919: Allow to hide version warning in multiple versions</li> </ul>"},{"location":"changelog/#9.0.12","title":"9.0.12 February 9, 2023","text":"<ul> <li>Updated Catalan translations</li> <li>Fixed #4975: Mermaid entity relationship rendering diagrams bug</li> <li>Fixed #4924: Header title not reset when using instant loading</li> </ul>"},{"location":"changelog/#9.0.11","title":"9.0.11 February 3, 2023","text":"<ul> <li>Added Mastodon verification for social links (<code>rel=me</code>)</li> <li>Updated Italian translations</li> </ul>"},{"location":"changelog/#9.0.10","title":"9.0.10 February 2, 2023","text":"<ul> <li>Updated Arabic translations</li> <li>Updated Korean translations</li> <li>Updated Hungarian translations</li> <li>Updated Russian translations</li> <li>Fixed #4977: Improved accessibility for content tabs</li> <li>Fixed #4960: Sometimes anchor following doesn't bring last item into view</li> </ul>"},{"location":"changelog/#9.0.9","title":"9.0.9 January 30, 2023","text":"<ul> <li>Updated Bulgarian translations</li> <li>Updated Chinese (Simplified) translations</li> <li>Updated Dutch translations</li> <li>Updated Hindi translations</li> <li>Updated Japanese translations</li> <li>Updated Polish translations</li> </ul>"},{"location":"changelog/#9.0.8","title":"9.0.8 January 29, 2023","text":"<ul> <li>Updated Croatian translations</li> <li>Updated French translations</li> <li>Updated Hungarian translations</li> <li>Updated Portuguese (Brasilian) translations</li> <li>Updated Spanish translations</li> <li>Updated Ukrainian translations</li> <li>Updated Urdu translations</li> <li>Updated Vietnamese translations</li> </ul>"},{"location":"changelog/#9.0.7","title":"9.0.7 January 28, 2023","text":"<ul> <li>Improved accessibility of sidebar navigation</li> <li>Moved all translations into community edition</li> <li>Updated Polish and Portuguese (Brasilian) translations</li> <li>Fixed info plugin terminating on subsequent reload when serving</li> <li>Fixed #4910: Sidebar navigation labels have invalid ARIA roles</li> <li>Fixed #4884: Search query terms can't be separated by colons</li> </ul>"},{"location":"changelog/#9.0.6","title":"9.0.6 January 19, 2023","text":"<ul> <li>Fixed #4883: Automatically disable info plugin when serving</li> <li>Fixed #4885: Search plugin crashes in some exotic cases (9.0.3 regression)</li> </ul>"},{"location":"changelog/#9.0.5","title":"9.0.5 January 14, 2023","text":"<ul> <li>Fixed #4842: Improved accessibility of search result list</li> </ul>"},{"location":"changelog/#9.0.4","title":"9.0.4 January 12, 2023","text":"<ul> <li>Fixed #4823: Improved contrast ratio in footer (9.0.2 regression)</li> <li>Fixed #4832: Set navigation items back to black (9.0.3 regression)</li> <li>Fixed #4843: Emojis broken due to maxcdn.com shutting down</li> <li>Upgraded Python Markdown Extensions to 9.9.1</li> </ul>"},{"location":"changelog/#9.0.3","title":"9.0.3 January 8, 2023","text":"<ul> <li>Improved discernibility of section index pages in navigation</li> <li>Improved collapsing of adjacent whitespace in search plugin</li> <li>Updated Indonesian translations</li> <li>Fixed view source of this page button when edit URL points to blob</li> <li>Fixed #4829: Search overlay does not close for active anchor result</li> <li>Fixed #4824: Search plugin crashes for <code>h[1-6]</code> contained in other elements</li> <li>Fixed #4804: Nested navigation items not expandable with keyboard</li> <li>Fixed #4689: anchor tracking not working for anchors in tables</li> <li>Upgraded to Mermaid 9.3.0</li> </ul>"},{"location":"changelog/#9.0.2","title":"9.0.2 January 4, 2023","text":"<ul> <li>Fixed #4823: Improved contrast ratio in footer to meet WCAG guidelines</li> <li>Fixed #4819: Social plugin crashes when card generation is disabled</li> <li>Fixed #4817: Search plugin crashes on numeric page titles in <code>nav</code></li> </ul>"},{"location":"changelog/#9.0.1","title":"9.0.1 January 3, 2023","text":"<ul> <li>Removed <code>pipdeptree</code> dependency for built-in info plugin</li> <li>Fixed appearance of linked tags when hovered (9.0.0 regression)</li> <li>Fixed #4810: Abbreviations run out of screen on touch devices</li> <li>Fixed #4813: View source and edit button links are the same</li> </ul>"},{"location":"changelog/#9.0.0","title":"9.0.0 January 2, 2023","text":"<p>Additions and improvements</p> <ul> <li>Added support for rich search previews</li> <li>Added support for tokenizer lookahead</li> <li>Added support for better search highlighting</li> <li>Added support for excluding content from search</li> <li>Added support for configurable search pipeline</li> <li>Added support for offline search via offline plugin</li> <li>Added support for multiple instances of built-in tags plugin</li> <li>Added support for removing copy-to-clipboard button</li> <li>Added support for removing footer navigation</li> <li>Added support for button to view the source of a page</li> <li>Improved readability of query string for search sharing</li> <li>Improved stability of search plugin when using <code>--dirtyreload</code></li> <li>Improved search result group button, now sticky and stable</li> <li>Updated Norwegian translations</li> <li>Updated MkDocs to 1.4.2</li> </ul> <p>Removals</p> <ul> <li>Removed deprecated alternative admonition qualifiers</li> <li>Removed <code>:is()</code> selectors (in output) for easier overriding</li> <li>Removed <code>.title</code> suffix on translations</li> <li>Removed legacy method for providing page title in feedback URL</li> <li>Removed support for indexing only titles in search</li> <li>Removed support for custom search transforms</li> <li>Removed support for custom search workers</li> <li>Removed temporary snow feature (easter egg)</li> </ul> <p>Fixes</p> <ul> <li>Fixed Norwegian and Korean language code</li> <li>Fixed detection of composition events in search interface</li> <li>Fixed search plugin not using title set via front matter</li> <li>Fixed search highlighting of tags</li> <li>Fixed search sharing URL using post transformed string</li> <li>Fixed theme-color meta tag getting out-of-sync with palette toggle</li> <li>Fixed prev/next page keyboard navigation when footer is not present</li> <li>Fixed overflowing navigation tabs not being scrollable</li> <li>Fixed inclusion of code block line numbers from search</li> </ul>"},{"location":"changelog/#8.5.11","title":"8.5.11 November 30, 2022","text":"<ul> <li>Let it snow, see https://twitter.com/squidfunk/status/1597939243090788352</li> </ul>"},{"location":"changelog/#8.5.10","title":"8.5.10 November 11, 2022","text":"<ul> <li>Adjusted CSS to better allow for custom primary and accent colors</li> <li>Fixed #4620: Primary color is not applied (8.5.9 regression)</li> </ul>"},{"location":"changelog/#8.5.9","title":"8.5.9 November 8, 2022","text":"<ul> <li>Fixed #4600: Illegible link colors for black and white primary colors</li> <li>Fixed #4594: Need to set schema to change link color</li> </ul>"},{"location":"changelog/#8.5.8","title":"8.5.8 November 3, 2022","text":"<ul> <li>Added support for always showing settings in cookie consent</li> <li>Fixed #4571: Buttons invisible if primary color is <code>white</code> or <code>black</code></li> <li>Fixed #4517: Illegible note in sequence diagram when using <code>slate</code> scheme</li> </ul>"},{"location":"changelog/#8.5.7","title":"8.5.7 October 22, 2022","text":"<ul> <li>Deprecated additional admonition qualifiers to reduce size of CSS</li> <li>Fixed #4511: Search boost does not apply to sections</li> </ul>"},{"location":"changelog/#8.5.6","title":"8.5.6 October 2, 2022","text":"<ul> <li>Modernized appearance of admonitions (with fallback, see docs)</li> <li>Improved appearance of inline code blocks in admonition titles</li> </ul>"},{"location":"changelog/#8.5.5","title":"8.5.5 October 1, 2022","text":"<ul> <li>Updated MkDocs to 1.4</li> <li>Fixed compatibility issues with MkDocs 1.4</li> <li>Fixed #4430: build error when enabling consent without repository URL</li> </ul>"},{"location":"changelog/#8.5.4","title":"8.5.4 September 30, 2022","text":"<ul> <li>Fixed expand icons shift on sidebar overflow (using <code>scrollbar-gutter</code>)</li> <li>Fixed #4429: Text in sequence diagrams overflows in Firefox</li> </ul>"},{"location":"changelog/#8.5.3","title":"8.5.3 September 20, 2022","text":"<ul> <li>Fixed build error when enabling cookie consent without analytics</li> <li>Fixed #4381: Code blocks render ligatures for some fonts</li> </ul>"},{"location":"changelog/#8.5.2","title":"8.5.2 September 18, 2022","text":"<ul> <li>Updated Mermaid.js to version 9.1.7</li> <li>Fixed overly large headlines in search results (8.5.0 regression)</li> <li>Fixed #4358: Navigation sections appear as clickable (8.5.0 regression)</li> <li>Fixed #4356: GitHub repository statistics fetched before cookie consent</li> </ul>"},{"location":"changelog/#8.5.1","title":"8.5.1 September 15, 2022","text":"<ul> <li>Fixed #4366: Removed dependencies with native extensions</li> </ul>"},{"location":"changelog/#8.5.0","title":"8.5.0 September 13, 2022","text":"<ul> <li>Added support for social cards</li> <li>Added support for code annotation anchor links (deep linking)</li> <li>Added support for code annotation comment stripping (syntax modifier)</li> <li>Added support for sidebars scrolling automatically to active item</li> <li>Added support for anchor following table of contents (= auto scroll)</li> <li>Added support for tag icons</li> </ul>"},{"location":"changelog/#8.4.4","title":"8.4.4 September 12, 2022","text":"<ul> <li>Moved comments integration to separate partial (<code>comments.html</code>)</li> </ul>"},{"location":"changelog/#8.4.3","title":"8.4.3 September 7, 2022","text":"<ul> <li>Added Simple Icons to bundled icons (+2,300 icons)</li> <li>Added support for changing edit icon</li> <li>Moved page actions to separate partial (<code>actions.html</code>)</li> <li>Fixed #4291: Version switching doesn't stay on page when anchors are used</li> <li>Fixed #4327: Links in data tables do not receive link styling</li> </ul>"},{"location":"changelog/#8.4.2","title":"8.4.2 August 27, 2022","text":"<ul> <li>Updated Slovenian translations</li> <li>Fixed #4277: Feedback widget hidden after navigation with instant loading</li> <li>Fixed numeric tags in front matter breaking search functionality</li> </ul>"},{"location":"changelog/#8.4.1","title":"8.4.1 August 21, 2022","text":"<ul> <li>Updated Croatian and Hebrew translations</li> </ul>"},{"location":"changelog/#8.4.0","title":"8.4.0 August 13, 2022","text":"<ul> <li>Added support for cookie consent</li> <li>Added support for feedback widget (Was this page helpful?)</li> <li>Added support for dismissible announcement bar</li> <li>Added Armenian, Lithuanian, Tagalog, and Urdu translations</li> </ul>"},{"location":"changelog/#8.3.9","title":"8.3.9 July 4, 2022","text":"<ul> <li>Updated Taiwanese translations for search</li> <li>Allow ids for content tabs with special characters (for mkdocstrings)</li> <li>Fixed #4083: home not clickable when using versioning (8.3.5 regression)</li> </ul>"},{"location":"changelog/#8.3.8","title":"8.3.8 June 24, 2022","text":"<ul> <li>Fixed #4053: Limit width of videos to content area</li> <li>Fixed empty tags in front matter breaking search</li> </ul>"},{"location":"changelog/#8.3.7","title":"8.3.7 June 22, 2022","text":"<ul> <li>Fixed search being stuck initializing when using tags (8.3.4 regression)</li> </ul>"},{"location":"changelog/#8.3.6","title":"8.3.6 June 16, 2022","text":"<ul> <li>Fixed #4028: Links not clickable when using versioning (8.3.5 regression)</li> </ul>"},{"location":"changelog/#8.3.5","title":"8.3.5 June 14, 2022","text":"<ul> <li>Fixed #4012: Stay on page not working for alias of active version</li> </ul>"},{"location":"changelog/#8.3.4","title":"8.3.4 June 11, 2022","text":"<ul> <li>Fixed #4004: Tags with multiple words not searchable</li> </ul>"},{"location":"changelog/#8.3.3","title":"8.3.3 June 7, 2022","text":"<ul> <li>Fixed #4000: Mermaid diagrams too dark in dark mode (8.3.0 regression)</li> </ul>"},{"location":"changelog/#8.3.2","title":"8.3.2 June 5, 2022","text":"<ul> <li>Fixed #3987: Custom admonition icons don't work when defining color palette</li> </ul>"},{"location":"changelog/#8.3.1","title":"8.3.1 June 4, 2022","text":"<ul> <li>Bump required Jinja version to 3.0.2</li> <li>Removed unnecessary conditions in templates</li> <li>Fixed scroll offset when content tabs are brought into view</li> <li>Fixed #3977: Content tabs snapping oddly in Firefox</li> <li>Fixed #3983: Missing condition in footer partial (8.3.0 regression)</li> </ul>"},{"location":"changelog/#8.3.0","title":"8.3.0 June 2, 2022","text":"<ul> <li>Added support for custom admonition icons</li> <li>Added support for linking of content tabs</li> <li>Added support for boosting pages in search</li> <li>Added support for hiding footer navigation</li> <li>Added previous/next indicators to content tabs</li> <li>Improved typeset link colors in light and dark modes</li> </ul>"},{"location":"changelog/#8.2.16","title":"8.2.16 May 28, 2022","text":"<ul> <li>Fixed #3957: Only animate code annotations when visible (save CPU cycles)</li> </ul>"},{"location":"changelog/#8.2.15","title":"8.2.15 May 14, 2022","text":"<ul> <li>Added Uzbek translations</li> <li>Fixed spacing for code block results in content tabs</li> </ul>"},{"location":"changelog/#8.2.14","title":"8.2.14 May 8, 2022","text":"<ul> <li>Fixed missing top right rounded border on admonition</li> <li>Fixed #3886: <code>4xx</code> status codes not handled when using instant loading</li> </ul>"},{"location":"changelog/#8.2.13","title":"8.2.13 May 2, 2022","text":"<ul> <li>Fixed #3865: Tags index links to tagged pages 404 on Windows</li> <li>Fixed #3866: Bump required Python version from 3.6+ to 3.7+</li> </ul>"},{"location":"changelog/#8.2.12","title":"8.2.12 April 30, 2022","text":"<ul> <li>Added support for GitHub-style hash fragments for dark/light images</li> <li>Improved rendering of nested code blocks in content tabs and annotations</li> <li>Fixed #3862: Upgraded to latest Pygments and Python Markdown Extensions</li> </ul>"},{"location":"changelog/#8.2.11","title":"8.2.11 April 25, 2022","text":"<ul> <li>Temporarily pinned Pygments to <code>&lt;2.12</code></li> <li>Temporarily pinned Python Markdown Extensions to <code>&lt;9.4</code></li> <li>Improved rendering of code annotation markers</li> </ul>"},{"location":"changelog/#8.2.10","title":"8.2.10 April 24, 2022","text":"<ul> <li>Added Macedonian translations</li> <li>Updated Mermaid.js to version 9.0.1</li> <li>Switched sidebar title in mobile navigation to bold font</li> <li>Fixed color of arrows in class and state diagrams for dark mode</li> <li>Fixed #3836: Inline admonitions overlayed by code block titles</li> </ul>"},{"location":"changelog/#8.2.9","title":"8.2.9 April 8, 2022","text":"<ul> <li>Mitigate flicker on color palette switch by disabling all transitions</li> <li>Fixed search suggestions not triggered when following deep link</li> <li>Fixed incorrectly computed header height when using instant loading</li> <li>Fixed #3782: Admonition titles have extra pixels on wide screens in Firefox</li> <li>Fixed #3802: Always render table of contents container (except when hidden)</li> </ul>"},{"location":"changelog/#8.2.8","title":"8.2.8 March 27, 2022","text":"<ul> <li>Bumped MkDocs version to 1.3.0 to mitigate breaking changes in Jinja</li> <li>Reverted Jinja version range limitation (added in 8.2.7)</li> <li>Improved styling of annotations and fixed borders of code blocks in tabs</li> <li>Added background color to code blocks in focused/hovered links</li> <li>Added check in tags plugin whether tags overview page exists</li> <li>Fixed #3744: Content tab indicator on wrong position when using back button</li> </ul>"},{"location":"changelog/#8.2.7","title":"8.2.7 March 24, 2022","text":"<ul> <li>Temporarily limit Jinja version range to &lt; 3.1 due to breaking changes</li> </ul>"},{"location":"changelog/#8.2.6","title":"8.2.6 March 23, 2022","text":"<ul> <li>Fixed #3695: Deprecation warning for unescaped backslashes in templates</li> <li>Fixed #3696: Annotations not mounted in some Terraform code blocks</li> <li>Fixed #3698: Annotations not mounted in long code blocks (8.2.5 regression)</li> </ul>"},{"location":"changelog/#8.2.5","title":"8.2.5 March 6, 2022","text":"<ul> <li>Fixed #3596: Mermaid not working when headline with name 'Mermaid' present</li> <li>Fixed #3643: Reduce time to render pages with thousands of code blocks</li> <li>Fixed #3665: Missing styles for Mermaid.js flowcharts cluster labels</li> </ul>"},{"location":"changelog/#8.2.4","title":"8.2.4 March 2, 2022","text":"<ul> <li>Fixed malformed Google Fonts URL when a font setting was omitted</li> <li>Fixed #3648: Fixed specificity issue with admonitions in lists</li> <li>Fixed #3653: Invalid outdated version banner URL when using instant loading</li> </ul>"},{"location":"changelog/#8.2.3","title":"8.2.3 February 27, 2022","text":"<ul> <li>Fixed #3578: Active element in table of contents off-by-one on large screens</li> </ul>"},{"location":"changelog/#8.2.2","title":"8.2.2 February 26, 2022","text":"<ul> <li>Added automatic removal of query parameter when search is closed</li> <li>Fixed #3599: Anchors always overridden when using navigation tracking</li> </ul>"},{"location":"changelog/#8.2.1","title":"8.2.1 February 17, 2022","text":"<ul> <li>Fixed module <code>material.plugins</code> not being found (8.2.0 regression)</li> </ul>"},{"location":"changelog/#8.2.0","title":"8.2.0 February 17, 2022","text":"<ul> <li>Added native support for Mermaid.js diagrams</li> <li>Added native support for tags (with search integration)</li> <li>Added support for staying on page when switching versions</li> </ul>"},{"location":"changelog/#8.1.11","title":"8.1.11 February 10, 2022","text":"<ul> <li>Added Portuguese (Brasilian) translations</li> <li>Updated FontAwesome to v6 \u2013 check which icons were renamed here</li> <li>Fixed #3545: Color palette toggle and search overlaying version selector</li> </ul>"},{"location":"changelog/#8.1.10","title":"8.1.10 February 6, 2022","text":"<ul> <li>Fixed cutoff of very wide logos in the sidebar on mobile</li> </ul>"},{"location":"changelog/#8.1.9","title":"8.1.9 January 30, 2022","text":"<ul> <li>Added support for <code>mkdocs.yml</code> validation and auto-complete</li> <li>Fixed errors in Latvian translations</li> </ul>"},{"location":"changelog/#8.1.8","title":"8.1.8 January 23, 2022","text":"<ul> <li>Added Latvian translations</li> <li>Updated Giscus example integration with dynamic theme change support</li> <li>Fixed #3479: Back-to-top button not hidden when using sticky navigation tabs</li> <li>Fixed #3491: Logo in header and drawer doesn't honor aspect ratio</li> </ul>"},{"location":"changelog/#8.1.7","title":"8.1.7 January 16, 2022","text":"<ul> <li>Improved back-to-top button behavior - now not shown on anchor jump</li> </ul>"},{"location":"changelog/#8.1.6","title":"8.1.6 January 11, 2022","text":"<ul> <li>Fixed spacing of blockquotes (8.1.5 regression)</li> <li>Fixed edge cases for rounded corners on code blocks (8.1.5 regression)</li> <li>Fixed issues with code annotation line heights</li> </ul>"},{"location":"changelog/#8.1.5","title":"8.1.5 January 9, 2022","text":"<ul> <li>Improved browser support: Chrome 49+, Safari 10+, Firefox 53+, Edge 79+</li> <li>Improved rendering of inline code blocks in headlines</li> <li>Added Bahasa Malaysian translations</li> <li>Fixed #3354: MathJax formulas show vertical scrollbar</li> </ul>"},{"location":"changelog/#8.1.4","title":"8.1.4 January 2, 2022","text":"<ul> <li>Added indicator to navigation expander icon</li> <li>Improved support for reduced motion preference</li> <li>Fixed jitter of active content tab indicator</li> </ul>"},{"location":"changelog/#8.1.3","title":"8.1.3 December 19, 2021","text":"<ul> <li>Added animation to active content tab indicator</li> <li>Fixed #3360: Highlighted lines add blank lines in copied text</li> <li>Fixed usage of subsequent index files when using section index pages</li> </ul>"},{"location":"changelog/#8.1.2","title":"8.1.2 December 15, 2021","text":"<ul> <li>Switched CSS sources to logical properties</li> <li>Added transformation of logical properties to <code>ltr</code>/<code>rtl</code> equivalents</li> <li>Fixed spacing for admonitions inside lists (8.1.1 regression)</li> </ul>"},{"location":"changelog/#8.1.1","title":"8.1.1 December 13, 2021","text":"<ul> <li>Added support for <code>#only-light</code> and <code>#only-dark</code> image hash fragments</li> <li>Fixed copy-to-clipboard adding blank lines when using line anchors</li> <li>Fixed code annotation directionality for right-to-left languages</li> <li>Fixed header title positioning for right-to-left languages</li> <li>Fixed admonition borders for right-to-left languages (8.0.0 regression)</li> <li>Fixed footer navigation link positioning (8.0.0 regression)</li> <li>Fixed footer navigation title breaking out of container when too long</li> <li>Fixed shrinking arrow in navigation title when too long</li> <li>Fixed #3343: Filtered stopwords appear as missing search terms</li> <li>Fixed #3346: Site unusable due to usage of <code>:not()</code> (Firefox 78 ESR)</li> </ul>"},{"location":"changelog/#8.1.0","title":"8.1.0 December 10, 2021","text":"<ul> <li>Added basic support for code block line anchors</li> <li>Switched code annotation markers to <code>+</code> signs to improve usability</li> <li>Switched main site title to bold font</li> <li>Improved admonition icon positioning to align when <code>font-size</code> is increased</li> <li>Improved and simplified footnotes CSS</li> <li>Improved and simplified code annotation positioning</li> <li>Fixed syntax error in Russian translations</li> </ul>"},{"location":"changelog/#8.0.5","title":"8.0.5 December 6, 2021","text":"<ul> <li>Fixed #3302: Footer refactoring induced ellipsis in some browsers</li> <li>Fixed #3313: Details always rendered closed on load (8.0.4 regression)</li> </ul>"},{"location":"changelog/#8.0.4","title":"8.0.4 December 4, 2021","text":"<ul> <li>Improved support for deeply nested code annotations</li> <li>Improved code annotation and copy-to-clipboard interop</li> <li>Improved styling for code annotations inside admonitions</li> <li>Fixed #3274: Invalid anchor positioning when using instant loading</li> <li>Fixed #3294: Lists after code blocks without code annotations disappearing</li> <li>Fixed several positioning issues for code annotations</li> <li>Fixed JavaScript source map roots</li> </ul>"},{"location":"changelog/#8.0.3","title":"8.0.3 December 2, 2021","text":"<ul> <li>Removed deprecated <code>google_analytics</code> setting (was forgotten in 8.0.0)</li> <li>Fixed syntax error in Swedish and Polish translations</li> <li>Fixed #3283: Invalid back-to-top button position with sticky navigation tabs</li> <li>Fixed #3285: Default details marker showing due to Safari bug</li> </ul>"},{"location":"changelog/#8.0.2","title":"8.0.2 November 30, 2021","text":"<ul> <li>Fixed #3275: Code annotations always disappear on click</li> </ul>"},{"location":"changelog/#8.0.1","title":"8.0.1 November 28, 2021","text":"<ul> <li>Improved rendering of code annotation markers</li> <li>Fixed #3265: Wrong margin on nested admonitions</li> <li>Fixed wrong <code>box-sizing</code> for code annotations in details</li> </ul>"},{"location":"changelog/#8.0.0","title":"8.0.0 November 28, 2021","text":"<ul> <li>Added support for code annotations</li> <li>Added support for anchor tracking</li> <li>Added support for version warning</li> <li>Added <code>copyright</code> partial for easier override</li> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integation \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"changelog/#7.3.6","title":"7.3.6 October 30, 2021","text":"<ul> <li>Added support for adding titles to code blocks</li> </ul>"},{"location":"changelog/#7.3.5","title":"7.3.5 October 27, 2021","text":"<ul> <li>Added support for setting table of contents title via <code>mkdocs.yml</code></li> <li>Fixed back-to-top button position for right-to-left languages</li> </ul>"},{"location":"changelog/#7.3.4","title":"7.3.4 October 17, 2021","text":"<ul> <li>Bumped MkDocs version to 1.2.3 to mitigate CVE-2021-40978</li> <li>Fixed spacing issues when using integrate table of contents with tabs</li> <li>Fixed some spacings issues for right-to-left languages</li> <li>Fixed race condition in search initialization</li> </ul>"},{"location":"changelog/#7.3.3","title":"7.3.3 October 11, 2021","text":"<ul> <li>Rewrite of entire documentation</li> <li>Adjusted height of new content tabs to match single line code blocks</li> <li>Fixed new content tabs missing right padding in some browsers on overflow</li> <li>Fixed new content tabs bleeding out of flex container on overflow</li> <li>Fixed new content tabs overflow scrolling bugs on some browsers</li> <li>Fixed new content tabs stealing keyboard access when active</li> <li>Fixed some spacings issues for right-to-left languages</li> </ul>"},{"location":"changelog/#7.3.2","title":"7.3.2 October 6, 2021","text":"<ul> <li>Deprecated prebuilding of search index</li> <li>Improved graceful handling of broken search for <code>file://</code></li> <li>Added minimum Jinja version to list of requirements</li> <li>Fixed #3071: Section index pages render empty directories</li> <li>Fixed margin issues when using navigation tabs (7.3.1 regression)</li> <li>Fixed search placeholder sometimes being shown too early</li> </ul>"},{"location":"changelog/#7.3.1","title":"7.3.1 October 2, 2021","text":"<ul> <li>Added new experimental content tabs implementation</li> <li>Fixed #3069: GitHub stats broken for users/orgs (7.1.0 regression)</li> <li>Fixed #3070: Sections not linking to index page</li> <li>Fixed title not linking to index page when using tabs</li> <li>Fixed Disqus integration when using instant loading</li> <li>Fixed some spacing issues for right-to-left languages</li> <li>Fixed syntax error in Serbian translations</li> </ul>"},{"location":"changelog/#7.3.0","title":"7.3.0 September 23, 2021","text":"<ul> <li>Added support for sticky navigation tabs</li> <li>Added support for section index pages</li> <li>Added support for removing generator notice</li> </ul>"},{"location":"changelog/#7.2.8","title":"7.2.8 September 20, 2021","text":"<ul> <li>Fixed #3039: Search modal overlays menu on mobile (7.2.7 regression)</li> </ul>"},{"location":"changelog/#7.2.7","title":"7.2.7 September 19, 2021","text":"<ul> <li>Updated Serbian and Serbo-Croatian translations</li> <li>Improved appearance of outline on details</li> <li>Fixed #2934: Scrollbar when header is hidden on some mobile browsers</li> <li>Fixed #3032: Anchor in details doesn't open on load (7.0.0 regression)</li> <li>Fixed back-to-top button being focusable when invisible</li> <li>Fixed broken admonition icons (removed in upstream)</li> </ul>"},{"location":"changelog/#7.2.6","title":"7.2.6 September 1, 2021","text":"<ul> <li>Fixed rendering of <code>blockquote</code> elements (7.0.0 regression)</li> <li>Fixed #2973: Custom search worker setting ignored</li> </ul>"},{"location":"changelog/#7.2.5","title":"7.2.5 August 25, 2021","text":"<ul> <li>Updated Portuguese translations</li> <li>Fixed execution of RxJS teardown logic (7.2.3 regression)</li> <li>Fixed #2970: Search results show escaped characters (7.2.2 regression)</li> </ul>"},{"location":"changelog/#7.2.4","title":"7.2.4 August 11, 2021","text":"<ul> <li>Fixed #2926: Version selector not working (7.2.3 regression)</li> <li>Fixed #2929: Missing CSS class for banner (consistency with Insiders)</li> </ul>"},{"location":"changelog/#7.2.3","title":"7.2.3 August 9, 2021","text":"<ul> <li>Slight facelift of data tables, now closer to Material Design</li> <li>Fixed instant loading not respecting clicks on search results</li> <li>Fixed #2881: Invalid anchor offsets when using instant loading</li> </ul>"},{"location":"changelog/#7.2.2","title":"7.2.2 July 31, 2021","text":"<ul> <li>Updated Korean translations</li> <li>Fixed #2879: Search highlighting does not properly escape HTML</li> </ul>"},{"location":"changelog/#7.2.1","title":"7.2.1 July 25, 2021","text":"<ul> <li>Fixed #2862: Back-to-top button overlays active search bar</li> </ul>"},{"location":"changelog/#7.2.0","title":"7.2.0 July 21, 2021","text":"<ul> <li>Added support for search suggestions to save keystrokes</li> <li>Added support for search highlighting</li> <li>Added support for search sharing (i.e. deep linking)</li> </ul>"},{"location":"changelog/#7.1.11","title":"7.1.11 July 18, 2021","text":"<ul> <li>Updated Spanish and Galician translations</li> </ul>"},{"location":"changelog/#7.1.10","title":"7.1.10 July 10, 2021","text":"<ul> <li>Refactored appearance of back-to-top button</li> <li>Fixed graceful handling of search when browsing locally</li> </ul>"},{"location":"changelog/#7.1.9","title":"7.1.9 June 25, 2021","text":"<ul> <li>Improved search language support for Thai and Hindi</li> <li>Fixed #2761: License comments lined up at end of file</li> </ul>"},{"location":"changelog/#7.1.8","title":"7.1.8 June 12, 2021","text":"<ul> <li>Refactored analytics integration (because of MkDocs 1.2)</li> <li>Added support for Google Analytics 4 (<code>gtag.js</code>)</li> <li>Fixed missing escape for <code>aria-label</code> in footer links</li> </ul>"},{"location":"changelog/#7.1.7","title":"7.1.7 June 6, 2021","text":"<ul> <li>Improved screen reader support</li> </ul>"},{"location":"changelog/#7.1.6","title":"7.1.6 May 30, 2021","text":"<ul> <li>Deprecated <code>seealso</code> admonition qualifier</li> <li>Added Mongolian and updated Chinese translations</li> <li>Fixed #2429: Version selector not touch-friendly on Android devices</li> <li>Fixed #2703: Printed 'Initializing search' albeit ready on mobile</li> </ul>"},{"location":"changelog/#7.1.5","title":"7.1.5 May 19, 2021","text":"<ul> <li>Fixed #2655: Details breaking page margins on print</li> </ul>"},{"location":"changelog/#7.1.4","title":"7.1.4 May 6, 2021","text":"<ul> <li>Added support for git-revision-date-localized plugin creation date</li> <li>Improved footnote styles on <code>:target</code> and <code>:focus</code></li> </ul>"},{"location":"changelog/#7.1.3","title":"7.1.3 April 24, 2021","text":"<ul> <li>Fixed #2586: Empty table of contents shown (7.1.2 regression)</li> </ul>"},{"location":"changelog/#7.1.2","title":"7.1.2 April 18, 2021","text":"<ul> <li>Fixed #2554: List markers sometimes overlap floated elements</li> <li>Fixed #2563: Adding a class to a <code>h1</code> breaks the table of contents</li> <li>Fixed #2566: Back-to-top button clickable when invisible</li> </ul>"},{"location":"changelog/#7.1.1","title":"7.1.1 April 10, 2021","text":"<ul> <li>Fixed #2501: Nested definition lists compound bottom margin</li> <li>Fixed #2508: Switch <code>extracopyright</code> block to template variable</li> <li>Fixed #2533: Search (and other parts) not working in Safari &lt;14</li> <li>Fixed #2538: Visual quirk when opening language selector</li> </ul>"},{"location":"changelog/#7.1.0","title":"7.1.0 March 29, 2021","text":"<ul> <li>Added support for back-to-top button</li> <li>Added support for color palette toggle</li> <li>Added latest release to repository info (GitHub)</li> <li>Slight facelift of repository info (lighter fonts, spacing and icons)</li> </ul>"},{"location":"changelog/#7.0.7","title":"7.0.7 March 28, 2021","text":"<ul> <li>Updated Hungarian translations</li> <li>Fixed #2466: Docker image not based on latest Python and Alpine</li> <li>Fixed #2488: Inconsistent header shadow behavior</li> <li>Fixed #2492: Inline code blocks in admonition titles missing background</li> </ul>"},{"location":"changelog/#7.0.6","title":"7.0.6 March 14, 2021","text":"<ul> <li>Added trailing slash to version selector URL</li> <li>Added support for out-of-order anchors in table of contents</li> <li>Added <code>extra.homepage</code> option to link logo to arbitrary URL</li> <li>Improved security of Docker image (always update apk)</li> <li>Fixed horizontal spacing for nested inline admonitions</li> <li>Fixed text color of nested code blocks inside links</li> <li>Fixed version selector to always use version title</li> <li>Fixed logo link when using versioning with instant loading</li> </ul>"},{"location":"changelog/#7.0.5","title":"7.0.5 March 7, 2021","text":"<ul> <li>Added <code>extracopyright</code> block to allow for custom copyright info</li> <li>Fixed evaluation of third-party scripts when using instant loading</li> <li>Fixed edge cases when using instant loading without directory URLs</li> <li>Fixed handling of version selector when using instant loading</li> <li>Fixed regression with header title not being updated correctly</li> <li>Fixed expanded sections not opening on first click (7.0.4 regression)</li> </ul>"},{"location":"changelog/#7.0.4","title":"7.0.4 March 4, 2021","text":"<ul> <li>Added Icelandic translations</li> <li>Fixed #2386: Section close requires two clicks (navigation expansion)</li> <li>Fixed console error when search is disabled (7.0.0 regression)</li> <li>Fixed localsearch integration (7.0.0 regression)</li> </ul>"},{"location":"changelog/#7.0.3","title":"7.0.3 February 26, 2021","text":"<ul> <li>Fixed JavaScript errors in older browsers (target ES2020 -&gt; ES2015)</li> </ul>"},{"location":"changelog/#7.0.2","title":"7.0.2 February 25, 2021","text":"<ul> <li>Fixed #2343: Invalid source map URLs for JS and CSS files</li> <li>Fixed #2347: Version selector missing when using versioning</li> </ul>"},{"location":"changelog/#7.0.1","title":"7.0.1 February 24, 2021","text":"<ul> <li>Fixed #2334: Google Analytics triggers page view twice (7.0.0 regression)</li> <li>Fixed #2336: Details bleed into inline admonitions</li> <li>Fixed #2337: Images don't align correctly (7.0.0 regression)</li> </ul>"},{"location":"changelog/#7.0.0","title":"7.0.0 February 22, 2021","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Added support for integrating a language selector</li> <li>Added support for rendering admonitions as inline blocks</li> <li>Rewrite of the underlying reactive architecture</li> <li>Removed Webpack in favor of reactive build strategy (-480 dependencies)</li> <li>Fixed keyboard navigation for code blocks after content tabs switch</li> </ul>"},{"location":"changelog/#6.2.8","title":"6.2.8 February 4, 2021","text":"<ul> <li>Updated Japanese and Polish translations</li> <li>Fixed #2261: Print dialog auto-closing when using instant loading</li> </ul>"},{"location":"changelog/#6.2.7","title":"6.2.7 January 31, 2021","text":"<ul> <li>Fixed #2251: Updated Docker image to latest Alpine Linux</li> </ul>"},{"location":"changelog/#6.2.6","title":"6.2.6 January 26, 2021","text":"<ul> <li>Added Bulgarian translations</li> <li>Fixed #2233: Search not shown when using header autohiding</li> </ul>"},{"location":"changelog/#6.2.5","title":"6.2.5 January 17, 2021","text":"<ul> <li>Fixed syntax error in Swedish translations</li> <li>Optimized navigation partials to improve build speed for huge docs</li> </ul>"},{"location":"changelog/#6.2.4","title":"6.2.4 January 9, 2021","text":"<ul> <li>Fixed #2156: Missing syntax highlighting for binary numbers</li> <li>Fixed #2186: Disqus showing on 404 page</li> </ul>"},{"location":"changelog/#6.2.3","title":"6.2.3 December 27, 2020","text":"<ul> <li>Added back hidden overflow on root container</li> <li>Fixed #2142: MathJax formulas sometimes have vertical scrollbars</li> </ul>"},{"location":"changelog/#6.2.2","title":"6.2.2 December 22, 2020","text":"<ul> <li>Removed Markdown version range limit (6.2.0 regression)</li> </ul>"},{"location":"changelog/#6.2.1","title":"6.2.1 December 22, 2020","text":"<ul> <li>Fixed all import and asset paths in templates (6.2.0 regression)</li> <li>Downgraded webpack-asset-manifest-plugin - broke all asset paths</li> </ul>"},{"location":"changelog/#6.2.0","title":"6.2.0 December 22, 2020","text":"<ul> <li>Added support for navigation sections</li> <li>Added support for navigation expansion</li> <li>Added support for integrating table of contents into navigation</li> <li>Added support for autohiding header on scroll</li> <li>Added support for hiding navigation and table of contents per page</li> <li>Added support for arbitrary items in navigation tabs</li> <li>Refactored navigation tabs to simplify grouping behavior</li> <li>Fixed anchor offset for permalinks in Safari (partial revert)</li> <li>Fixed #2098: Active tab sometimes not highlighted correctly</li> <li>Improved appearance for horizontal rulers</li> <li>Improved Spanish and Swedish translations</li> </ul>"},{"location":"changelog/#6.1.7","title":"6.1.7 December 6, 2020","text":"<ul> <li>Fixed #2081: Fixed stats for private GitHub repositories</li> <li>Fixed alignment for admonition icon alignment for right-to-left languages</li> </ul>"},{"location":"changelog/#6.1.6","title":"6.1.6 November 22, 2020","text":"<ul> <li>Fixed #2048: Math formulas show scrollbars (Windows)</li> </ul>"},{"location":"changelog/#6.1.5","title":"6.1.5 November 15, 2020","text":"<ul> <li>Fixed search reset button not showing/hiding correctly</li> </ul>"},{"location":"changelog/#6.1.4","title":"6.1.4 November 7, 2020","text":"<ul> <li>Fixed sidebar jitter when scrolling footer into view</li> </ul>"},{"location":"changelog/#6.1.3","title":"6.1.3 November 5, 2020","text":"<ul> <li>Added support for keywords <code>meta</code> tag</li> <li>Fixed #2027: Line numbers don't scale with smaller font size</li> <li>Fixed link colors for black and white on <code>slate</code> color scheme</li> <li>Removed focus outline on scrolling code blocks for pointer devices</li> </ul>"},{"location":"changelog/#6.1.2","title":"6.1.2 October 31, 2020","text":"<ul> <li>Fixed sizing of icons in admonitions, task lists, etc. (6.1.1 regression)</li> </ul>"},{"location":"changelog/#6.1.1","title":"6.1.1 October 31, 2020","text":"<ul> <li>Fixed #2019: Page title not correctly updated when using instant loading</li> </ul>"},{"location":"changelog/#6.1.0","title":"6.1.0 October 17, 2020","text":"<ul> <li>Fixed #1973: Added support for printing in dark mode</li> <li>Fixed #1974: Added support for printing content tabs</li> <li>Fixed #1995: Improved customizability of details extension</li> </ul>"},{"location":"changelog/#6.0.2","title":"6.0.2 October 4, 2020","text":"<ul> <li>Added Georgian translations</li> <li>Added escaping for link <code>title</code> attributes where necessary</li> <li>Fixed #1956: Pages with whitespace in names have invalid links in search</li> <li>Removed unnecessary (duplicated) link <code>title</code> attributes</li> </ul>"},{"location":"changelog/#6.0.1","title":"6.0.1 September 26, 2020","text":"<ul> <li>Fixed stemmer support for <code>file://</code> protocol through <code>iframe-worker</code></li> <li>Fixed details marker showing for search result in Firefox</li> <li>Fixed tabbing behavior when search query is not empty</li> <li>Switched TypeScript compilation target to ES2015</li> <li>Reduced size of JavaScript by 30% (<code>176kb</code> \u2192 <code>124kb</code>)</li> <li>Removed <code>mkdocs</code> and <code>readthedocs</code> themes from Docker image</li> </ul>"},{"location":"changelog/#6.0.0","title":"6.0.0 September 25, 2020","text":"<ul> <li>Improved search result look and feel</li> <li>Improved search result stability while typing</li> <li>Improved search result grouping (pages + headings)</li> <li>Improved search result relevance and scoring</li> <li>Added display of missing query terms to search results</li> <li>Reduced size of vendor bundle by 25% (<code>84kb</code> \u2192 <code>67kb</code>)</li> <li>Reduced size of the Docker image to improve CI build performance</li> <li>Removed hero partial in favor of custom implementation</li> <li>Removed deprecated front matter features</li> </ul>"},{"location":"changelog/#5.5.14","title":"5.5.14 September 23, 2020","text":"<ul> <li>Improved spacing around image captions</li> <li>Fixed #1939: Long tables cause header overlap in print view</li> </ul>"},{"location":"changelog/#5.5.13","title":"5.5.13 September 19, 2020","text":"<ul> <li>Improved abbreviations on touch devices</li> </ul>"},{"location":"changelog/#5.5.12","title":"5.5.12 August 31, 2020","text":"<ul> <li>Fixed #1638: occasional <code>404</code> for images when using instant loading</li> </ul>"},{"location":"changelog/#5.5.11","title":"5.5.11 August 28, 2020","text":"<ul> <li>Fixed Disqus integration, as the minifier killed the config</li> </ul>"},{"location":"changelog/#5.5.10","title":"5.5.10 August 28, 2020","text":"<ul> <li>Improved rendering by moving Disqus integration after page load</li> <li>Fixed #1887: Moved navigation icons to CSS to reduce size of HTML</li> </ul>"},{"location":"changelog/#5.5.9","title":"5.5.9 August 26, 2020","text":"<ul> <li>Added Esperanto translations</li> <li>Fixed #1884: External links not included in navigation tabs</li> </ul>"},{"location":"changelog/#5.5.8","title":"5.5.8 August 23, 2020","text":"<ul> <li>Removed focus outline on <code>details</code> and content tabs for pointer devices</li> <li>Improved accessibility of content tabs (now navigable via arrow keys)</li> <li>Fixed #1877: <code>404</code> on search index when search is disabled</li> <li>Fixed some memleaks in observable subscriptions</li> <li>Fixed color definitions for <code>theme-color</code> meta tag</li> </ul>"},{"location":"changelog/#5.5.7","title":"5.5.7 August 16, 2020","text":"<ul> <li>Improved contrast ratio to 4.5:1 for syntax highlighting</li> <li>Improved contrast ratio to 4.5:1 for table of contents</li> </ul>"},{"location":"changelog/#5.5.6","title":"5.5.6 August 12, 2020","text":"<ul> <li>Switched base template for <code>404.html</code> to <code>main.html</code></li> <li>Fixed #1864: GitHub organisation stats not loading</li> </ul>"},{"location":"changelog/#5.5.5","title":"5.5.5 August 11, 2020","text":"<ul> <li>Fixed missing vendor and worker distribution files</li> </ul>"},{"location":"changelog/#5.5.4","title":"5.5.4 August 11, 2020","text":"<ul> <li>Added support for sortable data tables</li> </ul>"},{"location":"changelog/#5.5.3","title":"5.5.3 August 4, 2020","text":"<ul> <li>Fixed search for languages other than English (5.5.1 regression)</li> </ul>"},{"location":"changelog/#5.5.2","title":"5.5.2 August 3, 2020","text":"<ul> <li>Improved highlight colors and spacing for <code>ins</code>, <code>del</code> and <code>mark</code></li> <li>Changed some keyboard symbols for better equivalents</li> <li>Removed focus <code>outline</code> for details and code blocks on touch devices</li> <li>Fixed margins for admonitions (5.5.1 regression)</li> <li>Fixed too small content tab labels (5.5.1 regression)</li> <li>Fixed icon repeating for custom admonition icons</li> </ul>"},{"location":"changelog/#5.5.1","title":"5.5.1 August 1, 2020","text":"<ul> <li>Improved typesetting by basing <code>font-size</code> and spacings on <code>em</code></li> <li>Improved print view by slightly scaling down <code>font-size</code></li> <li>Changed custom site title (metadata) to be suffixed with site name</li> <li>Fixed top- and bottom spacing of paragraphs inside table cells</li> </ul>"},{"location":"changelog/#5.5.0","title":"5.5.0 July 24, 2020","text":"<ul> <li>Rewrite of entire documentation</li> <li>Rewrite of syntax highlighting to be customizable with CSS variables</li> <li>Improved syntax highlighting to work with light and dark theme</li> <li>Improved <code>slate</code> color scheme to be more customizable and easier on the eyes</li> <li>Added licenses of icon sets to distribution files</li> <li>Fixed stale document titles in Google Analytics when using instant loading</li> <li>Fixed width of previous and next footer links for tablet and above</li> <li>Fixed issues with top scroll margin for footnotes</li> <li>Fixed top margin for tabbed content when using a JavaScript highlighter</li> <li>Deprecated metadata-based redirects, source links and heroes</li> </ul>"},{"location":"changelog/#5.4.0","title":"5.4.0 June 29, 2020","text":"<ul> <li>Added support to wrap searches in quotes to switch from <code>OR</code> to <code>AND</code></li> <li>Fixed highlighting of numbers in search results</li> </ul>"},{"location":"changelog/#5.3.3","title":"5.3.3 June 24, 2020","text":"<ul> <li>Added Bengali translations</li> <li>Fixed #1773: Search for numbers does not return any result (regression)</li> </ul>"},{"location":"changelog/#5.3.2","title":"5.3.2 June 21, 2020","text":"<ul> <li>Improved search typeahead experience with non-Latin characters</li> <li>Fixed #1753: Japanese search doesn't work anymore</li> </ul>"},{"location":"changelog/#5.3.1","title":"5.3.1 June 20, 2020","text":"<ul> <li>Fixed #1761: Duplication of search worker when subscribing to observable</li> </ul>"},{"location":"changelog/#5.3.0","title":"5.3.0 June 15, 2020","text":"<ul> <li>Added support for color schemes based on user preference</li> <li>Fixed #1755: Tokenizer separator setting ignored</li> </ul>"},{"location":"changelog/#5.2.3","title":"5.2.3 June 6, 2020","text":"<ul> <li>Improved search typeahead behavior for some languages (<code>de</code>, <code>fr</code>, ...)</li> <li>Improved styles for scrollbars on Firefox</li> <li>Fixed #1741: Removed <code>preconnect</code> hint for Google Analytics</li> </ul>"},{"location":"changelog/#5.2.2","title":"5.2.2 May 26, 2020","text":"<ul> <li>Fixed #1728: Legacy Edge doesn't support <code>deg</code> values in <code>hsla</code> colors</li> </ul>"},{"location":"changelog/#5.2.1","title":"5.2.1 May 22, 2020","text":"<ul> <li>Fixed color of links in table headers, e.g. footnotes</li> <li>Fixed color scheme not being applied without primary or accent color</li> <li>Fixed hover delay for links inside code blocks</li> </ul>"},{"location":"changelog/#5.2.0","title":"5.2.0 May 18, 2020","text":"<ul> <li>Added color schemes implementation + dark mode</li> <li>Fixed #1583: Missing option for separate link colors</li> </ul>"},{"location":"changelog/#5.1.7","title":"5.1.7 May 16, 2020","text":"<ul> <li>Added keyboard focus support for overflowing code blocks</li> <li>Fixed #1696: Infinite loop in some cases when using instant loading</li> </ul>"},{"location":"changelog/#5.1.6","title":"5.1.6 May 9, 2020","text":"<ul> <li>Added Burmese translations</li> <li>Added general anchor offset solution using <code>scroll-margin-top</code></li> <li>Fixed #1653: Instant loading shouldn't intercept links to <code>*.html</code> files</li> </ul>"},{"location":"changelog/#5.1.5","title":"5.1.5 May 3, 2020","text":"<ul> <li>Added <code>name</code> attribute for social links to set link <code>title</code></li> <li>Fixed #1623: Allow arbitrary links in social links</li> <li>Fixed #1664: Height of <code>iframe</code> is not adjustable</li> <li>Fixed #1667: Sidebars are scrolled to bottom on load (bug in Chrome 81+)</li> </ul>"},{"location":"changelog/#5.1.4","title":"5.1.4 April 30, 2020","text":"<ul> <li>Switched to @mdi/svg Material Design icon package</li> <li>Fixed #1655: Navigation may disappear after switching viewports</li> <li>Fixed #1659: Unnecessary scrollbar for search results on Windows</li> <li>Fixed occasional distortions for images with explicit dimensions</li> <li>Fixed errors in German translations</li> </ul>"},{"location":"changelog/#5.1.3","title":"5.1.3 April 26, 2020","text":"<ul> <li>Fixed overflowing content area after switch to flexbox</li> </ul>"},{"location":"changelog/#5.1.2","title":"5.1.2 April 26, 2020","text":"<ul> <li>Added status information to search observable</li> <li>Added status information to search modal</li> <li>Removed announcement bar from print media</li> <li>Removed media query packing logic due to race conditions</li> <li>Fixed #1520: Gracefully disable search on <code>file://</code> if Worker fails</li> <li>Fixed re-submission of query after search is initialized</li> <li>Fixed jitter of sidebars on all browsers by switching to <code>sticky</code></li> </ul>"},{"location":"changelog/#5.1.1","title":"5.1.1 April 17, 2020","text":"<ul> <li>Added new FontAwesome icons</li> <li>Fixed #1609: Instant loading doesn't honor <code>target=_blank</code></li> <li>Fixed GitHub stars count rounding errors</li> <li>Fixed GitLab stars count retrieval</li> </ul>"},{"location":"changelog/#5.1.0","title":"5.1.0 April 12, 2020","text":"<ul> <li>Added support for icons from Markdown through mkdocs-material-extensions</li> </ul>"},{"location":"changelog/#5.0.2","title":"5.0.2 April 10, 2020","text":"<ul> <li>Added CSS source maps to distribution files</li> <li>Fixed errors in Chinese (Traditional) translations</li> <li>Fixed creation of stale directory on installation from git</li> <li>Improved overflow scrolling behavior on iOS (reduced bundle size by <code>4kb</code>)</li> </ul>"},{"location":"changelog/#5.0.1","title":"5.0.1 April 7, 2020","text":"<ul> <li>Fixed syntax error in Spanish translation</li> </ul>"},{"location":"changelog/#5.0.0","title":"5.0.0 April 7, 2020","text":"<ul> <li>Reactive architecture \u2013 try <code>app.dialog$.next(\"Hi!\")</code> in the console</li> <li>Instant loading \u2013 make Material behave like a Single Page Application</li> <li>Improved CSS customization with CSS variables \u2013 set your brand's colors</li> <li>Improved CSS resilience, e.g. proper sidebar locking for customized headers</li> <li>Improved icon integration and configuration \u2013 now including over 5k icons</li> <li>Added possibility to use any icon for logo, repository and social links</li> <li>Search UI does not freeze anymore (moved to web worker)</li> <li>Search index built only once when using instant loading</li> <li>Improved extensible keyboard handling</li> <li>Support for prebuilt search indexes</li> <li>Support for displaying stars and forks for GitLab repositories</li> <li>Support for scroll snapping of sidebars and search results</li> <li>Reduced HTML and CSS footprint due to deprecation of Internet Explorer support</li> <li>Slight facelifting of some UI elements (admonitions, tables, ...)</li> </ul>"},{"location":"changelog/#4.6.3","title":"4.6.3 February 14, 2020","text":"<ul> <li>Removed optional third-party plugins from <code>requirements.txt</code></li> <li>Updated Docker image to contain all supported third-party plugins</li> </ul>"},{"location":"changelog/#4.6.2","title":"4.6.2 February 8, 2020","text":"<ul> <li>Added Romanian translations</li> <li>Fixed #1451: Inconsistent spacing for fenced code blocks</li> </ul>"},{"location":"changelog/#4.6.1","title":"4.6.1 February 8, 2020","text":"<ul> <li>Fixed #1324: Metadata author only rendering first character</li> <li>Fixed #1393: Set <code>tabindex</code> to <code>0</code> for skip to content link</li> <li>Fixed code blocks after Markdown 3.2 release</li> <li>Fixed errors in Japanese translations</li> <li>Improved Google Lighthouse score</li> </ul>"},{"location":"changelog/#4.6.0","title":"4.6.0 December 11, 2019","text":"<ul> <li>Added support for git-revision-date-localized-plugin</li> <li>Fixed invalid character in Google Fonts URL</li> </ul>"},{"location":"changelog/#4.5.1","title":"4.5.1 December 2, 2019","text":"<ul> <li>Added Thai translations</li> <li>Fixed missing assets in GitHub release <code>.zip</code> and <code>.tar.gz</code></li> </ul>"},{"location":"changelog/#4.5.0","title":"4.5.0 November 16, 2019","text":"<ul> <li>Fixed #1330: Upgraded EmojiOne to Tweomji due to licensing issues</li> <li>Fixed #1339: Temporarily pinned PyMdown and Markdown due to</li> <li>Fixed errors in Greek translations</li> <li>Improved GitHub statistics retrieval</li> </ul>"},{"location":"changelog/#4.4.3","title":"4.4.3 October 3, 2019","text":"<ul> <li>Added Estonian translations</li> <li>Fixed removal of copyright banners in minified JavaScript</li> <li>Removed unnecessary title attributes from links in table of contents</li> </ul>"},{"location":"changelog/#4.4.2","title":"4.4.2 August 27, 2019","text":"<ul> <li>Added Afrikaans translations</li> <li>Fixed broken page title when <code>h1</code> contained HTML tags</li> <li>Improved accessibility for IE users</li> <li>Removed unnecessary <code>title</code> attributes from links in navigation</li> </ul>"},{"location":"changelog/#4.4.1","title":"4.4.1 August 22, 2019","text":"<ul> <li>Added support for <code>black</code> as a primary color</li> <li>Fixed broken footer bar when <code>h1</code> contained HTML tags</li> </ul>"},{"location":"changelog/#4.4.0","title":"4.4.0 June 15, 2019","text":"<ul> <li>Added Slovenian translations</li> <li>Reverted template minification in favor of <code>mkdocs-minify-plugin</code></li> <li>Fixed #1114: Tabs don't reappear when default <code>font-size</code> is smaller than <code>16</code></li> </ul>"},{"location":"changelog/#4.3.1","title":"4.3.1 May 23, 2019","text":"<ul> <li>Fixed spelling error in Danish translations</li> </ul>"},{"location":"changelog/#4.3.0","title":"4.3.0 May 17, 2019","text":"<ul> <li>Added support for changing header through metadata title property</li> <li>Added <code>font-display: swap</code> to Google Font loading logic</li> <li>Removed whitespace from templates, saving <code>4kb</code> (<code>.7kb</code> gzipped) per request</li> <li>Fixed alignment of repository icons on tablet and desktop</li> </ul>"},{"location":"changelog/#4.2.0","title":"4.2.0 April 28, 2019","text":"<ul> <li>Added Norwegian (Nynorsk) translations</li> <li>Fixed loss of focus in non-form input elements due to search hotkeys</li> <li>Fixed #1067: Search hotkeys not working for mobile/tablet screensize</li> <li>Fixed #1068: Search not correctly aligned for tablet screensize</li> </ul>"},{"location":"changelog/#4.1.2","title":"4.1.2 April 16, 2019","text":"<ul> <li>Fixed #1072: HTML tags appearing in navigation link titles</li> </ul>"},{"location":"changelog/#4.1.1","title":"4.1.1 March 28, 2019","text":"<ul> <li>Fixed minor CSS errors detected during validation</li> </ul>"},{"location":"changelog/#4.1.0","title":"4.1.0 March 22, 2019","text":"<ul> <li>Fixed #1023: Search for Asian languages broken after Lunr.js update</li> <li>Fixed #1026: contenteditable elements loose focus on hotkeys</li> </ul>"},{"location":"changelog/#4.0.2","title":"4.0.2 March 1, 2019","text":"<ul> <li>Fixed #1012: HTML character entities appear in search result titles</li> </ul>"},{"location":"changelog/#4.0.1","title":"4.0.1 February 13, 2019","text":"<ul> <li>Fixed #762, #816: Glitch in sidebar when collapsing items</li> <li>Fixed #869: Automatically expand details before printing</li> </ul>"},{"location":"changelog/#4.0.0","title":"4.0.0 February 13, 2019","text":"<ul> <li>Added background on hover for table rows</li> <li>Removed Google Tag Manager and reverted to Google Analytics</li> <li>Removed blocks in partials - Jinja doesn't support them</li> <li>Fixed #911: Chrome breaks layout if system language is Chinese (BREAKING)</li> <li>Fixed #976: Removed FastClick</li> </ul>"},{"location":"changelog/#3.3.0","title":"3.3.0 January 29, 2019","text":"<ul> <li>Moved Google Analytics integration into <code>head</code> using Google Tag Manager</li> <li>Fixed #972: Unicode slugifier breaks table of contents blur on scroll</li> <li>Fixed #974: Additional links in table of contents break blur on scroll</li> </ul>"},{"location":"changelog/#3.2.0","title":"3.2.0 December 28, 2018","text":"<ul> <li>Added support for redirects using metadata refresh</li> <li>Fixed #921: Load Google Analytics snippet asynchronously</li> </ul>"},{"location":"changelog/#3.1.0","title":"3.1.0 November 17, 2018","text":"<ul> <li>Added support for Progressive Web App Manifest</li> <li>Fixed #915: Search bug in Safari (upgraded Lunr.js)</li> </ul>"},{"location":"changelog/#3.0.6","title":"3.0.6 October 26, 2018","text":"<ul> <li>Added Taiwanese translations</li> <li>Fixed #906: JavaScript code blocks evaluated in search results</li> </ul>"},{"location":"changelog/#3.0.5","title":"3.0.5 October 23, 2018","text":"<ul> <li>Added Croatian and Indonesian translations</li> <li>Fixed #899: Skip-to-content link invalid from 2nd level on</li> <li>Fixed #902: Missing URL filter in footer for FontAwesome link</li> </ul>"},{"location":"changelog/#3.0.4","title":"3.0.4 September 3, 2018","text":"<ul> <li>Updated Dutch translations</li> <li>Fixed #856: Removed preconnect meta tag if Google Fonts are disabled</li> </ul>"},{"location":"changelog/#3.0.3","title":"3.0.3 August 7, 2018","text":"<ul> <li>Fixed #841: Additional path levels for extra CSS and JS</li> </ul>"},{"location":"changelog/#3.0.2","title":"3.0.2 August 6, 2018","text":"<ul> <li>Fixed #839: Lunr.js stemmer imports incorrect</li> </ul>"},{"location":"changelog/#3.0.1","title":"3.0.1 August 5, 2018","text":"<ul> <li>Fixed #838: Search result links incorrect</li> </ul>"},{"location":"changelog/#3.0.0","title":"3.0.0 August 5, 2018","text":"<ul> <li>Upgraded MkDocs to 1.0 (BREAKING)</li> <li>Upgraded Python in official Docker image to 3.6</li> <li>Added Serbian and Serbo-Croatian translations</li> </ul>"},{"location":"changelog/#2.9.4","title":"2.9.4 July 29, 2018","text":"<ul> <li>Fixed build error after MkDocs upgrade</li> </ul>"},{"location":"changelog/#2.9.3","title":"2.9.3 July 29, 2018","text":"<ul> <li>Added link to home for logo in drawer</li> <li>Fixed dependency problems between MkDocs and Tornado</li> </ul>"},{"location":"changelog/#2.9.2","title":"2.9.2 June 29, 2018","text":"<ul> <li>Added Hindi and Czech translations</li> </ul>"},{"location":"changelog/#2.9.1","title":"2.9.1 June 18, 2018","text":"<ul> <li>Added support for different spellings for theme color</li> <li>Fixed #799: Added support for webfont minification in production</li> <li>Fixed #800: Added <code>.highlighttable</code> as an alias for <code>.codehilitetable</code></li> </ul>"},{"location":"changelog/#2.9.0","title":"2.9.0 June 13, 2018","text":"<ul> <li>Added support for theme color on Android</li> <li>Fixed #796: Rendering of nested tabbed code blocks</li> </ul>"},{"location":"changelog/#2.8.0","title":"2.8.0 June 10, 2018","text":"<ul> <li>Added support for grouping code blocks with tabs</li> <li>Added Material and FontAwesome icon fonts to distribution files (GDPR)</li> <li>Added note on compliance with GDPR</li> <li>Added Slovak translations</li> <li>Fixed #790: Prefixed <code>id</code> attributes with <code>__</code> to avoid name clashes</li> </ul>"},{"location":"changelog/#2.7.3","title":"2.7.3 April 26, 2018","text":"<ul> <li>Added Finnish translations</li> </ul>"},{"location":"changelog/#2.7.2","title":"2.7.2 April 9, 2018","text":"<ul> <li>Fixed rendering issue for <code>details</code> on Edge</li> </ul>"},{"location":"changelog/#2.7.1","title":"2.7.1 March 21, 2018","text":"<ul> <li>Added Galician translations</li> <li>Fixed #730: Scroll chasing error on home page if Disqus is enabled</li> <li>Fixed #736: Reset drawer and search upon back button invocation</li> </ul>"},{"location":"changelog/#2.7.0","title":"2.7.0 March 6, 2018","text":"<ul> <li>Added ability to set absolute URL for logo</li> <li>Added Hebrew translations</li> </ul>"},{"location":"changelog/#2.6.6","title":"2.6.6 February 22, 2018","text":"<ul> <li>Added preconnect for Google Fonts for faster loading</li> <li>Fixed #710: With tabs sidebar disappears if JavaScript is not available</li> </ul>"},{"location":"changelog/#2.6.5","title":"2.6.5 February 22, 2018","text":"<ul> <li>Reverted <code>--dev-addr</code> flag removal from <code>Dockerfile</code></li> </ul>"},{"location":"changelog/#2.6.4","title":"2.6.4 February 21, 2018","text":"<ul> <li>Added Catalan translations</li> <li>Fixed incorrect margins for buttons in Firefox and Safari</li> <li>Replaced package manager <code>yarn</code> with <code>npm 5.6</code></li> <li>Reverted GitHub stars rounding method</li> <li>Removed <code>--dev-addr</code> flag from <code>Dockerfile</code> for Windows compatibility</li> </ul>"},{"location":"changelog/#2.6.3","title":"2.6.3 February 18, 2018","text":"<ul> <li>Added Vietnamese translations</li> </ul>"},{"location":"changelog/#2.6.2","title":"2.6.2 February 12, 2018","text":"<ul> <li>Added Arabic translations</li> <li>Fixed incorrect rounding of amount of GitHub stars</li> <li>Fixed double-layered borders for tables</li> </ul>"},{"location":"changelog/#2.6.1","title":"2.6.1 February 11, 2018","text":"<ul> <li>Added ability to override Disqus integration using metadata</li> <li>Fixed #690: Duplicate slashes in source file URLs</li> <li>Fixed #696: Active page highlight not working with default palette</li> <li>Adjusted German translations</li> </ul>"},{"location":"changelog/#2.6.0","title":"2.6.0 February 2, 2018","text":"<ul> <li>Moved default search configuration to default translation (English)</li> <li>Added support to automatically set text direction from translation</li> <li>Added support to disable search stop word filter in translation</li> <li>Added support to disable search trimmer in translation</li> <li>Added Persian translations</li> <li>Fixed support for Polish search</li> <li>Fixed disappearing GitHub, GitLab and Bitbucket repository icons</li> </ul>"},{"location":"changelog/#2.5.5","title":"2.5.5 January 31, 2018","text":"<ul> <li>Added Hungarian translations</li> </ul>"},{"location":"changelog/#2.5.4","title":"2.5.4 January 29, 2018","text":"<ul> <li>Fixed #683: <code>gh-deploy</code> fails inside Docker</li> </ul>"},{"location":"changelog/#2.5.3","title":"2.5.3 January 25, 2018","text":"<ul> <li>Added Ukrainian translations</li> </ul>"},{"location":"changelog/#2.5.2","title":"2.5.2 January 22, 2018","text":"<ul> <li>Added default search language mappings for all localizations</li> <li>Fixed #673: Error loading non-existent search language</li> <li>Fixed #675: Uncaught reference error when search plugin disabled</li> </ul>"},{"location":"changelog/#2.5.1","title":"2.5.1 January 20, 2018","text":"<ul> <li>Fixed permalink for main headline</li> <li>Improved missing translation handling with English as a fallback</li> <li>Improved accessibility with skip-to-content link</li> </ul>"},{"location":"changelog/#2.5.0","title":"2.5.0 January 13, 2018","text":"<ul> <li>Added support for right-to-left languages</li> </ul>"},{"location":"changelog/#2.4.0","title":"2.4.0 January 11, 2018","text":"<ul> <li>Added focus state for clipboard buttons</li> <li>Fixed #400: Search bar steals tab focus</li> <li>Fixed search not closing on Enter when result is selected</li> <li>Fixed search not closing when losing focus due to Tab</li> <li>Fixed collapsed navigation links getting focus</li> <li>Fixed <code>outline</code> being cut off on Tab focus of navigation links</li> <li>Fixed bug with first search result navigation being ignored</li> <li>Removed search result navigation via Tab (use Up and Down)</li> <li>Removed <code>outline</code> resets for links</li> <li>Improved general tabbing behavior on desktop</li> </ul>"},{"location":"changelog/#2.3.0","title":"2.3.0 January 9, 2018","text":"<ul> <li>Added <code>example</code> (synonym: <code>snippet</code>) style for admonitions</li> <li>Added synonym <code>abstract</code> for <code>summary</code> style for admonitions</li> </ul>"},{"location":"changelog/#2.2.6","title":"2.2.6 December 27, 2017","text":"<ul> <li>Added Turkish translations</li> <li>Fixed unclickable area below header in case JavaScript is not available</li> </ul>"},{"location":"changelog/#2.2.5","title":"2.2.5 December 18, 2017","text":"<ul> <li>Fixed #639: Broken default favicon</li> </ul>"},{"location":"changelog/#2.2.4","title":"2.2.4 December 18, 2017","text":"<ul> <li>Fixed #638: Build breaks with Jinja &lt; 2.9</li> </ul>"},{"location":"changelog/#2.2.3","title":"2.2.3 December 13, 2017","text":"<ul> <li>Fixed #630: Admonition sets padding on any last child</li> <li>Adjusted Chinese (Traditional) translations</li> </ul>"},{"location":"changelog/#2.2.2","title":"2.2.2 December 8, 2017","text":"<ul> <li>Added Dutch translations</li> <li>Adjusted targeted link and footnote offsets</li> <li>Simplified admonition styles and fixed padding bug</li> </ul>"},{"location":"changelog/#2.2.1","title":"2.2.1 December 2, 2017","text":"<ul> <li>Fixed #616: Minor styling error with title-only admonitions</li> <li>Removed border for table of contents and improved spacing</li> </ul>"},{"location":"changelog/#2.2.0","title":"2.2.0 November 22, 2017","text":"<ul> <li>Added support for hero teaser</li> <li>Added Portuguese translations</li> <li>Fixed #586: Footnote backref target offset regression</li> <li>Fixed #605: Search stemmers not correctly loaded</li> </ul>"},{"location":"changelog/#2.1.1","title":"2.1.1 November 21, 2017","text":"<ul> <li>Replaced deprecated <code>babel-preset-es2015</code> with <code>babel-preset-env</code></li> <li>Refactored Gulp build pipeline with Webpack</li> <li>Removed right border on sidebars</li> <li>Fixed broken color transition on header</li> </ul>"},{"location":"changelog/#2.1.0","title":"2.1.0 November 19, 2017","text":"<ul> <li>Added support for <code>white</code> as a primary color</li> <li>Added support for sliding site name and title</li> <li>Fixed redundant clipboard button when using line numbers on code blocks</li> <li>Improved header appearance by making it taller</li> <li>Improved tabs appearance</li> <li>Improved CSS customizability by leveraging inheritance</li> <li>Removed scroll shadows via <code>background-attachment</code></li> </ul>"},{"location":"changelog/#2.0.4","title":"2.0.4 November 5, 2017","text":"<ul> <li>Fixed <code>details</code> not opening with footnote reference</li> </ul>"},{"location":"changelog/#2.0.3","title":"2.0.3 November 5, 2017","text":"<ul> <li>Added Japanese translations</li> <li>Fixed #540: Jumping to anchor inside <code>details</code> doesn't open it</li> <li>Fixed active link colors in footer</li> </ul>"},{"location":"changelog/#2.0.2","title":"2.0.2 November 1, 2017","text":"<ul> <li>Added Russian translations</li> <li>Fixed #542: Horizontal scrollbar between <code>1220px</code> and <code>1234px</code></li> <li>Fixed #553: Metadata values only rendering first character</li> <li>Fixed #558: Flash of unstyled content</li> <li>Fixed favicon regression caused by deprecation upstream</li> </ul>"},{"location":"changelog/#2.0.1","title":"2.0.1 October 31, 2017","text":"<ul> <li>Fixed error when initializing search</li> <li>Fixed styles for link to edit the current page</li> <li>Fixed styles on nested admonition in details</li> </ul>"},{"location":"changelog/#2.0.0","title":"2.0.0 October 31, 2017","text":"<ul> <li>Upgraded MkDocs to 0.17.1 (BREAKING)</li> <li>Added support for easier configuration of search tokenizer</li> <li>Added support to disable search</li> <li>Added Korean translations</li> </ul>"},{"location":"changelog/#1.12.2","title":"1.12.2 October 26, 2017","text":"<ul> <li>Added Italian, Norwegian, French and Chinese translations</li> </ul>"},{"location":"changelog/#1.12.1","title":"1.12.1 October 22, 2017","text":"<ul> <li>Added Polish, Swedish and Spanish translations</li> <li>Improved downward compatibility with custom partials</li> <li>Temporarily pinned MkDocs version within Docker image to 0.16.3</li> <li>Fixed #519: Missing theme configuration file</li> </ul>"},{"location":"changelog/#1.12.0","title":"1.12.0 October 20, 2017","text":"<ul> <li>Added support for setting language(s) via <code>mkdocs.yml</code></li> <li>Added support for default localization</li> <li>Added German and Danish translations</li> <li>Fixed #374: Search bar misalignment on big screens</li> </ul>"},{"location":"changelog/#1.11.0","title":"1.11.0 October 19, 2017","text":"<ul> <li>Added localization to clipboard</li> <li>Refactored localization logic</li> </ul>"},{"location":"changelog/#1.10.4","title":"1.10.4 October 18, 2017","text":"<ul> <li>Improved print styles of code blocks</li> <li>Improved search UX (don't close on enter if no selection)</li> <li>Fixed #495: Vertical scrollbar on short pages</li> </ul>"},{"location":"changelog/#1.10.3","title":"1.10.3 October 11, 2017","text":"<ul> <li>Fixed #484: Vertical scrollbar on some MathJax formulas</li> <li>Fixed #483: Footnote backref target offset regression</li> </ul>"},{"location":"changelog/#1.10.2","title":"1.10.2 October 6, 2017","text":"<ul> <li>Fixed #468: Sidebar shows scrollbar if content is shorter (in Safari)</li> </ul>"},{"location":"changelog/#1.10.1","title":"1.10.1 September 14, 2017","text":"<ul> <li>Fixed #455: Bold code blocks rendered with normal font weight</li> </ul>"},{"location":"changelog/#1.10.0","title":"1.10.0 September 1, 2017","text":"<ul> <li>Added support to make logo default icon configurable</li> <li>Fixed uninitialized overflow scrolling on main pane for iOS</li> <li>Fixed error in mobile navigation in case JavaScript is not available</li> <li>Fixed incorrect color transition for nested panes in mobile navigation</li> <li>Improved checkbox styles for Tasklist from PyMdown Extension package</li> </ul>"},{"location":"changelog/#1.9.0","title":"1.9.0 August 29, 2017","text":"<ul> <li>Added <code>info</code> (synonym: <code>todo</code>) style for admonitions</li> <li>Added <code>question</code> (synonym: <code>help</code>, <code>faq</code>) style for admonitions</li> <li>Added support for Details from PyMdown Extensions package</li> <li>Improved admonition styles to match details</li> <li>Improved styles for social links in footer</li> <li>Replaced ligatures with Unicode code points to avoid broken layout</li> <li>Upgraded PyMdown Extensions package dependency to &gt;= 3.4</li> </ul>"},{"location":"changelog/#1.8.1","title":"1.8.1 August 7, 2017","text":"<ul> <li>Fixed #421: Missing pagination for GitHub API</li> </ul>"},{"location":"changelog/#1.8.0","title":"1.8.0 August 2, 2017","text":"<ul> <li>Added support for lazy-loading of search results for better performance</li> <li>Added support for customization of search tokenizer/separator</li> <li>Fixed #424: Search doesn't handle capital letters anymore</li> <li>Fixed #419: Search doesn't work on whole words</li> </ul>"},{"location":"changelog/#1.7.5","title":"1.7.5 July 25, 2017","text":"<ul> <li>Fixed #398: Forms broken due to search shortcuts</li> <li>Improved search overall user experience</li> <li>Improved search matching and highlighting</li> <li>Improved search accessibility</li> </ul>"},{"location":"changelog/#1.7.4","title":"1.7.4 June 21, 2017","text":"<ul> <li>Fixed functional link colors in table of contents for active palette</li> <li>Fixed #368: Compatibility issues with IE11</li> </ul>"},{"location":"changelog/#1.7.3","title":"1.7.3 June 7, 2017","text":"<ul> <li>Fixed error when setting language to Japanese for site search</li> </ul>"},{"location":"changelog/#1.7.2","title":"1.7.2 June 6, 2017","text":"<ul> <li>Fixed offset of search box when <code>repo_url</code> is not set</li> <li>Fixed non-disappearing tooltip</li> </ul>"},{"location":"changelog/#1.7.1","title":"1.7.1 June 1, 2017","text":"<ul> <li>Fixed wrong <code>z-index</code> order of header, overlay and drawer</li> <li>Fixed wrong offset of targeted footnote back references</li> </ul>"},{"location":"changelog/#1.7.0","title":"1.7.0 June 1, 2017","text":"<ul> <li>Added \"copy to clipboard\" buttons to code blocks</li> <li>Added support for multilingual site search</li> <li>Fixed search term highlighting for non-latin languages</li> </ul>"},{"location":"changelog/#1.6.4","title":"1.6.4 May 24, 2017","text":"<ul> <li>Fixed #337: JavaScript error for GitHub organization URLs</li> </ul>"},{"location":"changelog/#1.6.3","title":"1.6.3 May 16, 2017","text":"<ul> <li>Fixed #329: Broken source stats for private or unknown GitHub repos</li> </ul>"},{"location":"changelog/#1.6.2","title":"1.6.2 May 15, 2017","text":"<ul> <li>Fixed #316: Fatal error for git clone on Windows</li> <li>Fixed #320: Chrome 58 creates double underline for <code>abbr</code> tags</li> <li>Fixed #323: Ligatures rendered inside code blocks</li> <li>Fixed miscalculated sidebar height due to missing margin collapse</li> <li>Changed deprecated MathJax CDN to Cloudflare</li> </ul>"},{"location":"changelog/#1.6.1","title":"1.6.1 April 23, 2017","text":"<ul> <li>Fixed following of active/focused element if search input is focused</li> <li>Fixed layer order of search component elements</li> </ul>"},{"location":"changelog/#1.6.0","title":"1.6.0 April 22, 2017","text":"<ul> <li>Added build test for Docker image on Travis</li> <li>Added search overlay for better user experience (focus)</li> <li>Added language from localizations to <code>html</code> tag</li> <li>Fixed #270: source links broken for absolute URLs</li> <li>Fixed missing top spacing for first targeted element in content</li> <li>Fixed too small footnote divider when using larger font sizes</li> </ul>"},{"location":"changelog/#1.5.5","title":"1.5.5 April 20, 2017","text":"<ul> <li>Fixed #282: Browser search (Meta+F) is hijacked</li> </ul>"},{"location":"changelog/#1.5.4","title":"1.5.4 April 8, 2017","text":"<ul> <li>Fixed broken highlighting for two or more search terms</li> <li>Fixed missing search results when only a <code>h1</code> is present</li> <li>Fixed unresponsive overlay on Android</li> </ul>"},{"location":"changelog/#1.5.3","title":"1.5.3 April 7, 2017","text":"<ul> <li>Fixed deprecated calls for template variables</li> <li>Fixed wrong palette color for focused search result</li> <li>Fixed JavaScript errors on 404 page</li> <li>Fixed missing top spacing on 404 page</li> <li>Fixed missing right spacing on overflow of source container</li> </ul>"},{"location":"changelog/#1.5.2","title":"1.5.2 April 5, 2017","text":"<ul> <li>Added requirements as explicit dependencies in <code>setup.py</code></li> <li>Fixed non-synchronized transitions in search form</li> </ul>"},{"location":"changelog/#1.5.1","title":"1.5.1 March 30, 2017","text":"<ul> <li>Fixed rendering and offset of targeted footnotes</li> <li>Fixed #238: Link on logo is not set to <code>site_url</code></li> </ul>"},{"location":"changelog/#1.5.0","title":"1.5.0 March 24, 2017","text":"<ul> <li>Added support for localization of search placeholder</li> <li>Added keyboard events for quick access of search</li> <li>Added keyboard events for search control</li> <li>Added opacity on hover for search buttons</li> <li>Added git hook to skip CI build on non-src changes</li> <li>Fixed non-resetting search placeholder when input is cleared</li> <li>Fixed error for unescaped parentheses in search term</li> <li>Fixed #229: Button to clear search missing</li> <li>Fixed #231: Escape key doesn't exit search</li> <li>Removed old-style figures from font feature settings</li> </ul>"},{"location":"changelog/#1.4.1","title":"1.4.1 March 16, 2017","text":"<ul> <li>Fixed invalid destructuring attempt on NodeList (in Safari, Edge, IE)</li> </ul>"},{"location":"changelog/#1.4.0","title":"1.4.0 March 16, 2017","text":"<ul> <li>Added support for grouping searched sections by documents</li> <li>Added support for highlighting of search terms</li> <li>Added support for localization of search results</li> <li>Fixed #216: table of contents icon doesn't show if <code>h1</code> is not present</li> <li>Reworked style and layout of search results for better usability</li> </ul>"},{"location":"changelog/#1.3.0","title":"1.3.0 March 11, 2017","text":"<ul> <li>Added support for page-specific title and description using metadata</li> <li>Added support for linking source files to documentation</li> <li>Fixed jitter and offset of sidebar when zooming browser</li> <li>Fixed incorrectly initialized tablet sidebar height</li> <li>Fixed regression for #1: GitHub stars break if <code>repo_url</code> ends with a <code>/</code></li> <li>Fixed undesired white line below copyright footer due to base font scaling</li> <li>Fixed issue with whitespace in path for scripts</li> <li>Fixed #205: support non-fixed (static) header</li> <li>Refactored footnote references for better visibility</li> <li>Reduced repaints to a minimum for non-tabs configuration</li> <li>Reduced contrast of edit button (slightly)</li> </ul>"},{"location":"changelog/#1.2.0","title":"1.2.0 March 3, 2017","text":"<ul> <li>Added <code>quote</code> (synonym: <code>cite</code>) style for admonitions</li> <li>Added help message to build pipeline</li> <li>Fixed wrong navigation link colors when applying palette</li> <li>Fixed #197: Link missing in tabs navigation on deeply nested items</li> <li>Removed unnecessary dev dependencies</li> </ul>"},{"location":"changelog/#1.1.1","title":"1.1.1 February 26, 2017","text":"<ul> <li>Fixed incorrectly displayed nested lists when using tabs</li> </ul>"},{"location":"changelog/#1.1.0","title":"1.1.0 February 26, 2017","text":"<ul> <li>Added tabs navigation feature (optional)</li> <li>Added Disqus integration (optional)</li> <li>Added a high resolution Favicon with the new logo</li> <li>Added static type checking using Facebook's Flow</li> <li>Fixed #173: Dictionary elements have no bottom spacing</li> <li>Fixed #175: Tables cannot be set to 100% width</li> <li>Fixed race conditions in build related to asset revisioning</li> <li>Fixed accidentally re-introduced Permalink on top-level headline</li> <li>Fixed alignment of logo in drawer on IE11</li> <li>Refactored styles related to tables</li> <li>Refactored and automated Docker build and PyPI release</li> <li>Refactored build scripts</li> </ul>"},{"location":"changelog/#1.0.5","title":"1.0.5 February 18, 2017","text":"<ul> <li>Fixed #153: Sidebar flows out of constrained area in Chrome 56</li> <li>Fixed #159: Footer jitter due to JavaScript if content is short</li> </ul>"},{"location":"changelog/#1.0.4","title":"1.0.4 February 16, 2017","text":"<ul> <li>Fixed #142: Documentation build errors if <code>h1</code> is defined as raw HTML</li> <li>Fixed #164: PyPI release does not build and install</li> <li>Fixed offsets of targeted headlines</li> <li>Increased sidebar font size by <code>0.12rem</code></li> </ul>"},{"location":"changelog/#1.0.3","title":"1.0.3 January 22, 2017","text":"<ul> <li>Fixed #117: Table of contents items don't blur on fast scrolling</li> <li>Refactored sidebar positioning logic</li> <li>Further reduction of repaints</li> </ul>"},{"location":"changelog/#1.0.2","title":"1.0.2 January 15, 2017","text":"<ul> <li>Fixed #108: Horizontal scrollbar in content area</li> </ul>"},{"location":"changelog/#1.0.1","title":"1.0.1 January 14, 2017","text":"<ul> <li>Fixed massive repaints happening when scrolling</li> <li>Fixed footer back reference positions in case of overflow</li> <li>Fixed header logo from showing when the menu icon is rendered</li> <li>Changed scrollbar behavior to only show when content overflows</li> </ul>"},{"location":"changelog/#1.0.0","title":"1.0.0 January 13, 2017","text":"<ul> <li>Introduced Webpack for more sophisticated JavaScript bundling</li> <li>Introduced ESLint and Stylelint for code style checks</li> <li>Introduced more accurate Material Design colors and shadows</li> <li>Introduced modular scales for harmonic font sizing</li> <li>Introduced git-hooks for better development workflow</li> <li>Rewrite of CSS using the BEM methodology and SassDoc guidelines</li> <li>Rewrite of JavaScript using ES6 and Babel as a transpiler</li> <li>Rewrite of Admonition, Permalinks and CodeHilite integration</li> <li>Rewrite of the complete typographical system</li> <li>Rewrite of Gulp asset pipeline in ES6 and separation of tasks</li> <li>Removed Bower as a dependency in favor of NPM</li> <li>Removed custom icon build in favor of the Material Design icon set</li> <li>Removed <code>_blank</code> targets on links due to vulnerability: http://bit.ly/1Mk2Rtw</li> <li>Removed unversioned assets from build directory</li> <li>Restructured templates into base templates and partials</li> <li>Added build and watch scripts in <code>package.json</code></li> <li>Added support for Metadata and Footnotes Markdown extensions</li> <li>Added support for PyMdown Extensions package</li> <li>Added support for collapsible sections in navigation</li> <li>Added support for separate table of contents</li> <li>Added support for better accessibility through REM-based layout</li> <li>Added icons for GitHub, GitLab and BitBucket integrations</li> <li>Added more detailed documentation on specimen, extensions etc.</li> <li>Added a <code>404.html</code> error page for deployment on GitHub Pages</li> <li>Fixed live reload chain in watch mode when saving a template</li> <li>Fixed variable references to work with MkDocs 0.16</li> </ul>"},{"location":"changelog/#0.2.4","title":"0.2.4 June 26, 2016","text":"<ul> <li>Fixed improperly set default favicon</li> <li>Fixed #33: Protocol relative URL for webfonts doesn't work with <code>file://</code></li> <li>Fixed #34: IE11 on Windows 7 doesn't honor <code>max-width</code> on <code>main</code> tag</li> <li>Fixed #35: Add styling for blockquotes</li> </ul>"},{"location":"changelog/#0.2.3","title":"0.2.3 May 16, 2016","text":"<ul> <li>Fixed #25: Highlight inline fenced blocks</li> <li>Fixed #26: Better highlighting for keystrokes</li> <li>Fixed #30: Suboptimal syntax highlighting for PHP</li> </ul>"},{"location":"changelog/#0.2.2","title":"0.2.2 March 20, 2016","text":"<ul> <li>Fixed #15: Document Pygments dependency for CodeHilite</li> <li>Fixed #16: Favicon could not be set through <code>mkdocs.yml</code></li> <li>Fixed #17: Put version into own container for styling</li> <li>Fixed #20: Fix rounded borders for tables</li> </ul>"},{"location":"changelog/#0.2.1","title":"0.2.1 March 12, 2016","text":"<ul> <li>Fixed #10: Invisible header after closing search bar with ESC key</li> <li>Fixed #13: Table cells don't wrap</li> <li>Fixed empty list in table of contents when no headline is defined</li> <li>Corrected wrong path for static asset monitoring in Gulpfile.js</li> <li>Set up tracking of site search for Google Analytics</li> </ul>"},{"location":"changelog/#0.2.0","title":"0.2.0 February 24, 2016","text":"<ul> <li>Fixed #6: Include multiple color palettes via <code>mkdocs.yml</code></li> <li>Fixed #7: Better colors for links inside admonition notes and warnings</li> <li>Fixed #9: Text for prev/next footer navigation should be customizable</li> <li>Refactored templates (replaced <code>if</code>/<code>else</code> with modifiers where possible)</li> </ul>"},{"location":"changelog/#0.1.3","title":"0.1.3 February 21, 2016","text":"<ul> <li>Fixed #3: Ordered lists within an unordered list have <code>::before</code> content</li> <li>Fixed #4: Click on Logo/Title without Github-Repository: <code>\"None\"</code></li> <li>Fixed #5: Page without headlines renders empty list in table of contents</li> <li>Moved Modernizr to top to ensure basic usability in IE8</li> </ul>"},{"location":"changelog/#0.1.2","title":"0.1.2 February 16, 2016","text":"<ul> <li>Fixed styles for deep navigational hierarchies</li> <li>Fixed webfont delivery problem when hosted in subdirectories</li> <li>Fixed print styles in mobile/tablet configuration</li> <li>Added option to configure fonts in <code>mkdocs.yml</code> with fallbacks</li> <li>Changed styles for admonition notes and warnings</li> <li>Set download link to latest version if available</li> <li>Set up tracking of outgoing links and actions for Google Analytics</li> </ul>"},{"location":"changelog/#0.1.1","title":"0.1.1 February 11, 2016","text":"<ul> <li>Fixed #1: GitHub stars don't work if the repo_url ends with a <code>/</code></li> <li>Updated NPM and Bower dependencies to most recent versions</li> <li>Changed footer/copyright link to Material theme to GitHub pages</li> <li>Made MkDocs building/serving in build process optional</li> <li>Set up continuous integration with Travis</li> </ul>"},{"location":"changelog/#0.1.0","title":"0.1.0 February 9, 2016","text":"<ul> <li>Initial release</li> </ul>"},{"location":"channels/IVR-integration/","title":"IVR Integration","text":"<p>Interactive Voice Response (IVR) systems are preferred in many leading organizations to automate customer interactions. However, if you are using an IVR  system, you may often encounter the following two issues:</p> <ul> <li>Non-Intuitive Interface: IVR systems do not simply let the customers state their needs, they make the users go through an extensive list of menu options, from which customers must select before finding the intent. Even if they allow users to express their intent at first, the backend programs can only understand a limited number of phrases.</li> <li> <p>Static Flows: IVR systems use static call flows that do not align with the nonlinear and contextual nature of human interactions. Following is a scenario where a customer is trying to Book Flight tickets:</p> <pre><code>User: Book me a ticket to NYC\nIVR: Sure, for which date?\nUser: Wait, will it rain there this Sunday?\nIVR: Sorry, I don't understand the input.\n</code></pre> </li> </ul> <p>Conventional IVR systems do not have diversified options for the users to articulate their requests beyond the rigid program flows.</p>"},{"location":"channels/IVR-integration/#koreai-ivr-support","title":"Kore.ai IVR Support","text":"<p>Kore.ai XO Platform allows you to give a conversational makeover to your IVR system. It lets you build Virtual Assistants with human-like conversation capabilities and integrate them with your existing IVR system, thus taking your organization\u2019s customer service experience to a new level.</p> <p>The following features enable  the seamless integration of your Kore.ai VAs with your existing IVR:</p> <ul> <li>Native VXML Support: Built-in support to parse and generate World Wide Web Consortium (W3C) compliant Voice Extensible Markup Language(VXML) files.</li> <li>Hybrid integration: Flexibility to build use cases or dialogs on the  Kore.ai Experience Optimization (XO) Platform, which can work in sync with the IVR dialogs.</li> <li>Discourse Analyzer: Kore.ai\u2019s discourse analyzer helps enterprises generate conversation flows using historical chat or call transcripts. Chat and call transcripts are analyzed using neural network-based machine learning models to identify intents and discourse patterns to fulfill a specific intent. This is an out-of-the-box feature that is in Beta state. Contact our support team if you want to try this feature.</li> <li>Granular Call Flow Support: Ability to define all the call flow elements such as grammar, prompts, retry and time-out periods. Kore.ai supports call termination handlers, and allows you to end calls or invoke dialogs in case of exceptions.</li> </ul>"},{"location":"channels/IVR-integration/#ivr-set-up","title":"IVR Set Up","text":"<p>To setup IVR integration, perform the following steps:</p> <ol> <li>Configure IVR Settings: Define IVR settings such as transcription options, welcome messages, standard responses, and VXML properties.</li> <li>Configure Dialog Node IVR Properties: Define dialog by configuring node-specific grammar, prompts, and call flow behavior like time-out, retries.</li> <li>IVR Channel Setup: Set up authentication, configure WebHook in your IVR system and enable channel.</li> </ol>"},{"location":"channels/IVR-integration/#configure-ivr-settings","title":"Configure IVR Settings","text":"<p>This section explains the IVR settings you need to configure for your Virtual Assistant (VA). As a first step, you must enable the IVR settings for the VA and define the **Transcription **options and **VXML **properties. These settings act as the default for the VA. You can override VXML properties configured at the VA level by defining custom values at the node level of the Dialog tasks.</p> <p>Steps to configure IVR settings for your Virtual Assistant:</p> <ol> <li>Open the VA for which you want to integrate the IVR.</li> <li>Go to the **Deploy **tab from the top menu.</li> <li>The Channels page is displayed. Locate and click the IVR under Voice Channels. \\       The IVR Panel with Instructions is displayed.   </li> <li>On the Configurations tab, perform the following steps:</li> <li>Use Kore.ai IVR Sandbox for testing your VA. See Sandbox Configuration for more details.</li> <li>Associate an App with the IVR channel, either by creating a new one or selecting an existing one. If you do not have any apps, a message is displayed as shown in the following screenshot.  </li> <li>Use the WebHook URL provided in your external application.</li> <li>Enter the details to complete the setup, see Voice Call Properties: Channel Settings for more information.  </li> <li>From the Voice Call Properties tab, set the configurations.</li> <li>The Platform supports all UniMRCP-encoded voice-to-text services. If you select the Enable Transcription option for the VA, then the platform allows you to skip defining grammar during configuring IVR settings for any node (described in Configure Dialog Node IVR Properties). See Voice Call Properties: Configuring Grammar for a detailed configuration for Grammar syntax.</li> </ol> <p>Note</p> <p>If you already have created apps, then select an app from the Select App drop-down or create a new app. See Sandbox Configuration steps to know more.</p> <p>Note</p> <p>If you have enabled IVR Sandbox, the following settings are required to be configured on the platform. These are pre-populated if you do not enable the IVR settings. In case you have enabled the settings, ensure the values are the same as follows:  \u2013 Enable Transcription set to Yes.  \u2013 Transcription engine source set to builtin:speech/transcribe.  \u2013 IVR Data Extraction Key set to user input.  \u2013 ASR Confidence Threshold Key set to userinput confidence.  \u2013 ASR Threshold Confidence set to 50.</p> <p> </p> <p>Note</p> <p>Sandbox may not respond as expected if you use different values.</p> <p>Note</p> <p>If you save the configuration after associating  an app without enabling IVR Settings, the  platform pre-populates the required settings for Sandbox.</p> <p>Once you have enabled the IVR channel, configure the Telephony Welcome Event in IVR Settings. This plays a welcome message for users when they connect to the VA through the IVR channel.</p> <p>Steps to configure Telephony Welcome Event:</p> <ol> <li>Under the Build tab, select Intelligence &gt; Events.</li> <li>Select the Use Voice Call Properties option to open the voice settings section.</li> <li>Under the Initial Prompts text field, enter the message that needs to be played when the user connects to the VA. To know more about other configuration fields, see the Voice Call Properties: Dialog Node Settings section. </li> </ol>"},{"location":"channels/IVR-integration/#sandbox-configuration","title":"Sandbox Configuration","text":"<p>Note</p> <p>This option was introduced in ver 7.1 of the platform. It is not available for on-prem installation.</p> <p>Kore.ai XO Platform offers an IVR Sandbox environment to instantly launch your VA for interactions over voice calls. This is useful when a working IVR system is not available for testing your VA over a voice channel. IVR Sandbox is an optional integration and it can coexist with your custom IVR integration.</p> <p>Enabling this option generates a** Phone Number, Pin, and **Secret. To develop and test it with your teams, you can call your VA by using the phone number and PIN allocated for your VA. On receiving the valid Pin and Secret you will be connected with the VA for interactions. See the following steps to understand the Sandbox configuration.</p> <ol> <li>To enable the Sandbox, select Enable for Kore.ai IVR Sandbox under the Configurations tab.  </li> <li>In the Select App drop-down, select an existing app or create a new app by clicking the Add button or choosing the Create App option.</li> <li>The details are populated for an existing app, as shown in the following screenshot.   </li> <li>Click Save.</li> <li>The following pop-up is displayed for the new app creation. Enter the details and click Create to create the app.   </li> <li>Upon saving the details, the following pop-up is displayed with Phone Number, PIN and Secret values. Click OK.</li> <li>Once enabled, you can access the IVR Sandbox interaction details by clicking the Test button, which becomes visible upon hovering over the IVR icon under the Configured Channels.   </li> <li>On clicking Test, the following pop-up is displayed. </li> </ol> <p>The Phone Number, PIN, and Secret are populated in the IVR Configurations panel as shown in the following screenshot. </p> <p>IVR Sandbox Limitations:</p> <ul> <li>The platform supports only a limited number of concurrent lines, hence calls to your VAs through IVR Sandbox may not be answered at times.</li> <li>We strongly recommend you use IVR Sandbox only for internal testing purposes and not for the end-users of your Virtual Assistants, as there might be some functional limitations.</li> </ul>"},{"location":"channels/IVR-integration/#configure-dialog-node-ivr-properties","title":"Configure Dialog Node IVR Properties","text":"<p>You can configure IVR properties for a node in a dialog task. Click the IVR Properties icon and  enter initial prompts, define Grammar, enter timeout, number of retries and other available fields. To know more about dialog definition, see the Voice Call Properties: Dialog Node Settings section.</p> <p></p>"},{"location":"channels/IVR-integration/#ivr-channel-setup","title":"IVR Channel Setup","text":"<p>This section explains the IVR channel setup for your virtual assistant. After configuring IVR Settings at both the VA and the Dialog levels, you must configure IVR Channel for the VA. IVR channel provides a generic integration to connect VAs with IVR systems. Kore.ai XO platform generates required VXML files to be exchanged as part of the VA interaction with the end user through the IVR systems.</p> <p>Enable IVR Channel and Associate with an APP</p> <p>Kore.ai Virtual Assistants require a JWT token to authenticate the incoming requests from IVR. For generating a JWT token, you should associate an app with the VA. You can select any existing Apps available in your Kore.ai account or create a new app.</p> <ol> <li>Go to Deploy &gt; Channels in the left navigation panel of the virtual assistant.</li> <li> <p>On the Channels page, click IVR. The IVR Channel Instructions panel is displayed.  </p> </li> <li> <p>The **IVR Voice Sample CURL **request is as follows:  <pre><code> `curl --location --request POST\n '{{host}}/ivr/hooks/{{streamId}}?token={{token}}'  \n   --header 'Content-Type: application/json'\n   --data-raw '{\n       \"callId\":\"98ab21298XXXXX46\",\n       \"message\":\"check balance\",\n        \"from\":\"1402XXX455\",\n        \"app_root\":\"app.vxml\"\n}'\n</code></pre>  The following table provides the descriptions of all the mandatory and optional request parameters:</p> </li> </ol> PARAMETER REQUIRED DESCRIPTION      callId          Y          Unique Id to identify or create a new user          message          Y          Message from User. If the value is empty, then the Welcome message will be triggered.          from          N          Created as a secondary user identity          app_root          N          Select any document to be the application root document  **Note**: The application root contains the file path, which is an entry point for the application.            token          N          The JWT token can be passed in the body if it is not provided as a query parameter.     <ol> <li>Click the Configurations tab.</li> </ol> <p> 5. From the Select App drop-down list, select an existing App or create a new app. See Configure IVR Settings to know more.</p> <ol> <li>Copy the following values:</li> <li>WebHook URL: For calling the VA from IVR.</li> <li>Client Secret: To generate a JWT token that must be appended to the WebHook URL.    </li> <li>Select Yes for Enable Channel.</li> </ol> <p>Note</p> <p>The Webhook Payload is used to test the IVR channel configuration for your VA. It can be tested using Postman.</p> <p>Generating JWT Token</p> <ol> <li> <p>To generate the JWT Token, click here.</p> </li> <li> <p>JWT has to be passed in the IVR hook URL as a value for the query parameter \u201ctoken\u201d: <code>https://{{host}}/ivr/hooks/{{botId}}?token={{JWT}} \\</code>The token can also be passed as the body parameter.</p> </li> </ol> <p>Note</p> <p>For a quick overview of the JWT token, refer to Introduction to JWT tokens.</p> <p>Note</p> <p>The host name, {{host}} refers to an environment URL, for example, https://bots.kore.ai. It changes based on the domain name.</p> <p>Call The Virtual Assistant From IVR Call flow</p> <p>You can pass data to the VA from the IVR call flow using VXML &gt; subdialog &gt; as shown in the following screenshot. The subdialog src should be Webhook URL with JWT Token, which receives the following parameters as Input.   </p> <ul> <li>message: Message from User. If the value is empty, then Welcome message would be triggered.</li> <li>callId:  A unique Call ID, based on which the VA identifies the IVR sessions</li> <li>from: Unique User\u2019s Identity, e.g., Phone Number</li> <li>to: Bot Stream Id</li> </ul> <p>The endOfConversation variable should be processed through the data returned from the sub-dialog. If the value is true, it indicates that the dialog execution (conversation) is complete. It can be a trigger point to end the call with the user.</p>"},{"location":"channels/IVR-integration/#asr-metadata-extraction","title":"ASR Metadata Extraction","text":"<p>The Automatic Speech Recognition (ASR) engine configured by bot engineers compares the speech input with many pre-specified possibilities and converts the speech to text. In addition to the \u2018text,\u2019 the bot designers need additional information from the ASR engine that helps them customize the conversation flow and the user experience. The two major additional details extracted from the ASR Metadata are:</p> <ul> <li>Input Mode (Speech or DTMF) \u2013 The mode used by the user to provide the input. The two modes available include Speech and DTMF.</li> <li>ASR Confidence \u2013 The confidence with which the ASR engine identifies the user input.</li> </ul> <p>To extract the metadata from the ASR transcription, follow these steps:</p> <ol> <li>In IVR Channel settings under Voice Call Properties various details like Input Mode, ASR Confidence Threshold etc. are configured.  </li> <li>See Voice Call Properties: Channel Settings for more information.The additional information provided by the ASR engines can be extracted using the context object. This is configured at  Bot User Session \u2192 lastMessage \u2192  asrMetaData.</li> <li>Go to the Settings panel of the last message node for your dialog task and configure the JavaScript Message under Bot Responses, as shown below:    The ASR metadata is extracted in the response using the following syntax:</li> </ol> <p><code>print(JSON.stringify(context.session.BotUserSession.lastMessage.asrMetaData))</code> </p> <p>In this example, based on the ASR Confidence value extracted from the user input, we define the connection rules for the dialog as shown below:</p> <p> 4. Go to Analyze \u2192 NLP Insights of your Virtual Assistant on the Kore.ai XO Platform.    5. Click on the relevant utterance to see the Chat History **details. 6. Click the **ellipsis icon on top of the Javascript Message to view the details of the **ASR metadata **extracted from the response.   </p> <p>In this example, the parameters like ASR Confidence, score,input mode, utterance, etc. are extracted in the syntax shown below:</p> <pre><code> ```\n\n data:\n {\n \"text\":\n {\n   \"confidence\": \"0.810000\",\n   \"Inputmode\": \"voice\",\n   \"interpretation\": \"Login.\",\n   \"utterance\": \"Login.\"\"\n }\n\n ```\n</code></pre> <p>Note</p> <p>The information is available for the existing and new virtual assistants whose IVR channel is enabled.</p>"},{"location":"channels/add-cisco-channel/","title":"Adding the Cisco Webex Teams","text":"<p>To add the Cisco Webex Teams (formerly Cisco Webex) channel to your VA, the developer must create a dedicated VA app and an integration app in Cisco Webex Teams.</p> <p>Adding the Cisco Webex Teams channel to your Kore.ai VA is a four-step process to allow end-users to interact with it using their _Webex _accounts.</p>"},{"location":"channels/add-cisco-channel/#step-1-create-a-bot-with-cisco-webex-team","title":"Step 1: Create a Bot with Cisco Webex Team","text":"<p>To create a Bot from within Cisco Webex Teams, please follow the steps below:</p> <ol> <li>Log in to the Cisco Webex Developer Portal and proceed to the Start Building Apps page or to the My Webex Apps page.</li> <li> <p>Click the Create a New App option and choose the Create a Bot option. </p> </li> <li> <p>Provide all the required information to create the bot and click on Add Bot.</p> </li> <li>This step will create a Bot User and an Access Token is also generated for accessing this bot.</li> <li>Make a note of the Bot Username and Access Token from this page. </li> </ol>"},{"location":"channels/add-cisco-channel/#step-2-enable-the-cisco-webex-team-channel-from-the-xo-platform","title":"Step 2: Enable the Cisco Webex Team channel from the XO Platform","text":"<ol> <li>In the XO Platform, select the assistant you want to add the channel to.</li> <li>Go to Deploy &gt; Channels, and select Cisco Webex Teams. The channel window opens.</li> <li>Enter the Bot Username and Access Token from the previous step.</li> <li>Make a note of the Redirect URL.</li> </ol>"},{"location":"channels/add-cisco-channel/#step-3-set-up-an-integration-with-cisco-webex-team","title":"Step 3: Set Up an Integration with Cisco Webex Team","text":"<ol> <li>On the Cisco Webex Team Developer portal, click the Profile drop-down list on the top-right and go to the My Webex Apps page.</li> <li>Click Create a New App and choose the Create an Integration option to add a new integration app for Webex.</li> <li>Provide all the required details to create the integration like integration name, description, logo, etc. This information must be user-facing as this is displayed to end-users in the permissions dialog.</li> <li>For Redirect URI(s), paste the Redirect URL from the previous step.</li> <li>Under Scopes, select spark:all for enabling bot communication.</li> <li>After providing all the required information, click the Add Integration to create the new integration app.</li> <li>This step creates a new integration app and also generates the Client ID and Client Secret for this app.</li> <li> <p>Make a note of the Client Id and Client Secret.</p> <p>For more information, read Cisco\u2019s documentation</p> <p></p> </li> </ol> <p>Note</p> <p>The Redirect URI now includes the streamid in the API request to identify the virtual assistant being accessed. When an incoming request is qualified with this identifier, it helps with traceability, troubleshooting, and remediation at the network level during anomalies like malicious calls or unusual bot activity.</p>"},{"location":"channels/add-cisco-channel/#step-4-complete-cisco-webex-team-channel-configuration-from-the-xo-platform","title":"Step 4: Complete Cisco Webex Team Channel Configuration from the XO Platform","text":"<ol> <li>In the XO Platform, on the Channel Configuration page, enter the Post URL where you want Webex Client ID and Client Secret noted in the previous step.</li> <li>Enable Channel to complete the configuration.</li> <li>Save the configuration. </li> </ol> <p>After the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available for end-users, with the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/add-cisco-jabber-channel/","title":"Adding the Cisco Jabber Channel","text":"<p>Cisco Jabber is a platform that offers multiple communication methods, and which you can integrate with the assistants built with the Kore.ai XO Platform. Adding the Jabber channel to your Kore.ai VA allows end-users to interact with it using their Jabber accounts. This article shows you how to add it as a Channel, where your VA can communicate to end-users via Jabber. You must have or register for a developer account in the Jabber portal.</p>"},{"location":"channels/add-cisco-jabber-channel/#configuration","title":"Configuration","text":"<p>To add the Cisco Jabber channel, follow the below steps:</p> <ol> <li>Select the assistant that you want to add the Jabber channel to.</li> <li>Go to Deploy &gt; Channels.</li> <li>Click the** Jabber** icon. The Jabber Channel page is displayed.</li> <li>To enable a webhook integration on your Jabber application, log into your Jabber app. Copy the Webhook URL from the Configurations tab on the Jabber channel page and enter the Webhook URL field in the Jabber app for integration.</li> <li>Go to the Configurations tab on the Jabber channel page to complete the channel setup.</li> <li>Capture the POST URL details from your Jabber app and enter them in the POST URL field.</li> <li>You can also optionally generate and capture the Access Token **details from your Jabber integration and enter in the Access Token field** to enable secure communication between Jabber and the VA.</li> <li>Select Yes and click Save to enable Jabber Channel. </li> </ol> <p>After enabling the channel and verifying all the configurations, you can optionally publish the assistant for the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p> <p>Following are code snippets of the payload formats for verifying the integration.</p>"},{"location":"channels/add-cisco-jabber-channel/#payload-for-post-url","title":"Payload for Post URL","text":"<p>Below is the response message from the bot that must be accepted by the POST URL that is registered in the Configurations tab.</p> <pre><code>  {\n                \"message\": {\n                \"text\" : \"Hi\"\n                }\n                \"to\" : \"&lt;recipient-id/group-id&gt;\",\n                \"from\" : \"&lt;sender-id&gt;\"\n             }\n</code></pre>"},{"location":"channels/add-cisco-jabber-channel/#webhook-payload","title":"Webhook Payload","text":"<p>Below is the Webhook payload format to post messages to the Kore.ai Bots Platform from Jabber.</p> <pre><code>{\n  {\n    \"message\": {\n        \"text\" : \"&lt;Message&gt;\",\n        \"attachments\" : [&lt;array of attachment links (optional)&gt;]\n    },\n    \"from\" : {\n        \"id\": \"&lt;unique-id-of-sender(mandatory)&gt;\",\n        \"userInfo\" : {\n          \"firstName\" : \"&lt;first-name(optional)&gt;\",\n          \"lastName\" : \"&lt;second-name(optional)&gt;\",\n          \"email\" : \"&lt;email(optional)&gt;\"\n        }\n    },\n    \"to\" : {\n        \"id\": &lt;unique-id-of-recipient(mandatory)&gt;,\n        \"groupInfo\" : { //If message comes from a group/team/room conversations.\n            \"id\" : \"&lt;unique-id-of-group&gt;\",\n            \"name\": \"&lt;group-name(optional)&gt;\"\n        }\n    }\n}\n</code></pre>"},{"location":"channels/add-genesys-chat-channel/","title":"Adding Genesys Chat as a Channel","text":"<p>The Kore.ai XO Platform now allows you to add Genesys Chat as a messaging channel for your Virtual Assistants (VAs). Genesys Chat helps instantly share your ideas with people inside your organization with the persistent chat history feature to start a conversation with your colleagues and continue it anywhere any time.</p> <p>With the Genesys Chat integration on the Kore.ai XO Platform, you can achieve the following:</p> <ul> <li>Set up the REST API and authorization flow for events and conversations.</li> <li>Link the app to the Kore.ai XO Platform using the app\u2019s credentials.</li> <li>Deploy the VAs and transfer conversations to the Genesys Agent System.</li> <li>Leverage various templates like Button, Quick Replies, and Bullets List provided by Genesys for message formatting.</li> <li>Accept any attachments in the chat messages that Genesys supports.</li> </ul> <p>After the integration, you can do the following:</p> <ul> <li>Track Virtual Assistant conversations.</li> <li>Listen to new messages from Genesys Chat.</li> <li>Have VAs post and respond to messages in Genesys Chat conversations.</li> <li>Have VAs handle incoming notifications from your apps into Genesys Chat.</li> </ul> <p>To set up Genesys Chat as a channel, you should create an account on the Genesys Cloud Platform and enable a webhook for the platform to receive messages.</p> <p>The steps to add the channel are summarized below:</p> <ol> <li>Create a Bot Connector.</li> <li>Create an inbound message flow.</li> <li>Configure the Messenger SDK.</li> <li>Enable the Channel.</li> <li>Publish the Bot.</li> </ol>"},{"location":"channels/add-genesys-chat-channel/#step-1-create-a-bot-connector","title":"Step 1: Create a Bot Connector","text":"<p>A Bot Connector service enables your bot to exchange messages with the Genesys Agent System configured on the Kore.ai XO Platform by using industry-standard REST and JSON over HTTPS.</p> <ol> <li>Log in to the Genesys Developer Portal.</li> <li> <p>Create a Bot Connector with the steps below:</p> <ul> <li>Navigate to Admin &gt; Integrations on the left menu.</li> <li>Click the Configuration tab.</li> <li> <p>On the Kore.ai XO Platform, navigate to Deploy &gt; Channels &gt; Genesys Chat. </p> </li> <li> <p>Copy the Webhook URL from the Configurations section.</p> </li> <li>Paste it in the Value field of the Properties section under Configuration on the Genesys Chat Portal. </li> <li>In the Genesys Cloud login URL field under Configuration, provide the URL of your Genesys AWS Region which will allow the platform to correctly route the conversation requests. This is a mandatory field. You can find the URL of your region through the link provided with the field. </li> <li>Create an app on the Kore.ai XO platform. A JWT Token is created with the clientId and clientSecret credentials. To create an app, follow the steps below:</li> <li>Click the Create App link under the Configurations section of the Genesys Chat Channel. </li> <li>Follow the steps mentioned here. Note: Select HS256 for JWT Signing Algorithms Used For Client App Authentication.</li> <li>Copy the Client Secret value of the app you\u2019ve created.</li> <li>Navigate to the Configuration &gt; Credentials page, and click Change. </li> <li>Paste the copied Client Secret in the Value field when the Change Credentials window appears.</li> <li>Click OK. </li> <li>Once you paste all the required credentials, click Authorize to validate the authorization. </li> </ul> <p>Your Bot Connector is created successfully!</p> </li> </ol>"},{"location":"channels/add-genesys-chat-channel/#step-2-create-an-inbound-message-flow","title":"Step 2: Create an Inbound Message Flow","text":"<p>To create an inbound message flow after connecting your VA to the Bot Connector, follow the steps below:</p> <ol> <li>Navigate to Admin &gt; Architect on the Genesys Bot Connector page.</li> <li>Click the Flows: Inbound Message tab.</li> <li>Click the Add button.</li> <li>In the Create \u2018Inbound Message Flow\u2019 window, enter the values for the required fields.</li> <li>Click Create Flow. </li> <li> <p>After creating the Inbound Message Flow, follow the steps below:</p> <ul> <li>Click the flow you\u2019ve created in the list.</li> <li>Click the Initial State icon on the top menu.</li> <li>Select the Call Bot Connector option by navigating to Start &gt; Toolbox &gt; Bot. </li> <li>Select the bot connector and the relevant Bot from the list.</li> <li>Enter values for the given fields. </li> </ul> </li> <li> <p>Click Publish on the top panel.</p> </li> </ol>"},{"location":"channels/add-genesys-chat-channel/#step-3-configure-the-messenger-sdk","title":"Step 3: Configure the Messenger SDK","text":"<p>After creating the inbound messaging flow, you should configure and deploy the messenger with the steps below:</p> <ol> <li>Navigate to Admin &gt; Message &gt; Messenger Deployments.</li> <li>Enter the values for Name and Description.</li> <li>Set Status to Active.</li> <li>For Select your Configuration, select the Messenger Configuration to assign it to the deployment.</li> <li>For Restrict Domain Access, select Allow all domains.</li> <li>For Select your Architect Flow, select your Message Flow created in the previous step.</li> <li> <p>Click Save.   The system routes the message sent by the user via the Genesys Messenger to the message flow.   </p> </li> <li> <p>Paste the script generated in the messenger deployment on the HTML page where you want to add the Genesys Messenger.   </p> </li> </ol>"},{"location":"channels/add-genesys-chat-channel/#step-4-enable-the-channel","title":"Step 4: Enable the Channel","text":"<p>After you\u2019ve configured the Genesys Messenger and deployed it for your Virtual Assistant, you must enable the Genesys Chat Channel by following the steps below:</p> <ol> <li>Navigate to Deploy &gt; Channels &gt; Genesys Chat on the Kore.ai XO Platform.</li> <li>Click the Configurations tab.</li> <li>Select YES for Enable Channel.</li> <li>Click Save.</li> </ol>"},{"location":"channels/add-genesys-chat-channel/#step-5-publish-the-bot","title":"Step 5: Publish the Bot","text":"<p>After enabling the channel and verifying all the configurations, you can test the new channel integration by publishing your virtual assistant. Learn more.</p> <p>To learn more about working with messaging channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/add-google-business-messaging-channel/","title":"Adding the Google Business Messaging Channel","text":"<p>Modern business applications require agent integrations on web/mobile devices to enable seamless customer communication via SMS/chats.</p> <p>The Kore.ai XO Platform now helps a Google Business Messaging Partner to create rich and asynchronous messaging experiences within apps and during calls through the GBM channel enablement. This feature helps seamlessly integrate real-time business agents to Virtual Assistants.</p> <p>Google Business Messaging (GBM) is a mobile conversational channel that combines digital customer touchpoints or entry points on Google Maps, Search, and brand websites.</p>"},{"location":"channels/add-google-business-messaging-channel/#how-does-it-work","title":"How does it work?","text":"<p>The Kore.ai XO Platform registers each Business as a partner with Business Messages and the conversations between the customers and brands will be enabled by creating agents.</p> <p>Customers can send messages to your brand or its locations through these agents. When a user finds a brand that Kore.ai manages with the business in Google Search or Google Maps.</p> <p>When a customer clicks the button, a conversation is initiated with the brand\u2019s virtual agent on the device. Businesses can receive and respond to customer messages through an agent, which is a conversational entity that represents business functions, such as website support, and brand locations. Google delivers the message defined as a JSON payload to the Webhook that Kore.ai provides. The agent uses this Webhook and the Conversational Agent API to receive and respond to the customer\u2019s messages.</p>"},{"location":"channels/add-google-business-messaging-channel/#set-up-on-the-gbm-channel","title":"Set up on the GBM Channel","text":"<p>The important steps to set up the GBM channel are summarized below:</p> <ol> <li>Creating a Google Cloud Platform (GCP) project.</li> <li>Submitting the partner information to Google.</li> <li>Enabling the Conversational Agent API.</li> </ol> <p>Prerequisites</p> <ul> <li>An active Google account.</li> <li>The Partner Name field appears in the Google My Business (GMB) Console for locations associated with the agents you manage.</li> <li>A webhook endpoint URL that can accept messages (Kore.ai generates the webhook URL, which will be associated with a virtual assistant built on the platform).</li> </ul> <p>Create a Google Cloud Platform Project</p> <p>You must create and register a Google Cloud Platform (GCP) project to enable the Google Cloud API service for your partner account. Learn more.</p> <p>Tip<p>Please note the project number to register as a partner.</p> </p>"},{"location":"channels/add-google-business-messaging-channel/#gbm-channel-enablement-on-the-platform","title":"GBM Channel Enablement on the Platform","text":"<p>To set up the GBM channel on the Kore.ai XO Platform and launch the agent, follow the steps below:</p> <ol> <li>Register as a Google Business Messaging Partner.</li> <li>Create an agent for your account.</li> <li>Set up the Webhook for the agent.</li> <li>Create a Service Account Key.</li> <li>Configure the Virtual Assistant for the service account.</li> </ol>"},{"location":"channels/add-google-business-messaging-channel/#step1-register-as-a-gbm-partner","title":"Step1: Register as a GBM Partner","text":"<p>To integrate with the GBM channel, you need to register as a partner for Google Business Messaging with the steps below:</p> <ol> <li>Open the Business Communications Developer Console.</li> <li> <p>Under Business Messages, click Create partner account. </p> </li> <li> <p>Enter the values for the following fields in the Create a Business Messages partner account window:</p> </li> <li>Your Name</li> <li>Partner Name</li> <li>Partner Website</li> <li>Region</li> <li>Click Create. </li> </ol>"},{"location":"channels/add-google-business-messaging-channel/#step-2-create-an-agent-for-your-account","title":"Step 2: Create an Agent for your Account","text":"<p>To create an agent for your GBM Partner account, you must submit information on the brand and the agent on the Business Communications Developer Console with the steps below:</p> <p>Note<p>To manage multiple brands, you must create an agent for each brand.</p> </p> <ol> <li>Sign in to your account on the Business Communications Developer Console.</li> <li> <p>Click Create Agent. </p> </li> <li> <p>Enter the values for the Brand name and Agent name fields. </p> </li> <li> <p>Select Enable the Business Messages Helper Bot to activate the agent.</p> </li> <li>Click Create Agent.</li> <li>Click your agent\u2019s name when your agent is available.</li> </ol> <p>Please ensure you have the following values before you create an agent:</p> <ul> <li>Brand name</li> <li>Brand website</li> <li>Agent name to appear in conversations with users.</li> <li>Agent logo as a publicly available URL.</li> <li>Agent welcome message</li> <li>Live chat hours</li> <li>A physical location of the brand for testing purposes. Please avoid the corporate headquarters or other locations not represented by the brand agent.</li> <li>Partner name</li> <li>Partner ID</li> <li>GCP project number</li> <li>(Optional) Business ID identifies the brand in messages the webhook receives.</li> <li>Escalation of contact name, email, and phone number.</li> </ul> <p>Note<p>Once your agent is available, you can add the business and branding information.</p> </p>"},{"location":"channels/add-google-business-messaging-channel/#step-3-set-up-the-webhook-for-the-agent","title":"Step 3: Set up the Webhook for the Agent","text":"<p>After creating the agent, you need to copy the Webhook URL from the Kore.ai Platform and generate the Client Token for the agent to integrate for messaging and events. To set up the agent webhook, follow the steps below:</p> <ol> <li>Open the Business Communications Developer Console and sign in with your Business Messages Google account.</li> <li>Click on the panel with your agent\u2019s name.</li> <li>On the Business Communications **page, click **Integrations on the left menu.</li> <li> <p>For the Webhook option, click the Configure link. </p> </li> <li> <p>Copy the Webhook URL from the Kore.ai XO Platform under Deploy &gt; Channels &gt; Google Business Messaging &gt; Configurations. </p> </li> <li> <p>Paste the copied link for the Webhook endpoint URL field in the Configure your webhook window on the Business Communications Developer Console. </p> </li> <li> <p>Click the Refresh icon for the Client token field to generate the Client token.</p> </li> <li>Click Verify. </li> </ol> <p>The GBM platform sends a POST request to the Kore.ai XO Platform\u2019s webhook with the ClientToken and Secret Key parameters for verification before sending/receiving messages.</p>"},{"location":"channels/add-google-business-messaging-channel/#step-4-create-a-service-account-key","title":"Step 4: Create a Service Account Key","text":"<p>To send messages and events as your agent, you need to authenticate API calls with a service account key. The Business Communications Developer Console creates a service account for you, but you need to create a unique key to access your agent with the steps below:</p> <ol> <li> <p>On the left menu, click Service account. </p> </li> <li> <p>Click the Create key button. </p> </li> <li> <p>Click Create on the confirmation window to download the JSON file with the service account key. </p> </li> </ol> <p></p> <ol> <li>Rename the downloaded file to rbm-agent-service-account-credentials.json.</li> <li>Store the key securely to recover it if required.</li> </ol>"},{"location":"channels/add-google-business-messaging-channel/#step-5-configure-the-virtual-assistant-for-the-service-account","title":"Step 5: Configure the Virtual Assistant for the Service Account","text":"<p>To configure the virtual assistant for the service account on the Kore.ai XO Platform, follow the steps below:</p> <p>Tip<p>For the private key, please copy only the key value within the BEGIN PRIVATE KEY and END PRIVATE KEY header tags. The XO Platform adds these tags by default.</p> </p> <ol> <li>Copy the client_email, client_id, token_uri, and private_key values from the downloaded JSON file.</li> <li>Paste the values in the respective fields under Deploy &gt; Channels &gt; Enterprise Channels &gt; Google Business Messaging &gt; Configurations.</li> </ol> <p></p> <p></p> <ol> <li>Select Yes for the Enable Channel option.</li> <li>Click Save</li> </ol> <p>After enabling the channel and verifying all the configurations, you can test the new channel integration by publishing your virtual assistant. Learn more.</p> <p>To learn more about working with messaging channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/add-kore-channel/","title":"Adding the Kore Channel","text":"<p>Adding the Kore channel to your assistant allows end-users to interact with it using the Kore Messaging application available as a web, desktop, or mobile client.</p> <p>To add the Kore channel, follow the below steps:</p> <ol> <li>Select the assistant that you want to add the Kore Messaging channel to.</li> <li>On the Channels tab, click the Kore icon. The **Kore Channel **page is displayed.</li> <li>Under the Enable/Disable Channel section, select Enable</li> <li>Enable Bot Commands to be used within Kore Messenger Rooms. Provide a Command Name, add Help text, give an Example Command and enter a Description.</li> <li>Click Save to enable the channel.</li> </ol> <p>After the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available for end-users, with the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p> <p></p>"},{"location":"channels/add-live-person-channel/","title":"Adding the LivePerson Channel","text":"<p>The Kore.ai XO Platform lets you easily connect with the LivePerson channel to quickly identify your customers\u2019 intent and power your conversational experiences.</p> <p>To add LivePerson as a channel to your Kore.ai assistant, you must add a bot user in LivePerson and set up the integration. Adding the LivePerson channel to your Kore.ai VA allows end-users to interact with your assistant using their LivePerson account.</p> <p>Note</p> <p>A LivePerson account with administrator credentials is required to complete this configuration.      .</p> <p>Steps to enable the LivePerson channel:</p>"},{"location":"channels/add-live-person-channel/#step-1-create-a-liveperson-account","title":"Step 1: Create A LivePerson Account","text":"<ol> <li>Go to the LivePerson account setup page and create a standard or an enterprise account. For more information, see LivePerson documentation.</li> <li> <p>On the Login page, log in with your admin account credentials as shown below. </p> </li> <li> <p>Click Next and enter your Login Name and password, then click Sign-in.</p> </li> <li>You are redirected to the Agent Workspace, as shown below. </li> </ol>"},{"location":"channels/add-live-person-channel/#step-2-add-a-skill-in-liveperson","title":"Step 2: Add a skill in LivePerson","text":"<p>Once you have created an account, you must add a skill that you want to assign to an agent in LivePerson.</p> <p>Steps to add a skill to an agent in LivePerson:</p> <ol> <li>Sign in to your LivePerson account as an administrator and then select the Manage Users tab.</li> <li> <p>In the Manage Users &amp; Skills tab, click Add Skill to create a new skill. </p> </li> <li> <p>On the Skills page, click +Add Skill (at the bottom bar) and enter the details of the required skills.</p> </li> <li>Enter skill name as . For example, if your Kore.ai VA name is weather bot, then the skill name must be weather_skill.</li> <li>Enter a Description for the skill, and then unselect the check box \u2013 Conversation assigned to skill can be transferred to other skills.</li> <li> <p>Click Save to save the skill. </p> </li> <li> <p>Read more about creating skills in LivePerson.</p> </li> </ol>"},{"location":"channels/add-live-person-channel/#step-3-add-a-user-in-liveperson","title":"Step 3: Add a user in LivePerson","text":"<p>Create a user and generate API keys that you can use to configure the LivePerson channel for this user.</p> <p>Steps to add a user in LivePerson:</p> <ol> <li> <p>Sign in to the LivePerson admin account, and then go to Manage Users &amp; Skills and click Add User. </p> </li> <li> <p>On the Add User page, select the User Type as Bot.</p> </li> <li> <p>Enter a Login Name, Email, Nickname, Employee ID, and Name. (The nickname and name are displayed on the screen in the user chat.) </p> </li> <li> <p>Provide a URL for the bot avatar.</p> </li> <li>Choose the Login method as API Key, and select the Generate API Key option from the API key drop-down list to generate a new API key. </li> <li>Copy the App key, Secret, Access Token, and Access Token Secret, and enter them in the kore.ai Configurations tab of the LivePerson Channel page. For more information, see Step 4 \u2013 Configure the LivePerson Channel in the XO Platform section.</li> <li>Select Agent from the Assignment drop-down list, set Max no. live chats as Unlimited, and then select the skill created in the previous step from the Skills drop-down list. </li> <li>Click Save. For further information, see Create and manage users and Create a bot user within LivePerson\u2019s documentation.</li> </ol>"},{"location":"channels/add-live-person-channel/#step-4-configure-the-channel-in-the-xo-platform","title":"Step 4: Configure the Channel in the XO Platform","text":"<p>Configure the LivePerson channel to start communication with the kore.ai XO Platform.</p> <p>Steps to configure the LivePerson channel:</p> <ol> <li>In the XO Platform, select the assistant you\u2019re working with, then go to Deploy &gt; Channels &gt; LivePerson.</li> <li>Go to the Configurations tab. In the Account ID field, enter your LivePerson account ID. In the Login Name field, enter the Login Name of the bot user from your LivePerson account.</li> <li> <p>Under Interaction Options, select how you would like the XO Platform to interact with LivePerson \u2013 via Chat Agent API, Messaging Agent SDK, or both. </p> </li> <li> <p>Enter the details of the API Key, Secret, Access Token, and Access Token Secret values of your LivePerson user account, which you copied in Step 3. </p> </li> <li> <p>In the Enable Channel section, select Yes to activate the channel, and then click Save to complete the user creation process.</p> </li> </ol> <p>After the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available for end-users with the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/add-live-person-channel/#step-5-verify-the-liveperson-channel-integration","title":"Step 5: Verify the LivePerson Channel Integration","text":"<p>Once the LivePerson channel is enabled, you can verify the integration by publishing the campaign with the skills you created in LivePerson and embedding the LivePerson code snippet in the WebServer or Web Page where the kore.ai XO Platform is hosted.</p> <p>Steps to verify the LivePerson channel integration:</p> <ol> <li>Sign in to the LivePerson account with your admin user credentials.</li> <li> <p>Go to the Manage Campaigns and Engagements page and click the Live Messaging on your site link, as shown below. </p> </li> <li> <p>On the Live Messaging page, go to the Engagement Settings area, select the Skill you created in step 2, and then click Next. </p> </li> <li> <p>Click Next four times to select the Engagement Studio, Theme, Entry points, and Behavioral targeting library options, and then click Publish as shown below. </p> </li> <li> <p>Once the LivePerson campaign is published, go to Manage Campaigns and Engagements &gt; Campaign Builder &gt; Data Sources, as shown below. </p> </li> <li>On the Data Sources page, select the Web card and click Edit. </li> <li>On the Web Tag page, copy the embed code and paste it into the html page you use to interact with the Kore.ai XO Platform Virtual Assistant (VA). </li> <li>Send a message from the LivePerson Chat console to the kore.ai XO platform VA for which you have enabled the LivePerson channel.</li> <li>In the XO Platform, once you receive a message from the LivePerson Agent console, you can send a response to start communication between the two systems, as shown below. </li> </ol>"},{"location":"channels/add-microsoft-teams-channel/","title":"Adding the Microsoft Teams Channel","text":"<p>You can add Microsoft Teams as a delivery channel to your Kore.ai Virtual Assistant to allow it to interact with end-users using Microsoft Teams.</p>"},{"location":"channels/add-microsoft-teams-channel/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure you have an account with the Microsoft Bot Framework.</li> <li>Create a Bot Channel Service and register it in Azure.</li> <li>Enable a webhook for the platform to receive messages.</li> <li>Purchase an active subscription to Azure services with Admin access; required to subscribe to a new Azure service.</li> </ul>"},{"location":"channels/add-microsoft-teams-channel/#step-1-create-an-azure-bot","title":"Step 1: Create an Azure Bot","text":"<p>Create an Azure Bot and configure it on the Kore.ai XO Platform to establish a communication channel between Microsoft Teams and the platform.</p> <ol> <li>Log in to the Azure portal, and click + Create a resource from the portal menu.</li> <li> <p>Search and select Azure Bot on the page, and click Create. </p> </li> <li> <p>Fill in the required details, select the Multi Tenant **option in the **Type of App field then click Review + Create. </p> </li> <li>On the next page, review the details and check for the Validation status. Click **Create **to proceed. </li> <li>Associate the Azure Bot with a Microsoft App ID and Password. You can choose the default option: Auto create App Id and password. You can also choose to** Create a new Microsoft App ID** or Use existing app registration. For more information, see Microsoft Bot Framework documentation. </li> <li>Once the deployment is completed, click Go to resource to view details of your resource. </li> </ol> <p>Note<p>The platform supports both Single-Tenant and Multi-Tenant apps.</p> </p>"},{"location":"channels/add-microsoft-teams-channel/#step-2-configure-the-resource-app-id-and-password","title":"Step 2: Configure the Resource App Id and Password","text":"<p>Generate a new App Password and Client Secret to configure the Azure Bot on the Kore.ai XO Platform.</p> <ol> <li> <p>On the Configurations **tab, click the **Manage **option next to the **Microsoft App ID field. </p> </li> <li> <p>Choose Certificates &amp; secrets in the left navigation bar, and create a new client secret on the page:</p> <ul> <li>Click the + New client secret option.</li> <li>Provide the necessary details, and then click the **Add **option.</li> </ul> </li> <li> <p>Copy the Value **of the new client secret and provide it in the **App Password field present on the **Configurations **tab of the Kore.ai XO Platform. Refer Step 3: Enable Microsoft Teams Channel. \\ </p> </li> <li> <p>Close the** Certificates and secrets** section to return the **Configuration **section of the resource using the breadcrumbs.</p> </li> </ol> <p>Note<p>Make a note of the Microsoft App Id in the Azure Bot configurations page and provide it in the Configuration tab of this window.</p> </p>"},{"location":"channels/add-microsoft-teams-channel/#step-3-enable-microsoft-teams-channel","title":"Step 3: Enable Microsoft Teams Channel","text":"<p>Configure the MS Teams credentials on the Kore.ai XO Platform to establish communication between both.</p> <ol> <li>On the platform, select the assistant, and then go to the **Deploy **menu.</li> <li>Select the Microsoft Teams channel, click the Configuration **tab, and then enter the following details:**Multi-Tenant Apps Configuration<ul> <li>Microsoft App ID \u2013 The app ID of your Azure Bot resource.</li> <li>App Password \u2013 The App password value that you find in the Certificates &amp; Secrets page of the Azure bot.</li> <li>Enable Proactive Notifications (optional) \u2013 Drag the slider to enable proactive notifications.</li> <li>Application (Client) ID \u2013 The app ID of your Azure Bot resource.</li> <li>Client Secret \u2013 The client secret value that you find on the Certificates &amp; Secrets page of the Azure bot.</li> <li>**Delivery (tenant) ID **\u2013 The subscription ID that you can find on the Overview page of the Azure bot. </li> </ul> </li> </ol> <p>Single-Tenant App Configuration</p> <ol> <li> <p>Select the Single-Tenant option and enter the App Tenant ID value. </p> </li> <li> <p>Click Save.</p> </li> <li>Copy the Webhook URL from the tab and paste it in the Messaging endpoint field on the Configurations module in Azure bot.</li> <li>Click Apply to save the entered value.</li> <li> <p>Once the Configuration is completed, select the Channels option from the left menu and then select the Microsoft Teams channel. </p> </li> <li> <p>Select the I Agree checkbox on the Terms of Service dialog and then click Agree. </p> </li> <li> <p>Select the Microsoft Teams Commercial (most common) option to enable the Teams as per your commercial business requirements. If you want to enable the Azure bot for Government Community Cloud (GCC) organizations, select the Microsoft Teams Government option. Click the Learn more link next to the option on the screen for more information. </p> </li> <li> <p>Click Apply to complete the channel setup.</p> </li> </ol> <p>Note<p>The Web Chat option of Bot Framework is not supported.</p> </p>"},{"location":"channels/add-microsoft-teams-channel/#step-4-publish-your-bot-in-teams","title":"Step 4: Publish Your Bot in Teams","text":"<p>You can now publish the Azure bot on your MS Teams account so that your users can discover and converse with the bot.</p> <p>To do so, create an MS Teams app, associate the bot with it, and then publish the app.</p> <ol> <li>Log in to the MS Teams account with admin credentials.</li> <li>Click Ellipsis [\u2026] in the left navigation bar and then select the Developer Portal icon to launch the Apps builder. </li> <li>On the Developer Portal page, select the Apps tab and then click the New App button. </li> <li> <p>On the New App dialog, enter a name for the app, copy and paste the App ID of your Azure Bot in the App ID field, and then click Publish. </p> </li> <li> <p>On the Publish dialog, select the Publish to your org option. </p> </li> <li> <p>Grant the desired permissions to your MS Teams app. </p> </li> <li> <p>Click Publish your App and complete the publishing process. </p> </li> </ol> <p>Note<p>The Developer Portal view is only available on the Microsoft Teams Desktop client.</p> </p>"},{"location":"channels/add-microsoft-teams-channel/#step-5-approve-the-ms-teams-app-publish-request","title":"Step 5: Approve the MS Teams App Publish Request","text":"<p>The request to publish the MS Teams App must be approved by an MS Teams Admin. Log in to the MS Teams Admin Portal and proceed to Teams apps &gt; Manage apps. Search for the app that you published in the earlier step. Select the app and change the Publishing status to Published. This completes the process for publishing your bot for your Teams users.</p>"},{"location":"channels/add-microsoft-teams-channel/#step-6-configure-proactive-notifications-optional","title":"Step 6: Configure Proactive Notifications [Optional]","text":"<p>If you want to send Proactive Notifications to your users, you need to perform a few more actions.</p> <p>Note<p>You can skip the following sections and proceed to the Configurations tab if you do not intend to send Proactive Notifications.</p> </p> <p>To enable Proactive Notifications, follow these steps:</p> <ol> <li>Capture the App ID associated with the MS Teams App that is approved in Step 3. You can find this information on the details page of the app.</li> <li>Provide this App Id in the channel Configurations tab. </li> <li> <p>The bot requires additional app credentials for sending the Proactive Notifications. Go to the Azure portal, and click the More Services link. </p> </li> <li> <p>On the More Services page, search and select the App registrations.  </p> </li> <li> <p>On the App registrations page, click New registration. </p> </li> <li> <p>Provide the required information and click Register. </p> </li> <li> <p>You are redirected to the details page of the newly registered app.</p> </li> <li> <p>From the Manage menu, select the API permissions section and then click the Add a permission option. From the Request API permissions, select Microsoft Graph and choose Application Permissions. </p> </li> <li> <p>From the permissions list, select the following permissions and click Add permissions.</p> <ul> <li>TeamsAppInstallation.ReadForUser.All</li> <li>TeamsAppInstallation.ReadWriteSelfForUser.All</li> <li>TeamsAppInstallation.ReadWriteForUser.All</li> <li>User.Read.All</li> </ul> <p></p> </li> <li> <p>Click on the Grant admin consent for &gt; domain name&gt; option to complete the granting of the permissions.</p> </li> <li>Proceed to the Certificates &amp; secrets section and select the New client secret option.</li> <li>Copy the Value of the newly created certificate and provide it on the Configurations tab of MS Teams Channel on the Kore.ai XO Platform.</li> <li>Overview section of the app and capture Application (client) ID, Directory (tenant) Id and provide them on the Configurations tab of this page.</li> <li>Navigate to the Configurations tab to review and enable the Microsoft Teams channel for your bot.</li> </ol>"},{"location":"channels/add-microsoft-teams-channel/#related-links","title":"Related Links","text":"<ul> <li>Once the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available to end-users. Learn more about Publishing your Virtual Assistant.</li> <li>To learn more about working with Channels within the Kore.ai XO Platform, see Channel Enablement.</li> </ul>"},{"location":"channels/add-microsoft-yammer-channel/","title":"Adding the Yammer Channel","text":"<p>To add Yammer as a channel to your Kore.ai bot, you must create an app in Yammer and enable the platform to receive messages. Adding the Yammer channel to your Kore.ai bot allows end-users of your bot to interact with your bot using their Yammer accounts. To add the Yammer channel to your bot, you must:</p> <ol> <li>Register an App\u2013 To enable Yammer as a channel for your bot, create an app on Yammer. Log in to your Yammer developer account to Register a New App. Initially, to enable the Yammer channel, you must create and register for a developer account in the Yammer Developer portal.</li> <li>Enter the Redirect URL \u2013 Copy the_ Redirect URL_ provided in the Configurations tab of the Yammer channel page in the Bot Builder and enter it in the Redirect URL field to proceed with creating an app on Yammer.</li> <li>Get App Information\u2013 Go to the App Details page to get and reserve the Channel ID**and **Channel Secret for your channel configuration.</li> <li>Deploy Bot to your Enterprise\u2013 To allow your enterprise users to discover the bot in the App Directory, you can deploy the bot by updating the** App Directory** section.</li> <li>Authorize\u2013 You must Authorize the bot from the Configurations tab on the Yammer Channel page in the bot builder. This allows you to generate a developer access token to enable the Kore.ai bot platform to access the app.</li> <li>Enable Channel\u2013 After setting up the Yammer app and entering configuration data in Bot Builder, enable the channel.</li> </ol> <p>Note<p>The Callback/Redirect URL now includes the streamid in the API request to identify the virtual assistant being accessed. When an incoming request is qualified with this identifier, it helps with traceability, troubleshooting, and remediation at the network level during anomalies like malicious calls or unusual bot activity.</p> </p> <p>To add the Yammer channel, follow the below steps:</p> <ol> <li>In the Bots section of the Bot Builder, click the bot you want to add the Yammer channel to.</li> <li>On the Channels tab, click the** Yammer** icon. The Yammer Channel page is displayed.</li> <li>In a new browser tab, log in to your** Yammer Developer** account and go to the My Apps section to register a new app.</li> <li>To create an app, click Register New App. Enter the required details in the listed fields.</li> <li>Copy the Redirect URL from the Configurations tab of the Yammer Channel page and enter it in the **Redirect URL **field.</li> <li> <p>Click Continue to create the app. </p> </li> <li> <p>After app creation, you are redirected to the App Details page. Capture the Client ID and Client Secret of your Yammer channel and provide them in the Configurations tab of LINE channel page. </p> </li> <li> <p>To deploy bot to your enterprise, go to the App Directory section and enter the required information in the respective fields.</p> </li> <li> <p>Click Deploy to deploy the bot to your enterprise users. </p> </li> <li> <p>Go to the Configurations tab on the Yammer channel page to complete the channel setup.</p> </li> <li>Click** Authorize** to generate a developer access token which enables Kore.ai bot platform to access the App. Enter all the details in other required fields. Select Yes and click Save to enable Yammer Channel.</li> </ol>"},{"location":"channels/add-microsoft-yammer-channel/#edit-yammer-channel","title":"Edit Yammer Channel","text":"<p>To edit the Yammer channel, follow the below steps:</p> <ol> <li>Hover over the channel and click to modify. You can make necessary updates to your channel configurations and save them.</li> <li>You can also disable or delete the channel information by clicking the **Settings **icon as shown in the image. </li> </ol> <p>Select one of the following commands to modify the channel:</p> <ul> <li>Disable/Enable \u2013 Click Disable to temporarily disable the use of the Yammer channel for your bot. To enable the use of the Yammer channel, Click Enable.</li> <li>Delete \u2013 Click Delete. On the Delete Confirmation dialog box, click OK to permanently delete the bot channel configuration.</li> </ul> <p>Warning<p>This operation is permanent and cannot be undone.</p> </p>"},{"location":"channels/add-ringcentral-glip-channel/","title":"Adding Glip by RingCentral as a Channel","text":"<p>The Kore.ai XO Platform now allows you to add Glip by RingCentral as a messaging channel to your Virtual Assistants (VAs).</p> <p>With the Glip integration, you can achieve the following:</p> <ul> <li>Configure the Glip Sandbox account for testing the integration.</li> <li>Set up the REST API and the authorization flow for events and conversations.</li> <li>Enable Webhook Subscriptions, Read Accounts, and Team Messaging API permissions.</li> <li>Link the app to the Kore.ai XO Platform using the app\u2019s credentials.</li> <li>Authorize the VA for the existing/new Glip Sandbox account user.</li> </ul> <p>After the integration, you can do the following:</p> <ul> <li>Keep track of virtual assistant conversations.</li> <li>Listen to new messages from Glip or other sources.</li> <li>Have VAs post and respond to messages in Glip conversations.</li> <li>Have VAs handle incoming notifications from your apps into Glip teams so you don\u2019t have to check different sites for updates.</li> </ul> <p>To start the integration, you must register an application on RingCentral to gain access to the API and to integrate RingCentral into the Kore.ai XO Platform. To set up Glip as a channel, you must create an app in RingCentral\u2019s Developer Portal and enable a webhook for the platform to receive messages.</p> <p>The steps to add the channel are summarized below:</p> <ol> <li>Create a RingCentral App</li> <li>App Set Up on the Kore.ai XO Platform using the Application Key and App secret</li> <li>Authorize a valid extension (user) of your RingCentral account to generate the developer access token, access the Glip APIs, and enable the channel</li> <li>Test the integration</li> <li>(Recommended) Apply for Production</li> </ol>"},{"location":"channels/add-ringcentral-glip-channel/#step-1-create-a-ringcentral-app","title":"Step 1: Create a RingCentral App","text":"<p>To enable Glip as a channel for your Kore.ai Virtual Assistant, you must create an application in the Sandbox environment (using a sandbox account) with the steps below:</p> <p>For New Users</p> <ol> <li>Log in to the RingCentral Developer Console.</li> <li>On the left menu, click Setup Wizard under Getting Started.</li> <li>In the Get started to create your first app panel, click Create your First App.</li> </ol> <p>For Existing Users</p> <ol> <li>Log in to the RingCentral Developer Console.</li> <li>Click the Console button on the top left.</li> <li> <p>In the Apps section, click Create App. </p> </li> <li> <p>Select REST API App under App Type to call the RingCentral REST API. </p> </li> <li> <p>Click Next.</p> </li> <li> <p>Enter all the required details on the Create App \u2013 REST API App Settings page and click Next.</p> </li> <li> <p>Enter the values to the following fields on the     App Properties (internal-use only) page:</p> </li> <li>App Name</li> <li>App Description (optional)</li> <li>Primary Contact</li> <li> <p>Select the relevant option for Do you intend to promote this app in the RingCentral App Gallery? </p> </li> <li> <p>(Optional) In the App Card panel, enter the values for the given fields to configure how your application will be presented within our App Gallery.</p> </li> <li> <p>In the Auth panel, enter the values for the following fields to select the authentication method your app will use:</p> </li> <li>Select 3-legged OAuth flow authorization code.</li> <li> <p>Select Server-side web app (most common) or Client-side web app based on your app type for From what type of app will you be calling the API? </p> </li> <li> <p>On the Kore.ai XO Platform, copy the OAuth Redirect URI under the Configurations tab in the RingCentral Glip window.</p> </li> </ol> <p></p> <ul> <li>Paste the copied OAuth Redirect URI link in the Auth panel.</li> <li> <p>Select Yes for Issue refresh tokens?</p> </li> <li> <p>In the Security panel, to define the permissions to associate with the app, follow the steps below:</p> </li> <li> <p>Select the Webhook Subscriptions, Read Accounts, and Team Messaging permissions from the dropdown list. </p> </li> <li> <p>Click Create. Your App is created successfully and the system redirects to the App Dashboard page.</p> </li> </ul> <p>If you do not have a Sandbox Account to test your app in the Sandbox environment, follow the steps below:</p> <ul> <li> <p>In the following dialog window, click Next.  </p> </li> <li> <p>Setup the Password for your Sandbox Account.</p> </li> </ul> <p>Tip<p>The OAuth Redirect URI now includes the streamid in the API request to identify the virtual assistant being accessed. When an incoming request is qualified with this identifier, it helps with traceability, troubleshooting, and remediation at the network level during anomalies like malicious calls or unusual bot activity.</p> </p>"},{"location":"channels/add-ringcentral-glip-channel/#step-2-application-set-up-on-the-koreai-xo-platform","title":"Step 2: Application Set up on the Kore.ai XO Platform","text":"<p>After creating the app for the Sandbox/Production environment, you need to configure the app\u2019s credentials on the Kore.ai XO Platform using the Client ID and Client Secret from the RingCentral Glip Application Dashboard to link the app. To set the credentials, follow the steps below:</p> <ol> <li> <p>On the RingCentral Developer Application Dashboard, click Credentials on the left menu. </p> </li> <li> <p>Under Application Credentials, click the copy icons for the Client ID and Client Secret (tap on click to see first) fields. </p> </li> <li> <p>On the Kore.ai XO Platform, navigate to Deploy &gt; Channels and click RingCentral Glip. </p> </li> <li> <p>In the RingCentral Glip window, click the Configurations tab.</p> </li> <li>Paste the copied Client ID to the Application Key input field, and the Client Secret to the Application Secret input field.</li> <li>Click Save. </li> </ol>"},{"location":"channels/add-ringcentral-glip-channel/#step-3-authorize-extension-user-of-your-ringcentral-sandbox-account","title":"Step 3: Authorize Extension (user) of your RingCentral Sandbox Account","text":"<p>The virtual assistant on the Kore.ai XO Platform must be associated with the extension (user) on your RingCentral account to access the Glip API via the developer access token. To enable this, you should authorize the virtual assistant with an existing or new extension user\u2019s credentials. To add a new (non-admin) user, follow the steps below:</p> <ol> <li>Log in to your RingCentral Sandbox account.</li> <li>Click the Users tab.</li> <li>Click Users with Extension on the left menu.</li> <li>Click +Add User.</li> <li>On the Add Users and Phones dialog box, select Add Users without Phone, and follow the instructions on the page.</li> <li>Click Unassigned Extensions on the left menu.</li> <li>Click Add Unassigned Ext. </li> <li>On the user profile information page, enter all the required information.</li> <li>Click Save &amp; Enable to enable the extension.</li> </ol> <p>Note</p> <p>Please provide a meaningful name like Travel Bot or HR Assistant to the virtual assistant inside Teams Messaging.</p> <p>Notes</p> <ul> <li> <p>If you receive an account activation email on your registered email address, please note the username and password to authorize the virtual assistant on the Kore.ai XO Platform.</p> </li> <li> <p>Alternatively, select the \u201cpre-assigned credentials\u201d option and just provide/save the password.**.</p> </li> <li> <p>If you receive an account activation email on your registered email address, please note the username and password to authorize the virtual assistant on the Kore.ai XO Platform.</p> </li> <li>Alternatively, select the \u201cpre-assigned credentials\u201d option and just provide/save the password.</li> </ul>"},{"location":"channels/add-ringcentral-glip-channel/#step-3a-test-the-validation","title":"Step 3(a): Test the Validation","text":"<p>To access the admin portal from the Sandbox account screen and test the validation, follow the steps below:</p> <ol> <li>Go to the Sandbox Account section and click the link in the Team Messaging section. </li> <li>Navigate to Messages on the left menu.</li> <li>In the Direct Messages section, click the + icon to start a new DM with the virtual assistant.</li> <li>Find the virtual assistant using either the name or email address you used in Step 3.</li> <li>Send the virtual assistant an opening message, such as \u201cHello\u201d or \u201cgood afternoon\u201d. The VA should respond based on the default behavior configured for Dialog Tasks.</li> </ol>"},{"location":"channels/add-ringcentral-glip-channel/#step-3b-channel-setup-on-the-platform","title":"Step 3(b): Channel Setup on the Platform","text":"<p>On the Kore.ai XO Platform, navigate to RingCentral Glip &gt; Configurations and follow the steps below:</p> <ol> <li> <p>In the RingCentral Glip window, click the Authorize button. </p> </li> <li> <p>In the Sign-in window, click Continue as **to sign in with the existing user\u2019s account, or click **Use Another Account. </p> </li> <li> <p>Click Authorize on the Access Request page.</p> </li> <li>Once the access token is obtained successfully, authorization is complete. </li> <li>On the Kore.ai XO Platform, select Yes for the Enable Channel option under the RingCentral Glip &gt; Configurations tab.</li> <li>Click Save to enable the channel and Publish the Virtual Assistant. Learn more.</li> </ol> <p></p>"},{"location":"channels/add-ringcentral-glip-channel/#step-4-test-the-integration","title":"Step 4: Test the Integration","text":"<p>Please follow the steps given here to test the integration.</p>"},{"location":"channels/add-ringcentral-glip-channel/#recommended-step-5-apply-for-production","title":"(Recommended) Step 5: Apply for Production","text":"<p>Once your app is tested in the Sandbox environment and ready for production, follow the RingCentral app graduation process mentioned here to apply for production after meeting all the graduation requirements for your app as shown below:</p> <p></p> <p>Once your app is production ready, follow the steps below on the Kore.ai XO Platform:</p> <ol> <li>Navigate to Deploy &gt; Channels &gt; RingCentral Glip.</li> <li>Under the Configurations tab, select Production for Ringcentral Environment.</li> <li>Follow these steps to complete the configuration.</li> </ol> <p>Congratulations! You have now completed the Glip by RingCentral channel enablement. To learn how to enable other business messaging channels, click here.</p>"},{"location":"channels/add-skype-business-channel/","title":"Adding the Skype for Business Channel","text":"<p>To set up Skype for Business as a channel, you must register a Bot Channel service in Azure and enable a webhook for the platform to receive messages. To enable Skype for Business, follow the below steps:</p> <ol> <li>Register a Bot Channel \u2013 Log in to the Azure portal and register a bot channel.</li> <li>**Create Microsoft ID and Password **\u2013 You must add all the bot details and create the Microsoft ID and Password.</li> <li>**Enable Skype for Business **\u2013 After registering the bot, enable the channel.</li> <li>**Publish Channel **\u2013 After the channel is enabled and all configurations are verified, publish the bot to make it available for developers.</li> </ol> <p>To add Skype for Business channel, follow the below steps:</p> <ol> <li>In the Bots section of the Bot Builder, click the bot you want to add the Skype for Business channel to.</li> <li>On the Channels tab, click the Skype for Business **icon. The **Skype for Business Channel page is displayed.</li> <li>In a new browser tab, log in to the Azure portal to register a bot channel.</li> <li>On the left pane, click + Create a Resource. On the search window, search and select Bot Channels Registration.</li> <li> <p>On the new Bot Channel Service creation page, click Create and proceed to the next screen to enter the details. </p> </li> <li> <p>Enter all the required details to register the bot channel. Copy the Webhook URL from the Configurations tab of the Skype for Business channel page on the builder and provide it in the Messaging Endpoint field. </p> </li> <li> <p>Click Create to complete the registration. After successful creation, you are redirected to the Dashboard of your Azure account.</p> </li> <li> <p>To create Microsoft App ID and password from your Azure Dashboard, select the resource that you have created in the previous steps. You are redirected to the details page of the new resource that you have created. </p> </li> <li> <p>On the left pane, click Settings &gt; Manage next to the Microsoft App ID field. You are redirected to a new browser tab to manage your app credentials. </p> </li> <li> <p>Click Generate New Password to create a new password for your app. Make a note of the password displayed on the window and enter it in the Configurations tab of this window.</p> </li> <li>Click Ok to go back to the previous screen. Make a note of the App ID and enter it in the Configuration tab of the channel page.</li> <li> <p>Click Save at the end of the page to save your changes. </p> </li> <li> <p>To enable Skype for Business, go to your Azure portal and click Channels on the left pane of your app. Select Skype for Business.</p> </li> <li> <p>You are redirected to the channel information page and the channel is enabled. Proceed to the next step to add this bot to your Skype for Business Tenant account. </p> </li> <li> <p>The Tenant Administrator of your Skype for Business Online environment has to add this bot to your enterprise Skype for Business account. Refer to instructions from Microsoft Bot Framework to add this bot to your enterprise Skype for Business account.</p> </li> <li>After these instructions are executed, end-users of your enterprise can find this bot in their Skype for Business contacts list and start chatting with the bot.</li> </ol>"},{"location":"channels/add-skype-business-onpemise-channel/","title":"Adding the Skype Channel","text":"<p>To add the Skype channel to your bot, you need a developer _Microsoft Bot Framework _account to configure the connection between Skype and Kore.ai. Adding the Skype channel to your Kore.ai bot is a three-step process to allow end-users to interact with your bot. To add the Skype channel to your bot, follow the below steps:</p> <ol> <li>Register the Bot **\u2013 In your Microsoft Bot Framework developer account, you must register the bot by adding all the bot details and creating the **App ID and Password. To register the bot, you must have created and registered for a free account in the Microsoft Bot Framework developer portal.</li> <li>Enable Channel \u2013 After registering the bot, you must enable the channel.</li> <li>Publish Channel \u2013 After the channel is enabled and all configurations are verified, you must publish the bot to make it available for developers.</li> </ol>"},{"location":"channels/add-skype-business-onpemise-channel/#add-skype-channel","title":"Add Skype Channel","text":"<p>To complete this procedure, you must have or register for a new developer account in the Microsoft Bot Framework developer portal.</p> <ol> <li>In Bot Builder, under the Bots section, click the bot you want to add the Skype channel to.</li> <li> <p>On the Channels tab, click the Expand icon for the Skype section. The Skype Channel page is displayed. </p> </li> <li> <p>Log in to the Microsoft Bot Framework portal, and then click Register a bot.</p> </li> <li>On the Register a bot tab, under the Bot profile section, enter your Bot Name, Bot handle, and Description.</li> <li>In the Configuration section, paste the Webhook URL from the Bot Builder into the Messaging endpoint field. For example, https://bots.kore.ai/hooks/skype/st-2724c525-484b-55ca-a844-8d7dfa6b6b23</li> <li> <p>Click Create Microsoft App ID and password as shown in the following illustration. </p> </li> <li> <p>On the Generate App ID and password page, click Generate an app password to continue.</p> </li> <li> <p>Save the generated Password and the App ID to use later in the Register the Bot tab in Bot Builder for the Skype Channel page. \\ Note: The only time the full password is displayed is when it is generated and displayed in the Generate Password dialog. Copy and save the password to a secure location until added to the Skype Channel page in Bot Builder. ![generated app ID] (./images/Skype-Channel3.png \"generated app ID\")</p> </li> <li> <p>Click Finish and go back to Bot Framework. **The **Register a bot tab is displayed.</p> </li> <li>To save your settings, agree to Privacy statement, Terms of Use, and Code of Conduct.</li> <li>Click Register.</li> <li>On the Bot created dialog, click OK. The My bots tab is displayed.</li> <li>Optionally, click** Test** to check the connection to your bot. The Endpoint authorization succeeded message is displayed.</li> <li>In Bot Builder, on the Register the Bot tab, paste the App ID and Password **you saved from the Microsoft Bot Framework developer portal into the APP ID** and** APP PASSWORD **fields.</li> <li> <p>Click Next as shown in the following illustration. </p> </li> <li> <p>On the** Enable Channel tab, review how to edit the Skype channel settings in the Microsoft Bot Framework developer portal if needed, and then click **Next. The Publish Channel tab is displayed.</p> </li> <li>In the Enable Channel section, click Yes to enable the Skype channel for Kore.ai.</li> <li>Click Save.</li> </ol> <p>The channel configuration settings are saved and the Skype Channel page is closed.</p>"},{"location":"channels/add-skype-business-onpemise-channel/#edit-skype-channel","title":"Edit Skype Channel","text":"<p>To edit the Skype channel, follow the below steps:</p> <ol> <li>Hover over the channel to modify, and then click the Settings icon displayed to show the command menu displayed in the following illustration. </li> <li>Select one of the following commands to modify the channel:</li> <li>Edit \u2013 Click to open the Skype Channel page.</li> <li>Disable/Enable \u2013 Click Disable to temporarily disable the use of the Skype channel for your bot.</li> <li>Enable - When the channel is disabled, click Enable to enable use of the Skype channel.</li> <li>Delete \u2013 Click Delete. On the Delete Confirmation dialog box, click OK to permanently delete the bot channel configuration.</li> </ol> <p>Warning<p>This operation is permanent and cannot be undone.</p> </p>"},{"location":"channels/add-slack-channel/","title":"Adding the Slack Channel","text":"<p>To set up Slack as a channel, you must associate the assistant with a Slack app. Adding the Slack channel to your Kore.ai VA allows end-users to interact with it using their Slack accounts.</p> <p>To complete this procedure, you must already have a Slack account and be a member of a Slack team.</p>"},{"location":"channels/add-slack-channel/#step-1-create-an-app-on-slack","title":"Step 1: Create an App on Slack","text":"<ol> <li>In the XO Platform, select the assistant to which you want to add the Slack Channel.</li> <li>Go to Deploy &gt; Channels &gt; Slack, and open the **Configuration **tab.</li> <li> <p>In a new browser tab, Login to the Slack developer portal and go to the Apps section https://api.slack.com/apps. If this is your first app, click Create an App and if you already have some apps, then click Create New App. \\ </p> </li> <li> <p>You will now be asked to choose how you\u2019d like to configure your app\u2019s scopes and settings. Select From Scratch.</p> </li> <li> <p>On the Create App window, enter the App Name and select a team from the Development Slack Team drop-down list. Use your assistant\u2019s name as the App Name. \\ </p> </li> <li> <p>After you enter the required information, click Create App. Slack will now create a new app and you are redirected to the Basic Information section of the new app.</p> </li> </ol>"},{"location":"channels/add-slack-channel/#step-2-set-redirect-url-and-scopes","title":"Step 2: Set Redirect URL and Scopes","text":"<ol> <li>Go to the OAuth &amp; Permissions tab and click Add a new Redirect URL. Copy the Redirect URL provided in the Configurations tab of the Slack channel page within the XO Platform and enter in the Redirect URLs field.</li> <li> <p>Click Add a new Redirect URL, then click Save URLs. \\ </p> </li> <li> <p>Proceed to Scopes &gt; Bot Token Scopes section.</p> </li> <li>Add \u2018incoming-webhook\u2018,\u2018chat:write\u2018, \u2018users:read.email\u2018, and \u2018users:read\u2018 scopes.</li> <li>If you would like your users to send attachments to your bot, then select the \u2018files:write\u2019 scope.</li> <li>If you would like to send Proactive Notifications to your users on Slack, then select the users:read, users:read.email, team:read scopes. \\ </li> </ol>"},{"location":"channels/add-slack-channel/#step-3-install-the-app","title":"Step 3: Install the App","text":"<ol> <li> <p>Next, navigate to the OAuth Tokens &amp; Redirect URLs section, and select the Install to Workspace option. Choose the required Workspace and complete the process. \\ </p> </li> <li> <p>Optionally, if you would like to send Proactive Notifications to your users on Slack, copy the Bot User OAuth Token from the **OAuth Tokens for Your Workspace **section and provide it in the Slack Channel Configurations tab within the XO Platform. </p> </li> </ol>"},{"location":"channels/add-slack-channel/#step-4-enable-interactivity","title":"Step 4 : Enable Interactivity","text":"<ol> <li> <p>To enable Interactive Components, go to the Interactivity &amp; Shortcuts section and enable Interactivity. Copy the Webhook URL provided in the Configurations tab of this page and enter it in the Request URL field.</p> </li> <li> <p>Click Save Changes.</p> </li> </ol> <p>Note</p> <p>The Webhook URL now includes the streamid in the API request to identify the virtual assistant being accessed. When an incoming request is qualified with this identifier, it helps with traceability, troubleshooting, and remediation at the network level during anomalies like malicious calls or unusual bot activity.</p> <p></p>"},{"location":"channels/add-slack-channel/#step-5-enable-events","title":"Step 5 : Enable Events","text":"<ol> <li>Go to the Event Subscriptions section and activate the Enable Events option.</li> <li>Copy the Webhook URL provided in the Configurations tab of Slack Channel page and enter it in the Request URL field.</li> <li>In the Subscribe to Bot Events section, add app_mention, message_channels, and message_im events.</li> <li>In the Subscribe to Workspace Events section, add message_im event.</li> <li>Click Save Changes. </li> </ol>"},{"location":"channels/add-slack-channel/#step-6-enable-interactions-from-the-messages-tab","title":"Step 6: Enable Interactions from the Messages tab","text":"<ol> <li>Navigate to the App Home section and under Show tabs.</li> <li>Enable the Messages Tab and also enable the Allow users to send Slash commands and messages from the messages tab.</li> </ol> <p>This is required to allow your users to directly interact with the app from the Messages tab.</p> <p></p>"},{"location":"channels/add-slack-channel/#step-7-configure-app-credentials","title":"Step 7: Configure App Credentials","text":"<ol> <li>Go to the Basic Information section and scroll down to the App Credentials section.</li> <li>Capture the values for Client ID, Client Secret, and Verification Token fields.</li> <li>Provide them in the Configurations tab of the Slack Channel within the XO Platform. </li> </ol>"},{"location":"channels/add-slack-channel/#step-8-manage-distribution","title":"Step 8: Manage Distribution","text":"<p>If you want to enable the public distribution of your app on Slack, you must proceed with the following steps.</p> <ol> <li>Go to the Manage Distribution section and click on Remove Hard Coded Information.</li> <li>Select the checkbox I\u2019ve reviewed and removed any hard-coded information and click Activate Public Distribution. </li> </ol>"},{"location":"channels/add-slack-channel/#step-9-enable-the-channel","title":"Step 9: Enable the Channel","text":"<ol> <li>Go to the Configurations tab to review and complete the channel setup.</li> <li>Click Authorize under the app credentials area.</li> <li>Under Enable Channel, select **Yes **and click on **Save **to enable the Slack channel. </li> </ol> <p>The Successfully added Slack channel message is displayed at the top of the XO Platform. In Slack, it is optional to submit your app to the Slack App Directory.</p> <p>After the channel is enabled and all configurations are verified, you can optionally publish</p> <p>the assistant to make it available for end-users, with the new channel. Learn more about</p> <p>Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/add-workplace-by-facebook-channel/","title":"Adding the Workplace by Facebook Channel","text":"<p>This channel enablement flow is modified as per the changes implemented by Facebook post v7.2 of the product.</p> <p>To add the Workplace by Facebook channel to your assistant, you need a developer portal Facebook account to configure the connection between Facebook Workplace and Kore.ai. Kore.ai application must be authorized to send and receive messages from the Workplace by Facebook channel.</p>"},{"location":"channels/add-workplace-by-facebook-channel/#add-the-workplace-by-facebook-channel","title":"Add the Workplace by Facebook Channel","text":"<p>To complete the following procedure, you must have an admin account in the Facebook Workplace Developers Portal (https://&lt;Your Domain&gt;workplace.com/work/admin).</p> <ol> <li>In the XO Platform, under the Bots section, click the assistant you want to enable the Workplace by Facebook channel.</li> <li>On the Channels tab, click the Workplace by Facebook icon.</li> <li>The Workplace by Facebook Channel page is displayed.</li> <li> <p>Go to the Configurations tab:</p> <ul> <li>In the Communication Mode section, select one or both of the following:<ul> <li>Allow communication with a VA in a Workplace Group</li> <li>Allow communication with a VA through a Work Chat</li> </ul> </li> <li>In the Manage Permissions section, set the following as per your requirements (click here for more on the permissions):<ul> <li>Message any member \u2013 To send messages to any group member. This permission is selected by default and is mandatory hence not editable.</li> <li>Mention bot \u2013 Needed when the VA is mentioned in a post, to see the post and to reply to comments. This permission is selected by default and is required for the assistant to respond to users in groups.</li> <li>Manage group content \u2013 Required to post and comment in groups. This permission is selected by default and is required for the VA to respond to users in groups.</li> <li>Create link previews \u2013 Needed to see links added to posts in order to display a preview for certain domains.</li> <li>Read user email \u2013 Required to see any group member\u2019s email address.</li> <li>Read work profile \u2013 Required to see any group member\u2019s complete profile, including phone number, department, and location.</li> <li>Read org chart \u2013 Needed to check a group member\u2019s profile to see who they report to and who reports to them;</li> </ul> </li> </ul> </li> <li> <p>Click Authorize.</p> </li> </ol> <p>Note<p>You are advised to set the permissions correctly after evaluating the above-mentioned link carefully. Managing the permissions for your VA after installing the Kore.ai application on your workplace account needs you to uninstall the application on the workplace account and re-authorize it in the XO platform.</p> </p> <p> 6. You are redirected to Workplace by Facebook page.</p> <ol> <li> <p>Log in to your Facebook Workplace admin account.</p> </li> <li> <p>Click Customize to provide the following details for the instance of Kore.ai application installed on Workplace by Facebook account:</p> <ul> <li>integration logo</li> <li>name</li> <li>description </li> </ul> </li> <li> <p>The permissions needed by the Kore.ai assistant is selected based upon the configuration given in step 4.</p> </li> <li> <p>Select the groups to which the assistant needs to be added and click Add to Workplace.</p> </li> <li> <p>Once the instance of Kore.ai application is added to your Workplace by Facebook account, you are redirected to the Kore.ai XO Platform. </p> </li> <li> <p>In XO Platform, from the Configuration tab, click Yes in the Enable Channel section; and click Save.</p> </li> </ol> <p>The assistant may require your Bots Admin approval and assignment before it is available to any users.</p>"},{"location":"channels/amazon-alexa/","title":"Adding the Amazon Alexa Channel","text":"<p>The Kore.ai XO Platform supports the integration of Virtual Assistants (VA) into the Amazon Alexa Channel. Ensure you have an Amazon Developer account for this configuration. Additionally, Amazon Alexa should be enabled for VAs built for voice-based channels.</p> <p>To accomplish the channel enablement, you must do the following:</p> <ol> <li>First, update the JSON file with the supported bot tasks from the Kore.ai XO Platform to the Alexa Developer Portal.</li> <li>Next, configure the Webhook URL from the Kore.ai XO Platform as the Service Endpoint on the Alexa Developer Portal to receive messages.</li> </ol>"},{"location":"channels/amazon-alexa/#important-checks-and-considerations","title":"Important Checks and Considerations","text":"<p>The following are the important checks to do and considerations before you enable the Amazon Alexa channel:</p> <ol> <li>Enterprise assistants that require the user\u2019s authorization to communicate with it are not supported.</li> <li>If your dialog tasks require the user\u2019s authorization to communicate with external systems, then the Platform will push a card with URL information to the Alexa app.</li> <li>Intents and entities of only Published Dialog Tasks can be exported to Amazon Alexa.</li> <li>Ensure that your intents and entities adhere to the naming guidelines of Amazon Alexa.</li> <li>Not all entity types available in the Kore.ai Platform are available in Alexa. Verify that your tasks contain Alexa-supported entities for optimal user experience.</li> <li>Ensure that your dialog tasks contain one or more utterances.</li> <li>To display responses as templates on supported devices like Echo Show, you must define channel-specific responses/prompts.</li> <li>Ensure that your dialog tasks contain only the Message node as the last node. Alexa marks a task as completed if a VA message is displayed without expecting input from the user.</li> <li>Webhook Nodes work asynchronously and are currently not supported.</li> <li>Amazon Alexa executes one task at a time, so the Hold &amp; Resume functionality is not supported.</li> </ol>"},{"location":"channels/amazon-alexa/#configuration-overview","title":"Configuration Overview","text":"<p>The steps to add the Amazon Alexa channel are given below:</p> <ol> <li>Add a New Skill \u2013 Create a new Alexa skill in the Amazon developer console.</li> <li>Configure the Interaction Model \u2013 The Alexa skill can be built in one of the following ways:<ul> <li>Dialog Migration to extract the dialog tasks from Kore.ai and import them into Amazon Alexa\u2019s Skills. This will entail reimport for reflecting the ongoing changes in the dialog definition. Intent detection and execution are primarily controlled by Alexa.</li> <li>Redirection to create a single intent in your skill with the SearchQuery Slot Type that accepts user inputs and redirects them to your Kore.ai VA. Intent detection and execution are primarily controlled by the Kore.ai VA.</li> </ul> </li> <li>Enable Account Linking (Optional) \u2013 To access end user\u2019s authentication details to make API calls to external services.</li> <li>Enable Webhook Integration \u2013 To integrate Amazon Alexa with your Kore.ai VA, enable webhook integration by copying the Webhook URL on the Configurations tab of the Amazon Alexa Channel page in the XO Platform and select HTTPS as the Service Endpoint type.</li> <li>Enable Channel \u2013 Enable the channel after completing the integration setup.</li> <li>Test Integration \u2013 Once the channel is enabled, test any intent utterance using the Test tab of your Alexa Skill to validate a successful integration and check its responses for the given test utterances.</li> <li>Distribution, Privacy &amp; Compliance, and Certification \u2013 Publish your Alexa Skill on Alexa App and provide details for Privacy and Compliance to enable Skills Beta Testing, which allows you to invite your co-developers to test your app. You must also submit your Skill to Amazon for certification to enable your skill to become visible on Alexa Skills on Amazon App Store after it is certified.</li> </ol>"},{"location":"channels/amazon-alexa/#step-1-add-a-new-skill","title":"Step 1: Add a New Skill","text":"<ol> <li>Log in to your Amazon Developer Dashboard and click the Alexa tab.</li> <li>Select Alexa Skills Kit on the menu. </li> <li>Click the Skills tab on the Alexa Developer Console.</li> <li>Click Create Skill.  </li> <li>Enter the Skill Name field information on the Create a New Skill page and select the primary locale value.</li> <li>Then, follow the steps below:<ul> <li>Enable the Sync Locale option, if required.</li> <li>Select Custom (default selection) to Choose a model to add to your skill to create all of your skill\u2019s interactions and map them to your custom model. </li> <li>Under Choose a method to host your skill\u2019s backend resources section, select Alexa-hosted(Node.js).</li> <li>Click Create Skill. </li> <li>Select a template to add to your skill with these steps:</li> <li>Select the Start from Scratch tab.</li> <li>Click Continue with Template. </li> </ul> </li> <li>Enter the captcha shown on the screen and click Submit to process and create an Amazon Alexa voice skill. Your skill is built and listed on the Developer Console. </li> <li>Click Your Skills to view the custom skill you added to the console.</li> </ol>"},{"location":"channels/amazon-alexa/#step-2-configure-the-interaction-model","title":"Step 2: Configure the Interaction Model","text":"<p>Configuring the Interaction Model helps define the words and phrases in the user utterances on the Alexa channel to configure the virtual assistant skill accordingly. An Interaction Model lets you add intents and annotations and check the Intent History and Utterance Conflicts. Learn more.</p>"},{"location":"channels/amazon-alexa/#dialog-migration-to-extract-the-dialog-tasks-from-koreai","title":"Dialog Migration to Extract the Dialog Tasks from Kore.ai","text":"<p>To configure a custom Interaction Model, follow the steps below:</p> <ol> <li>On the Developer Console, select the Build tab. Then, click the Interaction Model left menu option.</li> <li>Select the JSON Editor option.    </li> <li>In the JSON Editor window, define the intents and entities to associate with your newly created skill based on the Kore.ai XO Platform definitions.</li> <li>To capture the intents and entities from the Kore.ai XO Builder, follow these steps:</li> <li>Select the virtual assistant.</li> <li>Navigate to Deploy &gt; Channels &gt; Amazon Alexa &gt; Configurations.</li> <li> <p>Click Download File under Alexa Skill Definition JSON to download the VA\u2019s tasks.   </p> </li> <li> <p>Click Confirm on the Download window.</p> </li> <li>Click Drag and drop a .json file on the JSON Editor of the Alexa Developer Console and upload the file.  </li> <li>The JSON Editor gets updated with the information in the uploaded file.</li> <li>Click Evaluate Model to review and ensure that there are no errors.</li> <li>Click Save Model, then click Build Model.  </li> </ol> <p>Note</p> <p>It takes 2-5 mins for the Model to build. Any changes to the built model can be implemented by rebuilding the model.</p>"},{"location":"channels/amazon-alexa/#create-a-single-intent-with-the-searchquery-slot-type","title":"Create a Single Intent with the SearchQuery Slot Type","text":"<p>The <code>AMAZON.SearchQuery</code> slot type helps capture less-predictable user utterances in the search query for an intent name. Once you configure the SearchQuery Slot Type, the Alexa Channel redirects the utterances to your Kore.ai Virtual Assistant for intent detection.</p> <p>Tip</p> <p>Please ensure that your skill uses at most one <code>AMAZON.SearchQuery</code> slot per intent. The <code>Amazon.SearchQuery</code> slot type cannot be combined with another intent slot in sample utterances.</p> <p>To configure a custom Interaction Model for the SearchQuery Slot Type, follow the steps below:</p> <ol> <li>Follow the sequence in Step 4 of Dialog Migration to Extract the Dialog Tasks from Kore.ai.</li> <li>Create a new custom intent by following these steps.</li> <li>After writing a few utterances, pick the words or phrases representing variable information as the intent\u2019s slots; For example, \u201cI would like to order two iPhones.\u201d</li> <li>Create a slot for each word or phrase and replace the original word with the slot name in curly brackets ({ }).</li> <li>To create a slot, follow the steps below:</li> <li>Sign in to the Alexa Developer Console.</li> <li>Click the Skills tab.</li> <li>In the SKILL NAME column, click the name of your custom skill.  </li> <li>From the left menu, click Custom &gt; Interaction Model &gt; Intents.</li> <li>Click +Add Intent to create a custom intent.</li> <li>Type a Custom Intent Name and click Create custom Intent.  </li> <li>Click this intent name listed on the left menu under Intents to open the detail page.</li> <li>Add the phrases or words in the Sample Utterances text input field.  </li> <li>In the drop-down box, enter the slot name and click the + icon.   </li> <li>Repeat these steps for all the remaining variable words.</li> <li>Select <code>AMAZON.SearchQuery</code> from the dropdown list in the SLOT TYPE column. </li> <li>Click Save Model and Build Model on the top action panel.</li> </ol> <p>Note</p> <p>On the Intents detail page, the Intent Slots section displays the slots you add. When you highlight a word or phrase in an utterance, you can add a new slot or select an existing slot.</p>"},{"location":"channels/amazon-alexa/#step-3-enable-account-linking-optional","title":"Step 3: Enable Account Linking (Optional)","text":"<p>If end-user authorization is required for making API calls to external services, you need to enable the Account Linking feature for your Alexa Skill with the steps below:</p> <ol> <li>On Your Skills console, select the Build tab.</li> <li>Expand the Tools left menu, then click Account Linking.</li> <li>Auth Code Grant is the default Authorization grant type selection on the Account Linking page.Enter the values for the mandatory fields under Security Provider Information. Learn more.</li> <li>Click Save to configure the Implicit Grant flow for Account Linking. </li> </ol> <p>Alexa shares the user access tokens with Kore.ai assistants to make API calls defined for the Service nodes.</p> <p>Tip</p> <p>Please enable Account Linking on the Kore.ai Platform under Configurations in the Amazon Alexa window. This allows Kore.ai assistants to use the access tokens from Alexa to make API calls defined in the Service nodes.</p> <p></p>"},{"location":"channels/amazon-alexa/#step-4-enable-the-webhook-integration","title":"Step 4: Enable the Webhook Integration","text":"<ol> <li>On the Alexa Developer Console, click the Build tab on the top panel.</li> <li>Click the Endpoint left menu option.</li> <li> <p>Select HTTPS as the Service Endpoint Type.    </p> </li> <li> <p>On the Kore.ai XO Platform, copy the Webhook URL available under Configurations on the Amazon Alexa Channel window.</p> </li> <li> <p>Paste the URL for the Default Region field on the Service Endpoint Type page. </p> </li> <li> <p>For the Select SSL Certificate Type drop-down, select the option \u201cMy development endpoint is a sub-domain of a domain that has a wildcard certificate from a certificate authority.\u201d </p> </li> <li> <p>Click the Save Endpoint button on the top panel.</p> </li> </ol> <p>The webhook/callback URL is configured successfully to receive messages and events.</p>"},{"location":"channels/amazon-alexa/#step-5-enable-the-channel","title":"Step 5: Enable the Channel","text":"<p>Before testing your assistant on Alexa, complete the channel setup with these steps:</p> <ol> <li>Click the Configurations in the Amazon Alexa window on the Kore.ai XO Platform.</li> <li>Select Yes for Enable Channel.</li> <li>Click Save to complete the configuration.</li> </ol>"},{"location":"channels/amazon-alexa/#step-6-test-the-integration","title":"Step 6: Test the Integration","text":"<p>Once done, test the utterance integration on the Alexa Developer Console using the steps below:</p> <ol> <li>Click the Test tab.</li> <li> <p>Select Development for the Skill testing is enabled in option. </p> </li> <li> <p>Navigate to the Alexa Simulator section, type an intent utterance, and click enter. </p> </li> </ol> <p>If you get a successful response, then the integration is considered a success.</p>"},{"location":"channels/amazon-alexa/#step-7-distribution","title":"Step 7: Distribution","text":"<p>To publish your Alexa Skill on the Alexa App, follow the steps below:</p> <ol> <li>Click the Distribution tab on the Alexa Developer Console.</li> <li>Click Skill Preview. </li> <li>Enter the values for the required fields.</li> <li>Click Save and Continue.</li> </ol>"},{"location":"channels/amazon-alexa/#privacy-compliance","title":"Privacy &amp; Compliance","text":"<p>On Alexa, it\u2019s important to set up your Privacy and Compliance information before building the model. To update Privacy and Compliance information, follow these steps:</p> <ol> <li>Click the Distribution tab. Then, click the Privacy &amp; Compliance left menu option. </li> <li>Provide all the required details.</li> <li>Click Save and Continue.</li> </ol>"},{"location":"channels/amazon-alexa/#availability","title":"Availability","text":"<p>You will be redirected to the Availability page to invite your co-developers to test your app. To complete the invitation, follow the steps below:</p> <ol> <li>Enable the Beta Test option if it\u2019s disabled.</li> <li>Enter the required details.</li> <li>Click Save and Continue. </li> </ol>"},{"location":"channels/amazon-alexa/#validation","title":"Validation","text":"<p>The next step is to validate your skills for the model. After configuring Availability, you will be redirected to the Validation page under the Certification section. Here, follow these steps:</p> <ol> <li>Review and complete any required fixes based on the details displayed for the issue.</li> <li> <p>Click Run to validate your skill.  </p> </li> <li> <p>Upon successful validation, your skill will be visible under Alexa Skills on Amazon App Store.  </p> </li> <li> <p>Additionally, your Skill Builder Checklist will display green checks for all the options. </p> </li> <li>After enabling the channel and verifying all the configurations, you can test the new channel integration by publishing your virtual assistant. Learn more.</li> </ol> <p>To learn more about working with messaging channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/call-properties/","title":"Voice Call Properties","text":"<p>You can enable voice interaction with your virtual assistant, i.e., users can talk to the virtual assistant. For this, you need to enable one of the voice channels like IVR, Twilio, IVR-AudioCodes,SmartAssist Gateway, etc and publish the VA on those channels.</p> <p>There are some Voice Properties you can configure to streamline the user experience across the above-mentioned channels. These configurations can be done at multiple levels:</p> <ul> <li>VA level \u2013 at the time of channel enablement;</li> <li>Component level \u2013 once you enable the voice properties at the VA level, then you can define the behavior for various components like:<ul> <li>Entity Node</li> <li>Message Node</li> <li>Confirmation Node</li> <li>Standard Responses</li> <li>Welcome Message</li> </ul> </li> </ul> <p>IVR Properties are accessible by going to a Dialog Task, selecting an Entity, Message or _Confirmation _Node, then by accessing the IVR Properties section.</p> <p></p> <p>This document details the voice call properties and how they vary across various channels.</p>"},{"location":"channels/call-properties/#channel-settings","title":"Channel Settings","text":"FIELD DESCRIPTION APPLICABLE <p> TO <p> CHANNEL IVR Data Extraction Key     Specify the syntax to extract the filled data <p> For Entity and Confirmation nodes, you can define the extraction rule overriding the channel level setting. This is particularly helpful with ASR engines that provide transcription results in a different format based on the input type. For example, VXML can contain the word format of the credit card in one key and the number format in another key     IVR     End of Conversation Behavior     This property can be used to define the VA behavior at the end of the conversation. The options are: <ul> <li>Trigger End of Conversation Behavior and configure the Task, Script or Message to be initiated. See here for details.  <li>Terminate the call.  <p> !!! note      Selecting the Terminate call option under IVR Channel \u2013 Voice Call Properties \u2013 End of Task Behavior no longer turns off the End of Task event at the bot level.   IVR, <p> Twilio, <p> IVR-AudioCodes, <p> SmartAssist Gateway     Call Termination Handler     Select the name of the Dialog task that you want to use as the call termination handler when the call ends in error.     IVR, <p> Twilio, <p> IVR-AudioCodes, <p> SmartAssist Gateway     Call Control Parameters     Click Add Parameter. Enter property names and values to use in defining the call behavior. <p> !!! note    You should use these properties and values in the VXML files for all call flows in the IVR system and Session Parameters in AudioCodes channel.      IVR, <p> IVR-AudioCodes     ASR Confidence Threshold     Threshold Key     This is the variable where the ASR confidence levels are stored. This field is pre-populated, do not change it unless you are aware of the internal working of VXML.     IVR     Define ASR threshold confidence     In the range between 0 to 1.0 which defines when the IVR system hands over the control to the VA.     IVR     Timeout Prompt     Enter the default prompt text to play when the user doesn\u2019t provide the input within the timeout period. If you do not specify a Timeout Prompt for any node, this prompt takes its place.     IVR, <p> Twilio, <p> IVR-AudioCodes, <p> SmartAssist Gateway     Grammar     Define the grammar that should be used to detect user\u2019s utterance <ul> <li>The input type can be Speech or DTMF  <li>Source of grammar can be Custom or Link <ul> <li>For Custom, write VXML grammar in the textbox.  <li>For Link, enter the URL of the grammar. Ideally, the URL should be accessible to the IVR system so that the resource can be accessed while executing the calls at runtime  <p> See below for a detailed configuration for Grammar syntax. \\ !!! note      If the Enable Transcription option is enabled for the VA along with specifying the source of the transcription engine, defining grammar isn\u2019t mandatory.  IVR     No Match Prompt     Enter the default prompt text to play when user input is not present in the defined grammar. If you do not specify a No Match Prompt for any node, this prompt takes its place.     IVR     Barge-In     Select whether you want to allow a user input while a prompt is in progress. If you select no, the user cannot provide input until IVR completes the prompt.     IVR, <p> Twilio, <p> IVR-AudioCodes, <p> SmartAssist Gateway     Timeout     Select the maximum wait time to receive user input from the drop-down list, from 1 second up to 60 seconds.     IVR, <p> Twilio, <p> IVR-AudioCodes, <p> SmartAssist Gateway     No. of Retries     Select the maximum number of retries to allow. You can select from just 1 retry up to 10 retries.     IVR, <p> Twilio, <p> IVR-AudioCodes     Log     Select Yes if you want to send the chat log to the IVR system.     IVR"},{"location":"channels/call-properties/#dialog-node-settings","title":"Dialog Node Settings","text":"<p>On the Voice Call Properties panel for a node, you can enter node-specific prompts, grammar, as well as parameters for call-flow behavior such as time-out and retries.</p> <p>Voice Call Properties apply only for the following nodes and message types:</p> <ul> <li>Entity Node</li> <li>Message Node</li> <li>Confirmation Node</li> <li>Standard Responses</li> <li>Welcome Message</li> </ul> <p>Note</p> <p>Most settings are the same for all nodes, with a few exceptions.</p> <p></p> <p>Voice Call Settings Field Reference</p> <p>The following sections provide detailed descriptions of each IVR setting, including descriptions, applicability to nodes, default values, and other key information.</p> <p>Notes</p> <ul> <li>You can enter prompts in one of these formats: Plain text, Script, File location of an audio file. If you want to define JavaScript or attach an audio file, click the icon before the prompt text message box and select a mode. By default, it is set to Text mode.</li> <li>You can enter more than one prompt message of different types. You can define their order of sequence by dragging and dropping them.</li> <li>Multiple prompts are useful in scenarios where the prompt has to be played more than once, to avoid repetition, since the prompts are played in order.</li> </ul> FIELD DESCRIPTION APPLICABLE <p> TO <p> NODES APPLICABLE <p> TO <p> CHANNEL Initial Prompts     Prompts that are played when the IVR first executes the node. If you do not enter a prompt for a node, the default user prompt for the node plays by default. If you do not enter a prompt for Standard Responses and Welcome Message, the default Standard Response and Welcome Message are played by default.     Entity, <p> Confirmation, <p> Message nodes; <p> Standard Responses and <p> Welcome Message     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     Timeout Prompts     Prompts that are played on the IVR channel when the user has not given any input within the specified time. If you do not enter a prompt for a node, the default Error Prompt of the node is played. Standard Responses and Welcomes have a default Timeout Prompt that plays if you don\u2019t define No Match Prompts. <p> You can Customize Retries Behavior for the Timeout Prompts and define the number of retries to configure the number of times the user would be prompted for this entity value by setting the number of Allowed Retries to any value between 1 and 10. The default is 3. <p> Further, you can define the VA\u2019s Behavior on Exceeding Retries; this can be set to trigger Invoke Call Termination Handler, Initiate Dialog Task, or Jump to specific node in current task. When you select Initiate Dialog or Jump to specific node in the current task option, you are prompted to select the dialog task or task within the node.     Entity, <p> Confirmation; <p> Standard Responses <p> and Welcome Message     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     No Match Prompts     Prompts that are played on the IVR channel when the user\u2019s input has not matched any value in the defined grammar. If you do not enter a prompt here or select No Grammar option for an Entity or Confirmation node, the default Error Prompt of the node is played. Standard Responses and Welcomes have a default No Match Prompt that plays if you do not enter it. <p> You can Customize Retries Behavior for the No Match Prompts and define the number of retries to configure the number of times the user would be prompted for this entity value by setting the number of Allowed Retries to any value between 1 and 10. The default is 3. <p> Further, you can define the VA\u2019s Behavior on Exceeding Retries; this can be set to trigger Invoke Call Termination Handler, Initiate Dialog Task, or Jump to specific node in current task. When you select Initiate Dialog or Jump to specific node in the current task option, you are prompted to select the dialog task or task within the node.     Entity, <p> Confirmation; <p> Standard Responses and <p> Welcome Message     IVR     Error Prompts     Prompts that are played on the IVR channel when user input is an invalid Entity type. If you do not enter a prompt here, the default Error Prompt of the node is played. <p> You can Customize Retries Behavior for the Error Prompts and define the number of retries to configure the number of times the user would be prompted for this entity value by setting the number of Allowed Retries to any value between 1 and 10. The default is 3. <p> Further, you can define the VA\u2019s Behavior on Exceeding Retries, this can be set to trigger Invoke Call Termination Handler, Initiate Dialog Task, or Jump to specific node in current task. When you select Initiate Dialog or Jump to specific node in the current task option, you are prompted to select the dialog task or task within the node.     Entity, <p> Confirmation;     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     Grammar     Define the grammar that should be used to detect a user\u2019s utterance <ul> <li>The input type can be Speech or DTMF  <li>Source of grammar can be Custom or Link <ul> <li>For Custom, write VXML grammar in the textbox.  <li>For Link, enter the URL of the grammar. Ideally, the URL should be accessible to the IVR system so that the resource can be accessed while executing the calls at runtime  <p> See below for a detailed configuration for Grammar syntax.  !!! note      If the Enable Transcription option is enabled for the VA along with specifying the source of the transcription engine, defining grammar isn\u2019t mandatory.   Confirmation; <p> Standard Responses and <p> Welcome Message     IVR, <p> Twilio     Advanced Controls These properties override the properties set in the VA IVR Settings page and apply to the Dialog Task that you are currently working with.     Timeout     Select the maximum wait time to receive user input from the drop-down list, from 1 second up to 60 seconds. The default value is the same as defined in the VA IVR Settings page.     N/A     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     No. of Retries     Select the maximum number of retries to allow. You can select from just 1 retry up to 10 retries. <p> The default value is the same as defined in the VA IVR Settings page.     N/A     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     Behavior on Exceeding Retries <p> (applies only to entity node)     Define behavior when either the timeout or number of retry attempts exceed the specified limit. Options include: <ul> <li>Invoke Call Termination Handler  <li>Initiate Dialog: Select a Dialog task from the list of VA tasks.  <li>Jump to a specific node in the current task: Select a node from the list of nodes in the current Dialog task.  <p> Post v7.3, this feature has been enhanced so that on exceeding entity error count, the platform will trigger the Behavior on Exceeding Retries behavior, when the transcription is enabled.  N/A     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     Barge-In     Select whether you want to allow a user input while a prompt is in progress. If you select no, the user input is not considered until the prompt is completed. The default value is No.     N/A     IVR, <p> Twilio, <p> AudioCodes, <p> SmartAssist Gateway     Call Control Parameters     Click Add Property. Enter property names and values to use in defining the VXML definition in the IVR system and Session Parameters in AudioCodes channel. These values defined for a node or a standard response override the global Call Control Parameters defined in the VA IVR /AudioCodes settings page.     N/A     IVR, <p> AudioCodes, <p> SmartAssist Gateway     Log     Select Yes if you want to send the chat log to the IVR system. The default value is No.     N/A     IVR     Locale Definition     Enable the Locale Definition property to define the (xml:lang = \u201c&lt;value&gt;\u201d) attribute in the VXML file by enabling the Locale Definition property. Automatic Speech Recognition engines use the language attribute to enhance speech recognition. <p> Once the property is enabled, you can see one or more language codes corresponding to the bot languages.  Enter the locale code for a specific bot language in the Locale Value field. For example, enter \u2018US\u2018 or \u2018UK\u2018 as the Locale Value for the English (EN) bot language.     !!! note      By default, the Locale Definition property is disabled for all virtual assistants.       N/A     IVR     Document Type Definitions     The Document Type Definition (DTD) typically refers to a specific syntax used to define the structure and constraints of a Voice Extensible Markup Language (VXML) document. The DTD settings help the VXML to understand the response. <p> You can use the Default DTD settings defined in the Status, Public ID, and System ID fields for the VXML. If you want to modify settings, click Customize to change the values. <p>  !!! note      If the Status field is set to Include, you can enter the Public and System ID. If it is set to Exclude, you cannot view those fields.       N/A     IVR     Fallback Redirection     A Fallback Redirection is an alternative path that the IVR system uses to handoff the conversation whenever the call hangs up <p> You can add an URL to redirect the conversation whenever the call hangs up. <p> By default, the Fallback Redirection is disabled. If you want to enable the Fallback Redirection, click Customize. <p>  !!! note      The Fallback Redirection is supported by both standard and universal bots.       N/A     IVR     Propagate Values to Link Bots     Enable this option to propagate the Voice Call Properties from the Universal Bot to all its linked bots. It helps you to leverage the UB properties when a linked bot\u2019s execution is in progress. The Voice Call Properties of the linked bot are used when the conversation is happening directly with the bot as a Standard bot. <p> By default this option is disabled.     N/A     IVR     Recording     Define the state of recording to be initiated. The default value is Stop.     N/A     IVR     <p>Below is a demo of the IVR Properties section, within the Component Properties panel of a Dialog Task node.</p> <p></p>"},{"location":"channels/call-properties/#configuring-grammar","title":"Configuring Grammar","text":"<p>You will need to define at least one Speech Grammar to the IVR system. \\ There is no default Grammar that will be considered by the system. In this section, we will walk you through the steps needed to configure a Grammar system for the VA to function on the IVR system.</p> <p>Typically for an IVR-enabled VA, the speech utterance of the user will be vetted and parsed by the Grammar syntax at the IVR system before being diverted to the VA.</p> <p>Kore.ai supports the following Grammar systems:</p> <ul> <li>Nuance</li> <li>Voximal</li> <li>UniMRCP</li> </ul> <p>Each one requires its own configuration.</p>"},{"location":"channels/call-properties/#nuance","title":"Nuance","text":"<p>In case you want to use grammar syntax rules from Nuance Speech Recognition System, you need to get a license for the same. Once you register and obtain a license from Nuance, you will be given access to two files \u2013 dlm.zip &amp; nle.zip. Ensure that the path to this VXML is accessible to the VA.</p> <p>Configurations:</p> <ol> <li>Set Enable Transcription to no</li> <li>In the Grammar section:<ol> <li>Select the Speech or **DTMF **option as per your requirement.</li> <li>In the text box to define vxml enter the vxml path to dlm.zip file. The url will be of the format: <code>http://nuance.kore.ai/downloads/kore_dlm.zip?nlptype=krypton&amp;dlm_weight=0.2&amp;lang=en-US</code></li> <li>Replace the above path according to your setup</li> <li>The language code \u201clang=en-US\u201d will be based on your setup</li> </ol> </li> <li>Add Grammar to add another path to <code>nle.zip</code>. Follow the above-mentioned steps.</li> <li>Save the settings.</li> </ol>"},{"location":"channels/call-properties/#voximalunimrcp","title":"Voximal/UniMRCP","text":"<p>In case you want to use grammar syntax rules from Voximal or UniMRCP, you need to specify the transcription source.</p> <p>Configurations:</p> <ol> <li>Set Enable Transcription to yes</li> <li>In the Transcription engine source text box that appears:<ol> <li>for Voximal, enter \u201cbuiltin:grammar/text\u201d</li> <li>for UniMRCP, enter \u201cbuiltin:grammar/transcribe\u201d</li> </ol> </li> <li>You can leave the Grammar section blank, the above transcription source URL will handle the syntax and grammar vetting of the speech.</li> <li>Save the settings.</li> </ol>"},{"location":"channels/ivr-audio-codes/","title":"Adding the IVR-AudioCodes Channel","text":"<p>You can connect your assistant to AudioCodes using a Webhook based integration. Before you begin, please ensure that you have administration access to your AudioCodes account.</p>"},{"location":"channels/ivr-audio-codes/#step-1-associate-an-app","title":"Step 1: Associate an App","text":"<ol> <li>In the XO Platform, select the assistant that you want to add AudioCodes IVR to.</li> <li>Go to Deploy &gt; Channels &gt; IVR-Audiocodes.</li> <li>Navigate to the **Configurations **tab of this page and associate a secure app by choosing an existing app or by creating a new one.</li> <li>Generate the JWT token using the details of the selected app and use this token for secure communication with the Kore.ai XO Platform.</li> </ol>"},{"location":"channels/ivr-audio-codes/#step-2-configure-the-bot-url-in-audiocodes","title":"Step 2: Configure the Bot URL in AudioCodes","text":"<p>The Webhook URL associated with this assistant should be configured in your AudioAccounts account. Navigate to the Configurations **tab of this page, copy the Webhook URL, and configure it as the _botURL _in the **VoiceAI Connector of your AudioCodes account. See the AudioCodes documentation for further details.</p>"},{"location":"channels/ivr-audio-codes/#step-3-configure-voice-call-properties","title":"Step 3: Configure Voice Call Properties","text":"<p>Make sure to configure the properties under the Voice Call Properties tab for defining the default voice interaction experience for your customers. Learn more about configuring Voice Call Properties.</p> <p></p>"},{"location":"channels/ivr-audio-codes/#step-4-enable-the-channel","title":"Step 4: Enable the Channel","text":"<p>On the Configurations tab, select Yes, then Save your configuration in order to enable the channel.</p> <p></p> <p>After the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available for end-users, with the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"channels/smart-assist-gateway/","title":"Adding the SmartAssist Gateway Channel","text":"<p>SmartAssist is a Kore.ai Contact Center Automation Solution. It helps enterprises manage their contact center infrastructure from the omnichannel interface, voice infrastructure, gateway, and live agent interactions, including agent assistance. Learn more.</p> <p>Applications built on SmartAssist use the Kore.ai XO Platform\u2019s IVR-Audiocodes channel via the underlying voice gateway interface for virtual assistant interactions. Kore.ai\u2019s native voice gateway, SmartAssist Gateway, is now configured as a new Kore.ai XO platform channel to drive and manage virtual assistant conversations using open-source components.</p>"},{"location":"channels/smart-assist-gateway/#important-considerations","title":"Important Considerations","text":"<ol> <li>SmartAssist Gateway, when configured as a new channel, lets you set up Voice Call Properties, and the channel overrides on SmartAssist.</li> <li>You cannot enable this channel via the XO Platform. Alternatively, you must enable the channel for the required app on SmartAssist.</li> <li>However, you should configure channel overrides from the XO Platform in the Voice Call Properties section for the new channel.</li> <li>The channel supports the channel-level Voice Call Properties supported by the IVR-AudioCodes channel. Learn more.</li> <li>The Telephony Welcome event applies to the channel.</li> <li>The system behavior for the End_ of task_ event is the same as that of AudioCodes.</li> <li>Channel overrides are supported for prompts.</li> <li>Node-level (Dialog, FAQ, Standard Responses, Events, etc.) Voice Call Properties are supported for the channel.</li> </ol>"},{"location":"channels/smart-assist-gateway/#configuration-overview","title":"Configuration Overview","text":"<p>To accomplish the channel enablement, you must do the following:</p> <ol> <li>Create a new SmartAssist Application to associate with the channel or select an existing app for the association. The steps are similar to the IVR-Audiocodes channel.</li> <li>Configure the Voice Call Properties, and define the Channel-specific Prompts and Messages for any Virtual Assistants connected to your SmartAssist application.</li> </ol>"},{"location":"channels/smart-assist-gateway/#prerequisites","title":"Prerequisites","text":"<p>Before configuring the SmartAssist Gateway channel, please ensure the following:</p> <ol> <li>You have a SmartAssist account.</li> <li>You\u2019ve completed the voice channel configurations on SmartAssist. Learn more.</li> <li>You have associated an app with the channel.</li> </ol>"},{"location":"channels/smart-assist-gateway/#configuration-steps","title":"Configuration Steps","text":"<p>Once you\u2019ve created a SmartAssist app on SmartAssist, follow the steps below to complete the channel configuration:</p> <p>Note: This channel is auto-enabled when you create a new SmartAssist application.</p>"},{"location":"channels/smart-assist-gateway/#define-the-voice-call-properties","title":"Define the Voice Call Properties","text":"<p>To define the voice call properties specific to the SmartAssist Gateway, follow the steps below:</p> <ol> <li> <p>Navigate to DEPLOY &gt; CHANNELS, and click SmartAssist Gateway under Voice Channels. </p> </li> <li> <p>Click the Voice Call Properties tab in the SmartAssist Gateway window. Learn more on Voice Call Properties.</p> </li> </ol>"},{"location":"channels/smart-assist-gateway/#step-1-configure-the-end-of-task-behavior","title":"Step 1: Configure the End of Task Behavior","text":"<p>Select one of the following options for End of Task Behavior to define the bot behavior on reaching the End of task flow:</p> <ul> <li>Trigger End of Task Event: When this event is triggered, the bot ends the call and initiates any task like Feedback Survey, Fallback, Dialog generation, etc., linked to the event.</li> <li>Terminate call: The bot ends the call without triggering any event-based tasks.</li> </ul>"},{"location":"channels/smart-assist-gateway/#step-2-event-configuration","title":"Step 2: Event Configuration","text":"<p>To define the follow-up task when an event is detected, follow these steps:</p> <p>Note</p> <p>You can also manage this event from the Natural Language &gt; Event Handlers page.</p> <ol> <li>Select one of the following options:</li> <li>Initiate Task: Initiates the task you select from the list.</li> <li>Run Script: Run the script code you define.</li> <li>Show Message: Displays the response message you define.</li> <li> <p>After selecting Show Message, click the + Add Response button.  </p> </li> <li> <p>Select SmartAssist Gateway from the list for Channel in the Add Response window.</p> </li> <li>Add the response text in the input field for Response.</li> <li>Click Done.  </li> </ol> <p>Tip</p> <p>You can use any value currently stored in the <code>context</code> variable of your message construction with <code>{{variable brackets}}</code>. For example, \u2018Hello <code>{{context.session.UserContext.firstName}}</code>. How can I help you?\u2019 This helps personalize the response message.</p>"},{"location":"channels/smart-assist-gateway/#step-3-select-the-call-termination-handler","title":"Step 3: Select the Call Termination Handler","text":"<p>Select the intent(dialog) you previously created from the list to handle the Call Termination event. This initiates the relevant task for the event flow.</p>"},{"location":"channels/smart-assist-gateway/#step-4-define-the-call-control-parameters","title":"Step 4: Define the Call Control Parameters","text":"<p>Define the parameters to control the call flow behavior by following the steps below:</p> <ol> <li>Click Add Parameter.</li> <li>In the Add Call Control Parameter window, input the Parameter name and Parameter value.</li> <li>Click Save.</li> </ol> <p>The new call control parameter is listed on the SmartAssist Gateway window, as shown below. \\  </p>"},{"location":"channels/smart-assist-gateway/#step-5-define-the-timeout-prompt","title":"Step 5: Define the Timeout Prompt","text":"<p>To define the prompt played when the user input is not received within the timeout period, follow the steps below:</p> <ol> <li>First, provide the text in the Timeout prompt input field.</li> <li>Next, hit enter.</li> </ol>"},{"location":"channels/smart-assist-gateway/#step-6-define-user-input-parameters","title":"Step 6: Define User Input Parameters","text":"<p>To define the key parameters for user input management, follow the steps below:</p> <ol> <li>First, provide values for the following fields:</li> <li>Barge-in: Select YES to allow the user\u2019s input while a prompt is in progress. Otherwise, select No.</li> <li>Timeout: Select an option from the list (0 seconds to 60 seconds) to define the maximum wait time to receive the user\u2019s input.</li> <li>No. of Retries: Select an option from the list (1 to 10) to define the maximum number of user input retries allowed.</li> <li>Next, click Save.</li> </ol> <p>Note</p> <p>You don\u2019t have to enable the channel explicitly since it is auto-enabled.</p> <p>After the channel is enabled and all configurations are verified, you can optionally publish the assistant to make it available for end users with the new channel. Learn more about Publishing your Virtual Assistant.</p> <p>To learn more about working with Channels within the Kore.ai XO Platform, please see Channel Enablement.</p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/","title":"Agent Management","text":""},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agents","title":"Agents","text":"<p>In the Contact Center, the term Agent Management refers to the management of agents (customer support representatives), supervisors, and administrators with an account within the contact center. To serve customers, you must add users to contact center and provide them with the necessary access. You can create user profiles, assign them to voice, chat, or both channels, and specific skills or queues.</p> <p>You can find the Agents section by going to Contact Center &gt; AGENT &amp; SUPERVISORS &gt; Agent Management. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agents-section-features","title":"Agents Section Features","text":"<p>The Agents section includes the features in the table below.</p> FEATURE DESCRIPTION Search     Type in a user\u2019s name to retrieve their record.     User     This is the name of the user you are viewing, as entered within their profile. Under every user\u2019s name, contact center mentions the groups that the user is part of.     Actions     This field lets you perform actions on the user record: <p> ACTION DESCRIPTION Edit the user record.     More options:  <ul> <li>Clone: Create a copy of the user record with the same configuration. This feature is useful when adding new users by updating their profiles without needing to configure them every time.  <li>Delete: Deletes the user.  Note: You cannot restore deleted users. Please proceed with caution! </li> Role      Lists the role assigned to the user.      Skills      Lists the skills assigned to the user."},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#add-a-user","title":"Add a User","text":"<p>You can add a user to Contact Center by following the steps below:</p> <ol> <li> <p>In the Agent section, click +Add User. </p> </li> <li> <p>The New User window displays. Here, you can find the following three areas to configure: </p> <ol> <li>Profile: Provide the user\u2019s profile information. This section opens by default.</li> <li>Settings: Configure settings related to the Chat and Voice Experience.</li> <li>Queues &amp; Skills: Assign the user to specific queues and skills. </li> </ol> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#profile","title":"Profile","text":"<p>In the profile section, configure the following:</p> <ul> <li>(Optional) Profile Picture: Upload the user\u2019s profile picture here.</li> <li>First Name and Last Name are mandatory fields for the user\u2019s first and last names, respectively. Only alphanumeric characters are allowed.</li> <li>(Optional) Nick Name: This is a mandatory field for the user\u2019s nickname in contact center.</li> <li>Role: Select whether the new user should be an Agent, Supervisor, or Administrator. See Role Management for details.</li> <li>Phone Number: This mandatory field requires a 10-digit phone number.</li> <li>Email ID: This is a mandatory field for the user\u2019s email address.</li> <li>Group: This is a mandatory field for a new user\u2019s organizational group. The Unassigned group is pre-selected.</li> </ul> <p>Note</p> <p>Users in the Unassigned group are not considered when routing interactions.</p> <ul> <li>Custom ID: This optional field lets you enter a custom ID for each user. The field supports up to 15 alphanumeric characters and cannot include space or special characters. You can use this field via API while adding or editing a user.</li> <li>Desktop Layout: Choose the layout with which the user will work within the Agent Console. See Manage Layout for details. </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#settings","title":"Settings","text":""},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#digital-experience","title":"Digital Experience","text":"<p>This section sets the chat support features for a user, such as the capacity by channel type, language, and proficiency level selections, and whether you want to allow attachments and emails within chats.</p> <p>To configure the digital experience, follow these steps:</p> <ol> <li>Enable or Disable the digital experience using the toggle switch.</li> <li>CAPACITY BY CHANNEL TYPE \u2013 This lets you set the maximum number of sessions an agent can handle simultaneously in a specific channel (Digital, Email, or Message).</li> <li>Language Support \u2013 Allows you to enable or disable the languages known by the user and sets the proficiency level (Novice, Average, Good, or Expert). To add more languages, see  System Setup &gt; Languages &amp; Speech.  </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#voice-experience","title":"Voice Experience","text":"<p>This feature helps configure a user\u2019s voice (call) experience settings.</p> <p>In the Voice Experience section, the following options are available:</p> <ul> <li>Enable Voice Settings \u2013 Enabling this option adds the user to the voice channel so that they can handle incoming calls.</li> <li> <p>Language Support \u2013 Select the language for voice support from the given options and set the language proficiency level. To add more languages, see System Setup &gt; Languages &amp; Speech.  </p> </li> <li> <p>Voicemail \u2013 Enabling this option lets the user select the maximum number of voicemails an agent can receive.  </p> </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#queues-skills","title":"Queues &amp; Skills","text":"<p>This section lets you configure the queues and skills assigned to a user.</p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#queues","title":"Queues","text":"<p>To assign queues to a user, follow these steps:</p> <ol> <li>Type a Queue Name in the field, then select the one you need from the list. Clicking into the Skills field shows the list of available options. The list only contains queues that are already created. To add a queue, see Routing &gt; Queues.</li> <li>Once you select a queue, it will be added to the user\u2019s list of assigned queues. If you have more than one queue assigned to the same user, you can select or deselect the queues to assign; and set queues as Preferred. Queues set as such will take priority over others when the user receives incoming queries.  </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#skills","title":"Skills","text":"<p>This section lets you configure the skills that the user brings to your team.</p> <p>To assign skills to a user:</p> <ol> <li>Type a skill name, and select it from the dropdown list to add it to the user\u2019s skill list. Clicking into the Skills field shows the list of available options. The list only contains skills that are already created. To add more skills, see Routing &gt; Skills.</li> <li>Once you select a skill, choose the proficiency level  (Novice, Average, Good, or Expert).</li> <li>You can remove a skill by clicking the Delete (bin) button next to it. </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#save-a-user","title":"save a User","text":"<p>To save the user, click the Add button at the bottom of the New User window. This is available regardless of the section that you are currently navigating. </p> <p>Notes</p> <p>The minimum requirements to save a user record are the following:</p> <ol> <li>The mandatory profile fields (all except the Profile Picture and Nick Name);</li> <li>Enable at least one channel (Chat or Voice);</li> <li>Assign at least one language to the channel you enable.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#edit-a-user","title":"Edit a User","text":"<p>To edit a user, follow these steps:</p> <ol> <li> <p>On the Agents page, click the Edit icon corresponding to the user you want to edit. </p> </li> <li> <p>On the Edit User window, make the necessary edits.</p> </li> <li>Click Save.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#delete-a-user","title":"Delete a User","text":"<p>To delete a user, follow these steps:</p> <ol> <li>On the Agents page, click the ... icon corresponding to the user you want to delete.</li> <li> <p>Click Delete.    Alternatively, edit the user, and on the Edit User window, click the Delete (bin) icon on the bottom left.  </p> </li> <li> <p>You will be asked to confirm your choice.</p> </li> </ol> <p>Notes</p> <ol> <li>You cannot delete your own user.</li> <li>You cannot delete the SmartAssist account owner.</li> <li>Reports, dashboards, and APIs will display deleted agents as long as interaction</li> <li>After deleting a user record, the respective user can no longer sign into the contact center. If you want to temporarily restrict users from handling customer conversations, you can turn off their access to chat and voice channels, or add them to the Unassigned group.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agent-groups","title":"Agent Groups","text":"<p>An Agent Group is a collection of agents based on skills, scopes, roles, functionalities, etc. Agents are assigned to groups to streamline customer service within Contact Center.</p> <p>To find Agent Groups, go to Contact Center &gt; AGENT &amp; SUPERVISORS &gt; Agent Management. All groups are visible on this page by default. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agent-group-section-features","title":"Agent Group Section Features","text":"<p>The Agent Group section includes the following features:</p> <ul> <li>You can use the Search field to find a group by name.</li> <li>Each group item shows the Group Name, Description, and the Number of Agents it includes.</li> <li>Clicking any group name reveals the agents who are part of it. Each agent is listed with their name, Edit Action, Role, assigned Skills, and Queues. Learn more about User Management.</li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#pre-configured-groups","title":"Pre-configured Groups","text":"<p>There are two pre-configured groups available:</p> <ul> <li>Unassigned is automatically selected in the Group drop down while creating a new user. The Unassigned group is not considered for routing interactions.</li> <li>Default Group.</li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#create-an-agent-group","title":"Create an Agent Group","text":"<p>To create a new agent group, follow these steps:</p> <ol> <li> <p>On the Agent Groups page, click Add Group. </p> </li> <li> <p>In the New Group window, provide the input for the following fields:</p> <ol> <li>Group Name \u2013 Enter the name of the agent group.</li> <li>Description \u2013 Enter a brief description of the group.</li> </ol> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#add-agents-to-a-group","title":"Add Agents to a Group","text":"<p>To add agents to a group, you either need to add a new agent to the Contact Center or edit an existing one to assign the group to them. Follow these steps to add an agent to a group:</p> <ol> <li>Go to Agents and create or edit an agent.</li> <li>On the profile, select the desired group.</li> <li>Save the agent record.</li> </ol> <p>To learn more about adding or editing agents, please see User Management. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#edit-an-agent-group","title":"Edit an Agent Group","text":"<p>To modify an agent group, follow these steps:</p> <ol> <li> <p>On the Agent Groups page, hover over the group that you want to edit, then click the Edit icon next to the group name; </p> </li> <li> <p>In the Edit Group window, make the required changes;</p> </li> <li>Click Save.</li> </ol> <p>Note</p> <p>You cannot change the name of the pre-configured groups: Unassigned and Default Group.</p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#delete-an-agent-group","title":"Delete an Agent Group","text":"<p>To delete an agent group, follow these steps:</p> <ol> <li>On the Agent Groups page, click the Edit icon next to the group you want to delete.</li> <li>In the Edit Group window, click the Delete Agent Group icon at the bottom left. </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agent-status-management","title":"Agent Status Management","text":"<p>This feature lets you display various statuses of an Agent \u2013 such as available, offline, busy, or away \u2013 along with a brief description for each status. You can add new statuses and edit or delete the existing ones.</p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#the-agent-status-live-board","title":"The Agent Status Live Board","text":"<p>You can find the Agent Status section by going to Contact Center &gt; Agent Management &gt; AGENT &amp; SUPERVISORS.</p> <p>Here you can see a list of existing statuses, along with the following information:</p> <ul> <li>Name: The name of the status that is displayed within the Agent Console.</li> <li>Actions: The available action is to Edit the status entry.</li> <li>Type: The type of status, mentioning whether the agent is Available, Away, Busy, or Offline while the particular status is set.</li> <li>Description: A short description of the status. </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#create-an-agent-status","title":"Create an Agent Status","text":"<p>To create a new agent status, follow these steps:</p> <ol> <li>In the Agent Status section, click + New Status.</li> <li>In the New Status window, enter the following details:<ol> <li>Status Name \u2013 Enter the status name.</li> <li>Status Type \u2013 Select the status type: Away or Busy.</li> <li>Description \u2013 Type in a brief description of the status.</li> </ol> </li> <li> <p>Click Add &amp; Exit to create the status and exit the window or click Add &amp; Stay to create the status and continue to a new one.  </p> </li> <li> <p>The status created successfully success message is displayed on-screen and the new status is added to the Agent Status list.  </p> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#edit-an-agent-status","title":"Edit an Agent Status","text":"<p>To edit an existing Agent status entry, follow these steps:</p> <ol> <li> <p>In the Agent Status section, click the Edit icon corresponding to the status entry that you want to modify. </p> </li> <li> <p>In the Edit Status window, edit the Status Name, Status Type, and/or Description, then click Update. </p> </li> <li> <p>The Status updated successfully message appears in the window and the modified values reflect in the Agent Status window. </p> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#delete-an-agent-status","title":"Delete an Agent Status","text":"<p>Notes</p> <ol> <li>The default statuses (Available, Away, Busy, and Offline) cannot be deleted. Only custom statuses provide this option.</li> <li>Deleted Agent Status entries cannot be restored.</li> </ol> <p>To delete an existing Agent Status entry, follow these steps:</p> <ol> <li> <p>In the Agent Status section, click the Delete icon corresponding to the status that you want to delete. </p> </li> <li> <p>You will be asked to confirm your choice. Click Yes to confirm.</p> </li> <li>A success status message is displayed and the deleted Agent Status is removed from the list.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#configure-login-prep-status","title":"Configure Login Prep Status","text":"<p>Login Prep status ensures agents do not receive interactions immediately after they log in on the Console. This status provides agents with a designated time to prepare before they start receiving interactions. Administrators can enable and configure this status for their agents.</p> <p>Steps to enable and configure Login Prep status:</p> <ol> <li> <p>By default, the login prep status is disabled. Click the Edit button to enable login prep. </p> </li> <li> <p>On the Edit Status window, turn on the toggle to Enabled. You can customize the following fields:</p> <ol> <li>Status Name</li> <li>Description</li> <li>Message to Agent<ol> <li>Rule (default 30 seconds)</li> <li>Message   </li> </ol> </li> </ol> </li> <li> <p>Click Update to save the changes.    A confirmation message is displayed.    Once enabled, the Login Prep becomes the default status for every new login for the agent. Learn more.</p> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#agent-settings","title":"Agent Settings","text":"<p>Agent Settings let you configure the settings that apply to all agents across Contact Center.</p> <p>Go to Contact Center &gt; AGENT &amp; SUPERVISORS &gt; Agent Management &gt; Agent Settings to view and edit the following:</p> <ol> <li>Answer Mode: These settings let you define how conversations get answered on each channel (Digital \u2013 Chats, and Emails, as well as Voice).</li> <li>Conversation Status Control: These options let you define how conversation status behaves and the messages triggered by status changes.</li> <li>Call Recording Control: These settings let you configure call recording behavior. If enabled, you can further enable options to allow Agents and Virtual Assistants to Pause/Resume call recording.</li> <li>Transfers: This section lets you define settings related to External Transfers, Skill Match, and Transfer Destination Control.</li> <li>Skill Modification: You can decide if the agents can modify skills attached to a conversation.</li> <li>Auto Logout: Administrators can configure this setting to specify a period of inactivity that automatically logs out agents.</li> </ol> <p>These settings are grouped and presented as closed groups when first opening the Settings screen. Click any group to view its corresponding options.  </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#answer-mode","title":"Answer Mode","text":""},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#voice","title":"Voice","text":"<ul> <li> <p>Manual: Agents must click \u2018Accept\u2019 to begin their voice interaction with the next customer. </p> </li> <li> <p>Auto: Calls are auto-answered. The agent does not need to click \u2018Accept\u2019. </p> </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#chats","title":"Chats","text":"<ul> <li> <p>Manual: Agents must click _Accept _ to begin chatting with the next customer. Set the acceptance timeout for agents before a chat returns to the queue by entering the number of minutes and seconds. </p> </li> <li> <p>Auto: Chats are auto-answered, and the agent does not need to click \u2018Accept\u2019. Set the first response timeout for agents to respond to new chats. </p> </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#emails","title":"Emails","text":"<ul> <li> <p>Manual: Agents must click \u2018Accept\u2019 to begin their email interaction with the next customer. Set the acceptance timeout for agents before an email returns to the queue by entering the number of minutes and seconds. </p> </li> <li> <p>Auto: Emails are auto-accepted, and the agent does not need to click \u2018Accept\u2019. </p> </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#conversation-status-control","title":"Conversation Status Control","text":"<p>The Conversation Status Control settings are available for the following channels: Live Chat, Messaging, Voice, and Emails.</p> <p>Different statuses apply to each channel. Watch the short demo below to see what these look like in SmartAssist, and read the following sections for details on available statuses and their configuration. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#conversation-statuses-by-channel-live-chat-messaging-and-voice","title":"Conversation Statuses by Channel (Live Chat, Messaging, and Voice)","text":"<p>Conversation statuses apply in certain conditions for specific channels. These are listed in the table below:</p> Status Applicability Channel Message Variables On Connect     When the agent connects     Live Chat, Messaging.     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Voice     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name     Due Reminder For Agent     If the agent\u2019s response time is greater than the set percentile of overdue conversations.     Live Chat, Messaging.     To Agent     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Agent Inactivity     If the agent has not responded to an overdue conversation for the set time (in minutes and seconds).     Live Chat     To Agent     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Overdue     If the agent has not responded for the set amount of time (in minutes and seconds).     Live Chat, Messaging.     To Agent     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Idle Reminder For Customer     If the customer\u2019s response time is greater than the set percentile of total idle customer conversations.     Live Chat, Messaging.     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Idle     If the customer has not responded for the set amount of time (in minutes and seconds).     Live Chat, Messaging.     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     Auto Expire     If the customer\u2019s response time is greater than the set amount of time (in minutes and seconds).     Live Chat     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     To Agent     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name     On Interruption     If the agent disconnects unexpectedly.     Live Chat, Messaging.     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time.     On Close     If the agent closes the conversation.     Live Chat, Messaging.     To User     Agent Full Name, Agent First Name, Agent Last Name, Agent Nick Name Elapsed Time, Expired Time."},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#conversation-statuses-by-channel-email","title":"Conversation Statuses by Channel (Email)","text":"Status Applicability Channel Message Variables Overdue     If the agent has not responded for the set amount of time (in hours and minutes).     Email     To Agent     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     Due Reminder for Agent Inactivity     If the agent\u2019s response time is under the set amount of time (in hours).     Email     To Agent     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     Agent Inactivity     The conversation will be moved back to Queue, once it turns overdue if the agent has not responded for the set amount of time (in hours and minutes).     Email     To Agent     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     Agent Offline     If an agent gets disconnected unexpectedly, conversations will wait in queue for a set amount of time (in hours and minutes).     Email     To Agent     Customer Idle     If the customer has not responded for the set amount of time (in hours and minutes) since the last agent response.     Email     To User     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     Due Reminder for Auto Expiry     If the customer\u2019s response time is under the set amount of time (in hours) before Auto Expiry.     Email     To User     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     Auto Expire     Once the conversation turns idle if the customer does not respond for the set amount of time (in hours and minutes) the interaction expires.     Email     To User     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     To Agent     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry.     On Close     If the conversation is closed by the agent.     Email     To User     Elapsed Time, Expired Time, Time Left to Inactivity, Time Left to Expiry."},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#conversation-status-configuration","title":"Conversation Status Configuration","text":"<p>For each status, you can configure the following:</p> <ol> <li>The response time after which the status should trigger: This can be set in either as a percent value of a total or as minutes and seconds.<ol> <li>The statuses for which you can set a percent value are: Due Reminder For Agent, and Idle Reminder For Customer.</li> <li>The statuses for which you can set a response time (in minutes and seconds) are: Overdue, Agent Inactivity, Idle, and Auto Expire.</li> <li>The statuses that do not require percentile or response time configuration are: On Connect, On Interruption, and On Close.   The following applies to emails:</li> <li>The statuses for which you can set a response time (in hours) are Due Reminder for Agent Inactivity, and Due Reminder for Auto Expiry.</li> <li>The status for which there is no response time is On Close.</li> <li>The statuses for which you can set a response time (in hours and minutes) are Overdue, Agent Inactivity, Agent Offline, Customer Idle, and Auto Expire.</li> </ol> </li> <li> <p>The messaging goes out to either the user or the agent. Status Messages can be edited by clicking the Edit icon under the Message column.  </p> <ol> <li> <p>Each status lets you edit the message text, add variables and select the language. </p> </li> <li> <p>To add a variable, place the cursor where you want to insert the variable, click the Variable field, then select the one you need. This adds a variable placeholder in your message text, which will be replaced with contextual information once the message reaches its recipient. You can select more than one variable within the same message. For example: <code>{{agentFirstName}}</code> becomes Christine Mark.  See the table in Conversation Statuses by Channel for details on available variables.</p> </li> </ol> </li> </ol> <p>Once you configure your Conversation Statuses and Messaging, click Save at the bottom right of the Agent Settings screen. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#call-recording-control","title":"Call Recording Control","text":"<p>By default, SmartAssist records all voice interactions. SmartAssist admins can disable call recording for all voice interactions. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#allow-agent-to-pauseresume","title":"Allow Agent to Pause/Resume","text":"<p>By default, the Allow Agent to Pause/Resume feature is disabled. However, admins can enable it for agents handling voice interactions, allowing them to pause the recording during the call. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#allow-virtual-assistant-dialogs-to-pauseresume","title":"Allow Virtual Assistant Dialogs to Pause/Resume","text":"<p>By default, the Allow Virtual Assistant to Pause/Resume feature is disabled. However, admins can enable it for virtual assistants (automation) handling voice interactions, allowing them to pause the recording when collecting Personally Identifiable Information (PII). </p> <p>Recorded calls are accessible to supervisors on the Dashboard\u2019s Interactions tab. The interactions are not recorded in the interactions tab for the duration that the recording was stopped/paused.</p> <p>Changes to the Call Recording Control settings are logged on the Kore.ai Bots Admin Console &gt; Analytics &gt; Audit Report page.</p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#transfers","title":"Transfers","text":""},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#transfer-to-external-contacts","title":"Transfer to External Contacts","text":"<p>If enabled, this option allows agents to transfer ongoing customer calls to the external contacts list, via the Agent Console. Please see Agent Console &gt; Transfer Interactions to learn more. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#enforce-skill-match-for-transfers","title":"Enforce Skill Match for Transfers","text":"<p>If enabled, the system considers skills while finding an agent, during a queue transfer. If disabled, the system ignores skills while finding an agent, during a queue transfer. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#transfer-destinations","title":"Transfer Destinations","text":"<p>Supervisors can decide where agents can transfer interactions: </p> <ul> <li>Queues &amp; Agents: Agents can transfer interactions to queues and other individual agents.</li> <li>Queues only: Agents can transfer interactions only to queues. </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#skill-modification","title":"Skill Modification","text":"<p>If enabled, the system allows agents to modify skills attached to an interaction.</p> <p>You can select from the following options:</p> <ul> <li>Live Interaction: Selecting this option lets agents modify skills from the skills bar on the Live Interaction window.</li> <li>Transfer: Selecting this option lets agents modify skills when transferring an interaction. </li> </ul>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#auto-logout","title":"Auto Logout","text":"<p>This feature allows administrators to specify the period of inactivity after which auto logout occurs. By default, auto logout is disabled. </p> <p>Enabling the setting allows administrators to configure the following rules:</p> <p>Auto Logout: The period of inactivity after which auto logout occurs. The default setting is 8 hours.</p> <p>Due Reminder for Auto Logout: The time duration before auto logout when the alert message appears. </p>"},{"location":"contactcenter/agent-and-supervisors/agent-management/agent-management/#snooze","title":"Snooze","text":"<p>This feature allows agents to temporarily pause conversations that are awaiting a response from the customer or require any necessary action from the agent.</p> <p>By default, the snooze functionality is disabled. Administrators can turn on the Snooze toggle to enable the functionality. </p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/","title":"Dispositions","text":"<p>Dispositions represent a label that agents assign to the outcome of a conversation. In SmartAssist, you can create disposition sets to organize disposition codes according to your business requirements.</p> <p>To reach this feature, go to Contact Center &gt; AGENT &amp; SUPERVISORS &gt; Dispositions. </p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#disposition-sets","title":"Disposition Sets","text":"<p>A Disposition Set is a group of disposition codes that you can assign to queues or agent groups to collect information at the end of a conversation. The disposition codes within a set act as fields that agents must populate when ending an interaction.</p> <p>The Dispositions section opens with the Disposition Sets tab preselected. </p> <p>The **Resolution**vDisposition Set comes prebuilt. It can be edited but cannot be deleted or disabled. You can change your Display option and edit assigned Disposition Codes. Everything else within this Set is uneditable. The default Disposition Codes for this Set are: Resolved, Requires Supervisor Attention, and Unresolved.</p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#section-features","title":"Section Features","text":"<p>Within the Disposition Sets section, you can perform the following:</p> <ol> <li>Search disposition sets,</li> <li>Add a new Set,</li> <li>Edit an existing set,</li> <li>Delete an existing custom set (all sets are custom except for Resolution, which is the default).</li> <li>Reorder sets by dragging a set and dropping it into the desired position,</li> <li>View basic Disposition Set information: <ol> <li>Name: The name of the Disposition Set,</li> <li>Actions: This column lists the Edit option for custom sets,</li> <li>Description: A short description of the Disposition Set,</li> <li>Codes: Lists the number of codes contained within a set,</li> <li>Status: Lists whether the set is enabled or disabled.</li> </ol> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#add-a-disposition-set","title":"Add a Disposition Set","text":"<p>To add a new Disposition Set, follow these steps:</p> <ol> <li> <p>Under Dispositions &gt; Disposition Sets, click Add Set. </p> </li> <li> <p>In the New Disposition Set window, configure the following:</p> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#general","title":"General","text":"<p>In the General tab, you can configure the main settings for the Disposition Set. Populate the following fields:</p> <ol> <li>Name the Disposition Set.</li> <li>Description: Enter a short description of the set.</li> <li>Display: This field lets you specify how to display the disposition code selection options. Choose between Dropdown and Button, both allowing single selection.</li> <li>Is Required: Choose whether the Disposition Set is required at the end of a conversation. You can select Yes or No. If you select Yes, agents must select a disposition code within this set when ending interactions that are part of the queues assigned to the set or if the agent is part of a group assigned to the set.</li> <li> <p>Under the Assignment section, you can assign the Disposition Set to either queues or agent groups, as follows:</p> <ol> <li> <p>Select Assign to Queues and the disposition set will display to all agents who are in the assigned queues. You can assign the set to all queues or selected queues. Click Add Queue to search and select one or multiple queues from a list. Queues must have been previously created before becoming available to select here. See Queues to learn more about creating them. You can delete a queue assignment using the Delete (bin) icon on the right of the entry. </p> </li> <li> <p>Select Assign to Agent Groups and the Disposition Set will display to all agents in the selected agent groups. The selection process is similar to the Queue selection above.</p> </li> </ol> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#disposition-codes","title":"Disposition Codes","text":"<p>On the Disposition Codes tab, you can assign codes to the Disposition Set. The code must have been previously created and enabled before becoming available to select here. See the Disposition Codes section below for more.</p> <p>To assign a code:</p> <ol> <li>Click Add Code.</li> <li>Search for and select the desired code from the list of available codes.</li> </ol> <p>To delete a code, click the Delete (bin) icon on the right.</p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#enable-or-disable-a-set","title":"Enable or Disable a Set","text":"<p>By default, new Disposition Sets are enabled. Turn off the toggle if you want to disable a Disposition Code. </p> <p>Click Create when ready. Below is a short demo that shows you how to add a new Disposition Set. </p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#edit-a-disposition-set","title":"Edit a Disposition Set","text":"<p>To edit a Disposition Set, follow these steps: </p> <ol> <li> <p>Click the Edit icon corresponding to the set you want to edit. </p> </li> <li> <p>In the Edit Disposition Set window, make the required changes and click Save.</p> </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#delete-a-disposition-set","title":"Delete a Disposition Set","text":"<p>To delete a Disposition Set, follow these steps:</p> <ol> <li>Click the Edit icon corresponding to the set you want to delete.</li> <li>In the Edit Disposition Set window, click the Delete (bin) button on the bottom left. You must confirm your choice. </li> </ol> <p>Notes</p> <ol> <li>Deleted Disposition Sets are removed from the Agent Console and no longer display after conversations within assigned queues or agent groups.</li> <li>Deleted Disposition Sets cannot be restored. Please proceed with caution.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#example-disposition-sets","title":"Example Disposition Sets","text":"<p>Below are a couple of examples of disposition sets to help you create your own:</p> <ol> <li>Requires Follow Up, containing Disposition Codes for: Pending, Disconnected, Information Required, etc.</li> <li>Supervisor Required: containing Disposition Codes for: Requires Approval, Customer Asked for Supervisor, Complex Case, etc.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#disposition-codes_1","title":"Disposition Codes","text":"<p>A Disposition Code is a short label assigned to the outcome of an interaction. Disposition Codes are required to build Disposition Sets and cannot be assigned to Queues or Agent Groups on their own.  </p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#default-disposition-codes","title":"Default Disposition Codes","text":"<p>Contact Center provides three pre-defined disposition codes:</p> <ul> <li>Resolved: To be used for resolved requests that require no further action.</li> <li>Requires Supervisor Attention: For requests that need to be escalated to a supervisor.</li> <li>Unresolved: For requests which are closed but unresolved.</li> </ul>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#custom-disposition-codes","title":"Custom Disposition Codes","text":"<p>Contact center also allows you to create custom codes and makes them available to agents once enabled and included within a Disposition Set. You can find and create Disposition Codes by going to Contact Center &gt; AGENT &amp; SUPERVISORS &gt; Dispositions &gt; Disposition Codes. Here, you can find a list of existing Disposition Codes and create new ones. You can also perform a name-level keyword search.</p>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#add-a-custom-disposition-code","title":"Add a Custom Disposition Code","text":"<p>To add a Disposition Code:</p> <ol> <li> <p>Click + Add Code. </p> </li> <li> <p>A New Disposition Code page opens. Click Enable at the top right to activate the Code.</p> </li> <li>Enter the disposition Code Name and Description.</li> <li>Assign a color and check the preview to make sure it looks good.</li> <li>Click Create. </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#edit-a-custom-disposition-code","title":"Edit a Custom Disposition Code","text":"<p>To edit a custom Disposition Code, follow these steps:</p> <ol> <li>Find it in the list of Disposition Codes,</li> <li>Click the Edit button under the Actions column,</li> <li>Make your changes in the Edit Disposition Code window, then Save. </li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#delete-a-custom-disposition-code","title":"Delete a Custom Disposition Code","text":"<p>To delete a custom Disposition Code, follow these steps:</p> <ol> <li>Find it in the list of Disposition Codes.</li> <li>Click the Delete button under the Actions column.</li> <li>Confirm your choice. </li> </ol> <p>Notes</p> <ol> <li>You cannot restore deleted disposition codes.</li> <li>Deleted Disposition Codes are not displayed to agents in the Agent Console.</li> </ol>"},{"location":"contactcenter/agent-and-supervisors/dispositions/manage-dispositions/#the-agent-experience-with-dispositions","title":"The Agent Experience with Dispositions","text":"<p>Dispositions are displayed once agents end a conversation within the Agent Console. No disposition code is selected by default when choosing a Disposition Set at the end of an interaction. Agents must choose a disposition code. If you have assigned more than one Disposition Set to a specific Queue or Agent Group, then corresponding agents see all sets and must select codes for all required sets. </p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/","title":"Default Flows","text":"<p>The Default Flows feature lets you customize experiences for common events like welcome, transfer, or an unknown Intent.</p> <p>Here, you can configure the interaction flow based on the customer\u2019s behavior in two scenarios:</p> <ol> <li>Off-Working Hours: When the customer tries to connect to an agent during off-working hours.</li> <li>No Agents Available: When agents with specific skills, as required by the customer, are unavailable.</li> </ol> <p>The contact center module provides inbuilt Phone and Chat Experience flows for these scenarios. However, you can change the default flow and the message to the customer based on the current conversation channel.</p> <p>To start, go to Contact Center &gt; Configuration &gt; Default Flows. </p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#phone-experiences","title":"Phone Experiences","text":"<p>The following sections describe configuring the default flows for a phone experience.</p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#off-working-hours","title":"Off-Working Hours","text":"<p>This flow plays a voice message to the caller who tries to reach an agent during off-working or non-business hours. Off-working hours are considered those that are outside of your configured Hours of Operation.</p> <p>To configure the Off Working Hours flow, click the Off Working Hours tile in the Phone Experiences section. </p> <p>In the Off Working Hours for Calls panel, a text area displays the default message a customer hears while attempting to reach a live voice agent during off-working hours. You can edit this message by clicking the Edit icon on the top right. You can choose the message language by clicking on one of the language selection buttons. </p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#no-agents-available","title":"No Agents Available","text":"<p>You can set the message played to the customer if the available online agents don\u2019t have the required skills. To configure the No Agents Available flow, click the No Agents Available tile under Phone Experiences. </p> <p>In the No Online Agents with needed skill panel, use the text area to configure the message to be played to callers when no agent is available. You can edit this message by clicking the Edit icon on the top right. You can choose the message language by clicking on one of the language selection buttons. </p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#chat-experiences","title":"Chat Experiences","text":"<p>The following sections describe the default flows configuration for a chat experience.</p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#off-working-hours_1","title":"Off Working Hours","text":"<p>The Off Working Hours flow sets the auto-response message during non-business hours for automated and live chats. To configure this feature, follow these steps:</p> <ol> <li>Click the Off Working Hours tile under Chat Experiences.</li> <li>In the Off Working Hours for Chats panel, you can define the messages displayed during off-working hours (based on the hours of operation) when a customer attempts to reach a live chat agent.</li> </ol> <p>You can define messages for the following scenarios:</p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#messaging-chat-channels","title":"Messaging Chat Channels","text":"<p>This feature lets you customize the auto-response message during off-working hours. To use this option, follow these steps:</p> <ol> <li>Use the text area to configure the message to be played to callers when no agent is available. You can choose the message language by clicking on one of the language selection buttons. </li> <li> <p>You can edit the message and configure the next action by clicking the Edit icon on the top right. </p> </li> <li> <p>The After that section defines what happens after the message is displayed to the customer. Select one of the following options:</p> <ol> <li>End Chat ends the chat conversation.</li> <li>Add to Queue adds the customer to the waiting queue of an agent.</li> </ol> </li> <li>Save when done. </li> </ol>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#if-live-chat","title":"If Live Chat","text":"<p>You can set the message to the customer when they interact on a live chat channel. To configure, follow these steps:</p> <ol> <li>Use the text area to configure the message to be played to callers when no agent is available. You can choose the message language by clicking on one of the language selection buttons.</li> <li> <p>You can edit the message and configure the next action by clicking the Edit icon on the top right. </p> </li> <li> <p>The After that section defines what happens after the message is displayed to the customer. Select one of the following options:</p> <ol> <li>End Chat ends the chat conversation.</li> <li>End Chat with Email Deflection ends the chat conversation and deflects it to the Email channel. This option lets you configure the email message sent to the customer if their conversation is deflected.<ol> <li>You can choose the message language by clicking on one of the language selection buttons.</li> <li>You can configure the email subject and format the body text using the formatting toolbar.</li> </ol> </li> </ol> </li> <li>Save when done. </li> </ol>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#no-agents-available_1","title":"No Agents Available","text":"<p>You can set the message displayed to the customer if the available online agents don\u2019t have the required skills.</p> <p>To get started, click the No agents Available tile under Chat Experiences.</p> <p>In the No Online Agents with needed skill window, define what to do if the skills a customer requires do not match any online agent. Here you can configure the following:</p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#messaging-chat-channels_1","title":"Messaging Chat Channels","text":"<p>This section is where you can define the message displayed when the customer comes from a chat channel that supports async messaging.</p> <p>Use the text area to configure the message to be displayed when no agent is available. You can edit the message and choose the message language by clicking the Edit icon on the top right. </p>"},{"location":"contactcenter/configurations/default-flows/configure-default-flows/#live-chat-channels","title":"Live Chat Channels","text":"<p>If the customer comes from a live chat channel and SmartAssist determines that no available agent matches the required skills, then the customer will see the message configured in this section.</p> <p>Use the text area to configure the message to be displayed when no agent is available. You can edit the message and choose the message language by clicking the Edit icon on the top right. </p> <p>Once completing any of these default flows, click Save to save your changes.</p>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/","title":"Hours of Operation","text":"<p>The Hours of Operation feature helps set the standard hours when agents are available for customers based on business operating hours, non-operating hours, and holidays.</p> <p>In Contact Center, you can define the standard working hours for each day of the week and set the non-working hours for weekends and public holidays in different time zones.  Default Flows are handled by SmartAssist based on your configuration for Hours of Operation,</p> <p>You can reach the Hours of Operation feature by going to Contact Center &gt; Configurations &gt; Hours of Operation. </p> <p>The Hours of Operation section displays the following details:</p> <ul> <li>A Name for each configuration;</li> <li>Actions: Here is where you can Edit or Delete a configuration.</li> <li>Timezone: Lists the timezone for which the hours of operation are configured;</li> <li>Special Days: Lists any configured special days or holidays.</li> </ul>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/#add-hours-of-operation","title":"Add Hours of Operation","text":"<p>To add Hours of Operation, follow these steps:</p> <ol> <li> <p>Click + Add New to add a new Hours of Operation entry. </p> </li> <li> <p>In the New Hours of Operation panel, configure the following fields:</p> <ol> <li>Name: Add a name to identify the Hours of Operation profile. For example, Official Working Hours.</li> <li>Time Zone: Select the time zone for which these hours apply.</li> <li>Work Days, Holidays, and Special Days: Configure the days and hours of operation per day, and set up holidays and special days as follows:</li> </ol> </li> </ol>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/#standard-hours","title":"Standard Hours","text":"<p>Set the standard working hours explicitly or opt for the pre-selected hours (9 AM to 6 PM). By default, the weekdays are open, and weekends are closed. The status for Saturday or Sunday can be enabled or disabled using the toggle. </p>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/#holidays-and-special-days","title":"Holidays and Special Days","text":"<p>Set the Date, Name, Period, Start Work Time, and End Work Time for holidays or special days.</p> <p>To add a new entry, click the + Add New button. </p> <ul> <li>Enter the Date of the holiday or special day;</li> <li>Enter a Name;</li> <li>Toggle the Period to either Partial or Full. When set to Partial, you can adjust the working hours for the day. When set to Full, the day is considered a holiday.</li> <li>To add more hours of operation for holidays and special days, click + Add Another.</li> <li>To delete an entry, click the Delete (bin) icon next to it.</li> <li>Click Save. </li> </ul>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/#edit-hours-of-operation","title":"Edit Hours of Operation","text":"<p>To edit Hours of Operation, click the corresponding Edit icon under Actions. </p>"},{"location":"contactcenter/configurations/hours-of-operation/manage-hours-of-operation/#delete-hours-of-operation","title":"Delete Hours of Operation","text":"<p>To delete an Hours of Operation entry, click the corresponding Delete icon under Actions. You will be asked to confirm your choice. </p>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/","title":"Configure languages and speech","text":""},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#languages-and-speech","title":"Languages and Speech","text":"<p>This feature lets you configure the language and speech settings within Contact Center module, to manage how your contact center uses languages and speech recognition.</p> <p>Go to Contact Center &gt; CONFIGURATIONS &gt; Languages &amp; Speech to access Languages and Speech settings. </p> <p>This section of the Contact Center module provides access to the following settings:</p> <ul> <li>Supported languages: Define the languages you want agents and automation to work with.</li> <li>Voice Preferences: Choose the engines to use with SmartAssist for Automated Speech Recognition (ASR) and Text-to-Speech (TTS).</li> <li>Hold Audio: Define the default audio that plays to callers while on hold or waiting in the queue.</li> </ul>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#language-management","title":"Language Management","text":"<p>This feature helps manage the languages that are supported by the contact center infrastructure. You can add support for specific languages and enable, disable or delete specific languages.</p> <p>To manage languages, click Supported Languages. </p>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#add-a-language","title":"Add a Language","text":"<p>To add a new language, follow these steps:</p> <ol> <li>In the Language panel, select the language and click on Agent, Call Automation, Chat Automation or select all to enable the language for each functionality.</li> <li>Click Save to save your new language. </li> </ol>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#disable-and-re-enable-a-language","title":"Disable and Re-Enable a Language","text":"<p>To disable a language and its access flows, uncheck its corresponding checkbox, then click Save. This will deactivate the language, and it will no longer be available within the selected access channels; however, it will not be completely removed.</p> <p>You can enable the language again later by selecting its corresponding checkbox, then saving. </p>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#delete-a-language","title":"Delete a Language","text":"<p>In the Language panel, click the Delete (bin) icon for the language you want to remove. This removes the language completely from all your workflows. </p>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#voice-preferences","title":"Voice Preferences","text":"<p>In the Language &amp; Speech section of SmartAssist, you can configure the voice preferences to personalize the ASR Engine and the voice that plays for your text-to-speech conversions.</p> <p>To configure or modify the voice preferences, follow the steps below:</p> <ol> <li> <p>Under Languages &amp; Speech, click Voice Preferences. </p> </li> <li> <p>Select a Text-to-Speech Engine in the Voice Preferences window: Google Cloud Text-to-Speech, Microsoft Azure Speech Services, or AWS Amazon Polly.</p> <ol> <li>Enter Sample Text to preview your voice selection. You can play, navigate through the audio (Back/Fw), and adjust the preview volume. Clicking the More Options (\u22ee) button reveals options to adjust Playback Speed and Download the voice preview.</li> <li>Click the Play button next to any available voice to preview it. Voices are available for all TTS engines, but each engine has its own voice options.</li> <li>Select a different Voice Language if required. </li> </ol> </li> <li> <p>Select an Automated Speech Recognition Engine: Google Cloud Speech-to-Text, Microsoft Azure Speech Services, AmiVoice, or NVIDIA Riva. Afterward, choose the Dialect that you want to work with. </p> </li> <li> <p>Click Done once you have completed configuring your voice preferences. The set voice, language, and dialect apply to automated customer responses that use text-to-speech.</p> </li> </ol>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#hold-audio","title":"Hold Audio","text":"<p>This option helps configure the audio played to a caller while on hold or waiting in the queue.</p> <p>To configure the Hold Audio, go to Languages &amp; Speech and select the Hold Audio option. </p>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#add-hold-audio-files","title":"Add Hold Audio Files","text":"<ol> <li>In the Hold Audio panel, click Browse to select and upload your .WAV audio file. Alternatively, you can drag and drop the file to the panel.</li> <li>Once the file uploads, you can adjust the audio file name in the Rename Audio text area.</li> <li>Click Save to add the new audio file and it is automatically added to the Hold Audio list. The uploaded audio plays to the caller while on hold or waiting in the queue. </li> </ol>"},{"location":"contactcenter/configurations/languages-and-speech/configure-languages-and-speech/#delete-hold-audio-files","title":"Delete Hold Audio Files","text":"<p>The available audio file deletion methods are listed below and illustrated in the following screenshot:</p> <ol> <li>Delete a file from the saved list by clicking the Delete (bin) icon next to it. You will be asked to confirm your choice. Files deleted from the list have to be reuploaded if you change your mind.</li> <li>Remove an uploaded file that has not yet been saved to the list by clicking the Delete (x) button on the top right corner of the upload panel. </li> </ol>"},{"location":"contactcenter/flows-and-routing/waiting-flows/","title":"Waiting Flows","text":"<p>While customers wait for an agent to assist with their query via voice or chat, you can customize their Waiting Experience to maintain engagement and improve customer satisfaction.</p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#key-features","title":"Key Features","text":"<p>You can configure the Waiting Experience within Contact center using the following features:</p> <ul> <li>Routing rules based on agent skills.</li> <li>Message options for both voice and chat requests:<ul> <li>Initial message when a request is assigned to a queue.</li> <li>Hold audio for calls,</li> <li>Periodic message delivered while contacts wait \u2013 both for calls and chats.</li> </ul> </li> <li>Message language configuration.</li> <li>Call to chat deflection if the wait time exceeds a specified limit.</li> <li>Callback if the wait time exceeds a specified limit.</li> <li> <p>Send a voicemail if the call wait duration exceeds a specified limit, the queue position is too long, or the estimated wait time exceeds a specified limit.</p> <p>Note</p> <p>The voicemail option is only available for accounts configured with Kore Voice Gateway.</p> </li> </ul>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#the-waiting-experience-live-board","title":"The Waiting Experience Live Board","text":"<p>You can find the Waiting Experience Live Board by navigating to Contact Center &gt; FLOWS &amp; ROUTING &gt; Waiting Flows. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#waiting-experience-live-board-features","title":"Waiting Experience Live Board features","text":"<p>The Waiting Experience section displays the following fields:</p> FIELD DESCRIPTION Name     The name of the Waiting Experience entry.     Skill Rule     The skill rules that have been configured for the entry. The waiting experience. Conversations matching these skill rules will go through the waiting experience configured within this entry.     Description     The description of the Waiting Experience entry.     Update (Icon)     This icon lets you access the configuration area for a Waiting Experience entry, where you can update the available options."},{"location":"contactcenter/flows-and-routing/waiting-flows/#add-waiting-experience","title":"Add Waiting Experience","text":"<p>To add a new waiting experience entry, follow these steps:</p> <ul> <li>Navigate to Contact Center &gt; FLOWS &amp; ROUTING &gt; Waiting Flows.</li> <li> <p>Click the + New Waiting Experience button. </p> </li> <li> <p>In the Add New Waiting Experience window, you will see three tabs:</p> <ol> <li>Configuration, where you can set up the name, description, and routing rules;</li> <li>Call Experience, where you can configure the Waiting Experience for customers who call;</li> <li>Chat Experience, where you can customize the Waiting Experience for chats.</li> </ol> </li> </ul>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#configuration","title":"Configuration","text":"<p>The Configuration section lets you set up the basics of your Waiting Experience entry. </p> <p>Get started by configuring the following:</p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#name-and-description","title":"Name and Description","text":"<p>Provide a Name and a brief Description for the Waiting Experience entry. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#routing-rules","title":"Routing Rules","text":"<p>Define the configuration rules for the Skill Group and Skill waiting queue constraints.</p> <ol> <li>Select the Skill Group, then the Skill that the Waiting Experience should match;</li> <li>Click the row-wise +Add button to add a new row to the existing Routing Rule (OR) condition and the Delete icon to delete a row;</li> <li>Configure the AND/OR conditional logic by hovering over a rule row and toggling between the tabs, as shown in the demo below;</li> <li>To configure the AND condition, click the + Add button below the OR/AND section;</li> <li>To remove a rule row, click the Delete (\u24e7) icon next to the row. To delete a rule section, click the **Delete (bin) **icon next to it. </li> </ol> <p>Below is an example configuration for Routing Rules:  In this example, customers are mapped to a specific agent as follows:     1. If the skill group Languages and skill is English OR,     2. If the skill group is Languages and skill is Spanish, AND,     3. If the skill group is Travel Requirements and skill is US Entry.</p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#call-experience","title":"Call Experience","text":"<p>To set the call waiting experience, click Call Experience for customers contacting you using the voice channel. </p> <p>In the Call Experience page, configure the settings below:</p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#initial-message","title":"Initial Message","text":"<p>This message is played to the customer waiting in the queue and is enabled by default. To change the language, select the desired language tab, edit the message, and click Done. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#hold-audio","title":"Hold Audio","text":"<p>This audio is played to the customers on hold. Select the audio you wish to play from the Hold Audio dropdown list. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#periodic-messages","title":"Periodic Messages","text":"<p>These messages are played periodically to the customers waiting in the queue or put on hold. To configure them, follow these steps:</p> <ol> <li>Set the number of seconds within which the periodic message should play;</li> <li>Set the play order as either random _or _sequential;</li> <li>Select the type of playback \u2013 either once _or _looped;</li> <li>Edit the message and change the language, as needed, by clicking one of the language options at the top of the editor. Click \u2714 Done to save or click x Close to discard your changes;</li> <li>To add another message, click + Add Another;</li> <li>To delete a message, click the Delete icon next to it. </li> </ol> <p>Periodic messages also enable organizations to allow their customers to view/listen to their Queue Position and Estimated Wait Time (EWT).</p> <p>You can configure the following variables:</p> <ul> <li>Queue Wait Time: {{queue.waitTime}} min</li> <li>Queue Position: {{queue.position}}</li> </ul> <p>Chat Deflection</p> <p>You can configure the following call to chat deflection when the wait time exceeds a set limit:</p> <ol> <li>Enable the option to activate it;</li> <li>Set the digit key that customers should press for deflection; then set the time after which the chat deflection should occur. For example, deflect from call to chat if the estimated wait time exceeds 3 minutes, and ask customers to press #7;</li> <li>Edit the chat deflection message in the textbox. Use the language tab to change languages. Click \u2714 Done to save or click  x Close to discard your changes. </li> </ol> <p>CallBack Option </p> <p>If the wait time exceeds a set limit, you can offer or force a callback for waiting customers as follows:</p> <ol> <li>Enable the option to activate it;</li> <li>Set the digit key that customers should press to be redirected to the callback service. Waiting customers can either be offered or forced to receive a callback based on the settings configured here;</li> <li>Edit the chat deflection message in the textbox. Use the language tab to change languages. Click \u2714 Done to save or click x Close to discard your changes. </li> </ol> <p>Voicemail</p> <p>You can offer or force a voicemail for waiting customers in the following scenarios:</p> <ul> <li>Call waiting duration is greater than \u201cx\u201d minutes.</li> <li>Queue position is greater than \u201cx\u201d.</li> <li>Estimated wait time is greater than \u201cx\u201d minutes.</li> </ul> <p>Steps to offer or force voicemail:</p> <ol> <li>Enable the option to activate it;</li> <li>Set the digit key that customers should press to be redirected to the voicemail service. Customers waiting in the queue can either be offered or forced to receive a callback based on the settings configured here;</li> <li>Edit the message in the textbox. Use the language tab to change languages. Click \u2714 Done to save or click x Close to discard your changes. </li> </ol>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#chat-experience","title":"Chat Experience","text":"<p>Click the Chat Experience tab to start configuring the waiting experience for customers contacting you via chat. </p> <p>In the Chat Experience section, you can configure the following settings:</p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#initial-message_1","title":"Initial Message","text":"<p>This message will be displayed to the contact waiting in the queue. By default, the initial message is enabled.</p> <p>To edit this message text and language, type your custom message in the textbox, and then select a language. Click \u2714 Done to save or click x Close to discard your changes. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#periodic-messages_1","title":"Periodic Messages","text":"<p>These messages are periodically displayed to customers waiting in the chat queue. They can be configured as follows:</p> <ol> <li>Set the number of seconds within which the periodic message should display;</li> <li>Choose whether to display the messages randomly or sequentially;</li> <li>Select whether the message should display once or be looped;</li> <li>Edit the message text and change the language, as needed, by clicking one of the language options at the top of the editor. Click \u2714 Done to save or click x Close to discard your changes;</li> <li>To add another message, click + Add Another;</li> <li>To delete a message, click the Delete icon next to it. </li> </ol>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#save","title":"Save","text":"<p>Click the Save button at the bottom of the Edit Waiting Experience window to make sure that your configuration is saved. You can save all your settings by clicking in any tab. </p>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#edit-waiting-experience","title":"Edit Waiting Experience","text":"<p>To edit Waiting Experience configurations, follow these steps:</p> <ol> <li> <p>In the Waiting Experience section, click the Edit icon for the waiting experience entry you want to edit. </p> </li> <li> <p>In the Edit Waiting Experience window, modify the configurations as required, and click Save.</p> </li> <li>A success confirmation message is displayed when the Waiting Experience changes are updated. </li> </ol>"},{"location":"contactcenter/flows-and-routing/waiting-flows/#delete-waiting-experience","title":"Delete Waiting Experience","text":"<p>To delete a Waiting Experience entry, follow these steps:</p> <ol> <li>In the Waiting Experience section, edit the entry you want to delete;</li> <li> <p>At the top right of the Edit Waiting Experience window, click Delete Waiting Experience.; </p> </li> <li> <p>You will be asked to confirm your choice. If you are sure that you want to delete the entry, click Yes.</p> </li> </ol> <p>Note</p> <p>Deleted Waiting Experience entries cannot be restored. Please proceed with caution.</p>"},{"location":"contactcenter/routing/queues/queue-management/","title":"Queues","text":"<p>Queues are virtual, temporary waiting rooms that hold and process incoming requests for conversations between agents and customers. These are the holding areas for digital and audio conversations waiting for an agent to be assigned. </p> <p>All conversations get assigned to queues based on the agent selection logic and skill proficiency match. A conversation can only be in one queue at any given time. Once conversations get assigned to a queue, SmartAssist assigns them to agents. The agent assignment works based on pre-established rules and criteria, as shown in the illustration below: </p> <p>Once a conversation comes in, it gets assigned to a queue. Afterward, the next step is to check the routing mode. </p> <p>The Simple Routing mode checks for agent skills and agent availability. After the skill and availability match, an agent gets assigned to the conversation.</p> <p>The Advanced Routing mode checks for preferred agents. If a queue has preferred agents configured, admins can specify a time, after which the routing extends to skill match. If a preferred agent becomes available before the configured time expires, they will have priority over agents selected via skill match.</p> <p>For the agent to answer the conversation, they must have a required skill attached to their profile. The conversation cannot be assigned to the agent if the skill does not match.</p> <p>It is possible, however, to define a skill and its expiry period. SmartAssist will search for an agent with this skill for the configured time. If no agent with this skill is available before the skill expiration period ends, the skill is no longer considered a requirement.</p>"},{"location":"contactcenter/routing/queues/queue-management/#queue-routing-modes","title":"Queue Routing Modes","text":"<p>All conversations will get assigned to queues as they come in. This process is based on two Routing modes, as described below.</p> <p>Standard Routing</p> <ul> <li>Queue routing is primarily based on the highest average skill and proficiency match for a given conversation. This routing mode only considers proficiency after a skill match has occurred.</li> <li>If multiple agents match a skill, the routing is done based on currently utilized slots. Agents with fewer utilized slots get priority, as per proficiency thresholds. Also, agents get prioritized if more time has passed since their last conversation compared to other agents.</li> </ul> <p>Advanced Routing </p> <ul> <li>In this case, the conversation first routes to a preferred agent.</li> <li>For each new conversation, SmartAssist checks preferred agents (if any) for availability. During a preferred agent check, skills are ignored. If a preferred agent is not assigned and the preferred agent timeout expires, the check is expanded to the full agent list, and skills are matched to select the best available agent (according to the Simple Routing Mode).</li> </ul>"},{"location":"contactcenter/routing/queues/queue-management/#the-queues-live-board","title":"The Queues Live Board","text":"<p>To access Queues , go to Contact Center &gt; ROUTING &gt; Queues. </p> <p>This section displays the following:</p> <ul> <li>Search: Enter keywords to find queues by name;</li> <li>Queue: The name and description of available queues;</li> <li>Actions: Lists the Edit Queue option;</li> <li>Agents: Shows the agents available for a particular queue;</li> <li>Mode: Specifies whether the queue is set to the Simple or Advanced routing mode;</li> <li>Status: Displays the status of the conversation, Active or Inactive.</li> </ul>"},{"location":"contactcenter/routing/queues/queue-management/#add-a-queue","title":"Add a Queue","text":"<ol> <li>At the top-right corner of the Configuration page, Click New Queue.</li> <li>In the New Queue window, you can set up the queue as follows: <ol> <li>With Simple Routing, you can configure the Queue Settings and Assignments;  </li> <li>With Advanced Routings, you can configure the Queue Settings, Assignments, Preferred Agents, and Skills.</li> </ol> </li> </ol>"},{"location":"contactcenter/routing/queues/queue-management/#settings","title":"Settings","text":"<p>This section is available in Simple and Advanced Routing modes and allows you to configure the following:</p> <ol> <li>The Name by which to identify the queue;</li> <li>A short Description of the queue (optional);</li> <li> <p>Hours of Operation: Select from the available hours of operation. </p> </li> <li> <p>Transfer Rules: This feature lets you limit the agents\u2019 ability to transfer from one queue to another. If this feature is enabled, you can select the specific queues to which agents can transfer customers. If disabled, agents can transfer to any queue from the current one. </p> </li> </ol> <p>Note</p> <p>If the customer ends the chat before the completion of a transfer, then the transfer will be dropped, and the interaction will not be assigned to any queue or agent. This feature only applies to chat conversations and is available if you are using Kore WebSdk v1.0.</p> <ol> <li> <p>Maximum Wait Time: Specify the maximum time a conversation should wait in the queue before the default No available agent flow handles it. </p> </li> <li> <p>Enable Advanced Routing: Preferred agents and skill dropoffs will be available if you enable this option. </p> </li> </ol>"},{"location":"contactcenter/routing/queues/queue-management/#assignments","title":"Assignments","text":"<p>This section is available in Simple and Advanced Routing modes and allows you to assign agents, agent groups, or both to the queue. </p>"},{"location":"contactcenter/routing/queues/queue-management/#assign-agents","title":"Assign Agents","text":"<p>Follow these steps to assign agents to a queue: </p> <ol> <li>Click Add Agent;</li> <li>Click the checkbox next to an agent\u2019s name to select it. You can use the Search field at the top of the list to find a specific person. </li> </ol>"},{"location":"contactcenter/routing/queues/queue-management/#assign-agent-groups","title":"Assign Agent Groups","text":"<ol> <li>Click Add Agent Group;</li> <li>Click the checkbox next to the name of a group to select it. You can use the Search field at the top of the list to find a specific group. </li> </ol> <p>Note</p> <p>Agents from the agent group are not displayed in the agent\u2019s list. The list of agents added to the queue is displayed, along with the agent groups that are part of the queue.</p> <p>From the monitor screen, you can see the consolidated list of agents that are part of the queue.</p>"},{"location":"contactcenter/routing/queues/queue-management/#preferred-agents","title":"Preferred Agents","text":"<p>In the Preferred tab, you can assign preferred agents to the queue.</p> <ol> <li> <p>Under Preferred Agents, find the agent you need in the list. You can use the Search field for this purpose. Select the corresponding Preferred checkbox to set the agent as preferred. </p> </li> <li> <p>Under Advanced Settings, configure the preferred agent timeout. During a preferred agent check, skills are ignored. If a preferred agent is not assigned and the preferred agent timeout expires, the check expands to the full agent list, and skills match to select the best available agent for the conversation. </p> </li> </ol>"},{"location":"contactcenter/routing/queues/queue-management/#skills","title":"Skills","text":"<ol> <li> <p>In the Skills tab, search for a specific skill to assign to the Queue. </p> </li> <li> <p>Choose whether you want the skill to expire and set the time for this. Once a skill assignment expires, the conversation routes to other assigned skills. </p> </li> </ol> <p>When you are ready to save the Queue, click Create. The new Queue is then listed among your available queues. You must configure at least the Settings and Assignment tabs to save a queue. </p>"},{"location":"contactcenter/routing/queues/queue-management/#edit-a-queue","title":"Edit a Queue","text":"<ol> <li> <p>Click the Edit icon corresponding to the queue you want to edit. </p> </li> <li> <p>Make the required changes and click Save.</p> </li> </ol>"},{"location":"contactcenter/routing/queues/queue-management/#delete-a-queue","title":"Delete a Queue","text":"<p>To delete a queue, follow these steps:</p> <ol> <li>Click the Edit icon corresponding to the queue you want to edit.</li> <li> <p>Click the Delete (bin) button on the right of the bottom toolbar. </p> </li> <li> <p>Confirm your choice.</p> </li> </ol> <p>Note</p> <p>Deleting a queue means that all corresponding routing rules are removed.</p>"},{"location":"contactcenter/routing/queues/queue-management/#assign-a-conversation-to-a-queue","title":"Assign a Conversation to a Queue","text":"<p>There are two ways to assign a conversation to a queue:</p> <ol> <li>Using the Set Queue node within an experience flow.</li> <li>Using the agentUtils.setQueue() method.</li> </ol>"},{"location":"contactcenter/routing/skills/skill-management/","title":"Skills","text":"<p>The Skills feature helps set up organizational classifications to route calls or chats to an agent based on the agent\u2019s specialization, department, vertical, customer segment, and other categories. Examples of agent skills may include:</p> <ul> <li>Languages \u2013 Agents can speak different languages, such as English, Hindi, Spanish, etc. Language is considered a default skill that every agent must have.</li> <li>Customer Interactions \u2013 Agents are trained for retention, up-selling/cross-selling, or other related skills.</li> </ul>"},{"location":"contactcenter/routing/skills/skill-management/#the-skills-live-board","title":"The Skills Live Board","text":"<p>You can reach the Skills Live Board by going to Contact Center &gt; ROUTING &gt; Skills. </p> <p>The Skills section is organized by Skill Groups. Click a group to expand it and display the skills assigned to that group. You can use the Search field to find skills or skill groups by name.</p>"},{"location":"contactcenter/routing/skills/skill-management/#add-a-skill","title":"Add a Skill","text":"<p>Before adding a skill, you need a skill group. See Skill Groupsfor details. SmartAssist comes pre-configured with a Default Skill Group to which you can add skills.</p> <p>To add skills to a skill group, follow these steps:</p> <ol> <li>Click the respective skill group to get the drill-down view of associated Skills;</li> <li> <p>Click the + New Skill button. </p> </li> <li> <p>Enter the following details in the Add New Skill window:</p> <ol> <li>Skill Name: Enter the name to identify the skill by.</li> <li>Description: Enter a brief description of the skill or its purpose.</li> <li> <p>Agent Assignments: Associate agents to the skill and provide the proficiency level (Novice, Average, Good, and Expert); </p> </li> <li> <p>Click Create to complete the process. SmartAssist creates the new skill, adds it to the list, and displays a success confirmation message. </p> </li> </ol> </li> </ol>"},{"location":"contactcenter/routing/skills/skill-management/#add-a-skill-using-a-script","title":"Add a Skill Using a Script","text":"<p>You can use custom attributes to add skills dynamically.</p> <p>SmartAssist administrators can dynamically add skills using script nodes while building dialogs in the XO platform or building an experience flow in SmartAssist.</p> <p>The following methods are available:</p> <p>setSkills(skillsInfo) \u2013 You can use this method to append skills to the current conversation. skillsInfo is an array parameter.</p> <pre><code>var loanType = { //creating a sample variable of skill - loan type\n    \"Car Loan\": {\n         name: \"Car Loan\",\n         id: \"60b50bec5c4c1a4195b55d88\",\n    },\n    \"House Loan\": {\n         name: \"House Loan\",\n         id: \"60b50c005c4c1a4195b55d89\",\n    },\n    \"Education Loan\": {\n         name: \"Education Loan\",\n         id: \"60b894198afcca6accc5f466\",\n    },\n    \"Gold Loan\": {\n         name: \"Gold Loan\",\n         id: \"60b8943a8afcca6accc5f467\",\n    },\n};\n\nagentUtils.setSkills([loanType[a]]); //setting the skill - loan type\n</code></pre> <p>getSkills() \u2013 Returns an array of skills in the current conversation.</p> <p>getSkillById(skillId) \u2013 Returns a skill using the skill ID. Skills IDs are available under skills.</p> <p>deleteSkillById(skillId) \u2013 Deletes a skill from the context of the current conversation.</p> <p>deleteSkills(skillsToDelete) \u2013 Deletes an array of skills from the context of the current conversation.</p>"},{"location":"contactcenter/routing/skills/skill-management/#edit-a-skill","title":"Edit a Skill","text":"<p>To edit the field values of an existing skill, follow these steps:</p> <ol> <li>Click the desired skill group to get the associated skills list;</li> <li> <p>Click the Edit icon corresponding to the skill you want to update; </p> </li> <li> <p>Make your changes in the Edit Skill window;</p> </li> <li>Click Save. A success confirmation message is displayed once the skill details are updated.</li> </ol>"},{"location":"contactcenter/routing/skills/skill-management/#delete-a-skill","title":"Delete a Skill","text":"<p>To delete a skill, follow these steps:</p> <ol> <li>Click the desired skill group to get the associated skills list;</li> <li>Click the Edit icon corresponding to the skill you want to delete;</li> <li>Ensure that there are no agents assigned to the skill. If there are, you must remove them to delete the skill. Removing an agent from a skill also removes the skill assignment on the agent\u2019s profile. Follow these steps:<ol> <li>In the Edit Skill window, scroll down to Agent Assignments;</li> <li>Click the Delete icon for all the agents mapped to the skill.</li> <li>Click the Delete button on the confirmation pop-up for each agent. Once deleting all the agents under Agent Assignments, click Save.</li> <li>Click the Delete Skill icon.</li> <li>Click the Delete button on the confirmation pop-up to confirm your choice. </li> </ol> </li> </ol> <p>Note</p> <p>You cannot restore deleted Skills.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Material for MkDocs is an actively maintained and constantly improved project  that caters to a diverse user base with varying backgrounds and needs. In order to effectively address the needs of all our users, evaluate requests, and fix  bugs, a lot of work from us maintainers is required.</p>"},{"location":"contributing/#how-to-contribute","title":"How to contribute","text":"<p>We have invested quite a lot of time in creating better templates for our issue tracker, optimizing the processes for our users to report bugs, request features or changes, contribute to the project, or exchange with our community.  This section of the documentation explains each process.</p>"},{"location":"contributing/#creating-an-issue","title":"Creating an issue","text":"<ul> <li> <p> Something is not working?</p> <p>Report a bug in Material for MkDocs by creating an issue and a reproduction</p> <p> Report a bug</p> </li> <li> <p> Missing information in our docs?</p> <p>Report missing information or potential inconsistencies in our documentation</p> <p> Report a docs issue</p> </li> <li> <p> Want to submit an idea?</p> <p>Propose a change or feature request or suggest an improvement</p> <p> Request a change</p> </li> <li> <p> Have a question or need help?</p> <p>Ask questions on our discussion board and get in touch with our community</p> <p> Ask a question</p> </li> </ul>"},{"location":"contributing/reporting-a-bug/","title":"Reporting a bug","text":"<p>Material for MkDocs is an actively maintained project that we constantly strive to improve. With a project of this size and complexity, bugs may occur. If you think you have discovered a bug, you can help us by submitting an issue in our public issue tracker by following this guide.</p>"},{"location":"contributing/reporting-a-bug/#before-creating-an-issue","title":"Before creating an issue","text":"<p>With more than 20,000 users, issues are created every other day. The maintainers of this project are trying very hard to keep the number of open issues down by fixing bugs as fast as possible. By following this guide, you will know exactly what information we need to help you quickly.</p> <p>But first, please try the following things before creating an issue.</p>"},{"location":"contributing/reporting-a-bug/#upgrade-to-latest-version","title":"Upgrade to latest version","text":"<p>Chances are that the bug you discovered was already fixed in a subsequent version. Thus, before reporting an issue, ensure that you're running the latest version of Material for MkDocs. Please consult our upgrade guide to learn how to upgrade to the latest version.</p> <p>Bug fixes are not backported</p> <p>Please understand that only bugs that occur in the latest version of Material for MkDocs will be addressed. Also, to reduce duplicate efforts, fixes cannot be backported to earlier versions.</p>"},{"location":"contributing/reporting-a-bug/#remove-customizations","title":"Remove customizations","text":"<p>If you're using customizations like additional CSS, JavaScript, or theme extension, please remove them from <code>mkdocs.yml</code> before reporting a bug. We can't offer official support for bugs that might hide in your overrides, so make sure to omit the following settings from <code>mkdocs.yml</code>:</p> <ul> <li><code>theme.custom_dir</code></li> <li><code>theme.hooks</code></li> <li><code>extra_css</code></li> <li><code>extra_javascript</code></li> </ul> <p>If, after removing those settings, the bug is gone, the bug is likely caused by your customizations. A good idea is to add them back gradually to narrow down the root cause of the problem. If you did a major version upgrade, make sure you adjusted all partials you have overridden.</p> <p>Customizations mentioned in our documentation</p> <p>A handful of the features Material for MkDocs offers can only be implemented with customizations. If you find a bug in any of the customizations that our documentation explicitly mentions, you are, of course, encouraged to report it.</p> <p>Don't be shy to ask on our discussion board for help if you run into problems.</p>"},{"location":"contributing/reporting-a-bug/#search-for-solutions","title":"Search for solutions","text":"<p>At this stage, we know that the problem persists in the latest version and is not caused by any of your customizations. However, the problem might result from a small typo or a syntactical error in a configuration file, e.g., <code>mkdocs.yml</code>.</p> <p>Now, before you go through the trouble of creating a bug report that is answered and closed right away with a link to the relevant documentation section or another already reported or closed issue or discussion, you can save time for us and yourself by doing some research:</p> <ol> <li> <p>Search our documentation and look for the relevant sections that could     be related to your problem. If found, make sure that you configured     everything correctly.1</p> </li> <li> <p>Search our issue tracker, as another user might already     have reported the same problem, and there might even be a known workaround     or fix for it. Thus, no need to create a new issue.</p> </li> <li> <p>Search our discussion board to learn if other users     are struggling with similar problems and work together with our great     community towards a solution. Many problems are solved here.</p> </li> </ol> <p>Keep track of all search terms and relevant links, you'll need them in the bug report.2</p> <p>At this point, when you still haven't found a solution to your problem, we encourage you to create an issue because it's now very likely that you stumbled over something we don't know yet. Read the following section to learn how to create a complete and helpful bug report.</p>"},{"location":"contributing/reporting-a-bug/#issue-template","title":"Issue template","text":"<p>We have created a new issue template to make the bug reporting process as simple as possible and more efficient for the community and us. It is the result of our experience answering and fixing more than 1,600 issues (and counting) and consists of the following parts:</p> <ul> <li>Title</li> <li>Context optional</li> <li>Description</li> <li>Related links</li> <li>Reproduction</li> <li>Steps to reproduce</li> <li>Browser optional</li> <li>Checklist</li> </ul>"},{"location":"contributing/reporting-a-bug/#title","title":"Title","text":"<p>A good title is short and descriptive. It should be a one-sentence executive summary of the issue, so the impact and severity of the bug you want to report can be inferred from the title.</p> Example Clear Built-in <code>typeset</code> plugin changes precedence of nav title over <code>h1</code> Wordy The built-in <code>typeset</code> plugin changes the precedence of the nav title over the document headline Unclear Title does not work Generic Please help"},{"location":"contributing/reporting-a-bug/#context","title":"Context optional","text":"<p>Before describing the bug, you can provide additional context for us to understand what you are trying to achieve. Explain the circumstances in which you're using Material for MkDocs, and what you think might be relevant. Don't write about the bug here.</p> <p>Why this might be helpful: some errors only manifest in specific settings, environments or edge cases, for example, when your documentation contains thousands of documents.</p>"},{"location":"contributing/reporting-a-bug/#description","title":"Description","text":"<p>Now, to the bug you want to report. Provide a clear, focused, specific, and concise summary of the bug you encountered. Explain why you think this is a bug that should be reported to Material for MkDocs, and not to one of its dependencies.3 Adhere to the following principles:</p> <ul> <li> <p>Explain the what, not the how \u2013 don't explain     how to reproduce the bug here, we're getting there.     Focus on articulating the problem and its impact as clearly as possible.</p> </li> <li> <p>Keep it short and concise \u2013 if the bug can be precisely explained in one     or two sentences, perfect. Don't inflate it \u2013 maintainers and future users     will be grateful for having to read less.</p> </li> <li> <p>One bug at a time \u2013 if you encounter several unrelated bugs, please     create separate issues for them. Don't report them in the same issue, as     this makes attribution difficult.</p> </li> </ul> <p> Stretch goal \u2013 if you found a workaround or a way to fix the bug, you can help other users temporarily mitigate the problem before we maintainers can fix the bug in our code base.</p> <p>Why we need this: in order for us to understand the problem, we need a clear description of it and quantify its impact, which is essential for triage and prioritization.</p>"},{"location":"contributing/reporting-a-bug/#related-links","title":"Related links","text":"<p>Of course, prior to reporting a bug, you have read our documentation and could not find a working solution. Please share links to all sections of our documentation that might be relevant to the bug, as it helps us gradually improve it.</p> <p>Additionally, since you have searched our issue tracker and discussion board before reporting an issue, and have possibly found several issues or discussions, include those as well. Every link to an issue or discussion creates a backlink, guiding us maintainers and other users in the future.</p> <p> Stretch goal \u2013 if you also include the search terms you used when searching for a solution to your problem, you make it easier for us maintainers to improve the documentation.</p> <p>Why we need this: related links help us better understand what you were trying to achieve and whether sections of our documentation need to be adjusted, extended, or overhauled.</p>"},{"location":"contributing/reporting-a-bug/#reproduction","title":"Reproduction","text":"<p>A minimal reproduction is at the heart of every well-written bug report, as it allows us maintainers to quickly recreate the necessary conditions to inspect the bug and quickly find its root cause. It's a proven fact that issues with concise and small reproductions can be fixed much faster.</p> <p>\u00a0 Create a reproduction</p> <p>After you have created the reproduction, you should have a .zip file, ideally not larger than 1 MB. Just drag and drop the .zip file into this field, which will automatically upload it to GitHub.</p> <p>Why we need this: if an issue contains no minimal reproduction or just a link to a repository with thousands of files, the maintainers would need to invest a lot of time into trying to recreate the right conditions to even inspect the bug, let alone fix it.</p> <p>Don't share links to repositories</p> <p>While we know that it is a good practice among developers to include a link to a repository with the bug report, we currently don't support those in our process. The reason is that the reproduction which is automatically produced by the built-in info plugin contains all of the necessary environment information that is often forgotten to be included.</p> <p>Additionally, there are many non-technical users of Material for MkDocs that have trouble creating repositories.</p>"},{"location":"contributing/reporting-a-bug/#steps-to-reproduce","title":"Steps to reproduce","text":"<p>At this point, you provided us with enough information to understand the bug, and you gave us a reproduction that we could run and inspect. However, when we run your reproduction, it might not be immediately apparent how we can see the bug in action.</p> <p>Next, please list the specific steps we should follow when running your reproduction to observe the bug. Keep the steps short and concise, and make sure not to leave anything out. Use simple language as you would explain it to a five-year-old, and focus on continuity.</p> <p>Why we need this: we must know how to navigate your reproduction in order to observe the bug, as some bugs only occur at certain viewports or in specific conditions.</p>"},{"location":"contributing/reporting-a-bug/#browser","title":"Browser optional","text":"<p>If you're reporting a bug that only happens in one or more specific browsers, we need to know which browsers are affected. This field is optional, as it is only relevant when the bug you are reporting does not involve a crash when previewing or building your site.</p> <p>Why we need this: some bugs only occur in specific browsers or versions. Since now, almost all browsers are evergreen, we usually don't need to know the version in which it occurs, but we might ask for it later. When in doubt, add the browser version as the first step in the field above.</p>"},{"location":"contributing/reporting-a-bug/#checklist","title":"Checklist","text":"<p>Thanks for following the guide and creating a high-quality and complete bug report \u2013 you are almost done. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with everything we  need to know to help you.</p> <p>We'll take it from here.</p>"},{"location":"contributing/reporting-a-bug/#incomplete-issues","title":"Incomplete issues","text":"<p>Please understand that we reserve the right to close incomplete issues which do not contain minimal reproductions or do not adhere to the quality standards and requirements mentioned in this document. Issues can be reopened when the missing information has been provided.</p> <ol> <li> <p>When adding lines to <code>mkdocs.yml</code>, make sure you are preserving the indentation as mentioned in the documentation since YAML is a whitespace-sensitive language. Many reported issues turn out to be configuration errors.\u00a0\u21a9</p> </li> <li> <p>We might be using terminology in our documentation different from yours, but mean the same. When you include the search terms and related links in your bug report, you help us to adjust and improve the documentation.\u00a0\u21a9</p> </li> <li> <p>Sometimes, users report bugs on our issue tracker that are caused by one of our upstream dependencies, including MkDocs, Python Markdown, Python Markdown Extensions or third-party plugins. A good rule of thumb is to change the <code>theme.name</code> to <code>mkdocs</code> or <code>readthedocs</code> and check if the problem persists. If it does, the problem is likely not related to Material for MkDocs and should be reported upstream. When in doubt, use our discussion board to ask for help.\u00a0\u21a9</p> </li> </ol>"},{"location":"contributing/reporting-a-docs-issue/","title":"Reporting a docs issue","text":"<p>In the past seven years, our documentation has grown to more than 60 pages. With a site being this large, inconsistencies can occur. If you find an inconsistency or see room for clarification or improvement, please submit an issue to our public issue tracker by following this guide.</p>"},{"location":"contributing/reporting-a-docs-issue/#issue-template","title":"Issue template","text":"<p>Reporting a documentation issue is usually less involved than reporting a bug, as we don't need a reproduction. Please thoroughly read the following guide before creating a new documentation issue, and provide the following information as part of the issue:</p> <ul> <li>Title</li> <li>Description</li> <li>Related links</li> <li>Proposed change optional</li> <li>Checklist</li> </ul>"},{"location":"contributing/reporting-a-docs-issue/#title","title":"Title","text":"<p>A good title should be a short, one-sentence description of the issue, contain all relevant information and, in particular, keywords to simplify the search in the issue tracker.</p> Example Clear Clarify social cards setup on Windows Unclear Missing information in the docs Generic Please help"},{"location":"contributing/reporting-a-docs-issue/#description","title":"Description","text":"<p>Provide a clear and concise summary of the inconsistency or issue you  encountered in the documentation or the documentation section that needs  improvement. Explain why you think the documentation should be adjusted and  describe the severity of the issue:</p> <ul> <li> <p>Keep it short and concise \u2013 if the inconsistency or issue can be      precisely explained in one or two sentences, perfect. Maintainers and     future users will be grateful for having to read less.</p> </li> <li> <p>One issue at a time \u2013 if you encounter several unrelated inconsistencies,     please create separate issues for them. Don't report them in the same issue \u2013 it makes attribution difficult.</p> </li> </ul> <p>Why we need this: in order for us to understand the problem, we need a clear description of it and quantify its impact, which is essential for triage and prioritization.</p>"},{"location":"contributing/reporting-a-docs-issue/#related-links","title":"Related links","text":"<p>After you described the documentation section that needs to be adjusted above,  we now ask you to share the link to this specific documentation section and other possibly related sections. Make sure to use anchor links (permanent links)  where possible, as it simplifies discovery.</p> <p>Why we need this: providing the links to the documentation help us  understand which sections of our documentation need to be adjusted, extended,  or overhauled.</p>"},{"location":"contributing/reporting-a-docs-issue/#proposed-change","title":"Proposed change optional","text":"<p>Now that you have provided us with the description and links to the documentation sections, you can help us, maintainers, and the community by proposing an improvement. You can sketch out rough ideas or write a concrete proposal. This field is optional but very helpful.</p> <p>Why we need this: improvement proposal can be beneficial for other users  who encounter the same issue, as they offer solutions before we maintainers can update the documentation.</p>"},{"location":"contributing/reporting-a-docs-issue/#checklist","title":"Checklist","text":"<p>Thanks for following the guide and creating a high-quality and complete issue  report \u2013 you are almost done. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with every piece of information we need to improve our documentation.</p> <p>We'll take it from here.</p>"},{"location":"contributing/requesting-a-change/","title":"Requesting a change","text":"<p>Material for MkDocs is a powerful tool for creating beautiful and functional project documentation. With more than 20,000 users, we understand that our project serves a wide range of use cases, which is why we have created the following guide.</p> <p>Put yourself in our shoes \u2013 with a project of this size, it can be challenging to maintain existing functionality while constantly adding new features at the same time. We highly value every idea or contribution from our community, and we kindly ask you to take the time to read the following guidelines before  submitting your change request in our public issue tracker. This will help us  better understand the proposed change and how it will benefit the community.</p> <p>This guide is our best effort to explain the criteria and reasoning behind our decisions when evaluating change requests and considering them for implementation. </p>"},{"location":"contributing/requesting-a-change/#before-creating-an-issue","title":"Before creating an issue","text":"<p>Before you invest your time to fill out and submit a change request, we kindly ask you to do some preliminary work by answering some questions to determine if your idea is a good fit for Material for MkDocs and matches the project's philosophy and tone.</p> <p>Please find answers to the following questions before creating an issue.</p>"},{"location":"contributing/requesting-a-change/#its-not-a-bug-its-a-feature","title":"It's not a bug, it's a feature","text":"<p>Change requests are intended to suggest minor adjustments, ideas for new features, or to influence the project's direction and vision. It is important to note that change requests are not intended for reporting bugs, as they're missing essential information for debugging.</p> <p>If you want to report a bug, please refer to our bug reporting guide instead.</p>"},{"location":"contributing/requesting-a-change/#source-of-inspiration","title":"Source of inspiration","text":"<p>If you have seen your idea implemented in another static site generator or theme, make sure to collect enough information on its implementation before submitting, as this allows us to evaluate potential fit more quickly. Explain what you like and dislike about the implementation.</p>"},{"location":"contributing/requesting-a-change/#benefit-for-the-community","title":"Benefit for the community","text":"<p>Our discussion board is the best place to connect with our community. When  evaluating new ideas, it's essential to seek input from other users and consider  alternative viewpoints. This approach helps to implement new features in a way that benefits a large number of users.</p> <p>\u00a0 Start a discussion</p>"},{"location":"contributing/requesting-a-change/#issue-template","title":"Issue template","text":"<p>Now that you have taken the time to do the necessary preliminary work and ensure  that your idea meets our requirements, you are invited to create a change request. The following guide will walk you through all the necessary steps to  help you submit a comprehensive and useful issue:</p> <ul> <li>Title</li> <li>Context optional</li> <li>Description</li> <li>Related links</li> <li>Use cases</li> <li>Visuals optional</li> <li>Checklist</li> </ul>"},{"location":"contributing/requesting-a-change/#title","title":"Title","text":"<p>A good title is short and descriptive. It should be a one-sentence executive summary of the idea, so the potential impact and benefit for the community can  be inferred from the title.</p> Example Clear Index custom front matter in search Wordy Add a feature where authors can define custom front matter to be indexed in search Unclear Improve search Generic Please help"},{"location":"contributing/requesting-a-change/#context","title":"Context optional","text":"<p>Before describing your idea, you can provide additional context for us to understand what you are trying to achieve. Explain the circumstances in which you're using Material for MkDocs, and what you think might be relevant. Don't write about the change request here.</p> <p>Why this might be helpful: some ideas might only benefit specific settings, environments, or edge cases, for example, when your documentation contains thousands of documents. With a little context, change requests can be prioritized more accurately.</p>"},{"location":"contributing/requesting-a-change/#description","title":"Description","text":"<p>Next, provide a detailed and clear description of your idea. Explain why your  idea is relevant to Material for MkDocs and must be implemented here, and not in one of its dependencies:1</p> <ul> <li> <p>Explain the what, not the why \u2013 don't explain     the benefits of your idea here, we're getting there.     Focus on describing the proposed change request as precisely as possible.</p> </li> <li> <p>Keep it short and concise \u2013 be brief and to the point when describing      your idea, there is no need to over-describe it. Maintainers and future     users will be grateful for having to read less.</p> </li> <li> <p>One idea at a time \u2013 if you have multiple ideas that don't belong  together, please open separate change requests for each of those ideas.</p> </li> </ul> <p> Stretch goal \u2013 if you have a customization or another way to add the proposed change, you can help other users by sharing it here before we maintainers can add it to our code base.</p> <p>Why we need this: To understand and evaluate your proposed change, we need to have a clear understanding of your idea. By providing a detailed and  precise description, you can help save you and us time spent discussing further clarification of your idea in the comments.</p>"},{"location":"contributing/requesting-a-change/#related-links","title":"Related links","text":"<p>Please provide any relevant links to issues, discussions, or documentation  sections related to your change request. If you (or someone else) already discussed this idea with the community on our discussion board, please include  the link to the discussion as well.</p> <p>Why we need this: Related links help us gain a comprehensive understanding of your change request by providing additional context. Additionally, linking to previous issues and discussions allows us to quickly evaluate the feedback and input already provided by the community.</p>"},{"location":"contributing/requesting-a-change/#use-cases","title":"Use cases","text":"<p>Explain how your change request would work from an author's and user's perspective \u2013 what's the expected impact, and why does it benefit not only you but other users? How many of them? Furthermore, would it potentially break existing functionality?</p> <p>Why we need this: Understanding the use cases and benefits of an idea is  crucial in evaluating its potential impact and usefulness for the project and  its users. This information helps us to understand the expected value of the  idea and how it aligns with the goals of the project.</p>"},{"location":"contributing/requesting-a-change/#visuals","title":"Visuals optional","text":"<p>We now have a clear and detailed description of your idea, including information  on its potential use cases and relevant links for context. If you have any  visuals, such as sketches, screenshots, mockups, or external assets, you may  present them in this section.</p> <p>You can drag and drop the files here or include links to external assets.</p> <p>Additionally, if you have seen this change, feature, or improvement used in  other static site generators or themes, please provide an example by showcasing  it and describing how it was implemented and incorporated.</p> <p>Why we need this: Illustrations and visuals can help us maintainers  better understand and envision your idea. Screenshots, sketches, or mockups  can create an additional level of detail and clarity that text alone may not  be able to convey. Also, seeing how your idea has been implemented in other  projects can help us understand its potential impact and feasibility in  Material for MkDocs, which helps us maintainers evaluate and triage  change requests.</p>"},{"location":"contributing/requesting-a-change/#checklist","title":"Checklist","text":"<p>Thanks for following the change request guide and creating a high-quality  change request. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with every piece of  information to review your idea for Material for MkDocs.</p> <p>We'll take it from here.</p> <ol> <li> <p>Sometimes, users suggest ideas on our issue tracker that concern one of our upstream dependencies, including MkDocs, Python Markdown, Python Markdown Extensions or third-party plugins. It's a good idea to think about whether your idea is beneficial to other themes, upstreaming change requests for a bigger impact.\u00a0\u21a9</p> </li> </ol>"},{"location":"faq/sponsoring/","title":"Sponsoring FAQs","text":"<p>Do you have questions about Material for MkDocs Insiders? We do our best to answer all of your questions on this page. If you can't find your question  below, ask it on our discussion board!</p>"},{"location":"faq/sponsoring/#general","title":"General","text":"<p>Why is the Insiders edition offered as a subscription model?</p> <p>Material for MkDocs always was and will be Open Source, available for free to individuals and organizations. As the project grew over time, we found that maintaining and managing the overhead that comes with growth became more challenging and time-consuming.</p> <p>In order to sustain the project and add new and useful features more frequently, we decided to create the Insiders edition, with early access to the latest and greatest features of Material for MkDocs. The subscription-based model of the Insiders edition allows us to dedicate more time and resources to the project, which benefits all  users of Material for MkDocs. Once our funding goals based on monthly  subscriptions are hit, the Insiders features of those^ funding goals are released  to the community edition, letting everyone benefit from them. </p> <p>Maintaining both the community and Insiders editions is an ongoing process, and  we rely on our sponsors to support us on a monthly basis, which makes this whole  project possible.</p> <p>What features are included in the Insiders edition?</p> <p>The Insiders edition includes more than 20 additional features. You can find an  overview of these features on our Insiders page, which is updated when new features are added and released.</p> <p>How often is the Insiders edition updated?</p> <p>We try to keep our open issue count low, fixing known bugs quickly. Both our repositories, the community and Insiders edition, are constantly updated with bug fixes and new features.</p>"},{"location":"faq/sponsoring/#sponsorship","title":"Sponsorship","text":"<p>Can I sponsor the project without a GitHub account?</p> <p>Yes. You can support Material for MkDocs by sponsoring us on Ko-fi, regardless of whether you have a GitHub account or not. However, please note that Insiders is provided as a private repository on GitHub. If after sponsoring, you'd like to gain access to the repository, you'll need to have a GitHub individual or bot account that can be added as a collaborator. If your organization doesn't use GitHub or/and host its repositories on other platforms, you can mirror the Insiders repository in your environment once you have access.</p> <p>Which sponsoring tier should I choose?</p> <p>The sponsoring tiers are divided into non-commercial and commercial tiers. If  you are an individual or organization using Material for MkDocs for private or non-commercial Open Source projects, you have two tiers to choose from,  depending on the number of sites you want to build. For companies using  Material for MkDocs, we offer three different commercial tiers, from which  you can choose depending on your requirements.</p> <p>Also, please read what is considered commercial use.</p> <p>Why are one-time sponsorships not granted access to Insiders?</p> <p>Primarily due to technical reasons, that we're working on lifting in the future. We use GitHub webhooks to determine our current active sponsors. When you create or cancel your monthly subscription, GitHub sends events that we use to automatically add and remove collaborators.</p> <p>Note that $15 is the minimum amount to be granted access to Insiders.</p> <p>How is my sponsorship contribution used to support the project?</p> <p>Your sponsorship contribution directly supports the development and  maintenance of the project, by buying us maintainers time. It allows us to dedicate more time and resources to enhance the project's features and functionality. The additional funding helps us prioritize improvements and updates, benefiting Insiders users and the wider community. We also actively contribute to other upstream projects, fostering collaboration and giving back to the Open Source ecosystem.</p> <p>Are there any limitations on the number of sponsors for a particular tier?</p> <p>No, there are no limitations on the number of sponsors for any tier. You can sponsor the project at any tier regardless of how many other sponsors are already there.</p>"},{"location":"faq/sponsoring/#payment-billing","title":"Payment &amp; billing","text":"<p>Is there a trial period for the Insiders edition?</p> <p>No, we do not offer a trial period for the Insiders edition. However, if you're a company and are considering sponsoring on the commercial tier, but want to first give the Insiders edition a try, you can sponsor on the $15 tier with a personal account for non-commercial evaluation purposes.</p> <p>Additionally, our subscription model allows you to cancel your sponsorship anytime. If you decide to cancel, your sponsorship will remain active until  the end of your billing cycle.</p> <p>What payment options do you accept?</p> <p>We manage all our transactions and sponsorships through GitHub Sponsors and  Ko-fi. To become a sponsor of Material for MkDocs on GitHub, visit  our sponsors' page. On there, you can choose from five different sponsorship  tiers and pay by credit card. Please note that as of the beginning of 2023,  GitHub no longer supports PayPal payments. If you wish to pay with PayPal,  ou can find a selection of our sponsorship tiers on Ko-fi. Both platforms provide you with a payment receipt once your purchase is successful.</p> <p>If you're a company and need assistance choosing the right payment method, please don't hesitate to reach out to sponsors@squidfunk.com.</p> <p>Are discounts available for the Insiders edition, such as student discounts?</p> <p>Unfortunately, we are not able to offer any discounts for the Material for  MkDocs Insiders program. To ensure that everyone can afford the Insiders program  and keep the barrier as low as possible, we have set prices as low as $15 a month for non-commercial use.</p> <p>Do you offer free access to Insiders for Open Source projects?</p> <p>No, we do not offer free access to our Material for MkDocs Insiders edition.  We understand that non-profit organizations may have limited budgets and may  need to prioritize their spending on other projects or organizations. However, it's important to note that Material for MkDocs is maintained by a small team,  investing a lot of time and resources into constantly improving this project.  Material for MkDocs and its core features are free to the community through our  Open Source model. Therefore, Material for MkDocs itself is already free.</p> <p>However, we do offer an affordable sponsorship tier starting at $15 a month,  which is meant for individuals and non-profit organizations using Material for  MkDocs to build 1-2 sites for non-commercial purposes. This tier provides access  to all new features, benefiting you from our ongoing development efforts.</p> <p>Is Insiders free for those who contribute to this project?</p> <p>Great question! We can not offer free access to \"drive-by\" contributors that  only fix minor issues like typos or add new languages. These contributions are  always welcome, but as we need to review them, they result in a higher time  investment from our side and don't compensate for this work. However, as this  project keeps growing, we always seek for individuals to support us. In return,  we offer financial compensation or/and Insiders access. If you are interested  and have experience in the technologies and paradigms listed below, please get in touch with us at sponsors@squidfunk.com:</p> <ul> <li>Deep knowledge of CSS, HTML, TypeScript</li> <li>Experience with progressive enhancement and responsive design</li> <li>Experience with reactive programming with RxJS</li> <li>Solid understanding of Python, MkDocs + ecosystem</li> <li>Solid technical writing skills</li> </ul> <p>Additionally, we're working on a contributor program that will reward contributors that engage in the community by answering questions and helping users with access to Insiders.</p> <p>How can I set my billing to monthly or yearly?</p> <p>You can sponsor Material for MkDocs on a monthly or yearly basis. Depending on  your billing cycle you automatically become a monthly or yearly sponsor. Your  billing cycle is an account-level setting that you can easily change in your  account. If, for some reason, you cannot make this change, you can create a  dedicated bot account with a yearly billing cycle on GitHub, which you only use  for sponsoring (some sponsors already do that). If you have any problems or  further questions, please contact us at sponsors@squidfunk.com.</p> <p>Can I get an invoice for my sponsorship payment?</p> <p>Right now, we can't provide you with an invoice for your sponsoring transaction, as GitHub Sponsors handles all transactions for us. However, both payment platforms, GitHub and Ko-Fi, automatically send you a payment receipt  via mail once the sponsorship is active.</p> <p>Furthermore, we are working on a solution to optimize access management and more features. If you are interested in this, please get in touch with us via mail at sponsors@squidfunk.com or turn on all notifications for MkDocs, and we will reach out as soon as we are live.</p> <p>Can I switch between different sponsoring tiers?</p> <p>Yes, you can switch between different sponsoring tiers at any time. Simply go  to the GitHub Sponsors page and change your sponsoring tier. Once you make  that change, you will immediately change to the new tier.</p> <p>If you change to a higher tier, the amount will be prorated according to your billing cycle.</p> <p>Can I sponsor the project for a specific feature or development goal?</p> <p>While sponsoring specific goals directly is not possible, our sponsoring goals are connected to specific features or development goals aligned with the  project's roadmap. You can find an overview of these sponsoring goals and their  associated features on our website. Insider users have early access to all  already developed features, including those associated with higher funding goals  that will be reached at a later stage. If you're interested in accessing these  features, becoming a sponsor is the way to go. If you have a feature in mind  that you would like to see on the list, we encourage you to  initiate a new discussion to evaluate it with others.</p> <p>What happens if I reach my sponsoring limit for my current tier?</p> <p>If you extend the number of sites that are in your current sponsoring limit,  please upgrade your sponsorship to a higher tier to continue using the  Insiders version and build more sites. The change will be effective immediately.</p> <p>Do you offer refunds for sponsoring payments?</p> <p>Unfortunately, we cannot offer any refund for sponsorship payments.  GitHub Sponsors and Ko-Fi manage all sponsoring transactions. Because of  that, we do not have any insights into the details of the funds and cannot access  them. If you have any payment issues, please get in touch with the GitHub  or Ko-Fi support team, as they can help you.</p>"},{"location":"faq/sponsoring/#access-management","title":"Access management","text":"<p>How do I gain access to the private Insiders repository?</p> <p>If you sponsored with your individual account, you should have received an  email invitation to the private Material for MkDocs Insiders repository right  after you initiated your sponsorship. Simply accept the invitation within seven  days to gain access.</p> <p>If you sponsored using an organization account, please note we need  an individual account that we can list as a collaborator of the private Insiders  repository. After you initiate your sponsorship, please email us at  sponsors@squidfunk.com with the name of the individual or bot account. Once you  provide us with this information, we will add the account as a collaborator, and  after you accept the invitation, you will gain access to the repository.</p> <p>If you have yet to receive the email or the invitation link has expired, please  contact us, the maintainers, at sponsors@squidfunk.com. We're working on a solution that will allow you to manage collaborator status yourself.</p> <p>Why can't our whole organization get access to Insiders?</p> <p>Currently, it is not possible to grant access to an organizational account, as  GitHub only allows for adding individual user accounts. We are working on a  solution ourselves to simplify access for organizations. For now, to ensure that  access is not tied to a particular individual, we recommend creating a bot  account, i.e., a GitHub account that does not belong to a specific individual  but is listed as the owner of the organizational account and using this account  for sponsorship.</p> <p>Do I need to fork the repository to use it?</p> <p>It depends. If you are using the Insiders edition as an individual, you can work directly with the private repository, as you do not need to share the Insiders features with others. If you are working with a team, it is best to create a private fork using the individual account you listed as a collaborator of Material for MkDocs to grant access to all members of your organization to your fork.</p> <p>Can I share my Insiders access with others?</p> <p>At the moment, it is not possible to directly share your collaborator status  for the private Insiders repository with other accounts. However, if you are  working with a team and would like them to access Insiders, you can share the  Insiders repository by utilizing options such as cloning, forking, or  mirroring. By doing so, you can start collaborating with your team members on  the new repository you have shared. This way, you can collectively benefit  from the Insiders features and work together on the project.</p>"},{"location":"faq/sponsoring/#runtime-cancellation","title":"Runtime &amp; cancellation","text":"<p>How long is my sponsorship valid?</p> <p>Your sponsorship is valid for as long as your monthly or yearly subscription is valid. If you choose to cancel your sponsorship, you will lose access to  the Insiders edition once your cancelation is active and will be automatically  removed by GitHub as a collaborator from the private repository. </p> <p>How do I cancel my sponsorship?</p> <p>To cancel your sponsorship, follow the step-by-step guide provided by GitHub.  If you sponsored using an organizational account, please ensure that you cancel  your sponsorship using the same organizational account rather than your  individual account.</p> <p>What happens when I cancel my sponsorship?</p> <p>If you choose to cancel your subscription to Insiders, you will be  automatically removed by GitHub as a collaborator on the day your cancellation is  effective. From that day on, you will no longer receive future updates. However,  you are welcome to continue using the latest version that was available to  you at the time of your cancellation for as long as you like.</p> <p>Please note that GitHub deletes private forks, so you may want to take steps to ensure that you have a backup of the software if necessary and use the locally installed version.</p>"},{"location":"faq/sponsoring/#licensing","title":"Licensing","text":"<p>What constitutes commercial use of the Insiders version?</p> <p>Commercial use refers to any use of the software for a business or for-profit  purpose. This includes any use by a corporation or other organization, whether  or not they generate revenue directly from the software. We offer different  pricing tiers for commercial use, each tailored to the needs of different  businesses. It's important to note that internal use of the software within your  organization is also considered commercial use, as with all commercial software.</p> <p>What constitutes non-commercial use of the Insiders version?</p> <p>Non-commercial use of our Material for MkDocs refers to private use. This includes individuals using the Insiders edition for private or purely non-commercial Open Source projects. We offer two different tiers for non-commercial use, depending on the number of sites you want to build.  </p> <p>What is your fair use policy?</p> <p>Our fair use policy includes the following guidelines:</p> <ul> <li> <p>Please refrain from distributing the source code of Insiders. While you  may use the software for public, private, or commercial projects and may  privately fork or mirror it, we ask that you keep the source code private. This  is important to our sponsorware strategy, which helps us fund ongoing  development and support of the software. If this guidelines is violated, everybody loses, as it will reduce the time of us maintainers we can set aside to push this project forward.</p> </li> <li> <p>As our sponsoring tiers are based on the number of sites you want to build,  please make sure to upgrade your sponsorship once your current sponsoring tier  limit has been reached. </p> </li> </ul> <p>Does the Insiders version have a different license?</p> <p>No. Whether you're an individual or a company, you may use Material for  MkDocs Insiders precisely under the same terms as Material for MkDocs, which are  given by the MIT license.</p> <p>Can outside collaborators build and run the documentation locally without access to Insiders?</p> <p>Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, changing the general  appearance of your site should be optional. Most Insiders features enhance the  overall experience, e.g., by adding icons to pages or providing a feedback  widget. While these features add value for your site's users, they should be  optional for previewing when making changes to content. Currently, the only  content-related features in Insiders that non-Insiders users can't properly  preview are Annotations and Card grids.</p> <p>This means that outside collaborators can build the documentation locally with  Material for MkDocs, and when they push their changes, your CI pipeline will  build it with Insiders. When using built-in plugins exclusive to Insiders, it's  recommended to split configuration into a base <code>mkdocs.yml</code> and one with plugin  overrides via configuration inheritance.</p> <p>See the getting started guide for more information.</p>"},{"location":"faq/sponsoring/#support","title":"Support","text":"<p>How can I contact support if I have questions about becoming a sponsor? </p> <p>If you have any questions and would like to contact us before starting your  sponsorship, we are happy to answer all your non-technical questions about the  Insiders program via email at sponsors@squidfunk.com.</p> <p>All technical questions should be asked openly on our discussion board.</p> <p>Is additional support available for Material for MkDocs Insiders users?</p> <p>Yes, we provide non-technical support related to sponsoring at sponsors@squidfunk.com. For technical questions, please submit an issue openly  on our issue tracker or start a discussion on our discussion board. Issues  and discussions from our organizational sponsors, sponsoring on  The Organization tier or higher will be prioritized.1</p> <p>How can I display my logo on the list of premium sponsors?</p> <p>If your sponsorship tier includes logo placement, and you would like us to display your logo in the list of premium sponsors and have it linked to your site, please contact us via mail. Simply send us a horizontal SVG or PNG version of your logo making sure it displays the name of your company and the logo to sponsors@squidfunk.com. </p> <p>Is logo placement optional?</p> <p>Yes, all of our commercial benefits, such as logo placement and backlinks, are  optional and can be opted in or out at any time. You can keep your sponsorship completely private.</p> <p>How can I report a bug in the Insiders version?</p> <p>If you encounter a bug in the Insiders edition, we kindly request that you  report it on our issue tracker in the public community repository. When  submitting the bug report, please ensure that you do not include any private  Insiders' source code, as we want to uphold our fair use policy. </p>"},{"location":"faq/sponsoring/#privacy","title":"Privacy","text":"<p>Will you sign an NDA for sponsorships?</p> <p>Unfortunately, we cannot sign any NDA or vendor agreement form. As a small team working on Material for MkDocs, we have limited resources and cannot review  and sign agreements.</p> <p>Can I sponsor privately?</p> <p>Yes, you can. GitHub gives you the option to set your sponsorship to private  when you set up your sponsorship. Additionally, we have a recommended workflow  for you: We suggest you create a new GitHub bot account. This bot account should  not be tied to a particular individual and should be privately listed as an  owner of your GitHub organization. This account can then be used to sponsor  Material for MkDocs privately. As a bot account, it will automatically be listed  as a collaborator of the private Insiders repository. You can clone, fork, or  mirror using this account. All information will be kept confidential; only the  bot account and us maintainers will have insights into his sponsorship. </p> <p>Are there any geographical restrictions on becoming a sponsor?</p> <p>No, there are no geographical restrictions for becoming a sponsor. We welcome  sponsorships from individuals and organizations worldwide. As long as your  credit card is valid and accepted by GitHub or Ko-Fi, you are eligible to become  a sponsor and support the project, regardless of your location. </p> <ol> <li> <p>Priority support means we will prioritize your issue, meaning we will look  into it and do our best to solve your issue asap. However, the prioritized bug  support does not mean that we can solve your issue before any others since  some issues might take more time to solve.\u00a0\u21a9</p> </li> </ol>"},{"location":"insiders/","title":"Insiders","text":"<p>Material for MkDocs follows the sponsorware release strategy, which means that new features are first exclusively released to sponsors as part of Insiders. Read on to learn what sponsorships achieve, how to become a sponsor to get access to Insiders, and what's in it for you!</p>"},{"location":"insiders/#what-is-insiders","title":"What is Insiders?","text":"<p>Material for MkDocs Insiders is a private fork of Material for MkDocs, hosted as a private GitHub repository. Almost1 all new features are developed as part of this fork, which means that they are immediately available to all eligible sponsors, as they are made collaborators of this repository.</p> <p>Every feature is tied to a funding goal in monthly subscriptions. When a funding goal is hit, the features that are tied to it are merged back into Material for MkDocs and released for general availability, making them available to all users. Bugfixes are always released in tandem.</p> <p>Sponsorships start as low as $15 a month.2</p>"},{"location":"insiders/#what-sponsorships-achieve","title":"What sponsorships achieve","text":"<p>Sponsorships make this project sustainable, as they buy the maintainers of this project time \u2013 a very scarce resource \u2013 which is spent on the development of new features, bug fixing, stability improvement, issue triage and general support. The biggest bottleneck in Open Source is time.3</p> <p>If you're unsure if you should sponsor this project, check out the list of completed funding goals to learn whether you're already using features that were developed with the help of sponsorships. You're most likely using at least a handful of them, thanks to our awesome sponsors!</p>"},{"location":"insiders/#whats-in-it-for-me","title":"What's in it for me?","text":"<p>The moment you become a sponsor, you'll get immediate access to 23 additional features that you can start using now, and which are currently exclusively available to sponsors:</p> <ul> <li> Projects plugin </li> <li> Instant prefetching </li> <li> Social plugin: custom layouts </li> <li> Social plugin: background images </li> <li> Code range selection</li> <li> Code annotations: custom selectors</li> <li> Privacy plugin: optimization support</li> <li> Optimize plugin</li> <li> Navigation path (Breadcrumbs)</li> <li> Typeset plugin</li> <li> Privacy plugin: external links</li> <li> Navigation subtitles</li> <li> Tags plugin: allow list + custom sorting</li> <li> Blog plugin: custom index pages</li> <li> Blog plugin: related links</li> <li> Meta plugin</li> <li> Tags plugin: additional indexes</li> <li> Document contributors</li> <li> Automatic light / dark mode</li> <li> Content tabs: anchor links</li> <li> Tooltips</li> <li> Card grids</li> <li> Privacy plugin</li> </ul> <p>New features are added every other week. Be sure to come back.</p>"},{"location":"insiders/#how-to-become-a-sponsor","title":"How to become a sponsor","text":"<p>Thanks for your interest in sponsoring! In order to become an eligible sponsor with your GitHub account, visit squidfunk's sponsor profile, and complete a sponsorship of $15 a month or more. You can use your individual or organization GitHub account for sponsoring.</p> <p>Important: If you're sponsoring @squidfunk through a GitHub organization, please send a short email to sponsors@squidfunk.com with the name of your organization and the GitHub account of the individual that should be added as a  collaborator.4</p> <p>You can cancel your sponsorship anytime.5</p> <p> \u00a0 Join our  awesome sponsors</p> <p>Silver sponsors:</p> <p></p> <p>Bronze sponsors:</p> <p> </p>      If you sponsor publicly, you're automatically added here with a link to     your profile and avatar to show your support for Material for MkDocs.     Alternatively, if you wish to keep your sponsorship private, you'll be a     silent +1. You can select visibility during checkout and change it     afterwards."},{"location":"insiders/#funding","title":"Funding","text":""},{"location":"insiders/#goals","title":"Goals","text":"<p>The following section lists all funding goals. Each goal contains a list of features prefixed with a checkmark symbol, denoting whether a feature is  already available or   planned, but not yet implemented. When the funding goal is hit, the features are released for general availability.</p>"},{"location":"insiders/#14000-goats-horn","title":"$ 14,000 \u2013 Goat's Horn","text":"<ul> <li> Privacy plugin</li> <li> Card grids</li> <li> Tooltips</li> <li> Content tabs: anchor links</li> <li> Automatic light / dark mode</li> <li> Document contributors</li> </ul>"},{"location":"insiders/#16000-chipotle","title":"$ 16,000 \u2013 Chipotle","text":"<ul> <li> Meta plugin</li> <li> Blog plugin: related links</li> <li> Blog plugin: custom index pages</li> <li> Tags plugin: additional indexes</li> <li> Tags plugin: allow list + custom sorting</li> <li> Navigation subtitles</li> </ul>"},{"location":"insiders/#20000-jalapeno","title":"$ 20,000 \u2013 Jalape\u00f1o","text":"<ul> <li> Optimize plugin</li> <li> Typeset plugin</li> <li> Navigation path (Breadcrumbs)</li> <li> Privacy plugin: optimization support</li> <li> Privacy plugin: external links</li> <li> Instant prefetching</li> </ul>"},{"location":"insiders/#24000-blockpaprika","title":"$ 24,000 \u2013 Blockpaprika","text":"<ul> <li> Projects plugin</li> <li> Social plugin: custom layouts</li> <li> Social plugin: background images</li> <li> Code range selection</li> <li> Code annotations: custom selectors</li> <li> Code line wrap button</li> </ul>"},{"location":"insiders/#goals-completed","title":"Goals completed","text":"<p>This section lists all funding goals that were previously completed, which means that those features were part of Insiders, but are now generally available and can be used by all users.</p>"},{"location":"insiders/#12000-piri-piri","title":"$ 12,000 \u2013 Piri Piri","text":"<ul> <li> Blog plugin</li> <li> Chinese search support</li> <li> Annotations</li> <li> Navigation icons</li> <li> Navigation pruning</li> <li> Navigation status</li> </ul>"},{"location":"insiders/#10000-carolina-reaper","title":"$ 10,000 \u2013 Carolina Reaper","text":"<ul> <li> Brand new search plugin</li> <li> Rich search previews</li> <li> Tokenizer with lookahead</li> <li> Advanced search highlighting</li> <li> Excluding content from search</li> <li> Offline plugin</li> </ul>"},{"location":"insiders/#8000-scotch-bonnet","title":"$ 8,000 \u2013 Scotch Bonnet","text":"<ul> <li> Social cards</li> <li> Code annotations: anchor links</li> <li> Code annotations: strip comments</li> <li> Tag icons</li> <li> Table of contents anchor following</li> <li> Sidebars automatically scroll to active item</li> </ul>"},{"location":"insiders/#7000-royal-gold","title":"$ 7,000 \u2013 Royal Gold","text":"<ul> <li> Cookie consent</li> <li> Was this page helpful?</li> <li> Dismissable announcement bar</li> </ul>"},{"location":"insiders/#6000-trinidad-scorpion","title":"$ 6,000 \u2013 Trinidad Scorpion","text":"<ul> <li> Boosting pages in search</li> <li> Custom admonition icons</li> <li> Linking content tabs</li> </ul>"},{"location":"insiders/#5000-aji-panca","title":"$ 5,000 \u2013 Aji Panca","text":"<ul> <li> Mermaid.js integration</li> <li> Stay on page when switching versions</li> <li> Tags with search integration</li> </ul>"},{"location":"insiders/#4000-ghost-pepper","title":"$ 4,000 \u2013 Ghost Pepper","text":"<ul> <li> Anchor tracking</li> <li> Code annotations</li> <li> Version warning</li> </ul>"},{"location":"insiders/#3000-caribbean-red","title":"$ 3,000 \u2013 Caribbean Red","text":"<ul> <li> Sticky navigation tabs</li> <li> Section index pages</li> <li> Remove generator notice</li> </ul>"},{"location":"insiders/#2500-biquinho-vermelho","title":"$ 2,500 \u2013 Biquinho Vermelho","text":"<ul> <li> Search suggestions</li> <li> Search highlighting</li> <li> Search sharing</li> </ul>"},{"location":"insiders/#2000-black-pearl","title":"$ 2,000 \u2013 Black Pearl","text":"<ul> <li> Latest release tag</li> <li> Color palette toggle</li> <li> Back-to-top button</li> </ul>"},{"location":"insiders/#1500-bhut-jolokia","title":"$ 1,500 \u2013 Bhut Jolokia","text":"<ul> <li> Admonition inline blocks</li> <li> Site language selection</li> <li> Versioning</li> </ul>"},{"location":"insiders/#1000-prairie-fire","title":"$ 1,000 \u2013 Prairie Fire","text":"<ul> <li> Navigation sections</li> <li> Navigation expansion</li> <li> Hiding the sidebars</li> <li> Table of contents in navigation</li> <li> Header hides on scroll</li> </ul>"},{"location":"insiders/#500-madame-jeanette","title":"$ 500 \u2013 Madame Jeanette","text":"<ul> <li> Improved search result grouping</li> <li> Improved search result relevance and scoring</li> <li> Missing query terms in search results</li> </ul>"},{"location":"insiders/#frequently-asked-questions","title":"Frequently asked questions","text":""},{"location":"insiders/#compatibility","title":"Compatibility","text":"<p>We're building an open source project and want to allow outside collaborators to run and build our documentation locally without having access to Insiders. Is this still possible?</p> <p>Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, it should be rarely necessary to change the general appearance of your site. Most Insiders features enhance the overall experience, e.g. by adding icons to pages or providing a feedback widget. While this features add value for the user of your site, they shouldn't be necessary for previewing when making changes to content. Currently, the only content-related features in Insiders that can't be properly previewed by non-Insiders users are:</p> <ul> <li>Annotations</li> <li>Card grids</li> </ul> <p>This means that outside collaborators are able to build the documentation locally with Material for MkDocs and when they push their changes, your CI pipeline will build it with Insiders. When using built-in plugins that are exclusive to Insiders, it's recommended to split configuration into a base <code>mkdocs.yml</code> and one with plugin overrides via configuration inheritance.</p> <p>See the getting started guide for more information.</p>"},{"location":"insiders/#payment","title":"Payment","text":"<p>We don't want to pay for sponsorship every month. Are there any other options?</p> <p>Yes. You can sponsor on a yearly basis by switching your GitHub account to a yearly billing cycle. If for some reason you cannot do that, you could also create a dedicated GitHub account with a yearly billing cycle, which you only use for sponsoring (some sponsors already do that).</p> <p>If you have any problems or further questions, please reach out to sponsors@squidfunk.com.</p>"},{"location":"insiders/#terms","title":"Terms","text":"<p>Are we allowed to use Insiders under the same terms and conditions as Material for MkDocs?</p> <p>Yes. Whether you're an individual or a company, you may use Material for MkDocs Insiders precisely under the same terms as Material for MkDocs, which are given by the MIT license. However, we kindly ask you to respect our fair use policy:</p> <ul> <li> <p>Please don't distribute the source code of Insiders. You may freely use   it for public, private or commercial projects, privately fork or mirror it,   but please don't make the source code public, as it would counteract the    sponsorware strategy.</p> </li> <li> <p>If you cancel your subscription, you're automatically removed as a   collaborator and will miss out on all future updates of Insiders. However, you   may use the latest version that's available to you as long as you like.   Just remember that GitHub deletes private forks.</p> </li> </ul> <ol> <li> <p>In general, every new feature is first exclusively released to sponsors, but sometimes upstream dependencies like Python Markdown Extensions enhance existing features that must be supported by Material for MkDocs.\u00a0\u21a9</p> </li> <li> <p>Note that $15 a month is the minimum amount to become eligible for Insiders. While GitHub Sponsors also allows to sponsor lower amounts or one-time amounts, those can't be granted access to Insiders due to technical reasons.\u00a0\u21a9</p> </li> <li> <p>Making an Open Source project sustainable is exceptionally hard: maintainers burn out, projects are abandoned. That's not great and very unpredictable. The sponsorware model ensures that if you decide to use Material for MkDocs, you can be sure that bugs are fixed quickly and new features are added regularly.\u00a0\u21a9</p> </li> <li> <p>It's currently not possible to grant access to each member of an organization, as GitHub only allows for adding users. Thus, after sponsoring, please send an email to sponsors@squidfunk.com, stating which account should become a collaborator of the Insiders repository. We're working on a solution which will make access to organizations much simpler. To ensure that access is not tied to a particular individual GitHub account, create a bot account (i.e. a GitHub account that is not tied to a specific individual), and use this account for the sponsoring. After being added to the list of collaborators, the bot account can create a private fork of the private Insiders GitHub repository, and grant access to all members of the organizations.\u00a0\u21a9</p> </li> <li> <p>If you cancel your sponsorship, GitHub schedules a cancellation request which will become effective at the end of the billing cycle. This means that even though you cancel your sponsorship, you will keep your access to Insiders as long as your cancellation isn't effective. All charges are processed by GitHub through Stripe. As we don't receive any information regarding your payment, and GitHub doesn't offer refunds, sponsorships are non-refundable.\u00a0\u21a9</p> </li> </ol>"},{"location":"insiders/changelog/","title":"Changelog","text":""},{"location":"insiders/changelog/#material-for-mkdocs-insiders","title":"Material for MkDocs Insiders","text":""},{"location":"insiders/changelog/#4.38.1","title":"4.38.1 August 1, 2023","text":"<ul> <li>Improved nested serve mode for projects plugin</li> <li>Improved compat in privacy plugin with third-party plugins</li> <li>Fixed #5790: Typeset plugin ignores data-toc-label attribute</li> <li>Fixed #5778: Interplay of privacy plugin with git-revision-date-localized</li> <li>Fixed #5773: Info plugin erroring when community edition is in beta</li> </ul>"},{"location":"insiders/changelog/#4.38.0","title":"4.38.0 July 29, 2023","text":"<ul> <li>Added projects plugin for building nested projects</li> <li>Updated privacy plugin to new MkDocs API</li> </ul>"},{"location":"insiders/changelog/#4.37.1","title":"4.37.1 July 28, 2023","text":"<ul> <li>Updated MkDocs to 1.5.1</li> <li>Fixed deprecation warning in social plugin due to MkDocs upgrade</li> <li>Fixed #5772: Privacy plugin fails due to API change in MkDocs</li> </ul>"},{"location":"insiders/changelog/#4.37.0","title":"4.37.0 July 7, 2023","text":"<ul> <li>Added support for overriding social cards settings per page</li> <li>Added new social card <code>default/only/image</code> layout</li> <li>Improved resilience of optimize and social plugin</li> <li>Fixed rendering bugs for pruned navigation items</li> <li>Fixed jumping of content tabs anchor links when instant loading is enabled</li> <li>Fixed #5676: Optimize plugin doesn't check for <code>pngquant</code></li> </ul>"},{"location":"insiders/changelog/#4.36.1","title":"4.36.1 June 23, 2023","text":"<ul> <li>Fixed #5618: Date comparison breaking for drafts in blog plugin</li> </ul>"},{"location":"insiders/changelog/#4.36.0","title":"4.36.0 June 15, 2023","text":"<ul> <li>Added support for instant prefetching to speed up slow connections</li> <li>Improved stability of anchor link removal in built-in typeset plugin</li> <li>Improved performance of regular expressions in typeset plugin</li> <li>Removed unnecessary import test for <code>cairosvg</code> in optimize plugin</li> <li>Fixed #5590: Regular expression for anchor link removal too greedy</li> </ul>"},{"location":"insiders/changelog/#4.35.3","title":"4.35.3 June 1, 2023","text":"<ul> <li>Fixed #5579: Abbreviations in headlines filtered by typeset plugin</li> </ul>"},{"location":"insiders/changelog/#4.35.2","title":"4.35.2 May 29, 2023","text":"<ul> <li>Fixed #5555: Blog plugin crashes when computing readtime for emojis</li> </ul>"},{"location":"insiders/changelog/#4.35.1","title":"4.35.1 May 20, 2023","text":"<ul> <li>Fixed internal handling of errors in social plugin</li> </ul>"},{"location":"insiders/changelog/#4.35.0","title":"4.35.0 May 20, 2023","text":"<ul> <li>Improve editing experience and stability of social plugin</li> <li>Added support for custom layout syntax validation in social plugin</li> <li>Added support for layer origin for easier placement in social plugin</li> <li>Added support for in- and exclusion patterns in social plugin</li> <li>Catch and print syntax errors in custom layouts</li> </ul>"},{"location":"insiders/changelog/#4.34.1","title":"4.34.1 May 16, 2023","text":"<ul> <li>Disable social plugin debug mode by default on mkdocs build</li> <li>Added warning in social plugin debug mode when font style couldn't be found</li> <li>Set default concurrency of built-in multi-threaded plugins to CPUs - 1</li> <li>Fixed #5521: Social plugin triggers race condition when downloading fonts</li> <li>Fixed #5515: Social plugin crashes when concurrency is set to 1</li> </ul>"},{"location":"insiders/changelog/#4.34.0","title":"4.34.0 May 14, 2023","text":"<ul> <li>Added support for new overflow mode to auto-fit text in social plugin</li> <li>Reduced subtle rendering bugs in (code) annotations due to subpixel rounding</li> <li>Improved print styles for (code) annotation lists</li> <li>Improved performance of social plugin, now 3x as fast</li> <li>Improved interop of typeset plugin with MkDocstrings</li> <li>Fixed logo location for variants of default template in social plugin</li> <li>Fixed #5446: Built-in typeset plugin picks up headings in code blocks</li> </ul>"},{"location":"insiders/changelog/#4.33.2","title":"4.33.2 May 12, 2023","text":"<ul> <li>Fixed #5508: Social plugin crashes trying to copy cards on Docker/Windows</li> <li>Fixed #5507: Social plugin crashes on serve when layouts folder doesn't exist</li> <li>Fixed #5505: Social plugin trying to resolve logo in wrong location</li> <li>Fixed #5496: Annotations with nested lists incorrectly mounted</li> <li>Fixed #5493: Social plugin crashes on Python 3.8</li> </ul>"},{"location":"insiders/changelog/#4.33.1","title":"4.33.1 May 9, 2023","text":"<ul> <li>Added support for SVG background images in social plugin</li> </ul>"},{"location":"insiders/changelog/#4.33.0","title":"4.33.0 May 8, 2023","text":"<ul> <li>Added support for custom layouts for social plugin</li> <li>Added support for background images for social cards</li> </ul>"},{"location":"insiders/changelog/#4.32.6","title":"4.32.6 April 22, 2023","text":"<ul> <li>Fixed #5336: Interplay of blog plugin with git-revision-date-localized</li> </ul>"},{"location":"insiders/changelog/#4.32.5","title":"4.32.5 April 7, 2023","text":"<ul> <li>Fixed #5322: Navigation tabs hoist nested page icons</li> </ul>"},{"location":"insiders/changelog/#4.32.4","title":"4.32.4 March 24, 2023","text":"<ul> <li>Fixed #5241: Built-in typeset plugin jams navigation for anchors in headings</li> </ul>"},{"location":"insiders/changelog/#4.32.3","title":"4.32.3 March 9, 2023","text":"<ul> <li>Fixed Docker image release workflow (9.1.0 regression)</li> <li>Fixed #5159: Missing underline for abbreviations (9.1.0 regression)</li> </ul>"},{"location":"insiders/changelog/#4.32.2","title":"4.32.2 February 23, 2023","text":"<ul> <li>Fixed #5127: Privacy plugin not handling large number of occurrences</li> <li>Fixed #5126: Privacy plugin breaks when replacing specific emojis</li> </ul>"},{"location":"insiders/changelog/#4.32.1","title":"4.32.1 February 23, 2023","text":"<ul> <li>Fixed code block spans interfering with copying</li> <li>Fixed #5077: Privacy plugin breaks image <code>alt</code> text encoding</li> <li>Fixed #5079: Privacy plugin removing <code>rel=me</code> on external links</li> </ul>"},{"location":"insiders/changelog/#4.32.0","title":"4.32.0 February 19, 2023","text":"<ul> <li>Added support for custom selectors for code annotations</li> <li>Added support for code line range selection for better sharing</li> </ul>"},{"location":"insiders/changelog/#4.31.0","title":"4.31.0 February 18, 2023","text":"<ul> <li>Added support for table of contents on blog index and archive pages</li> <li>Fixed #4512: Allow custom search field boosts (experimental)</li> </ul>"},{"location":"insiders/changelog/#4.30.2","title":"4.30.2 February 13, 2023","text":"<ul> <li>Fixed privacy plugin excludes not working (4.30.0 regression)</li> </ul>"},{"location":"insiders/changelog/#4.30.1","title":"4.30.1 February 12, 2023","text":"<ul> <li>Fixed privacy plugin not handling static templates (e.g. <code>404.html</code>)</li> </ul>"},{"location":"insiders/changelog/#4.30.0","title":"4.30.0 February 6, 2023","text":"<ul> <li>Rewrite of privacy plugin for concurrency, now twice as fast</li> <li>Added support for explicit inclusion for privacy plugin</li> <li>Added optimization support for privacy plugin (+ optimize plugin)</li> </ul>"},{"location":"insiders/changelog/#4.29.0","title":"4.29.0 January 21, 2023","text":"<ul> <li>Added built-in optimize plugin for automatically compressing images</li> <li>Switched reporting in built-in privacy plugin to <code>info</code> level</li> </ul>"},{"location":"insiders/changelog/#4.28.1","title":"4.28.1 January 17, 2023","text":"<ul> <li>Fixed built-in info plugin erroring for Insiders on version check</li> <li>Fixed #4865: Navigation paths render bug when there's no top-level section</li> <li>Fixed #4875: Added support for hiding navigation paths</li> <li>Improved navigation path to not render for a single item</li> </ul>"},{"location":"insiders/changelog/#4.28.0","title":"4.28.0 January 14, 2023","text":"<ul> <li>Added support for navigation path (breadcrumbs)</li> </ul>"},{"location":"insiders/changelog/#4.27.1","title":"4.27.1 December 20, 2022","text":"<ul> <li>Fixed rendering of succeeding navigation items in typeset plugin</li> <li>Fixed #4795: Built-in typeset plugin changes MkDocs' title precedence</li> <li>Fixed #4724: Blog plugin not rendering integrate table of contents</li> </ul>"},{"location":"insiders/changelog/#4.27.0","title":"4.27.0 December 20, 2022","text":"<ul> <li>Added built-in typeset plugin to preserve formatting in sidebars</li> <li>Added URL and table of contents support for blog categories</li> </ul>"},{"location":"insiders/changelog/#4.26.6","title":"4.26.6 November 28, 2022","text":"<ul> <li>Fixed #4683: Tags plugin crashes when a tag is empty</li> </ul>"},{"location":"insiders/changelog/#4.26.5","title":"4.26.5 November 27, 2022","text":"<ul> <li>Fixed #4632: Post excerpt title link doesn't point to top of the page</li> </ul>"},{"location":"insiders/changelog/#4.26.4","title":"4.26.4 November 27, 2022","text":"<ul> <li>Fixed redundant file extension when using privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.26.3","title":"4.26.3 November 15, 2022","text":"<ul> <li>Fixed #4637: Attachments w/o titles in related links error in blog plugin</li> <li>Fixed #4631: Remote favicons not downloaded and inlined by privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.26.2","title":"4.26.2 November 3, 2022","text":"<ul> <li>Updated MkDocs to 1.4.2</li> <li>Added support for tag compare functions when sorting on index pages</li> <li>Fixed footnotes being rendered in post excerpts without separators</li> <li>Fixed error in blog plugin when <code>toc</code> extension is not enabled</li> <li>Fixed issues with invalid asset paths and linked post titles</li> <li>Fixed #4572: Privacy plugin fails when symlinks cannot be created</li> <li>Fixed #4545: Blog plugin doesn't automatically link headline to post</li> <li>Fixed #4542: Blog plugin doesn't allow for multiple instances</li> <li>Fixed #4532: Blog plugin doesn't allow for mixed use of date and datetime</li> </ul>"},{"location":"insiders/changelog/#4.26.1","title":"4.26.1 October 22, 2022","text":"<ul> <li>Improved reporting of configuration errors in tags plugin</li> <li>Fixed #4515: Privacy plugin fails when site URL is not defined</li> <li>Fixed #4514: Privacy plugin doesn't fetch Google fonts (4.26.0 regression)</li> </ul>"},{"location":"insiders/changelog/#4.26.0","title":"4.26.0 October 18, 2022","text":"<ul> <li>Refactored privacy plugin to prepare for new features</li> <li>Added support for <code>rel=noopener</code> links in privacy plugin</li> <li>Resolve encoding issues with blog and privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.25.5","title":"4.25.5 October 16, 2022","text":"<ul> <li>Updated MkDocs to 1.4.1</li> <li>Added namespace prefix to built-in plugins</li> <li>Updated <code>content</code> and <code>header</code> partial</li> </ul>"},{"location":"insiders/changelog/#4.25.4","title":"4.25.4 October 9, 2022","text":"<ul> <li>Fixed other path issues for standalone blogs (4.24.2 regression)</li> </ul>"},{"location":"insiders/changelog/#4.25.3","title":"4.25.3 October 9, 2022","text":"<ul> <li>Fixed #4457: Posts not collected for standalone blog (4.24.2 regression)</li> </ul>"},{"location":"insiders/changelog/#4.25.2","title":"4.25.2 October 4, 2022","text":"<ul> <li>Fixed #4452: Blog and tags plugin crash when specifying slugify function</li> </ul>"},{"location":"insiders/changelog/#4.25.1","title":"4.25.1 October 3, 2022","text":"<ul> <li>Updated <code>mkdocs-rss-plugin</code> in <code>Dockerfile</code> to fix MkDocs compat errors</li> </ul>"},{"location":"insiders/changelog/#4.25.0","title":"4.25.0 October 2, 2022","text":"<ul> <li>Added support for navigation subtitles</li> <li>Added support for defining an allow list for built-in tags plugin</li> <li>Added support for custom slugify functions for built-in tags plugin</li> <li>Improved stability of search plugin when using <code>--dirtyreload</code></li> </ul>"},{"location":"insiders/changelog/#4.24.2","title":"4.24.2 October 1, 2022","text":"<ul> <li>Updated MkDocs to 1.4</li> <li>Fixed compatibility issues with MkDocs 1.4</li> <li>Fixed incorrectly generated paths in privacy plugin</li> <li>Fixed blog index page not showing navigation when using meta plugin</li> </ul>"},{"location":"insiders/changelog/#4.24.1","title":"4.24.1 September 30, 2022","text":"<ul> <li>Fixed #4430: build error when enabling consent without repository URL</li> </ul>"},{"location":"insiders/changelog/#4.24.0","title":"4.24.0 September 27, 2022","text":"<ul> <li>Added support for custom content on index pages (blog)</li> <li>Added support for keeping content on paginated index pages (blog)</li> <li>Added support for limiting categories in post excerpts (blog)</li> <li>Added support for simple override of templates via front matter (blog)</li> <li>Added icon in navigation for pages with encrypted content</li> <li>Fixed #4396: Front matter of index pages not inherited by pagination (blog)</li> <li>Improved performance by building post excerpts once (blog)</li> </ul>"},{"location":"insiders/changelog/#4.23.6","title":"4.23.6 September 22, 2022","text":"<ul> <li>Fixed #4389: Blog posts in first week of year in wrong archive</li> <li>Fixed (= switched) footer previous and next links for blog posts</li> </ul>"},{"location":"insiders/changelog/#4.23.5","title":"4.23.5 September 18, 2022","text":"<ul> <li>Fixed #4367: Improved blog plugin date handling for MultiMarkdown syntax</li> <li>Fixed #4374: Fixed invalid URLs of related links to other blog posts</li> </ul>"},{"location":"insiders/changelog/#4.23.4","title":"4.23.4 September 14, 2022","text":"<ul> <li>Fixed #4365: Recursion error in blog plugin due to <code>deepcopy</code></li> <li>Fixed path errors for blog plugin on Windows</li> <li>Fixed publishing workflow in forked repositories</li> </ul>"},{"location":"insiders/changelog/#4.23.3","title":"4.23.3 September 13, 2022","text":"<ul> <li>Fixed previous and next page links for drafts of blog posts</li> </ul>"},{"location":"insiders/changelog/#4.23.2","title":"4.23.2 September 13, 2022","text":"<ul> <li>Fixed #4348: Blog plugin crashes on custom <code>nav</code> title</li> <li>Fixed blog plugin crashing when category contained only drafts</li> <li>Fixed rendering of content from blog index file</li> </ul>"},{"location":"insiders/changelog/#4.23.1","title":"4.23.1 September 12, 2022","text":"<ul> <li>Fixed #4345: Blog plugin errors with default settings</li> </ul>"},{"location":"insiders/changelog/#4.23.0","title":"4.23.0 September 12, 2022","text":"<ul> <li>Added blogging support via built-in blog plugin</li> </ul>"},{"location":"insiders/changelog/#4.22.1","title":"4.22.1 September 7, 2022","text":"<ul> <li>Fixed #4217: Tooltips in data tables render in wrong position</li> </ul>"},{"location":"insiders/changelog/#4.22.0","title":"4.22.0 August 21, 2022","text":"<ul> <li>Added support for navigation status</li> </ul>"},{"location":"insiders/changelog/#4.21.1","title":"4.21.1 August 13, 2022","text":"<ul> <li>Fixed #4176: Broken image when avatar is served by Gravatar</li> <li>Fixed #4212: Deferred search initialization for file:// locations</li> </ul>"},{"location":"insiders/changelog/#4.21.0","title":"4.21.0 July 17, 2022","text":"<ul> <li>Added meta plugin: set front matter for all pages in a folder</li> <li>Fixed #4114: Tags plugin fails if only <code>tags_extra_files</code> is set</li> </ul>"},{"location":"insiders/changelog/#4.20.1","title":"4.20.1 July 11, 2022","text":"<ul> <li>Fixed #4105: Tags plugin fails if <code>tags_file</code> is not set (4.20.0 regression)</li> </ul>"},{"location":"insiders/changelog/#4.20.0","title":"4.20.0 July 7, 2022","text":"<ul> <li>Added support for additional tags indexes</li> <li>Fixed #4100: Tag icons not shown in tags index</li> </ul>"},{"location":"insiders/changelog/#4.19.2","title":"4.19.2 July 4, 2022","text":"<ul> <li>Fixed #4051: Privacy plugin fails if symlinking isn't allowed on Windows</li> </ul>"},{"location":"insiders/changelog/#4.19.1","title":"4.19.1 June 25, 2022","text":"<ul> <li>Added <code>mkdocs-git-committers-plugin</code> to Dockerfile</li> <li>Added <code>mkdocs-git-revision-date-localized-plugin</code> to Dockerfile</li> </ul>"},{"location":"insiders/changelog/#4.19.0","title":"4.19.0 June 24, 2022","text":"<ul> <li>Added support for document contributors</li> <li>Updated French translations for cookie consent</li> </ul>"},{"location":"insiders/changelog/#4.18.2","title":"4.18.2 June 16, 2022","text":"<ul> <li>Fixed #4026: Fixed tooltips not mounted for nested navigation links</li> </ul>"},{"location":"insiders/changelog/#4.18.1","title":"4.18.1 June 14, 2022","text":"<ul> <li>Fixed #3990: Chinese search highlighting not working on non-boundaries</li> </ul>"},{"location":"insiders/changelog/#4.18.0","title":"4.18.0 June 11, 2022","text":"<ul> <li>Added support for automatic dark/light mode</li> <li>Fixed #4009: Privacy plugin uses invalid paths for file cache on Windows</li> </ul>"},{"location":"insiders/changelog/#4.17.2","title":"4.17.2 June 5, 2022","text":"<ul> <li>Added support for custom jieba dictionaries (Chinese search)</li> </ul>"},{"location":"insiders/changelog/#4.17.1","title":"4.17.1 June 5, 2022","text":"<ul> <li>Added support for cookie consent reject button</li> <li>Added support for cookie consent custom button ordering</li> <li>Fixed #3988: Content tab not focused after alternating anchor links</li> </ul>"},{"location":"insiders/changelog/#4.17.0","title":"4.17.0 June 4, 2022","text":"<ul> <li>Added support for content tabs anchor links (deep linking)</li> <li>Fixed #3975: Detect composition events in search interface (Chinese)</li> <li>Fixed #3980: Search plugin doesn't use title set via front matter</li> </ul>"},{"location":"insiders/changelog/#4.16.2","title":"4.16.2 May 29, 2022","text":"<ul> <li>Fixed #3961: Nested sections triggered build error for navigation tabs</li> </ul>"},{"location":"insiders/changelog/#4.16.1","title":"4.16.1 May 28, 2022","text":"<ul> <li>Switched feedback widget rating titles to tooltips</li> <li>Improved contrast of link colors for light/dark color schemes</li> <li>Fixed #3950: Sticky navigation tabs rendering broken (4.15.2 regression)</li> <li>Fixed #3958: Links invisible when using <code>white</code> primary color</li> </ul>"},{"location":"insiders/changelog/#4.16.0","title":"4.16.0 May 25, 2022","text":"<ul> <li>Added support for navigation pruning</li> <li>Fixed search results for non-segmented characters (4.15.2 regression)</li> </ul>"},{"location":"insiders/changelog/#4.15.2","title":"4.15.2 May 22, 2022","text":"<ul> <li>Removed workaround for <code>abbr</code> on touch devices (superseded by tooltips)</li> <li>Fixed #3915: Improved Chinese search query segmentation</li> <li>Fixed #3938: Fixed tooltips position for navigation titles with ellipsis</li> </ul>"},{"location":"insiders/changelog/#4.15.1","title":"4.15.1 May 14, 2022","text":"<ul> <li>Improved performance of element focus observables</li> <li>Fixed #3531: Added prev/next buttons to content tabs</li> <li>Fixed tooltip positioning when host element is hidden</li> </ul>"},{"location":"insiders/changelog/#4.15.0","title":"4.15.0 May 8, 2022","text":"<ul> <li>Added support for improved tooltips</li> <li>Fixed #3785: Show tooltip on hover for overflowing navigation link</li> </ul>"},{"location":"insiders/changelog/#4.14.0","title":"4.14.0 May 5, 2022","text":"<ul> <li>Added Chinese language support to built-in search plugin</li> <li>Fixed all-numeric page titles raising error in social plugin</li> </ul>"},{"location":"insiders/changelog/#4.13.2","title":"4.13.2 April 30, 2022","text":"<ul> <li>Improved caching of downloaded resources in privacy plugin</li> <li>Fixed #3851: External images not downloaded by privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.13.1","title":"4.13.1 April 25, 2022","text":"<ul> <li>Fixed #3839: Tags plugin breaks without icons (4.13.0 regression)</li> </ul>"},{"location":"insiders/changelog/#4.13.0","title":"4.13.0 April 24, 2022","text":"<ul> <li>Added support for tag icons</li> </ul>"},{"location":"insiders/changelog/#4.12.0","title":"4.12.0 March 27, 2022","text":"<ul> <li>Added support for card grids and grid layouts</li> <li>Fixed #3685: Annotations sometimes broken when using instant loading </li> <li>Fixed #3742: Automatically add Mermaid.js when building for offline usage</li> </ul>"},{"location":"insiders/changelog/#4.11.0","title":"4.11.0 March 6, 2022","text":"<ul> <li>Added support for excluding external assets from privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.10.1","title":"4.10.1 March 2, 2022","text":"<ul> <li>Added missing build dependencies to Dockerfile</li> <li>Fixed encoding issues in privacy plugin, now forcing UTF-8 encoding</li> <li>Fixed #3624: Scroll to active navigation item unreliable in Firefox</li> <li>Fixed #3642: Privacy plugin errors when font setting was omitted</li> </ul>"},{"location":"insiders/changelog/#4.10.0","title":"4.10.0 February 27, 2022","text":"<ul> <li>Added support for offline plugin (supersedes offline search support)</li> <li>Improved built-in privacy plugin to download nested JavaScript assets</li> <li>Refactored configuration of built-in privacy plugin</li> </ul>"},{"location":"insiders/changelog/#4.9.1","title":"4.9.1 February 21, 2022","text":"<ul> <li>Fixed #3610: missing <code>lxml</code> dependency for privacy plugin</li> <li>Fixed error when charset is missing in <code>content-type</code> header</li> </ul>"},{"location":"insiders/changelog/#4.9.0","title":"4.9.0 February 20, 2022","text":"<ul> <li>Added privacy plugin: automatic downloading of external assets</li> </ul>"},{"location":"insiders/changelog/#4.8.3","title":"4.8.3 February 13, 2022","text":"<ul> <li>Fixed #3560: Mermaid diagrams don't render for <code>file://</code> locations</li> </ul>"},{"location":"insiders/changelog/#4.8.2","title":"4.8.2 February 10, 2022","text":"<ul> <li>Fixed #3559: Mermaid diagrams don't render inside closed <code>details</code></li> </ul>"},{"location":"insiders/changelog/#4.8.1","title":"4.8.1 February 6, 2022","text":"<ul> <li>Fixed jump back to top on mobile when using anchor following</li> </ul>"},{"location":"insiders/changelog/#4.8.0","title":"4.8.0 February 6, 2022","text":"<ul> <li>Added support for anchor following table of contents (= auto scroll)</li> </ul>"},{"location":"insiders/changelog/#4.7.2","title":"4.7.2 February 2, 2022","text":"<ul> <li>Fixed #3526: Transparent sidebar title due to Safari bug</li> <li>Fixed #3528: Firefox sometimes clips text in flow chart diagrams</li> </ul>"},{"location":"insiders/changelog/#4.7.1","title":"4.7.1 January 30, 2022","text":"<ul> <li>Fixed #3506: Tags index not respecting title set via front matter</li> </ul>"},{"location":"insiders/changelog/#4.7.0","title":"4.7.0 January 25, 2022","text":"<ul> <li>Added native support for offline search</li> </ul>"},{"location":"insiders/changelog/#4.6.1","title":"4.6.1 January 16, 2022","text":"<ul> <li>Fixed #3459: Section index pages picking up wrong title</li> </ul>"},{"location":"insiders/changelog/#4.6.0","title":"4.6.0 January 11, 2022","text":"<ul> <li>Added support for annotations (outside of code blocks)</li> </ul>"},{"location":"insiders/changelog/#4.5.2","title":"4.5.2 January 8, 2022","text":"<ul> <li>Fixed #3440: Content tab indicator not moving when using linking</li> <li>Fixed #3445: Content tab switch flickers/jitters when using linking</li> </ul>"},{"location":"insiders/changelog/#4.5.1","title":"4.5.1 January 2, 2022","text":"<ul> <li>Added support for setting initial state of cookie consent</li> <li>Fixed #3396: Disappearing link in navigation due to Safari bug</li> </ul>"},{"location":"insiders/changelog/#4.5.0","title":"4.5.0 December 16, 2021","text":"<ul> <li>Added support for navigation icons</li> </ul>"},{"location":"insiders/changelog/#4.4.0","title":"4.4.0 December 10, 2021","text":"<ul> <li>Added support for code annotation anchor links (deep linking)</li> <li>Added new code annotation syntax modifier to strip comment</li> <li>Updated German translations for cookie consent</li> </ul>"},{"location":"insiders/changelog/#4.3.0","title":"4.3.0 December 5, 2021","text":"<ul> <li>Added support for custom fonts in social cards</li> <li>Fixed #3300: Announcement bar reappearing when using instant loading</li> </ul>"},{"location":"insiders/changelog/#4.2.0","title":"4.2.0 December 2, 2021","text":"<ul> <li>Added support for dismissible announcement bar</li> <li>Added support for named placeholders in feedback widget</li> </ul>"},{"location":"insiders/changelog/#4.1.0","title":"4.1.0 November 30, 2021","text":"<ul> <li>Added support for passing page title to feedback forms</li> </ul>"},{"location":"insiders/changelog/#4.0.0","title":"4.0.0 November 28, 2021","text":"<ul> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integration \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"insiders/changelog/#3.2.3","title":"3.2.3 November 20, 2021","text":"<ul> <li>Updated Swedish and French translations</li> <li>Removed support for <code>.mermaid-experimental</code> class (now <code>.mermaid</code>)</li> <li>Fixed #3202: Cookie consent not dismissable on <code>file://</code> locations</li> <li>Fixed #3216: Cookie consent not dismissed when invoked via anchor</li> <li>Fixed #3232: Mermaid.js sometimes runs twice (race condition)</li> </ul>"},{"location":"insiders/changelog/#3.2.2","title":"3.2.2 November 6, 2021","text":"<ul> <li>Fixed always last feedback rating being sent</li> <li>Fixed #3145: Code annotations eat whole comment lines</li> <li>Fixed #3170: Feedback widget doesn't send data to GA4</li> </ul>"},{"location":"insiders/changelog/#3.2.1","title":"3.2.1 November 4, 2021","text":"<ul> <li>Added support for custom Mermaid.js version via additional JavaScript</li> <li>Fixed some configuration edge cases for tags plugin (3.1.5 regression)</li> <li>Fixed feedback widget title not being centered in Firefox</li> <li>Fixed #3179: Safari doesn't send request for feedback widget</li> </ul>"},{"location":"insiders/changelog/#3.2.0","title":"3.2.0 October 31, 2021","text":"<ul> <li>Added support for feedback widget (Was this page helpful?)</li> </ul>"},{"location":"insiders/changelog/#3.1.5","title":"3.1.5 October 28, 2021","text":"<ul> <li>Fixed #3144: Rogue link when using tags with auto-populated navigation</li> <li>Fixed #3147: Code block line numbers appear in search results</li> <li>Fixed #3158: Social cards do not strip HTML tags from title</li> </ul>"},{"location":"insiders/changelog/#3.1.4","title":"3.1.4 October 17, 2021","text":"<ul> <li>Fixed #2974: Text cropped with other fonts than <code>Roboto</code> in social plugin</li> <li>Fixed #3099: Encoding problems with non-latin character in social plugin</li> <li>Fixed #3112: Japanese segmenter not executed as part of new tokenizer</li> <li>Fixed tags (front matter) appearing in search with disabled tags plugin</li> </ul>"},{"location":"insiders/changelog/#3.1.3","title":"3.1.3 October 12, 2021","text":"<ul> <li>Added warnings to search plugin for unsupported options and syntax</li> <li>Fixed #3503: Search sometimes returns entire page</li> <li>Fixed #3089: Single-line code annotations disappear when printing</li> </ul>"},{"location":"insiders/changelog/#3.1.2","title":"3.1.2 October 6, 2021","text":"<ul> <li>Fixed incorrect path separators for social cards on Windows</li> </ul>"},{"location":"insiders/changelog/#3.1.1","title":"3.1.1 September 26, 2021","text":"<ul> <li>Fixed ordering bug in search exclusion logic</li> </ul>"},{"location":"insiders/changelog/#3.1.0","title":"3.1.0 September 26, 2021","text":"<ul> <li>Added support for excluding pages, sections, and elements from search</li> <li>Fixed #2803: Code block annotations not visible when printing</li> </ul>"},{"location":"insiders/changelog/#3.0.1","title":"3.0.1 September 19, 2021","text":"<ul> <li>Added support for using literal <code>h1-6</code> tags for search plugin</li> <li>Fixed search plugin breaking on void elements without slashes</li> <li>Fixed search plugin filtering link contents from headlines</li> <li>Fixed search plugin handling of multiple <code>h1</code> headlines</li> <li>Fixed search plugin handling of missing <code>h1</code> headlines</li> </ul>"},{"location":"insiders/changelog/#3.0.0","title":"3.0.0 September 13, 2021","text":"<ul> <li>Rewrite of MkDocs' search plugin</li> <li>Added support for rich search previews</li> <li>Added support for tokenizer with lookahead</li> <li>Improved search indexing performance (twice as fast)</li> <li>Improved search highlighting</li> </ul>"},{"location":"insiders/changelog/#2.13.3","title":"2.13.3 September 1, 2021","text":"<ul> <li>Added support for disabling social card generation</li> </ul>"},{"location":"insiders/changelog/#2.13.2","title":"2.13.2 August 25, 2021","text":"<ul> <li>Fixed #2965: Social plugin error when primary color is not defined</li> </ul>"},{"location":"insiders/changelog/#2.13.1","title":"2.13.1 August 21, 2021","text":"<ul> <li>Fixed #2948: Social cards are not cached</li> <li>Fixed #2953: Mermaid.js diagrams can't be centered anymore</li> </ul>"},{"location":"insiders/changelog/#2.13.0","title":"2.13.0 August 7, 2021","text":"<ul> <li>Added support for custom colors in social cards</li> </ul>"},{"location":"insiders/changelog/#2.12.2","title":"2.12.2 August 4, 2021","text":"<ul> <li>Fixed #2891: Division by zero error in social plugin</li> </ul>"},{"location":"insiders/changelog/#2.12.1","title":"2.12.1 July 26, 2021","text":"<ul> <li>Fixed error in social plugin when <code>site_description</code> was not set</li> <li>Fixed error in social plugin for non-ASCII characters</li> </ul>"},{"location":"insiders/changelog/#2.12.0","title":"2.12.0 July 25, 2021","text":"<ul> <li>Added support for social cards</li> </ul>"},{"location":"insiders/changelog/#2.11.1","title":"2.11.1 July 20, 2021","text":"<ul> <li>Fixed order of tags index, now sorted alphabetically</li> </ul>"},{"location":"insiders/changelog/#2.11.0","title":"2.11.0 July 18, 2021","text":"<ul> <li>Improved Mermaid.js integration, now stable</li> <li>Added support for sequence diagrams</li> <li>Added support for entity relationship diagrams</li> <li>Added support for cookie consent configuration</li> <li>Added feature flag to always enable annotations</li> </ul>"},{"location":"insiders/changelog/#2.10.0","title":"2.10.0 July 10, 2021","text":"<ul> <li>Added support for cookie consent</li> <li>Fixed #2807: Back-to-top button not hidden when using sticky tabs</li> </ul>"},{"location":"insiders/changelog/#2.9.2","title":"2.9.2 May 30, 2021","text":"<ul> <li>Moved tags to partial for easier customization</li> <li>Added support for hiding tags on any page</li> </ul>"},{"location":"insiders/changelog/#2.9.1","title":"2.9.1 May 24, 2021","text":"<ul> <li>Added missing guard for linking of content tabs</li> </ul>"},{"location":"insiders/changelog/#2.9.0","title":"2.9.0 May 23, 2021","text":"<ul> <li>Added support for linking of content tabs</li> </ul>"},{"location":"insiders/changelog/#2.8.0","title":"2.8.0 May 12, 2021","text":"<ul> <li>Added support for boosting pages in search</li> </ul>"},{"location":"insiders/changelog/#2.7.2","title":"2.7.2 May 8, 2021","text":"<ul> <li>Fixed #2638: Warnings shown when using <code>tags</code> plugin without directory URLs</li> </ul>"},{"location":"insiders/changelog/#2.7.1","title":"2.7.1 May 3, 2021","text":"<ul> <li>Fixed <code>git-revision-date-localized</code> plugin integration (2.7.0 regression)</li> </ul>"},{"location":"insiders/changelog/#2.7.0","title":"2.7.0 May 1, 2021","text":"<ul> <li>Added support for tags (with search integration)</li> </ul>"},{"location":"insiders/changelog/#2.6.0","title":"2.6.0 April 11, 2021","text":"<ul> <li>Stay on page when switching versions</li> </ul>"},{"location":"insiders/changelog/#2.5.0","title":"2.5.0 March 28, 2021","text":"<ul> <li>Added support for version warning</li> </ul>"},{"location":"insiders/changelog/#2.4.0","title":"2.4.0 March 20, 2021","text":"<ul> <li>Added support for custom admonition icons</li> <li>Fixed #2444: Code block annotations with extra comments have wrong index</li> </ul>"},{"location":"insiders/changelog/#2.3.1","title":"2.3.1 March 14, 2021","text":"<ul> <li>Fixed anchor offset for permalinks when using sticky navigation tabs</li> </ul>"},{"location":"insiders/changelog/#2.3.0","title":"2.3.0 March 13, 2021","text":"<ul> <li>Added support for back-to-top button</li> </ul>"},{"location":"insiders/changelog/#2.2.1","title":"2.2.1 March 4, 2021","text":"<ul> <li>Fixed #2382: Repository stats failing when no release tag is present</li> </ul>"},{"location":"insiders/changelog/#2.2.0","title":"2.2.0 February 28, 2021","text":"<ul> <li>Added support for code block annotations</li> </ul>"},{"location":"insiders/changelog/#2.1.0","title":"2.1.0 February 26, 2021","text":"<ul> <li>Added support for anchor tracking</li> </ul>"},{"location":"insiders/changelog/#2.0.0","title":"2.0.0 February 24, 2021","text":"<ul> <li>Migrated Insiders to the new architecture</li> <li>Swapped color palette toggle configuration</li> </ul>"},{"location":"insiders/changelog/#1.17.0","title":"1.17.0 January 31, 2021","text":"<ul> <li>Added support for section index pages</li> </ul>"},{"location":"insiders/changelog/#1.16.1","title":"1.16.1 January 26, 2021","text":"<ul> <li>Fixed #2249: Instant loading + sticky tabs result in invalid links</li> <li>Fixed #2248: Search highlighting URL parameter always added</li> <li>Fixed #2235: Version selector doesn't select current version for aliases</li> </ul>"},{"location":"insiders/changelog/#1.16.0","title":"1.16.0 January 7, 2021","text":"<ul> <li>Added latest release to repository info (GitHub)</li> <li>Slight facelift of repository info (lighter fonts, spacing and icons)</li> </ul>"},{"location":"insiders/changelog/#1.15.0","title":"1.15.0 January 2, 2021","text":"<ul> <li>Added support for native Mermaid.js integration</li> </ul>"},{"location":"insiders/changelog/#1.14.0","title":"1.14.0 December 30, 2020","text":"<ul> <li>Added support for sharing searches</li> </ul>"},{"location":"insiders/changelog/#1.13.2","title":"1.13.2 December 22, 2020","text":"<ul> <li>Fixed version selector + sticky tabs navigation rendering issues</li> <li>Fixed version selector wrapping</li> </ul>"},{"location":"insiders/changelog/#1.13.1","title":"1.13.1 December 20, 2020","text":"<ul> <li>Removed horizontal scrollbars on language and version selector</li> <li>Fixed type conversion in JavaScript config</li> </ul>"},{"location":"insiders/changelog/#1.13.0","title":"1.13.0 December 13, 2020","text":"<ul> <li>Refactored navigation tabs to simplify grouping behavior</li> <li>Added support for sticky navigation tabs</li> <li>Added support for arbitrary links in navigation tabs</li> <li>Fixed #2098: Subsequent active subsection not highlighted correctly</li> </ul>"},{"location":"insiders/changelog/#1.12.1","title":"1.12.1 December 8, 2020","text":"<ul> <li>Fixed empty language selector being shown</li> </ul>"},{"location":"insiders/changelog/#1.12.0","title":"1.12.0 December 6, 2020","text":"<ul> <li>Added support for adding a language selector</li> </ul>"},{"location":"insiders/changelog/#1.11.2","title":"1.11.2 November 29, 2020","text":"<ul> <li>Fixed #2068: Search highlight interprets code blocks as JavaScript</li> </ul>"},{"location":"insiders/changelog/#1.11.1","title":"1.11.1 November 29, 2020","text":"<ul> <li>Refactored styling to be more stable and easier to adjust</li> <li>Fixed some styling regressions from latest features</li> </ul>"},{"location":"insiders/changelog/#1.11.0","title":"1.11.0 November 22, 2020","text":"<ul> <li>Added support for rendering admonitions as inline blocks</li> </ul>"},{"location":"insiders/changelog/#1.10.0","title":"1.10.0 November 15, 2020","text":"<ul> <li>Added support for integrating table of contents into navigation</li> </ul>"},{"location":"insiders/changelog/#1.9.0","title":"1.9.0 November 7, 2020","text":"<ul> <li>Added support for hiding navigation and table of contents on any page</li> <li>Removed autohiding table of contents when empty</li> </ul>"},{"location":"insiders/changelog/#1.8.0","title":"1.8.0 November 1, 2020","text":"<ul> <li>Added support for navigation sections</li> <li>Fixed appearance of inactive search suggestions</li> </ul>"},{"location":"insiders/changelog/#1.7.0","title":"1.7.0 October 25, 2020","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Fixed alignment of sidebar when content area is too small</li> </ul>"},{"location":"insiders/changelog/#1.6.0","title":"1.6.0 October 11, 2020","text":"<ul> <li>Added support for search suggestions to save keystrokes</li> <li>Added support for removing Made with Material for MkDocs from footer</li> <li>Fixed #1915: search should go to first result by pressing Enter</li> </ul>"},{"location":"insiders/changelog/#1.5.1","title":"1.5.1 September 21, 2020","text":"<ul> <li>Fixed content area stretching to whole width for long code blocks</li> </ul>"},{"location":"insiders/changelog/#1.5.0","title":"1.5.0 September 19, 2020","text":"<ul> <li>Added support for autohiding table of contents when empty</li> </ul>"},{"location":"insiders/changelog/#1.4.1","title":"1.4.1 September 6, 2020","text":"<ul> <li>Improved typeahead and search result relevance and scoring</li> </ul>"},{"location":"insiders/changelog/#1.4.0","title":"1.4.0 August 30, 2020","text":"<ul> <li>Added support for autohiding header on scroll</li> </ul>"},{"location":"insiders/changelog/#1.3.0","title":"1.3.0 August 26, 2020","text":"<ul> <li>Added support for user-selectable color palettes</li> </ul>"},{"location":"insiders/changelog/#1.2.0","title":"1.2.0 August 11, 2020","text":"<ul> <li>Added feature to expand navigation by default</li> </ul>"},{"location":"insiders/changelog/#1.1.0","title":"1.1.0 August 3, 2020","text":"<ul> <li>Added highlighting of search results</li> </ul>"},{"location":"insiders/changelog/#1.0.0","title":"1.0.0 July 14, 2020","text":"<ul> <li>Added grouping of search results</li> <li>Added missing query terms to search result</li> <li>Improved search result relevance and scoring</li> </ul>"},{"location":"insiders/getting-started/","title":"Getting started with Insiders","text":"<p>Material for MkDocs Insiders is a compatible drop-in replacement for Material for MkDocs, and can be installed similarly using <code>pip</code>, <code>docker</code> or <code>git</code>. Note that in order to access the Insiders  repository, you need to become an eligible sponsor of @squidfunk on GitHub.</p>"},{"location":"insiders/getting-started/#requirements","title":"Requirements","text":"<p>After you've been added to the list of collaborators and accepted the repository invitation, the next step is to create a personal access token for your GitHub account in order to access the Insiders repository programmatically  (from the command line or GitHub Actions workflows):</p> <ol> <li>Go to https://github.com/settings/tokens</li> <li>Click on Generate a new token</li> <li>Enter a name and select the <code>repo</code> scope</li> <li>Generate the token and store it in a safe place</li> </ol>"},{"location":"insiders/getting-started/#installation","title":"Installation","text":""},{"location":"insiders/getting-started/#with-pip","title":"with pip","text":"<p>Material for MkDocs Insiders can be installed with <code>pip</code>:</p> <pre><code>pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n</code></pre> <p>The <code>GH_TOKEN</code> environment variable must be set to the value of the personal access token you generated in the previous step. Note that the personal access token must be kept secret at all times, as it allows the owner to access your private repositories.</p>"},{"location":"insiders/getting-started/#with-docker","title":"with docker","text":"<p>In case you want to use Material for MkDocs Insiders from within Docker, some additional steps are necessary. While we cannot provide a hosted Docker image for Insiders1, GitHub Container Registry allows for simple and comfortable self-hosting:</p> <ol> <li>Fork the Insiders repository</li> <li>Enable GitHub Actions on your fork2</li> <li>Create a new personal access token3<ol> <li>Go to https://github.com/settings/tokens</li> <li>Click on Generate a new token</li> <li>Enter a name and select the <code>write:packages</code> scope</li> <li>Generate the token and store it in a safe place</li> </ol> </li> <li>Add a GitHub Actions secret on your fork<ol> <li>Set the name to <code>GHCR_TOKEN</code></li> <li>Set the value to the personal access token created in the previous step</li> </ol> </li> <li>Create a new release to build and publish the Docker image</li> <li>Install Pull App on your fork to stay in-sync with upstream</li> </ol> <p>The <code>publish</code> workflow4 is automatically run when a new tag (release) is created. When a new Insiders version is released on the upstream  repository, the Pull App will create a pull request with the changes and pull in the new tag, which is picked up by the <code>publish</code> workflow that builds and publishes the Docker image automatically to your private registry.</p> <p>Now, you should be able to pull the Docker image from your private registry:</p> <pre><code>docker login -u ${GH_USERNAME} -p ${GHCR_TOKEN} ghcr.io\ndocker pull ghcr.io/${GH_USERNAME}/mkdocs-material-insiders\n</code></pre> <p>Should you wish to add additional plugins to the insiders container image, follow the steps outlined in the Getting Started guide.</p>"},{"location":"insiders/getting-started/#with-git","title":"with git","text":"<p>Of course, you can use Material for MkDocs Insiders directly from <code>git</code>:</p> <pre><code>git clone git@github.com:squidfunk/mkdocs-material-insiders.git mkdocs-material\n</code></pre> <p>The theme will reside in the folder <code>mkdocs-material/material</code>. When cloning from <code>git</code>, the theme must be installed, so MkDocs can find the built-in plugins:</p> <pre><code>pip install -e mkdocs-material\n</code></pre>"},{"location":"insiders/getting-started/#upgrading","title":"Upgrading","text":"<p>When upgrading Insiders, you should always check the version of Material for MkDocs which makes up the first part of the version qualifier, e.g.Insiders <code>4.x.x</code> is currently based on <code>8.x.x</code>:</p> <pre><code>8.x.x-insiders-4.x.x\n</code></pre> <p>If the major version increased, it's a good idea to consult the upgrade guide and go through the steps to ensure your configuration is up to date and all necessary changes have been made. If you installed Insiders via <code>pip</code>, you can upgrade your installation with the following command:</p> <pre><code>pip install --upgrade git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n</code></pre>"},{"location":"insiders/getting-started/#caveats","title":"Caveats","text":"<p>This section describes some aspects to consider when using Insiders together with Material for MkDocs to ensure that users without access to Insiders can still build your documentation.</p>"},{"location":"insiders/getting-started/#built-in-plugins","title":"Built-in plugins","text":"<p>When using built-in plugins that are solely available via Insiders, it might be  necessary to split the <code>mkdocs.yml</code> configuration into a base configuration, and one with plugin overrides. Note that this is a limitation of MkDocs, which can be mitigated by using configuration inheritance:</p> <code>mkdocs.insiders.yml</code> <code>mkdocs.yml</code> <pre><code>INHERIT: mkdocs.yml\nplugins:\n- search\n- social\n- tags\n</code></pre> <pre><code># Configuration with everything except Insiders plugins\n</code></pre> <p>Now, when you're in an environment with access to Insiders (e.g. in your CI pipeline), you can build your documentation project with the following lines:</p> <pre><code>mkdocs build --config-file mkdocs.insiders.yml\n</code></pre> <p>Sharing plugin and extension configuration</p> <p>If you want to share <code>plugins</code> or <code>markdown_extensions</code> between both configuration files <code>mkdocs.insiders.yml</code> and <code>mkdocs.yml</code>, you can use the alternative key-value syntax in both files. The above example would then look like:</p> <code>mkdocs.insiders.yml</code> <code>mkdocs.yml</code> <pre><code>INHERIT: mkdocs.yml\nplugins:\nsocial: {}\n</code></pre> <pre><code># Additional configuration above\nplugins:\nsearch: {}\ntags: {}\n</code></pre> <ol> <li> <p>Earlier, Insiders provided a dedicated Docker image which was available to all sponsors. On March 21, 2021, the image was deprecated for the reasons outlined and discussed in #2442. It was removed on June 1, 2021.\u00a0\u21a9</p> </li> <li> <p>When forking a repository, GitHub will disables all workflows. While this is a reasonable default setting, you need to enable GitHub Actions to be able to automatically build and publish a Docker image on GitHub Container Registry.\u00a0\u21a9</p> </li> <li> <p>While you could just add the <code>write:packages</code> scope to the personal access token created to access the Insiders repository, it's safer to create a dedicated token which you'll only use for publishing the Docker image.\u00a0\u21a9</p> </li> <li> <p>The Insiders repository contains two GitHub Actions workflows:</p> <ul> <li><code>build.yml</code> \u2013 Build and lint the project (disabled on forks)</li> <li><code>publish.yml</code> \u2013 Build and publish the Docker image</li> </ul> <p>\u21a9</p> </li> </ol>"},{"location":"insiders/how-to/link-demos/","title":"Playing with links","text":"<p>how do different kind of links going to work?</p> <ol> <li>Open link from image  </li> <li>Open link through text </li> <li>Open link in new tab</li> <li></li> </ol> <p></p>"},{"location":"overview/introduction/","title":"Introduction","text":"<p>Workspace.ai is an end-to-end application that helps you to avoid switching between multiple tabs or applications and perform your tasks easily and effortlessly.</p> <p>It can fetch data from all your records and you can collaborate on the work objects by creating tasks, meetings, discussions, and documents. Using Workspace.ai, you can converse with your virtual assistant Kora to plan your day, manage tasks, and meetings, and lookup for anything you might need from the system.</p> <p>For example, using Workspace.ai, the sales team can connect to HubSpot and JIRA to fetch the required data and a product team can connect to JIRA and Spreadsheets to get the data required and access them all from the Workspace.ai application.</p>"},{"location":"overview/introduction/#core-capabilities-of-workspaceai","title":"Core capabilities of Workspace.ai","text":"<p>The Workspace.ai platform has the following capabilities:</p> <ul> <li>Create and manage workspaces</li> <li>Create and manage tables from scratch or using templates</li> <li>Create documents from scratch or using templates</li> <li>Embed a webpage</li> <li>Create and manage applications</li> <li>Automate tables</li> <li>Integrate with external applications and manage data from your application</li> <li>Manage meetings or events</li> <li>Create and manage your TO-DOs</li> <li>Manage messages through direct message option and at the board level</li> <li>Use Universal search feature</li> <li>Converse with your own virtual assistant- Kora Bot</li> <li>Create dashboards to view and analyze your data in the workspace</li> </ul>"},{"location":"overview/virtual-assistants-overview/","title":"Virtual Assistants Overview","text":""},{"location":"overview/virtual-assistants-overview/#introduction","title":"Introduction","text":"<p>Communication has been the essence of life from the beginning of time. Traditionally, conversations were restricted to verbal and textual interaction between humans. These interactions were usually guided by emotions, context, and awareness of previous conversations.</p> <p>With the advent of computers, interactions have expanded to include machines i.e. human-machine interactions. The transitions from a command-based interface to a Graphical User Interface (GUI) to a Conversational User Interface (CUI) became natural and need-based, making communication easier.</p> <p>Further enhancements facilitated the emergence of Artificial Intelligence (AI) that can process natural language (NLP). In turn, AI has contributed to Conversational Virtual Assistants that understand human communication, derive a task from this understanding and extract the information they require in order to execute this task.</p> <p>AI-driven, NLP-based chat, and voice Conversational Virtual Assistants are the latest in technology and a must for contemporary enterprises.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image1.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"overview/virtual-assistants-overview/#what-are-conversational-assistants","title":"What are Conversational Assistants?","text":"<p>A Conversational Virtual Assistant (VA) acts as an intelligent intermediary between people, digital systems, and internet-enabled things. It replaces the traditional Graphical User Interfaces (GUIs) of an application or website with a Conversational User Interface (CUI). It is a paradigm shift from the earlier communications achieved either by entering syntax-specific commands or clicking icons.</p> <p>These Virtual Assistants are designed to converse with users through a combination of natural language-based conversations. Responses can come in the form of text, links, buttons, calendars, or other widgets that accelerate the speed with which a user can respond.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image2.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>AI-powered messaging solutions or Conversational Virtual Assistants serve as the stepping stone to the future. They communicate with intelligent virtual agents, organization apps, websites, social media platforms, and messenger platforms. Users can interact with such assistants using voice or text to access information, complete tasks, and execute transactions.</p>"},{"location":"overview/virtual-assistants-overview/#why-add-a-conversational-virtual-assistant-to-your-business","title":"Why Add a Conversational Virtual Assistant to Your Business?","text":"<p>In a nutshell, such an assistant can significantly reduce the amount of time and labor required to maintain specific business processes. Here is what a Conversational VA can achieve:</p> <ul> <li>Talk to people, systems and internet-enabled things,</li> <li>Perform omnichannel communication through voice and text, using natural language,</li> <li>Understand natural language, including domain-specific,</li> <li>Learn from its interactions and apply this learning in future conversations,</li> <li>Handle multi-turn conversations,</li> <li>Apply context to improve communication,</li> <li>Handle task interruptions and accomplish what users want.</li> </ul> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image3.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"overview/virtual-assistants-overview/#how-do-conversational-virtual-assistants-work","title":"How Do Conversational Virtual Assistants Work?","text":"<p>A Conversational Virtual Assistant works by analyzing what users say, to detect their goals and extract the information required in order to achieve that goal.</p> <p>Let\u2019s take a look at the key components and the core process that enable a Virtual Assistant to fulfill its functions.</p>"},{"location":"overview/virtual-assistants-overview/#the-key-components","title":"The Key Components","text":"<p>Whatever the user says is considered an Utterance. The main task of the Conversational VA is to analyze the utterance and extract the intent, and entities essential to carry a conversation.</p> <p>An Intent is the user\u2019s intention and usually comes in the form of a verb or noun within the user utterance.</p> <p>Entities are a collection of data or information that the VA requires to complete the task which is identified in the user intent. They can be fields, data or words that the developer designates as necessary for the VA to complete a task. Entities can either be part of a user utterance, but the VA might also need to prompt the user to provide them. An Entity can be of any type; for instance: name, location, date, time, etc.</p> <p>For example, let us consider the following message that a user sends to the Virtual Assistant:</p> <p>I want to fly to London this weekend.</p> <ul> <li>The entire sentence represents the Utterance;</li> <li>\u201cI want to fly\u201d is the Intent;</li> <li>\u201cLondon\u201d and \u201cthis weekend\u201d form the values for the Entities representing \u201cDestination\u201d and \u201cTravel Date\u201d respectively. As you can notice, the \u201cSource\u201d entity value is missing and in such a case, the VA needs to ask the user where they want to fly from.</li> </ul>"},{"location":"overview/virtual-assistants-overview/#the-core-process","title":"The Core Process","text":"<p>In order for a Conversational Virtual Assistant to work as intended, it has to simultaneously perform the following three processes:</p> <ul> <li>Detect the user\u2019s Intent: Understand what the user wants</li> <li>Extract Entities: Obtain specific information from the user, in order to accomplish what the user wants;</li> <li>Execute the Dialog Task: Participate in the conversation process in order to accomplish what the user wants.</li> </ul>"},{"location":"overview/virtual-assistants-overview/#building-intelligent-conversational-virtual-assistants","title":"Building Intelligent Conversational Virtual Assistants","text":"<p>Virtual Assistants are not smart by default. They are designed to show some level of artificial intelligence by leveraging technologies such as machine learning, big data, natural language processing, etc. However, a Virtual Assistant is only intelligent when it can understand user needs, perspectives or context, and responds according to the user\u2019s mood or emotion. This is only achievable through training and interaction with users, over a period of time. Below are a few suggestions that may help you increase your VA\u2019s level of intelligence.</p>"},{"location":"overview/virtual-assistants-overview/#build-a-rich-collection-of-intents-and-entities","title":"Build a Rich Collection of Intents and Entities","text":"<p>The key for a Conversational Virtual Assistant to understand humans is its ability to identify human intentions (Intents), extract relevant information Entities) from utterances and map the relevant action/task against those utterances (Dialog Task execution). This is achievable using Natural Language Processing (NLP), which you can train according to your organization\u2019s needs.</p>"},{"location":"overview/virtual-assistants-overview/#develop-conversations","title":"Develop Conversations","text":"<p>Managing dialogs to keep track of multiple conversation threads, remember the context, and respond to the user tone or sentiment provides the much-needed humane touch to the conversation. At the same time, this serves the user with accurate and appropriate responses, ensuring a positive experience.</p>"},{"location":"overview/virtual-assistants-overview/#build-a-knowledge-graph","title":"Build a Knowledge Graph","text":"<p>In addition, having a Knowledge Graph gives the VA the ability to respond to frequently asked questions that return static responses. Building such knowledge collections is an attempt to represent entities, ideas, and events with all their interdependent properties and relations according to a system of categories. This structured categorization of data helps the VA to answer user queries effectively and with ease.</p>"},{"location":"reference/","title":"Reference","text":"<p>Material for MkDocs is packed with many great features that make technical writing a joyful activity. This section of the documentation explains how to set up a page, and showcases all available specimen that can be used directly from within Markdown files.</p>"},{"location":"reference/#configuration","title":"Configuration","text":""},{"location":"reference/#built-in-typeset-plugin","title":"Built-in typeset plugin","text":"<p> Sponsors only \u00b7  insiders-4.27.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in typeset plugin preserves HTML formatting in the navigation and table of contents. This means that now, code blocks, icons, emojis and other inline formatting will be preserved, which allows for a richer editing experience. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- typeset\n</code></pre> <p>For a demo, just take a look at the table of contents of this page  \u2013 code blocks and icons are preserved from the section headlines; even highlighting inline code blocks is supported </p>"},{"location":"reference/#built-in-meta-plugin","title":"Built-in meta plugin","text":"<p> Sponsors only \u00b7  insiders-4.21.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in meta plugin allows to set front matter per folder, which is especially handy to ensure that all pages in a folder use specific templates or  tags. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- meta\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>meta_file</code> <p> Default: <code>**/.meta.yml</code> \u2013 This option specifies the name of the meta files that the plugin should look for. The default setting assumes that meta files are called <code>.meta.yml</code>:</p> <pre><code>plugins:\n- meta:\nmeta_file: '**/.meta.yml' # (1)!\n</code></pre> <ol> <li>Note that it's strongly recommended to prefix meta files with a <code>.</code>,     since otherwise they would be included in the build output.</li> </ol>"},{"location":"reference/#usage","title":"Usage","text":""},{"location":"reference/#setting-the-page-title","title":"Setting the page <code>title</code>","text":"<p>Each page has a designated title, which is used in the navigation sidebar, for  social cards and in other places. While MkDocs attempts to automatically  determine the title of a page in a four step process, the title can also be  explicitly set with the front matter <code>title</code> property:</p> <pre><code>---\ntitle: Lorem ipsum dolor sit amet # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li>This line sets the <code>title</code> inside the HTML document's     <code>head</code> for the generated page to the given value. Note that the     site title, which is set via <code>site_name</code>, is appended with a     dash.</li> </ol>"},{"location":"reference/#setting-the-page-description","title":"Setting the page <code>description</code>","text":"<p>A Markdown file can include a description that is added to the <code>meta</code> tags of a page, and is also used for social cards. It's a good idea to set a  <code>site_description</code> in <code>mkdocs.yml</code> as a fallback value if the author does not explicitly define a description for a Markdown file:</p> <pre><code>---\ndescription: Nullam urna elit, malesuada eget finibus ut, ac tortor. # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li>This line sets the <code>meta</code> tag containing the description inside the     document <code>head</code> for the current page to the provided value.</li> </ol>"},{"location":"reference/#setting-the-page-icon","title":"Setting the page <code>icon</code>","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>An icon can be assigned to each page, which is then rendered as part of the navigation sidebar, as well as navigation tabs, if enabled. Use the front matter <code>icon</code> property to reference an icon, adding the following lines at the top of a Markdown file:</p> <pre><code>---\nicon: material/emoticon-happy # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol>"},{"location":"reference/#setting-the-page-status","title":"Setting the page <code>status</code>","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>A status can be assigned to each page, which is then displayed as part of the navigation sidebar. First, associate a status identifier with a description by  adding the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nstatus:\n&lt;identifier&gt;: &lt;description&gt; # (1)!\n</code></pre> <ol> <li> <p>The identifier can only include alphanumeric characters, as well as dashes     and underscores. For example, if you have a status <code>Recently added</code>, you can     set <code>new</code> as an identifier:</p> <pre><code>extra:\nstatus:\nnew: Recently added\n</code></pre> </li> </ol> <p>The page status can now be set with the front matter <code>status</code> property. For example, you can mark a page as <code>new</code> with the following lines at the top of a  Markdown file:</p> <pre><code>---\nstatus: new\n---\n# Document title\n...\n</code></pre> <p>The following status identifiers are currently supported:</p> <ul> <li> \u2013 <code>new</code></li> <li> \u2013 <code>deprecated</code></li> </ul>"},{"location":"reference/#setting-the-page-subtitle","title":"Setting the page <code>subtitle</code>","text":"<p> Sponsors only \u00b7  insiders-4.25.0 \u00b7  Experimental</p> <p>Each page can define a subtitle, which is then rendered below the title as part of the navigation sidebar by using the front matter <code>subtitle</code> property, and adding the following lines:</p> <pre><code>---\nsubtitle: Nullam urna elit, malesuada eget finibus ut, ac tortor\n---\n# Document title\n...\n</code></pre>"},{"location":"reference/#setting-the-page-template","title":"Setting the page <code>template</code>","text":"<p>If you're using theme extension and created a new page template in the <code>overrides</code> directory, you can enable it for a specific page. Add the following  lines at the top of a Markdown file:</p> <pre><code>---\ntemplate: custom.html\n---\n# Document title\n...\n</code></pre> How to set a page template for an entire folder? <p>With the help of the built-in meta plugin, you can set a custom template for an entire section and all nested pages, by creating a <code>.meta.yml</code> file in the corresponding folder with the following content:</p> <pre><code>template: custom.html\n</code></pre>"},{"location":"reference/#customization","title":"Customization","text":""},{"location":"reference/#using-metadata-in-templates","title":"Using metadata in templates","text":""},{"location":"reference/#on-all-pages","title":"on all pages","text":"<p>In order to add custom <code>meta</code> tags to your document, you can extend the theme  and override the <code>extrahead</code> block, e.g. to add indexing policies for search engines via the <code>robots</code> property:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block extrahead %}\n  &lt;meta name=\"robots\" content=\"noindex, nofollow\" /&gt;\n{% endblock %}\n</code></pre>"},{"location":"reference/#on-a-single-page","title":"on a single page","text":"<p>If you want to set a <code>meta</code> tag on a single page, or want to set different values for different pages, you can use the <code>page.meta</code> object inside your template override, e.g.:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block extrahead %}\n  {% if page and page.meta and page.meta.robots %}\n    &lt;meta name=\"robots\" content=\"{{ page.meta.robots }}\" /&gt;\n  {% else %}\n    &lt;meta name=\"robots\" content=\"index, follow\" /&gt;\n  {% endif %}\n{% endblock %}\n</code></pre> <p>You can now use <code>robots</code> exactly like <code>title</code> and <code>description</code> to set values. Note that in this case, the template defines an <code>else</code> branch, which would set a default if none was given.</p>"},{"location":"reference/admonitions/","title":"Admonitions","text":"<p>Admonitions, also known as call-outs, are an excellent choice for including side content without significantly interrupting the document flow. Material for MkDocs provides several different types of admonitions and allows for the inclusion and nesting of arbitrary content.</p>"},{"location":"reference/admonitions/#configuration","title":"Configuration","text":"<p>This configuration enables admonitions, allows to make them collapsible and to nest arbitrary content inside admonitions. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- admonition\n- pymdownx.details\n- pymdownx.superfences\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Admonition</li> <li>Details</li> <li>SuperFences</li> </ul>"},{"location":"reference/admonitions/#admonition-icons","title":"Admonition icons","text":"<p> 8.3.0</p> <p>Each of the supported admonition types has a distinct icon, which can be changed to any icon bundled with the theme, or even a custom icon. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nicon:\nadmonition:\n&lt;type&gt;: &lt;icon&gt; # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> Expand to show alternate icon sets  Octicons FontAwesome <pre><code>theme:\nicon:\nadmonition:\nnote: octicons/tag-16\nabstract: octicons/checklist-16\ninfo: octicons/info-16\ntip: octicons/squirrel-16\nsuccess: octicons/check-16\nquestion: octicons/question-16\nwarning: octicons/alert-16\nfailure: octicons/x-circle-16\ndanger: octicons/zap-16\nbug: octicons/bug-16\nexample: octicons/beaker-16\nquote: octicons/quote-16\n</code></pre> <pre><code>theme:\nicon:\nadmonition:\nnote: fontawesome/solid/note-sticky\nabstract: fontawesome/solid/book\ninfo: fontawesome/solid/circle-info\ntip: fontawesome/solid/bullhorn\nsuccess: fontawesome/solid/check\nquestion: fontawesome/solid/circle-question\nwarning: fontawesome/solid/triangle-exclamation\nfailure: fontawesome/solid/bomb\ndanger: fontawesome/solid/skull\nbug: fontawesome/solid/robot\nexample: fontawesome/solid/flask\nquote: fontawesome/solid/quote-left\n</code></pre>"},{"location":"reference/admonitions/#usage","title":"Usage","text":"<p>Admonitions follow a simple syntax: a block starts with <code>!!!</code>, followed by a single keyword used as a type qualifier. The content of the block follows on the next line, indented by four spaces:</p> Admonition<pre><code>!!! note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"reference/admonitions/#changing-the-title","title":"Changing the title","text":"<p>By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier:</p> Admonition with custom title<pre><code>!!! note \"Phasellus posuere in sem ut cursus\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"reference/admonitions/#removing-the-title","title":"Removing the title","text":"<p>Similar to changing the title, the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks:</p> Admonition without title<pre><code>!!! note \"\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"reference/admonitions/#collapsible-blocks","title":"Collapsible blocks","text":"<p>When Details is enabled and an admonition block is started with <code>???</code> instead of <code>!!!</code>, the admonition is rendered as a collapsible block with a small toggle on the right side:</p> Admonition, collapsible<pre><code>??? note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Adding a <code>+</code> after the <code>???</code> token renders the block expanded:</p> Admonition, collapsible and initially expanded<pre><code>???+ note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"reference/admonitions/#inline-blocks","title":"Inline blocks","text":"<p>Admonitions can also be rendered as inline blocks (e.g., for sidebars), placing them to the right using the <code>inline</code> + <code>end</code> modifiers, or to the left using only the <code>inline</code> modifier:</p>  inline end inline <p>Lorem ipsum</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>!!! info inline end \"Lorem ipsum\"\n\n    Lorem ipsum dolor sit amet, consectetur\n    adipiscing elit. Nulla et euismod nulla.\n    Curabitur feugiat, tortor non consequat\n    finibus, justo purus auctor massa, nec\n    semper lorem quam in massa.\n</code></pre> <p>Use <code>inline end</code> to align to the right (left for rtl languages).</p> <p>Lorem ipsum</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>!!! info inline \"Lorem ipsum\"\n\n    Lorem ipsum dolor sit amet, consectetur\n    adipiscing elit. Nulla et euismod nulla.\n    Curabitur feugiat, tortor non consequat\n    finibus, justo purus auctor massa, nec\n    semper lorem quam in massa.\n</code></pre> <p>Use <code>inline</code> to align to the left (right for rtl languages).</p> <p>Important: admonitions that use the <code>inline</code> modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the admonition next to the block, the admonition will stretch to the full width of the viewport, e.g., on mobile viewports.</p>"},{"location":"reference/admonitions/#supported-types","title":"Supported types","text":"<p>Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is <code>note</code>1:</p> <code>note</code> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>abstract</code> <p>Abstract</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>info</code> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>tip</code> <p>Tip</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>success</code> <p>Success</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>question</code> <p>Question</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>warning</code> <p>Warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>failure</code> <p>Failure</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>danger</code> <p>Danger</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>bug</code> <p>Bug</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>example</code> <p>Example</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>quote</code> <p>Quote</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"reference/admonitions/#customization","title":"Customization","text":""},{"location":"reference/admonitions/#classic-admonitions","title":"Classic admonitions","text":"<p>Prior to version  8.5.6, admonitions had a slightly different appearance:</p> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>If you want to restore this appearance, add the following CSS to an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-typeset .admonition,\n.md-typeset details {\nborder-width: 0;\nborder-left-width: 4px;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"reference/admonitions/#custom-admonitions","title":"Custom admonitions","text":"<p>If you want to add a custom admonition type, all you need is a color and an <code>*.svg</code> icon. Copy the icon's code from the <code>.icons</code> folder and add the following CSS to an additional style sheet:</p>    :root {     --md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"&gt;&lt;path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/&gt;&lt;/svg&gt;')   }   .md-typeset .admonition.pied-piper,   .md-typeset details.pied-piper {     border-color: rgb(43, 155, 70);   }   .md-typeset .pied-piper &gt; .admonition-title,   .md-typeset .pied-piper &gt; summary {     background-color: rgba(43, 155, 70, 0.1);   }   .md-typeset .pied-piper &gt; .admonition-title::before,   .md-typeset .pied-piper &gt; summary::before {     background-color: rgb(43, 155, 70);     -webkit-mask-image: var(--md-admonition-icon--pied-piper);             mask-image: var(--md-admonition-icon--pied-piper);   }  <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"&gt;&lt;path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/&gt;&lt;/svg&gt;')\n}\n.md-typeset .admonition.pied-piper,\n.md-typeset details.pied-piper {\nborder-color: rgb(43, 155, 70);\n}\n.md-typeset .pied-piper &gt; .admonition-title,\n.md-typeset .pied-piper &gt; summary {\nbackground-color: rgba(43, 155, 70, 0.1);\n}\n.md-typeset .pied-piper &gt; .admonition-title::before,\n.md-typeset .pied-piper &gt; summary::before {\nbackground-color: rgb(43, 155, 70);\n-webkit-mask-image: var(--md-admonition-icon--pied-piper);\nmask-image: var(--md-admonition-icon--pied-piper);\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, you can use the custom admonition type:</p> Admonition with custom type<pre><code>!!! pied-piper \"Pied Piper\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\n    euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\n    purus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p>Pied Piper</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> <p>Previously, some of the supported types defined more than one qualifier. For example, authors could use <code>summary</code> or <code>tldr</code> as alternative qualifiers to render an <code>abstract</code> admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/annotations/","title":"Annotations","text":"<p>One of the flagship features of Material for MkDocs is the ability to inject annotations \u2013 little markers that can be added almost anywhere in a document and expand a tooltip containing arbitrary Markdown on click or keyboard focus.</p>"},{"location":"reference/annotations/#configuration","title":"Configuration","text":"<p>This configuration allows to add annotations to all inline- and block-level elements, as well as code blocks, and nest annotations inside each other. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- md_in_html\n- pymdownx.superfences\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> <li>SuperFences</li> </ul>"},{"location":"reference/annotations/#usage","title":"Usage","text":""},{"location":"reference/annotations/#using-annotations","title":"Using annotations","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>Annotations consist of two parts: a marker, which can be placed anywhere in a block marked with the <code>annotate</code> class, and content located in a list below the block containing the marker:</p> Text with annotations<pre><code>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! I can contain `code`, __formatted\n    text__, images, ... basically anything that can be expressed in Markdown.\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol> <p>Note that the <code>annotate</code> class must only be added to the outermost block. All nested elements can use the same list to define annotations, except when annotations are nested themselves.</p>"},{"location":"reference/annotations/#in-annotations","title":"in annotations","text":"<p>When SuperFences is enabled, annotations can be nested inside annotations by adding the <code>annotate</code> class to the list item hosting the annotation content, repeating the process:</p> Text with nested annotations<pre><code>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! (1)\n    { .annotate }\n\n1.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> <p> I'm an annotation! (1)</p> <ol> <li> I'm an annotation as well!</li> </ol> </li> </ol>"},{"location":"reference/annotations/#in-admonitions","title":"in admonitions","text":"<p>The titles and bodies of admonitions can also host annotations by adding the <code>annotate</code> modifier after the type qualifier, which is similar to how inline blocks work:</p> Admonition with annotations<pre><code>!!! note annotate \"Phasellus posuere in sem ut cursus (1)\"\n\n    Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et\n    euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\n    purus auctor massa, nec semper lorem quam in massa.\n\n1.  :man_raising_hand: I'm an annotation!\n2.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> <p>Phasellus posuere in sem ut cursus (1)</p> <p>Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> I'm an annotation!</li> <li> I'm an annotation as well!</li> </ol>"},{"location":"reference/annotations/#in-content-tabs","title":"in content tabs","text":"<p>Content tabs can host annotations by adding the <code>annotate</code> class to the block of a dedicated content tab (and not to the container, which is not supported):</p> Content tabs with annotations<pre><code>=== \"Tab 1\"\n\n    Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n    { .annotate }\n\n1.  :man_raising_hand: I'm an annotation!\n\n=== \"Tab 2\"\n\n    Phasellus posuere in sem ut cursus (1)\n    { .annotate }\n\n1.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> Tab 1Tab 2 <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation!</li> </ol> <p>Phasellus posuere in sem ut cursus (1)</p> <ol> <li> I'm an annotation as well!</li> </ol>"},{"location":"reference/annotations/#in-everything-else","title":"in everything else","text":"<p>The Attribute Lists extension is the key ingredient for adding annotations to  most elements, but it has some limitations. However, it's always possible to leverage the Markdown in HTML extension to wrap arbitrary elements with a <code>div</code> with the <code>annotate</code> class:</p> HTML with annotations<pre><code>&lt;div class=\"annotate\" markdown&gt;\n&gt; Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n\n&lt;/div&gt;\n1.  :man_raising_hand: I'm an annotation!\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation!</li> </ol> <p>With this trick, annotations can also be added to blockquotes, lists, and many other elements that are not supported by the Attribute Lists extension. Furthermore, note that code blocks follow different semantics.</p> <p>Known limitations</p> <p>Please note that annotations currently don't work in data tables as reported in #3453, as data tables are scrollable elements and positioning is very tricky to get right. This might be fixed in the future.</p>"},{"location":"reference/buttons/","title":"Buttons","text":"<p>Material for MkDocs provides dedicated styles for primary and secondary buttons that can be added to any link, <code>label</code> or <code>button</code> element. This is especially useful for documents or landing pages with dedicated call-to-actions.</p>"},{"location":"reference/buttons/#configuration","title":"Configuration","text":"<p>This configuration allows to add attributes to all inline- and block-level elements with a simple syntax, turning any link into a button. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> </ul>"},{"location":"reference/buttons/#usage","title":"Usage","text":""},{"location":"reference/buttons/#adding-buttons","title":"Adding buttons","text":"<p>In order to render a link as a button, suffix it with curly braces and add the <code>.md-button</code> class selector to it. The button will receive the selected primary color and accent color if active.</p> Button<pre><code>[Subscribe to our newsletter](#){ .md-button }\n</code></pre> <p>Subscribe to our newsletter</p>"},{"location":"reference/buttons/#adding-primary-buttons","title":"Adding primary buttons","text":"<p>If you want to display a filled, primary button (like on the landing page of Material for MkDocs), add both, the <code>.md-button</code> and <code>.md-button--primary</code> CSS class selectors.</p> Button, primary<pre><code>[Subscribe to our newsletter](#){ .md-button .md-button--primary }\n</code></pre> <p>Subscribe to our newsletter</p>"},{"location":"reference/buttons/#adding-icon-buttons","title":"Adding icon buttons","text":"<p>Of course, icons can be added to all types of buttons by using the icon syntax together with any valid icon shortcode, which can be easily found with a few keystrokes through our icon search.</p> Button with icon<pre><code>[Send :fontawesome-solid-paper-plane:](#){ .md-button }\n</code></pre> <p>Send </p>"},{"location":"reference/code-blocks/","title":"Code blocks","text":"<p>Code blocks and examples are an essential part of technical project documentation. Material for MkDocs provides different ways to set up syntax highlighting for code blocks, either during build time using Pygments or during runtime using a JavaScript syntax highlighter.</p>"},{"location":"reference/code-blocks/#configuration","title":"Configuration","text":"<p>This configuration enables syntax highlighting on code blocks and inline code  blocks, and allows to include source code directly from other files. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\nline_spans: __span\npygments_lang_class: true\n- pymdownx.inlinehilite\n- pymdownx.snippets\n- pymdownx.superfences\n</code></pre> <p>The following sections discuss how to use different syntax highlighting features with Pygments, the recommended highlighter, so they don't apply when using a JavaScript syntax highlighter.</p> <p>See additional configuration options:</p> <ul> <li>Highlight</li> <li>InlineHilite</li> <li>SuperFences</li> <li>Snippets</li> </ul>"},{"location":"reference/code-blocks/#code-copy-button","title":"Code copy button","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>Code blocks can automatically render a button on the right side to allow the user to copy a code block's contents to the clipboard. Add the following to <code>mkdocs.yml</code> to enable them globally:</p> <pre><code>theme:\nfeatures:\n- content.code.copy\n</code></pre> Enabling or disabling code copy buttons for a specific code block <p>If you don't want to enable code copy buttons globally, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension:</p> <pre><code>``` { .yaml .copy }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>. Similarly, the copy button can also be disabled for a specific code block:</p> <pre><code>``` { .yaml .no-copy }\n# Code block content\n```\n</code></pre>"},{"location":"reference/code-blocks/#code-selection-button","title":"Code selection button","text":"<p> Sponsors only \u00b7  insiders-4.32.0 \u00b7  Experimental</p> <p>Code blocks can include a button to allow for the selection of line ranges by the user, which is perfect for linking to a specific subsection of a code block. This allows the user to apply line highlighting dynamically. Add the following to <code>mkdocs.yml</code> to enable it globally:</p> <pre><code>theme:\nfeatures:\n- content.code.select\n</code></pre> Enabling or disabling code selection buttons for a specific code block <p>If you don't want to enable code selection buttons globally, you can enable  them for a specific code block by using a slightly different syntax based on  the Attribute Lists extension:</p> <pre><code>``` { .yaml .select }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>. Similarly, the selection button can also be disabled for a specific code block:</p> <pre><code>``` { .yaml .no-select }\n# Code block content\n```\n</code></pre>"},{"location":"reference/code-blocks/#code-annotations","title":"Code annotations","text":"<p> 8.0.0 \u00b7  Feature flag</p> <p>Code annotations offer a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Add the following to <code>mkdocs.yml</code> to enable them globally:</p> <pre><code>theme:\nfeatures:\n- content.code.annotate # (1)!\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol> Enabling code annotations for a specific code block <p>If you don't want to enable code annotations globally, because you don't like the automatic inlining behavior, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension:</p> <pre><code>``` { .yaml .annotate }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>.</p>"},{"location":"reference/code-blocks/#custom-selectors","title":"Custom selectors","text":"<p> Sponsors only \u00b7  insiders-4.32.0 \u00b7  Experimental</p> <p>Normally, code annotations can only be placed in comments, as comments can be considered safe for placement. However, sometimes it might be necessary to place annotations in parts of the code block where comments are not allowed, e.g. in  strings.</p> <p>Additional selectors can be set per-language:</p> <pre><code>extra:\nannotate:\njson: [.s2] # (1)!\n</code></pre> <ol> <li> <p><code>.s2</code> is the name of the lexeme that Pygments generates for double-quoted     strings. If you want to use a code annotation in another lexeme than a     comment, inspect the code block and determine which lexeme needs to be added     to the list of additional selectors.</p> <p>Important: Code annotations cannot be split between lexemes.</p> </li> </ol> <p>Now, code annotations can be used from within strings in JSON:</p> <pre><code>{\n\"key\": \"value (1)\"\n}\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol>"},{"location":"reference/code-blocks/#usage","title":"Usage","text":"<p>Code blocks must be enclosed with two separate lines containing three backticks. To add syntax highlighting to those blocks, add the language shortcode directly after the opening block. See the list of available lexers to find the shortcode for a given language:</p> Code block<pre><code>``` py\nimport tensorflow as tf\n```\n</code></pre> <pre><code>import tensorflow as tf\n</code></pre>"},{"location":"reference/code-blocks/#adding-a-title","title":"Adding a title","text":"<p>In order to provide additional context, a custom title can be added to a code block by using the <code>title=\"&lt;custom title&gt;\"</code> option directly after the shortcode, e.g. to display the name of a file:</p> Code block with title<pre><code>``` py title=\"bubble_sort.py\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> bubble_sort.py<pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"reference/code-blocks/#adding-annotations","title":"Adding annotations","text":"<p>Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in <code>// ...</code> and <code>/* ... */</code>, for YAML in <code># ...</code>, etc.1:</p> Code block with annotation<pre><code>``` yaml\ntheme:\n  features:\n    - content.code.annotate # (1)\n```\n\n1.  :man_raising_hand: I'm a code annotation! I can contain `code`, __formatted\n    text__, images, ... basically anything that can be written in Markdown.\n</code></pre> <pre><code>theme:\nfeatures:\n- content.code.annotate # (1)\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol>"},{"location":"reference/code-blocks/#stripping-comments","title":"Stripping comments","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>If you wish to strip the comment characters surrounding a code annotation, simply add an <code>!</code> after the closing parenthesis of the code annotation:</p> Code block with annotation, stripped<pre><code>``` yaml\n# (1)!\n```\n\n1.  Look ma, less line noise!\n</code></pre> <pre><code># (1)!\n</code></pre> <ol> <li>Look ma, less line noise!</li> </ol> <p>Note that this only allows for a single code annotation to be rendered per comment. If you want to add multiple code annotations, comments cannot be stripped for technical reasons.</p>"},{"location":"reference/code-blocks/#adding-line-numbers","title":"Adding line numbers","text":"<p>Line numbers can be added to a code block by using the <code>linenums=\"&lt;start&gt;\"</code> option directly after the shortcode, whereas <code>&lt;start&gt;</code> represents the starting line number. A code block can start from a line number other than <code>1</code>, which allows to split large code blocks for readability:</p> Code block with line numbers<pre><code>``` py linenums=\"1\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"reference/code-blocks/#highlighting-specific-lines","title":"Highlighting specific lines","text":"<p>Specific lines can be highlighted by passing the line numbers to the <code>hl_lines</code> argument placed right after the language shortcode. Note that line counts start at <code>1</code>, regardless of the starting line number specified as part of <code>linenums</code>:</p> LinesLine ranges Code block with highlighted lines<pre><code>``` py hl_lines=\"2 3\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> Code block with highlighted line range<pre><code>``` py hl_lines=\"3-5\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"reference/code-blocks/#highlighting-inline-code-blocks","title":"Highlighting inline code blocks","text":"<p>When InlineHilite is enabled, syntax highlighting can be applied to inline code blocks by prefixing them with a shebang, i.e. <code>#!</code>, directly followed by the corresponding language shortcode.</p> Inline code block<pre><code>The `#!python range()` function is used to generate a sequence of numbers.\n</code></pre> <p>The <code>range()</code> function is used to generate a sequence of numbers.</p>"},{"location":"reference/code-blocks/#embedding-external-files","title":"Embedding external files","text":"<p>When Snippets is enabled, content from other files (including source files) can be embedded by using the <code>--8&lt;--</code> notation directly from within a code block:</p> Code block with external content<pre><code>``` title=\".browserslistrc\"\n--8&lt;-- \".browserslistrc\"\n```\n</code></pre> .browserslistrc<pre><code>last 4 years\n</code></pre>"},{"location":"reference/code-blocks/#customization","title":"Customization","text":""},{"location":"reference/code-blocks/#custom-syntax-theme","title":"Custom syntax theme","text":"<p>If Pygments is used, Material for MkDocs provides the styles for code blocks, which are built with a custom and well-balanced palette that works equally well for both color schemes:</p> <ul> <li> <code>--md-code-hl-number-color</code></li> <li> <code>--md-code-hl-special-color</code></li> <li> <code>--md-code-hl-function-color</code></li> <li> <code>--md-code-hl-constant-color</code></li> <li> <code>--md-code-hl-keyword-color</code></li> <li> <code>--md-code-hl-string-color</code></li> <li> <code>--md-code-hl-name-color</code></li> <li> <code>--md-code-hl-operator-color</code></li> <li> <code>--md-code-hl-punctuation-color</code></li> <li> <code>--md-code-hl-comment-color</code></li> <li> <code>--md-code-hl-generic-color</code></li> <li> <code>--md-code-hl-variable-color</code></li> </ul> <p>Code block foreground, background and line highlight colors are defined via:</p> <ul> <li> <code>--md-code-fg-color</code></li> <li> <code>--md-code-bg-color</code></li> <li> <code>--md-code-hl-color</code></li> </ul> <p>Let's say you want to change the color of <code>\"strings\"</code>. While there are several types of string tokens, they use the same color. You can assign a new color by using an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root &gt; * {\n--md-code-hl-string-color: #0FF1CE;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>If you want to tweak a specific type of string, e.g. <code>`backticks`</code>, you can lookup the specific CSS class name in the syntax theme definition, and override it as part of your additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.highlight .sb {\ncolor: #0FF1CE;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"reference/code-blocks/#annotation-tooltip-width","title":"Annotation tooltip width","text":"<p>If you have a lot of content hosted inside your code annotations, it can be a good idea to increase the width of the tooltip by adding the following as part of an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-tooltip-width: 600px;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>This will render annotations with a larger width:</p> <pre><code># (1)!\n</code></pre> <ol> <li>Muuuuuuuuuuuuuuuch more space for content</li> </ol>"},{"location":"reference/code-blocks/#annotations-with-numbers","title":"Annotations with numbers","text":"<p>Prior to  8.1.0, code annotations were rendered with markers showing the original number as used by the author. However, for technical reasons code annotation numbers restart each code block, which might lead to confusion. For this reason, code annotations now render as <code>+</code> signs which are rotated if they're open to denote that clicking them again will close them.</p> <p>If you wish to revert to the prior behavior and display code annotation numbers, you can add an additional style sheet and copy and paste the following CSS:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-typeset .md-annotation__index &gt; ::before {\ncontent: attr(data-md-annotation-id);\n}\n.md-typeset :focus-within &gt; .md-annotation__index &gt; ::before {\ntransform: none;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <ol> <li> <p>Code annotations require syntax highlighting with Pygments \u2013 they're currently not compatible with JavaScript syntax highlighters, or languages that do not have comments in their grammar. However, we're actively working on supporting alternate ways of defining code annotations, allowing to always place code annotations at the end of lines.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/content-tabs/","title":"Content tabs","text":"<p>Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Material for MkDocs allows for beautiful and functional tabs, grouping code blocks and other content.</p>"},{"location":"reference/content-tabs/#configuration","title":"Configuration","text":"<p>This configuration enables content tabs, and allows to nest arbitrary content inside content tabs, including code blocks and ... more content tabs! Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences\n- pymdownx.tabbed:\nalternate_style: true </code></pre> <p>See additional configuration options:</p> <ul> <li>SuperFences</li> <li>Tabbed</li> </ul>"},{"location":"reference/content-tabs/#anchor-links","title":"Anchor links","text":"<p> Sponsors only \u00b7  insiders-4.17.0 \u00b7  Experimental</p> <p>In order to link to content tabs and share them more easily, Insiders adds an anchor link to each content tab automatically, which you can copy via right click or open in a new tab:</p> Open me in a new tab ...... or me ...... or even me <p>You can copy the link of the tab and create a link on the same or any other page. For example, you can jump to the third tab above this paragraph or to the publishing guide for Insiders.</p> <p>Readable anchor links</p> <p>Python Markdown Extensions 9.6 adds support for slugification of content tabs, which produces nicer looking and more readable anchor links. Enable the slugify function with the following lines:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <p>Fore more information, please see the extension guide.</p>"},{"location":"reference/content-tabs/#linked-content-tabs","title":"Linked content tabs","text":"<p> 8.3.0 \u00b7  Feature flag</p> <p>When enabled, all content tabs across the whole documentation site will be linked and switch to the same label when the user clicks on a tab. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.tabs.link\n</code></pre> <p>Content tabs are linked based on their label, not offset. This means that all tabs with the same label will be activated when a user clicks a content tab regardless of order inside a container. Furthermore, this feature is fully integrated with instant loading and persisted across page loads.</p> Feature enabledFeature disabled <p></p> <p></p>"},{"location":"reference/content-tabs/#usage","title":"Usage","text":""},{"location":"reference/content-tabs/#grouping-code-blocks","title":"Grouping code blocks","text":"<p>Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing:</p> Content tabs with code blocks<pre><code>=== \"C\"\n\n    ``` c\n    #include &lt;stdio.h&gt;\n\n    int main(void) {\n      printf(\"Hello world!\\n\");\n      return 0;\n    }\n    ```\n\n=== \"C++\"\n\n    ``` c++\n    #include &lt;iostream&gt;\n\n    int main(void) {\n      std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n      return 0;\n    }\n    ```\n</code></pre> CC++ <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\nprintf(\"Hello world!\\n\");\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"reference/content-tabs/#grouping-other-content","title":"Grouping other content","text":"<p>When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks:</p> Content tabs<pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol>"},{"location":"reference/content-tabs/#embedded-content","title":"Embedded content","text":"<p>When SuperFences is enabled, content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like admonitions or blockquotes:</p> Content tabs in admonition<pre><code>!!! example\n\n    === \"Unordered List\"\n\n        ``` markdown\n        * Sed sagittis eleifend rutrum\n        * Donec vitae suscipit est\n        * Nulla tempor lobortis orci\n        ```\n\n    === \"Ordered List\"\n\n        ``` markdown\n        1. Sed sagittis eleifend rutrum\n        2. Donec vitae suscipit est\n        3. Nulla tempor lobortis orci\n        ```\n</code></pre> <p>Example</p> Unordered ListOrdered List <pre><code>* Sed sagittis eleifend rutrum\n* Donec vitae suscipit est\n* Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"reference/data-tables/","title":"Data tables","text":"<p>Material for MkDocs defines default styles for data tables \u2013 an excellent way of rendering tabular data in project documentation. Furthermore, customizations like sortable tables can be achieved with a third-party library and some additional JavaScript.</p>"},{"location":"reference/data-tables/#configuration","title":"Configuration","text":"<p>This configuration enables Markdown table support, which should normally be enabled by default, but to be sure, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- tables\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Tables</li> </ul>"},{"location":"reference/data-tables/#usage","title":"Usage","text":"<p>Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis:</p> Data table<pre><code>| Method      | Description                          |\n| ----------- | ------------------------------------ |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"reference/data-tables/#column-alignment","title":"Column alignment","text":"<p>If you want to align a specific column to the <code>left</code>, <code>center</code> or <code>right</code>, you can use the regular Markdown syntax placing <code>:</code> characters at the beginning and/or end of the divider.</p> LeftCenterRight Data table, columns aligned to left<pre><code>| Method      | Description                          |\n| :---------- | :----------------------------------- |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns centered<pre><code>| Method      | Description                          |\n| :---------: | :----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns aligned to right<pre><code>| Method      | Description                          |\n| ----------: | -----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"reference/data-tables/#customization","title":"Customization","text":""},{"location":"reference/data-tables/#sortable-tables","title":"Sortable tables","text":"<p>If you want to make data tables sortable, you can add tablesort, which is natively integrated with Material for MkDocs and will also work with instant loading via additional JavaScript:</p> <code>docs/javascripts/tablesort.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(function() {\nvar tables = document.querySelectorAll(\"article table:not([class])\")\ntables.forEach(function(table) {\nnew Tablesort(table)\n})\n})\n</code></pre> <pre><code>extra_javascript:\n- https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js\n- javascripts/tablesort.js\n</code></pre> <p>After applying the customization, data tables can be sorted by clicking on a column:</p> Data table, columns sortable<pre><code>| Method      | Description                          |\n| ----------- | ------------------------------------ |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource <p>Note that tablesort provides alternative comparison implementations like numbers, filesizes, dates and month names. See the tablesort documentation for more information.</p>    var tables = document.querySelectorAll(\"article table\")   new Tablesort(tables.item(tables.length - 1));"},{"location":"reference/data-tables/#import-table-from-file","title":"Import table from file","text":"<p> Plugin</p> <p>You can also import data from a CSV or Excel file using the plugin <code>mkdocs-table-reader-plugin</code>.</p> <p>First, you will need to install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-table-reader-plugin\n</code></pre> <p>Then extend the <code>mkdocs.yml</code> file like this:</p> <pre><code>plugins:\n- table-reader\n</code></pre> <p>Then, it is a simple process to import the data in to the Markdown files.</p> Import data from  CSV fileImport data from  Excel fileImport data from other file types <p>Let's use a  CSV in the local directory. The file may look like this:</p> ./data.csv<pre><code>col1,col2,col3\nr1c1,r1c2,r1c3\nr2c1,r2c2,r2c3\nr3c1,r3c2,r3c3\n</code></pre> <p>You can then add it to your  Markdown page like this:</p> ./markdown.md<pre><code>...\n\n{{ read_csv('./data.csv') }}\n\n...\n</code></pre> <p>...</p> col1 col2 col3 r1c1 r1c2 r1c3 r2c1 r2c2 r2c3 r3c1 r3c2 r3c3 <p>...</p> <p>Let's use an  Excel file in the local directory. The file may look like this:</p> <p></p> <p>And you can add it to your  Markdown page like this:</p> ./markdown.md<pre><code>...\n\n{{ read_excel('./Book1.xlsx', engine='openpyxl') }}\n\n...\n</code></pre> <p>It will then return a result like this:</p> col1 col2 col3 r1c1 r1c2 r1c3 r2c1 r2c2 r2c3 r3c1 r3c2 r3c3 <p>Warning</p> <p>You may receive an error if you use <code>engine='openpyxl'</code>.</p> <p>If this happens, you can resolve it by installing it using <code>pip</code>:</p> <pre><code>pip install openpyxl\n</code></pre> <p>Read more here: pandas.read_excel</p> <p>Pro Tip: Multiple Sheets</p> <p>If your Excel file contains multiple sheets, you may want to extend the function by adding the <code>sheet_name</code> parameter.</p> <p>It would look like this:</p> ./markdown.md<pre><code>...\n\n{{ read_excel('./Book1.xlsx', engine='openpyxl', sheet_name=\"Sheet1\") }}\n\n...\n</code></pre> <p>By default, Pandas will grab the first sheet in the workbook.</p> <p>Read more here: pandas.read_excel</p> <p>The plugin <code>mkdocs-table-reader-plugin</code> also provides readers for other formats:</p> <ul> <li><code>read_csv</code></li> <li><code>read_fwf</code></li> <li><code>read_yaml</code></li> <li><code>read_table</code></li> <li><code>read_json</code></li> <li><code>read_excel</code></li> <li><code>read_raw</code></li> </ul> <p>You can read more on their Docs website: mkdocs-table-reader-plugin</p>"},{"location":"reference/diagrams/","title":"Diagrams","text":"<p>Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js, a very popular and flexible solution for drawing diagrams.</p>"},{"location":"reference/diagrams/#configuration","title":"Configuration","text":"<p> 8.2.0</p> <p>This configuration enables native support for Mermaid.js diagrams. Material for MkDocs will automatically initialize the JavaScript runtime when a page  includes a <code>mermaid</code> code block:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <p>No further configuration is necessary. Advantages over a custom integration:</p> <ul> <li> Works with instant loading without any additional effort</li> <li> Diagrams automatically use fonts and colors defined in <code>mkdocs.yml</code>1</li> <li> Fonts and colors can be customized with additional style sheets</li> <li> Support for both, light and dark color schemes \u2013 try it on this page!</li> </ul>"},{"location":"reference/diagrams/#usage","title":"Usage","text":""},{"location":"reference/diagrams/#using-flowcharts","title":"Using flowcharts","text":"<p>Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps:</p> Flow chart<pre><code>``` mermaid\ngraph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];\n```\n</code></pre> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"reference/diagrams/#using-sequence-diagrams","title":"Using sequence diagrams","text":"<p>Sequence diagrams describe a specific scenario as sequential interactions  between multiple objects or actors, including the messages that are exchanged between those actors:</p> Sequence diagram<pre><code>``` mermaid\nsequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n```\n</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre>"},{"location":"reference/diagrams/#using-state-diagrams","title":"Using state diagrams","text":"<p>State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states:</p> State diagram<pre><code>``` mermaid\nstateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]\n```\n</code></pre> <pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre>"},{"location":"reference/diagrams/#using-class-diagrams","title":"Using class diagrams","text":"<p>Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them:</p> Class diagram<pre><code>``` mermaid\nclassDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n  }\n```\n</code></pre> <pre><code>classDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n  }</code></pre>"},{"location":"reference/diagrams/#using-entity-relationship-diagrams","title":"Using entity-relationship diagrams","text":"<p>An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge:</p> Entity-relationship diagram<pre><code>``` mermaid\nerDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    string name\n    int pricePerUnit\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n```\n</code></pre> <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    string name\n    int pricePerUnit\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>"},{"location":"reference/diagrams/#other-diagram-types","title":"Other diagram types","text":"<p>Besides the diagram types listed above, Mermaid.js provides support for pie charts, gantt charts, user journeys, git graphs and requirement diagrams, all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js, but we don't consider them a good choice, mostly as they don't work well on mobile.</p> <ol> <li> <p>While all Mermaid.js features should work out-of-the-box, Material for MkDocs will currently only adjust the fonts and colors for flowcharts, sequence diagrams, class diagrams, state diagrams and entity relationship  diagrams. See the section on other diagrams for more information why this is currently not implemented for all diagrams.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/footnotes/","title":"Footnotes","text":"<p>Footnotes are a great way to add supplemental or additional information to a specific word, phrase or sentence without interrupting the flow of a document. Material for MkDocs provides the ability to define, reference and render footnotes.</p>"},{"location":"reference/footnotes/#configuration","title":"Configuration","text":"<p>This configuration adds the ability to define inline footnotes, which are then rendered below all Markdown content of a document. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- footnotes\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Footnotes</li> </ul>"},{"location":"reference/footnotes/#usage","title":"Usage","text":""},{"location":"reference/footnotes/#adding-footnote-references","title":"Adding footnote references","text":"<p>A footnote reference must be enclosed in square brackets and must start with a caret <code>^</code>, directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax.</p> Text with footnote references<pre><code>Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2]\n</code></pre> <p>Lorem ipsum1 dolor sit amet, consectetur adipiscing elit.2</p>"},{"location":"reference/footnotes/#adding-footnote-content","title":"Adding footnote content","text":"<p>The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added.</p>"},{"location":"reference/footnotes/#on-a-single-line","title":"on a single line","text":"<p>Short footnotes can be written on the same line:</p> Footnote<pre><code>[^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n</code></pre> <p> Jump to footnote</p>"},{"location":"reference/footnotes/#on-multiple-lines","title":"on multiple lines","text":"<p>Paragraphs can be written on the next line and must be indented by four spaces:</p> Footnote<pre><code>[^2]:\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p> Jump to footnote</p> <ol> <li> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit.\u00a0\u21a9</p> </li> <li> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/formatting/","title":"Formatting","text":"<p>Material for MkDocs provides support for several HTML elements that can be used  to highlight sections of a document or apply specific formatting. Additionally,  Critic Markup is supported, adding the ability to display suggested changes for a document.</p>"},{"location":"reference/formatting/#configuration","title":"Configuration","text":"<p>This configuration enables support for keyboard keys, tracking changes in documents, defining sub- and superscript and highlighting text. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.critic\n- pymdownx.caret\n- pymdownx.keys\n- pymdownx.mark\n- pymdownx.tilde\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Critic</li> <li>Caret, Mark &amp; Tilde</li> <li>Keys</li> </ul>"},{"location":"reference/formatting/#usage","title":"Usage","text":""},{"location":"reference/formatting/#highlighting-changes","title":"Highlighting changes","text":"<p>When Critic is enabled, Critic Markup can be used, which adds the ability to  highlight suggested changes, as well as add inline comments to a document:</p> Text with suggested changes<pre><code>Text can be {--deleted--} and replacement text {++added++}. This can also be\ncombined into {~~one~&gt;a single~~} operation. {==Highlighting==} is also\npossible {&gt;&gt;and comments can be added inline&lt;&lt;}.\n\n{==\n\nFormatting can also be applied to blocks by putting the opening and closing\ntags on separate lines and adding new lines between the tags and the content.\n\n==}\n</code></pre> <p>Text can be deleted and replacement text added. This can also be combined into onea single operation. Highlighting is also possible and comments can be added inline.</p> <p>       Formatting can also be applied to blocks by putting the opening and       closing tags on separate lines and adding new lines between the tags and       the content.     </p>"},{"location":"reference/formatting/#highlighting-text","title":"Highlighting text","text":"<p>When Caret, Mark &amp; Tilde are enabled, text can be highlighted with a simple  syntax, which is more convenient that directly using the corresponding <code>mark</code>, <code>ins</code> and <code>del</code> HTML tags:</p> Text with highlighting<pre><code>- ==This was marked==\n- ^^This was inserted^^\n- ~~This was deleted~~\n</code></pre> <ul> <li>This was marked</li> <li>This was inserted</li> <li>This was deleted</li> </ul>"},{"location":"reference/formatting/#sub-and-superscripts","title":"Sub- and superscripts","text":"<p>When Caret &amp; Tilde are enabled, text can be sub- and  superscripted with a simple syntax, which is more convenient than directly using the corresponding <code>sub</code> and <code>sup</code> HTML tags:</p> Text with sub- and superscripts<pre><code>- H~2~O\n- A^T^A\n</code></pre> <ul> <li>H2O</li> <li>ATA</li> </ul>"},{"location":"reference/formatting/#adding-keyboard-keys","title":"Adding keyboard keys","text":"<p>When Keys is enabled, keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available shortcodes:</p> Keyboard keys<pre><code>++ctrl+alt+del++\n</code></pre> <p>Ctrl+Alt+Del</p>"},{"location":"reference/grids/","title":"Grids","text":"<p>Material for MkDocs makes it easy to arrange sections into grids, grouping blocks that convey similar meaning or are of equal importance. Grids are just perfect for building index pages that show a brief overview of a large section of your documentation.</p>"},{"location":"reference/grids/#configuration","title":"Configuration","text":"<p>This configuration enables the use of grids, allowing to bring blocks of identical or different types into a rectangular shape. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions: # (1)!\n- attr_list\n- md_in_html\n</code></pre> <ol> <li>Note that some of the examples listed below use icons and emojis, which     have to be configured separately.</li> </ol> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> </ul>"},{"location":"reference/grids/#usage","title":"Usage","text":"<p>Grids come in two flavors: card grids, which wrap each element in a card that levitates on hover, and generic grids, which allow to arrange arbitrary block elements in a rectangular shape.</p>"},{"location":"reference/grids/#using-card-grids","title":"Using card grids","text":"<p> Sponsors only \u00b7  insiders-4.12.0 \u00b7  Experimental</p> <p>Card grids wrap each grid item with a beautiful hover card that levitates on hover. They come in two slightly different syntaxes: list and block syntax, adding support for distinct use cases.</p>"},{"location":"reference/grids/#list-syntax","title":"List syntax","text":"<p>The list syntax is essentially a shortcut for card grids, and consists of an unordered (or ordered) list wrapped by a <code>div</code> with both, the <code>grid</code> and <code>cards</code> classes:</p> Card grid<pre><code>&lt;div class=\"grid cards\" markdown&gt;\n- :fontawesome-brands-html5: __HTML__ for content and structure\n- :fontawesome-brands-js: __JavaScript__ for interactivity\n- :fontawesome-brands-css3: __CSS__ for text running out of boxes\n- :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh?\n\n&lt;/div&gt;\n</code></pre> <ul> <li> HTML for content and structure</li> <li> JavaScript for interactivity</li> <li> CSS for text running out of boxes</li> <li> Internet Explorer ... huh?</li> </ul> <p>List elements can contain arbitrary Markdown, as long as the surrounding <code>div</code> defines the <code>markdown</code> attribute. Following is a more complex example, which includes icons and links:</p> Card grid, complex example<pre><code>&lt;div class=\"grid cards\" markdown&gt;\n-   :material-clock-fast:{ .lg .middle } __Set up in 5 minutes__\n\n    ---\n\n    Install [`mkdocs-material`](#) with [`pip`](#) and get up\n    and running in minutes\n\n    [:octicons-arrow-right-24: Getting started](#)\n\n-   :fontawesome-brands-markdown:{ .lg .middle } __It's just Markdown__\n\n    ---\n\n    Focus on your content and generate a responsive and searchable static site\n\n    [:octicons-arrow-right-24: Reference](#)\n\n-   :material-format-font:{ .lg .middle } __Made to measure__\n\n    ---\n\n    Change the colors, fonts, language, icons, logo and more with a few lines\n\n    [:octicons-arrow-right-24: Customization](#)\n\n-   :material-scale-balance:{ .lg .middle } __Open Source, MIT__\n\n    ---\n\n    Material for MkDocs is licensed under MIT and available on [GitHub]\n\n    [:octicons-arrow-right-24: License](#)\n\n&lt;/div&gt;\n</code></pre> <ul> <li> <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> </li> <li> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> </li> <li> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> </li> <li> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on GitHub</p> <p> License</p> </li> </ul> <p>If there's insufficient space to render grid items next to each other, the items will stretch to the full width of the viewport, e.g. on mobile viewports. If there's more space available, grids will render in items of 3 and more, e.g. when hiding both sidebars.</p>"},{"location":"reference/grids/#block-syntax","title":"Block syntax","text":"<p>The block syntax allows for arranging cards in grids together with other elements, as explained in the section on generic grids. Just add the <code>card</code> class to any block element inside a <code>grid</code>:</p> Card grid, blocks<pre><code>&lt;div class=\"grid\" markdown&gt;\n:fontawesome-brands-html5: __HTML__ for content and structure\n{ .card }\n\n:fontawesome-brands-js: __JavaScript__ for interactivity\n{ .card }\n\n:fontawesome-brands-css3: __CSS__ for text running out of boxes\n{ .card }\n\n&gt; :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh?\n\n&lt;/div&gt;\n</code></pre> <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer ... huh?</p> <p>While this syntax may seem unnecessarily verbose at first, the previous example shows how card grids can now be mixed with other elements that will also stretch to the grid.</p>"},{"location":"reference/grids/#using-generic-grids","title":"Using generic grids","text":"<p> Sponsors only \u00b7  insiders-4.12.0 \u00b7  Experimental</p> <p>Generic grids allow for arranging arbitrary block elements in a grid, including admonitions, code blocks, content tabs and more. Just wrap a set of blocks by using a <code>div</code> with the <code>grid</code> class:</p> Generic grid<pre><code>&lt;div class=\"grid\" markdown&gt;\n=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n\n``` title=\"Content tabs\"\n=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n```\n\n&lt;/div&gt;\n</code></pre> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol> Content tabs<pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"reference/icons-emojis/","title":"Icons, Emojis","text":"<p>One of the best features of Material for MkDocs is the possibility to use more than 10,000 icons and thousands of emojis in your project  documentation with practically zero additional effort. Moreover, custom icons  can be added and used in <code>mkdocs.yml</code>, documents and templates.</p>"},{"location":"reference/icons-emojis/#search","title":"Search","text":"<p> Tip: Enter some keywords to find icons and emojis and click on the   shortcode to copy it to your clipboard. </p>"},{"location":"reference/icons-emojis/#configuration","title":"Configuration","text":"<p>This configuration enables the use of icons and emojis by using simple shortcodes which can be discovered through the icon search. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <p>The following icon sets are bundled with Material for MkDocs:</p> <ul> <li> \u2013 Material Design</li> <li> \u2013 FontAwesome</li> <li> \u2013 Octicons</li> <li> \u2013 Simple Icons</li> </ul> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Emoji</li> <li>Emoji with custom icons</li> </ul>"},{"location":"reference/icons-emojis/#usage","title":"Usage","text":""},{"location":"reference/icons-emojis/#using-emojis","title":"Using emojis","text":"<p>Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. If you're using Twemoji (recommended), you can look up the shortcodes at Emojipedia:</p> Emoji<pre><code>:smile: \n</code></pre> <p></p>"},{"location":"reference/icons-emojis/#using-icons","title":"Using icons","text":"<p>When Emoji is enabled, icons can be used similar to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the <code>.icons</code> directory, and replacing <code>/</code> with <code>-</code>:</p> Icon<pre><code>:fontawesome-regular-face-laugh-wink:\n</code></pre> <p></p>"},{"location":"reference/icons-emojis/#with-colors","title":"with colors","text":"<p>When Attribute Lists is enabled, custom CSS classes can be added to icons by suffixing the icon with a special syntax. While HTML allows to use inline styles, it's always recommended to add an additional style sheet and move declarations into dedicated CSS classes:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.twitter {\ncolor: #1DA1F2;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, add the CSS class to the icon shortcode:</p> Icon with color<pre><code>:fontawesome-brands-twitter:{ .twitter }\n</code></pre> <p></p>"},{"location":"reference/icons-emojis/#with-animations","title":"with animations","text":"<p>Similar to adding colors, it's just as easy to add animations to icons by using an additional style sheet, defining a <code>@keyframes</code> rule and adding a dedicated CSS class to the icon:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>@keyframes heart {\n0%, 40%, 80%, 100% {\ntransform: scale(1);\n}\n20%, 60% {\ntransform: scale(1.15);\n}\n}\n.heart {\nanimation: heart 1000ms infinite;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, add the CSS class to the icon shortcode:</p> Icon with animation<pre><code>:octicons-heart-fill-24:{ .heart }\n</code></pre> <p></p>"},{"location":"reference/icons-emojis/#icons-emojis-in-sidebars","title":"Icons, emojis in sidebars","text":"<p>With the help of the built-in typeset plugin, you can use icons and emojis in headings, which will then be rendered in the sidebars. The plugin preserves Markdown and HTML formatting.</p>"},{"location":"reference/icons-emojis/#customization","title":"Customization","text":""},{"location":"reference/icons-emojis/#using-icons-in-templates","title":"Using icons in templates","text":"<p>When you're extending the theme with partials or blocks, you can simply reference any icon that's bundled with the theme with Jinja's <code>include</code> function and wrap it with the <code>.twemoji</code> CSS class:</p> <pre><code>&lt;span class=\"twemoji\"&gt;\n  {% include \".icons/fontawesome/brands/twitter.svg\" %} &lt;!-- (1)! --&gt;\n&lt;/span&gt;\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>This is exactly what Material for MkDocs does in its templates.</p>"},{"location":"reference/images/","title":"Images","text":"<p>While images are first-class citizens of Markdown and part of the core syntax,  it can be difficult to work with them. Material for MkDocs makes working with  images more comfortable, providing styles for image alignment and image captions.</p>"},{"location":"reference/images/#configuration","title":"Configuration","text":"<p>This configuration adds the ability to align images, add captions to images (rendering them as figures), and mark large images for lazy-loading. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- md_in_html\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> </ul>"},{"location":"reference/images/#lightbox","title":"Lightbox","text":"<p> 0.1.0 \u00b7  Plugin</p> <p>If you want to add image zoom functionality to your documentation, the  glightbox plugin is an excellent choice, as it integrates perfectly with Material for MkDocs. Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-glightbox\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- glightbox\n</code></pre> <p>We recommend checking out the available configuration options.</p>"},{"location":"reference/images/#usage","title":"Usage","text":""},{"location":"reference/images/#image-alignment","title":"Image alignment","text":"<p>When Attribute Lists is enabled, images can be aligned by adding the respective alignment directions via the <code>align</code> attribute, i.e. <code>align=left</code> or <code>align=right</code>:</p> LeftRight Image, aligned to left<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=left }\n</code></pre> <p></p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> Image, aligned to right<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=right }\n</code></pre> <p></p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports.</p> Why is there no centered alignment? <p>The <code>align</code> attribute doesn't allow for centered alignment, which is why this option is not supported by Material for MkDocs.1 Instead, the image captions syntax can be used, as captions are optional.</p>"},{"location":"reference/images/#image-captions","title":"Image captions","text":"<p>Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to use the Markdown in HTML extension with literal <code>figure</code> and <code>figcaption</code> tags:</p> Image with caption<pre><code>&lt;figure markdown&gt;\n  ![Image title](https://dummyimage.com/600x400/){ width=\"300\" }\n  &lt;figcaption&gt;Image caption&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre> Image caption"},{"location":"reference/images/#image-lazy-loading","title":"Image lazy-loading","text":"<p>Modern browsers provide native support for lazy-loading images through the <code>loading=lazy</code> directive, which degrades to eager-loading in browsers without support:</p> Image, lazy-loaded<pre><code>![Image title](https://dummyimage.com/600x400/){ loading=lazy }\n</code></pre> <p></p>"},{"location":"reference/images/#light-and-dark-mode","title":"Light and dark mode","text":"<p> 8.1.1</p> <p>If you added a color palette toggle and want to show different images for light and dark color schemes, you can append a <code>#only-light</code> or <code>#only-dark</code> hash fragment to the image URL:</p> Image, different for light and dark mode<pre><code>![Image title](https://dummyimage.com/600x400/f5f5f5/aaaaaa#only-light)\n![Image title](https://dummyimage.com/600x400/21222c/d5d7e2#only-dark)\n</code></pre> <p> </p> <p>Requirements when using custom color schemes</p> <p>The built-in color schemes define the aforementioned hash fragments, but if you're using custom color schemes, you'll also have to add the following selectors to your scheme, depending on whether it's a light or dark scheme:</p> Custom light schemeCustom dark scheme <pre><code>[data-md-color-scheme=\"custom-light\"] img[src$=\"#only-dark\"],\n[data-md-color-scheme=\"custom-light\"] img[src$=\"#gh-dark-mode-only\"] {\ndisplay: none; /* Hide dark images in light mode */\n}\n</code></pre> <pre><code>[data-md-color-scheme=\"custom-dark\"] img[src$=\"#only-light\"],\n[data-md-color-scheme=\"custom-dark\"] img[src$=\"#gh-light-mode-only\"] {\ndisplay: none; /* Hide light images in dark mode */\n}\n</code></pre> <p>Remember to change <code>\"custom-light\"</code> and <code>\"custom-dark\"</code> to the name of your scheme.</p> <ol> <li> <p>You might also realize that the <code>align</code> attribute has been deprecated as of HTML5, so why use it anyways? The main reason is portability \u2013 it's still supported by all browsers and clients, and is very unlikely to be completely removed, as many older websites still use it. This ensures a consistent appearance when a Markdown file with these attributes is viewed outside of a website generated by Material for MkDocs.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/lists/","title":"Lists","text":"<p>Material for MkDocs supports several flavors of lists that cater to different use cases, including unordered lists and ordered lists, which are supported through standard Markdown, as well as definition lists and task lists, which are supported through extensions.</p>"},{"location":"reference/lists/#configuration","title":"Configuration","text":"<p>This configuration enables the use of definition lists and tasks lists, which are both not part of the standard Markdown syntax. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- def_list\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Definition Lists</li> <li>Tasklist</li> </ul>"},{"location":"reference/lists/#usage","title":"Usage","text":""},{"location":"reference/lists/#using-unordered-lists","title":"Using unordered lists","text":"<p>Unordered lists can be written by prefixing a line with a <code>-</code>, <code>*</code> or <code>+</code> list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other:</p> List, unordered<pre><code>- Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur\n  accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh\n  lacinia sed. Aenean in finibus diam.\n\n* Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\n    * Nam vulputate tincidunt fringilla.\n    * Nullam dignissim ultrices urna non auctor.\n</code></pre> <ul> <li> <p>Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur   accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh   lacinia sed. Aenean in finibus diam.</p> <ul> <li>Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.</li> <li>Nam vulputate tincidunt fringilla.</li> <li>Nullam dignissim ultrices urna non auctor.</li> </ul> </li> </ul>"},{"location":"reference/lists/#using-ordered-lists","title":"Using ordered lists","text":"<p>Ordered lists must start with a number immediately followed by a dot. The  numbers do not need to be consecutive and can be all set to <code>1.</code>, as they will be re-numbered when rendered:</p> List, ordered<pre><code>1.  Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis\n    sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis\n    nulla. Vivamus a pharetra leo.\n\n1.  Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet\n        quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a\n        ultricies libero efficitur sed.\n\n2.  Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\n        rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a.\n\n1.  Mauris dictum mi lacus\n        2.  Ut sit amet placerat ante\n        3.  Suspendisse ac eros arcu\n</code></pre> <ol> <li> <p>Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis     sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis     nulla. Vivamus a pharetra leo.</p> <ol> <li> <p>Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet     quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a     ultricies libero efficitur sed.</p> </li> <li> <p>Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet     rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a.</p> <ol> <li>Mauris dictum mi lacus</li> <li>Ut sit amet placerat ante</li> <li>Suspendisse ac eros arcu</li> </ol> </li> </ol> </li> </ol>"},{"location":"reference/lists/#using-definition-lists","title":"Using definition lists","text":"<p>When Definition Lists is enabled, lists of arbitrary key-value pairs, e.g. the parameters of functions or modules, can be enumerated with a simple syntax:</p> Definition list<pre><code>`Lorem ipsum dolor sit amet`\n:   Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus\n    tellus non sem sollicitudin, quis rutrum leo facilisis.\n\n`Cras arcu libero`\n:   Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin\n    ut eros sed sapien ullamcorper consequat. Nunc ligula ante.\n\n    Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\n    Nam vulputate tincidunt fringilla.\n    Nullam dignissim ultrices urna non auctor.\n</code></pre> <code>Lorem ipsum dolor sit amet</code> <p>Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.</p> <code>Cras arcu libero</code> <p>Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante.</p> <p>Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.</p>"},{"location":"reference/lists/#using-task-lists","title":"Using task lists","text":"<p>When Tasklist is enabled, unordered list items can be prefixed with <code>[ ]</code> to render an unchecked checkbox or <code>[x]</code> to render a checked checkbox, allowing for the definition of task lists:</p> Task list<pre><code>- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n- [ ] Vestibulum convallis sit amet nisi a tincidunt\n    * [x] In hac habitasse platea dictumst\n    * [x] In scelerisque nibh non dolor mollis congue sed et metus\n    * [ ] Praesent sed risus massa\n- [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul>"},{"location":"reference/math/","title":"Math","text":"<p>MathJax and KaTeX are two popular libraries for displaying  mathematical content in browsers. Although both libraries offer similar  functionality, they use different syntaxes and have different configuration  options. This documentation site provides information on how to integrate them  with Material for MkDocs easily.</p>"},{"location":"reference/math/#configuration","title":"Configuration","text":"<p>The following configuration enables support for rendering block and  inline block equations using MathJax and KaTeX.</p>"},{"location":"reference/math/#mathjax","title":"MathJax","text":"<p>MathJax is a powerful and flexible library that supports multiple input formats,  such as LaTeX, MathML, AsciiMath, as well as various output formats like  HTML, SVG, MathML. To use MathJax within your project, add the following lines  to your <code>mkdocs.yml</code>.</p> <code>docs/javascripts/mathjax.js</code> <code>mkdocs.yml</code> <pre><code>window.MathJax = {\ntex: {\ninlineMath: [[\"\\\\(\", \"\\\\)\"]],\ndisplayMath: [[\"\\\\[\", \"\\\\]\"]],\nprocessEscapes: true,\nprocessEnvironments: true\n},\noptions: {\nignoreHtmlClass: \".*|\",\nprocessHtmlClass: \"arithmatex\"\n}\n};\ndocument$.subscribe(() =&gt; { // (1)!\nMathJax.typesetPromise()\n})\n</code></pre> <ol> <li>This integrates MathJax with instant loading.</li> </ol> <pre><code>markdown_extensions:\n- pymdownx.arithmatex:\ngeneric: true\nextra_javascript:\n- javascripts/mathjax.js\n- https://polyfill.io/v3/polyfill.min.js?features=es6\n- https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Arithmatex</li> </ul>"},{"location":"reference/math/#katex","title":"KaTeX","text":"<p>KaTeX is a lightweight library that focuses on speed and simplicity. It  supports a subset of LaTeX syntax and can render math to HTML and SVG. To use  KaTeX within your project, add the following lines to your <code>mkdocs.yml</code>.</p> <code>docs/javascripts/katex.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(({ body }) =&gt; { // (1)!\nrenderMathInElement(body, {\ndelimiters: [\n{ left: \"$$\",  right: \"$$\",  display: true },\n{ left: \"$\",   right: \"$\",   display: false },\n{ left: \"\\\\(\", right: \"\\\\)\", display: false },\n{ left: \"\\\\[\", right: \"\\\\]\", display: true }\n],\n})\n})\n</code></pre> <ol> <li>This integrates KaTeX with instant loading.</li> </ol> <pre><code>extra_javascript:\n- javascripts/katex.js - https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js  # (1)!\n- https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js\nextra_css:\n- https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css\n</code></pre> <ol> <li>Alternatively, you can add these JavaScript and CSS files via <code>script</code> tags by overriding HTML files.</li> </ol>    window.MathJax = {     tex: {       inlineMath: [[\"\\\\(\", \"\\\\)\"]],       displayMath: [[\"\\\\[\", \"\\\\]\"]],       processEscapes: true,       processEnvironments: true     },     options: {       ignoreHtmlClass: \".*|\",       processHtmlClass: \"arithmatex\"     }   };"},{"location":"reference/math/#usage","title":"Usage","text":""},{"location":"reference/math/#using-block-syntax","title":"Using block syntax","text":"<p>Blocks must be enclosed in <code>$$...$$</code> or <code>\\[...\\]</code> on separate lines:</p> block syntax<pre><code>$$\n\\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}}\n$$\n</code></pre> \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]"},{"location":"reference/math/#using-inline-block-syntax","title":"Using inline block syntax","text":"<p>Inline blocks must be enclosed in <code>$...$</code> or <code>\\(...\\)</code>:</p> inline syntax<pre><code>The homomorphism $f$ is injective if and only if its kernel is only the \nsingleton set $e_G$, because otherwise $\\exists a,b\\in G$ with $a\\neq b$ such \nthat $f(a)=f(b)$.\n</code></pre> <p>The homomorphism \\(f\\) is injective if and only if its kernel is only the  singleton set \\(e_G\\), because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such  that \\(f(a)=f(b)\\).</p>"},{"location":"reference/math/#comparing-mathjax-and-katex","title":"Comparing MathJax and KaTeX","text":"<p>When deciding between MathJax and KaTeX, there are several key factors to  consider:</p> <ul> <li> <p>Speed: KaTeX is generally faster than MathJax. If your site requires rendering large  quantities of complex equations quickly, KaTeX may be the better choice.</p> </li> <li> <p>Syntax Support: MathJax supports a wider array of LaTeX commands and can  process a variety of mathematical markup languages (like AsciiMath and MathML).  If you need advanced LaTeX features, MathJax may be more suitable.</p> </li> <li> <p>Output Format: Both libraries support HTML and SVG outputs. However,  MathJax also offers MathML output, which can be essential for accessibility, as  it is readable by screen readers.</p> </li> <li> <p>Configurability: MathJax provides a range of configuration options,  allowing for more precise control over its behavior. If you have specific  rendering requirements, MathJax might be a more flexible choice.</p> </li> <li> <p>Browser Support: While both libraries work well in modern browsers,  MathJax has broader compatibility with older browsers. If your audience uses a  variety of browsers, including older ones, MathJax might be a safer option.</p> </li> </ul> <p>In summary, KaTeX shines with its speed and simplicity, whereas MathJax offers  more features and better compatibility at the expense of speed. The choice  between the two will largely depend on your specific needs and constraints.</p>"},{"location":"reference/tooltips/","title":"Tooltips","text":"<p>Technical documentation often incurs the usage of many acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries.</p>"},{"location":"reference/tooltips/#configuration","title":"Configuration","text":"<p>This configuration enables abbreviations and allows to build a simple project-wide glossary, sourcing definitions from a central location. Add the following line to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- abbr\n- attr_list\n- pymdownx.snippets\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Abbreviations</li> <li>Attribute Lists</li> <li>Snippets</li> </ul>"},{"location":"reference/tooltips/#improved-tooltips","title":"Improved tooltips","text":"<p> Sponsors only \u00b7  insiders-4.15.0 \u00b7  Experimental</p> <p>When improved tooltips are enabled, Material for MkDocs replaces the browser's rendering logic for <code>title</code> attribute with beautiful little tooltips. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.tooltips\n</code></pre> <p>Now, tooltips will be rendered for the following elements:</p> <ul> <li>Content \u2013 elements with a <code>title</code>, permalinks and code copy button</li> <li>Header \u2013 home button, header title, color palette switch and repository link</li> <li>Navigation \u2013 links that are shortened with ellipsis, i.e. <code>...</code></li> </ul>"},{"location":"reference/tooltips/#usage","title":"Usage","text":""},{"location":"reference/tooltips/#adding-tooltips","title":"Adding tooltips","text":"<p>The Markdown syntax allows to specify a <code>title</code> for each link, which will render as a beautiful tooltip when improved tooltips are enabled. Add a  tooltip to a link with the following lines:</p> Link with tooltip, inline syntax<pre><code>[Hover me](https://example.com \"I'm a tooltip!\")\n</code></pre> <p>Hover me</p> <p>Tooltips can also be added to link references:</p> Link with tooltip, reference syntax<pre><code>[Hover me][example]\n\n  [example]: https://example.com \"I'm a tooltip!\"\n</code></pre> <p>Hover me</p> <p>For all other elements, a <code>title</code> can be added by using the Attribute Lists extension:</p> Icon with tooltip<pre><code>:material-information-outline:{ title=\"Important information\" }\n</code></pre> <p></p>"},{"location":"reference/tooltips/#adding-abbreviations","title":"Adding abbreviations","text":"<p>Abbreviations can be defined by using a special syntax similar to URLs and  footnotes, starting with a <code>*</code> and immediately followed by the term or acronym to be associated in square brackets:</p> Text with abbreviations<pre><code>The HTML specification is maintained by the W3C.\n\n*[HTML]: Hyper Text Markup Language\n*[W3C]: World Wide Web Consortium\n</code></pre> <p>The HTML specification is maintained by the W3C.</p>"},{"location":"reference/tooltips/#adding-a-glossary","title":"Adding a glossary","text":"<p>The Snippets extension can be used to implement a simple glossary by moving all abbreviations in a dedicated file1, and auto-append this file to all pages with the following configuration:</p> <code>includes/abbreviations.md</code> <code>mkdocs.yml</code> <pre><code>*[HTML]: Hyper Text Markup Language\n*[W3C]: World Wide Web Consortium\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.snippets:\nauto_append:\n- includes/abbreviations.md\n</code></pre> <ol> <li> <p>It's highly recommended to put the Markdown file containing the abbreviations outside of the <code>docs</code> folder (here, a folder with the name  <code>includes</code> is used), as MkDocs might otherwise complain about an unreferenced file.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/","title":"Setup","text":"<p>Material for MkDocs offers a wide range of options for customizing your documentation. In this section, we will explain how you can create a meaningful structure for your site, change the look and feel, add a blog and comment system, and build a highly optimized site.</p>"},{"location":"setup/#site-structure","title":"Site structure","text":"<p>Set up and customize the structure of your documentation by configuring the header and footer to your taste, choosing among many modes of navigation, setting up site search, and more.</p> <ul> <li> Language \u2013 Choose out of the 60+ supported languages or add a new one</li> <li> Navigation \u2013 Create a clear, concise, and comprehensive navigation structure</li> <li> Header \u2013 Customize the behavior of the header, add an announcement bar</li> <li> Footer \u2013 Add links to your social media profiles or websites in the footer </li> <li> Search \u2013 Set up and configure search, running entirely in the user's browser</li> <li> Tags \u2013 Categorize your pages with tags and group related pages</li> </ul>"},{"location":"setup/#appearance","title":"Appearance","text":"<p>Match your brand's colors, fonts, icons, logo, and more with a few lines of configuration \u2013 Material for MkDocs makes it easy to extend the basic configuration or alter the appearance.</p> <ul> <li> Colors Change colors with an existing color palette or customize with CSS</li> <li> Fonts \u2013 Choose among 1,000 Google Fonts or load self-hosted fonts</li> <li> Logo &amp; Icons \u2013 Change the logo, use any of the 8,000+ icons, or add new ones</li> <li> Social Cards \u2013 Automatically create social media previews when sharing links</li> </ul>"},{"location":"setup/#content","title":"Content","text":"<p>Create a blog, integrate a comment system, connect a git repository, and set up versioned documentation that matches your project's versioning methodology.</p> <ul> <li> Blog \u2013 Set up a standalone blog or host it alongside your documentation</li> <li> Comment System \u2013 Add a third-party comment system on any page or footer</li> <li> Versioning \u2013 Deploy multiple versions by integrating with external utilities</li> <li> Repository \u2013 Connect your documentation to your git repository</li> </ul>"},{"location":"setup/#optimization","title":"Optimization","text":"<p>Add site analytics and build an optimized site by adding automatic image compression, complying with GDPR data privacy regulations, and making it offline-capable.</p> <ul> <li> Site analytics \u2013 Learn how your users experience your documentation</li> <li> Optimized site \u2013 Create optimized sites that rank great on search engines</li> <li> Data Privacy \u2013 Ensure compliance with data privacy regulations</li> <li> Offline usage \u2013 Build an online and offline-capable documentation</li> </ul>"},{"location":"setup/adding-a-comment-system/","title":"Adding a comment system","text":"<p>Material for MkDocs allows to easily add the third-party comment system of your choice to the footer of any page by using theme extension. As an example, we'll be integrating Giscus, which is Open Source, free, and uses GitHub discussions as a backend.</p>"},{"location":"setup/adding-a-comment-system/#customization","title":"Customization","text":""},{"location":"setup/adding-a-comment-system/#giscus-integration","title":"Giscus integration","text":"<p>Before you can use Giscus, you need to complete the following steps:</p> <ol> <li>Install the Giscus GitHub App and grant access to the repository     that should host comments as GitHub discussions. Note that this can be a     repository different from your documentation.</li> <li> <p>Visit Giscus and generate the snippet through their configuration tool     to load the comment system. Copy the snippet for the next step. The     resulting snippet should look similar to this:</p> <pre><code>&lt;script\nsrc=\"https://giscus.app/client.js\"\ndata-repo=\"&lt;username&gt;/&lt;repository&gt;\"\ndata-repo-id=\"...\"\ndata-category=\"...\"\ndata-category-id=\"...\"\ndata-mapping=\"pathname\"\ndata-reactions-enabled=\"1\"\ndata-emit-metadata=\"1\"\ndata-theme=\"light\"\ndata-lang=\"en\"\ncrossorigin=\"anonymous\"\nasync\n&gt;\n&lt;/script&gt;\n</code></pre> </li> </ol> <p>The <code>comments.html</code> partial (empty by default) is the best place to add the snippet generated by Giscus. Follow the guide on theme extension and override the <code>comments.html</code> partial with:</p> <pre><code>{% if page.meta.comments %}\n  &lt;h2 id=\"__comments\"&gt;{{ lang.t(\"meta.comments\") }}&lt;/h2&gt;\n&lt;!-- Insert generated snippet here --&gt;\n&lt;!-- Synchronize Giscus theme with palette --&gt;\n&lt;script&gt;\nvar giscus = document.querySelector(\"script[src*=giscus]\")\n/* Set palette on initial load */\nvar palette = __md_get(\"__palette\")\nif (palette &amp;&amp; typeof palette.color === \"object\") {\nvar theme = palette.color.scheme === \"slate\" ? \"dark\" : \"light\"\ngiscus.setAttribute(\"data-theme\", theme) // (1)!\n}\n/* Register event handlers after documented loaded */\ndocument.addEventListener(\"DOMContentLoaded\", function() {\nvar ref = document.querySelector(\"[data-md-component=palette]\")\nref.addEventListener(\"change\", function() {\nvar palette = __md_get(\"__palette\")\nif (palette &amp;&amp; typeof palette.color === \"object\") {\nvar theme = palette.color.scheme === \"slate\" ? \"dark\" : \"light\"\n/* Instruct Giscus to change theme */\nvar frame = document.querySelector(\".giscus-frame\")\nframe.contentWindow.postMessage(\n{ giscus: { setConfig: { theme } } },\n\"https://giscus.app\"\n)\n}\n})\n})\n&lt;/script&gt;\n{% endif %}\n</code></pre> <ol> <li>This code block ensures that Giscus renders with a dark theme when the     palette is set to <code>slate</code>. Note that multiple dark themes are available,     so you can change it to your liking.</li> </ol> <p>Replace the highlighted line with the snippet you generated with the Giscus configuration tool in the previous step. If you copied the snippet from above, you can enable comments on a page by setting the <code>comments</code> front matter property to <code>true</code>:</p> <pre><code>---\ncomments: true\n---\n# Document title\n...\n</code></pre> <p>If you wish to enable comments for an entire folder, you can use the built-in meta plugin.</p>"},{"location":"setup/adding-a-git-repository/","title":"Adding a git repository","text":"<p>If your documentation is related to source code, Material for MkDocs provides the ability to display information to the project's repository as part of the static site, including stars and forks. Furthermore, the date of last update and creation, as well as contributors can be shown.</p>"},{"location":"setup/adding-a-git-repository/#configuration","title":"Configuration","text":""},{"location":"setup/adding-a-git-repository/#repository","title":"Repository","text":"<p> 0.1.0 \u00b7  Default: none</p> <p>In order to display a link to the repository of your project as part of your documentation, set <code>repo_url</code> in <code>mkdocs.yml</code> to the public URL of your repository, e.g.:</p> <pre><code>repo_url: https://github.com/squidfunk/mkdocs-material\n</code></pre> <p>The link to the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Additionally, for public repositories hosted on GitHub or GitLab, the number of stars and forks is automatically requested and rendered.</p> <p>GitHub repositories also include the tag of the latest release.1</p>"},{"location":"setup/adding-a-git-repository/#repository-name","title":"Repository name","text":"<p> 0.1.0 \u00b7  Default: automatically set to <code>GitHub</code>, <code>GitLab</code> or <code>Bitbucket</code></p> <p>MkDocs will infer the source provider by examining the URL and try to set the repository name automatically. If you wish to customize the name, set <code>repo_name</code> in <code>mkdocs.yml</code>:</p> <pre><code>repo_name: squidfunk/mkdocs-material\n</code></pre>"},{"location":"setup/adding-a-git-repository/#repository-icon","title":"Repository icon","text":"<p> 5.0.0 \u00b7  Default:  \u2013 <code>fontawesome/brands/git-alt</code></p> <p>While the default repository icon is a generic git icon, it can be set to any icon bundled with the theme by referencing a valid icon path in <code>mkdocs.yml</code>:</p> <pre><code>theme:\nicon:\nrepo: fontawesome/brands/git-alt # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>Some popular choices:</p> <ul> <li> \u2013 <code>fontawesome/brands/git</code></li> <li> \u2013 <code>fontawesome/brands/git-alt</code></li> <li> \u2013 <code>fontawesome/brands/github</code></li> <li> \u2013 <code>fontawesome/brands/github-alt</code></li> <li> \u2013 <code>fontawesome/brands/gitlab</code></li> <li> \u2013 <code>fontawesome/brands/gitkraken</code></li> <li> \u2013 <code>fontawesome/brands/bitbucket</code></li> <li> \u2013 <code>fontawesome/solid/trash</code></li> </ul>"},{"location":"setup/adding-a-git-repository/#code-actions","title":"Code actions","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>If the repository URL points to a valid GitHub, GitLab or Bitbucket repository, MkDocs provides a setting called <code>edit_uri</code>, which resolves to the subfolder where your documentation is hosted.</p> <p>If your default branch is called <code>main</code>, change the setting to:</p> <pre><code>edit_uri: edit/main/docs/\n</code></pre> <p>After making sure that <code>edit_uri</code> is correctly configured, buttons for code actions can be added. Two types of code actions are supported: <code>edit</code> and <code>view</code> (GitHub only):</p>  Edit this page View source of this page <pre><code>theme:\nfeatures:\n- content.action.edit\n</code></pre> <pre><code>theme:\nfeatures:\n- content.action.view\n</code></pre> <p>The icon of the edit and view buttons can be changed with the following lines:</p> <pre><code>theme:\nicon:\nedit: material/pencil # (1)!\nview: material/eye\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol>"},{"location":"setup/adding-a-git-repository/#revisioning","title":"Revisioning","text":"<p>The following plugins are fully integrated with Material for MkDocs, allowing for showing the date of last update and creation of a document, as well as links to all contributors or authors involved.</p>"},{"location":"setup/adding-a-git-repository/#document-dates","title":"Document dates","text":"<p> 4.6.0 \u00b7  Plugin</p> <p>The git-revision-date-localized plugin adds support for adding the date of last update and creation of a document at the bottom of each page. Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-revision-date-localized-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenable_creation_date: true\n</code></pre> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenabled: !ENV [CI, false]\n</code></pre> <code>type</code> <p> Default: <code>date</code> \u2013 The format of the date to be displayed. Valid values are <code>date</code>, <code>datetime</code>, <code>iso_date</code>, <code>iso_datetime</code> and <code>timeago</code>:</p> <pre><code>plugins:\n- git-revision-date-localized:\ntype: date\n</code></pre> <code>enable_creation_date</code> <p> Default: <code>false</code> \u2013 Enables the display of the creation date of the file associated with the page next to the last updated date at the bottom of the page:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenable_creation_date: true\n</code></pre> <code>fallback_to_build_date</code> <p> Default: <code>false</code> \u2013 Enables falling back to the time when <code>mkdocs build</code> was executed. Can be used as a fallback when the build is performed outside of a git repository:</p> <pre><code>plugins:\n- git-revision-date-localized:\nfallback_to_build_date: true\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"setup/adding-a-git-repository/#document-contributors","title":"Document contributors","text":"<p> Sponsors only \u00b7  insiders-4.19.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The git-committers2 plugin renders the GitHub avatars of all contributors, linking to their GitHub profiles at the bottom of each page. As always, it can be installed with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-committers-plugin-2\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-committers:\nrepository: squidfunk/mkdocs-material\nbranch: main\n</code></pre> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- git-committers:\nenabled: !ENV [CI, false]\n</code></pre> <code>repository</code> <p> Default: none \u00b7  Required \u2013 This property must be set to the slug of the repository that contains your documentation. The slug must follow the pattern <code>&lt;username&gt;/&lt;repository&gt;</code>:</p> <pre><code>plugins:\n- git-committers:\nrepository: squidfunk/mkdocs-material\n</code></pre> <code>branch</code> <p> Default: <code>master</code> \u2013 This property should be set to the branch of the repository from which to retrieve the contributors. To use the <code>main</code> branch:</p> <pre><code>plugins:\n- git-committers:\nbranch: main\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"setup/adding-a-git-repository/#document-authors","title":"Document authors","text":"<p> Sponsors only \u00b7  insiders-4.19.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The git-authors plugin is a lightweight alternative to the git-committers plugin and extracts the authors of a document from git to display them at the bottom of each page.</p> <p>Insiders offers deep integration for git-authors. This means the customized overrides are not necessary, and additional styling (such as nice icons) are added. Simply install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-authors-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-authors\n</code></pre> <ol> <li> <p>Unfortunately, GitHub only provides an API endpoint to obtain the latest release - not the latest tag. Thus, make sure to create a release (not  pre-release) for the latest tag you want to display next to the number of stars and forks.\u00a0\u21a9</p> </li> <li> <p>We currently recommend using a fork of the git-committers plugin, as it contains many improvements that have not yet been merged back into the original plugin. See byrnereese/mkdocs-git-committers-plugin#12 for more information.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/building-an-optimized-site/","title":"Building an optimized site","text":"<p>Material for MkDocs, by default, allows to build optimized sites that rank great on search engines, load fast (even on slow networks), and work perfectly without JavaScript. Additionally, the built-in optimize plugin adds support for further useful automatic optimization techniques.</p>"},{"location":"setup/building-an-optimized-site/#configuration","title":"Configuration","text":""},{"location":"setup/building-an-optimized-site/#built-in-projects-plugin","title":"Built-in projects plugin","text":"<p> Sponsors only \u00b7  insiders-4.38.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in projects plugin allows to split your documentation into multiple distinct MkDocs projects, build them concurrently and serve them together. Add the following to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- projects\n</code></pre> <p>Next, create a folder called <code>projects</code> in your root directory which will contain all projects. For example, if we want to build a project with two additional languages, we can use:</p> <pre><code>.\n\u251c\u2500 projects/\n\u2502  \u251c\u2500 de/\n\u2502  \u2502  \u251c\u2500 docs/\n\u2502  \u2502  \u2514\u2500 mkdocs.yml\n\u2502  \u2514\u2500 fr/\n\u2502     \u251c\u2500 docs/\n\u2502     \u2514\u2500 mkdocs.yml\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>If you now invoke <code>mkdocs serve</code> and change a file in one of the projects, the projects plugin makes sure that MkDocs will also reload those files. Note that the projects are currently entirely separate, which means they will have separate search indexes and sitemaps. We're happy to receive feedback on this plugin and learn about your requirements to make it better, as we plan to add support for merging and hoisting files. Create a discussion to share your thoughts!</p> Use cases for the projects plugin <p>Ideal use cases for the projects plugin are:</p> <ul> <li>Building a multi-language site</li> <li>Building a blog alongside your documentation</li> <li>Splitting large code bases for better performance</li> </ul> <p>Note that the plugin is currently experimental. We're releasing it early, so that we can improve it together with our users and make it even more powerful as we discover new use cases.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- projects:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when building projects. With more CPUs, the plugin can do more work in the same time, thus complete optimization faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- projects:\nconcurrency: 1\n</code></pre>"},{"location":"setup/building-an-optimized-site/#projects","title":"Projects","text":"<p>The following configuration options are available for projects:</p> <code>projects</code> <p> Default: <code>true</code> \u2013 This option specifies whether to build nested projects. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable:</p> <pre><code>plugins:\n- projects:\nprojects: !ENV [CI, false]\n</code></pre> <code>projects_dir</code> <p> Default: <code>projects</code> \u2013 This option specifies the name of the folder the plugin expects your projects to be stored. While it's usually not necessary to change this option, change it with:</p> <pre><code>plugins:\n- projects:\nprojects_dir: path/to/folder\n</code></pre>"},{"location":"setup/building-an-optimized-site/#built-in-optimize-plugin","title":"Built-in optimize plugin","text":"<p> Sponsors only \u00b7  insiders-4.29.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in optimize plugin automatically identifies and optimizes all media files as part of the build using compression and conversion techniques. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- optimize # (1)!\n</code></pre> <ol> <li>Please ensure that all dependencies for image processing are installed,     or the plugin will not work properly.</li> </ol> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- optimize:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when optimizing media files. With more CPUs, the plugin can do more work in the same time, thus complete optimization faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- optimize:\nconcurrency: 1\n</code></pre>"},{"location":"setup/building-an-optimized-site/#optimization","title":"Optimization","text":"<p>Technical documentation often includes screenshots or diagrams, both of which are prime candidates for compression. The built-in optimize plugin allows to automatically compress images using pngquant (for PNGs), and Pillow (for JPGs).</p> <p>The following configuration options are available for optimization:</p> <code>optimize_png</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should optimize PNG files using pngquant, which must be installed on the system. PNG optimization can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_png: false\n</code></pre> <code>optimize_png_speed</code> <p> Default: <code>4</code> of <code>[1,10]</code> \u2013 This option specifies the speed/quality tradeoff that pngquant applies when compressing. The lower the number, the more time will be spent optimizing:</p> Slower smallFaster rough <pre><code>plugins:\n- optimize:\noptimize_png_speed: 1\n</code></pre> <pre><code>plugins:\n- optimize:\noptimize_png_speed: 10\n</code></pre> <p>A factor of <code>10</code> has 5% lower quality, but is 8x faster than the default <code>4</code>.</p> <code>optimize_png_strip</code> <p> Default: <code>true</code> \u2013 This option specifies whether pngquant should remove all non-optional metadata that is not necessary for rendering images in a browser:</p> <pre><code>plugins:\n- optimize:\noptimize_png_strip: false\n</code></pre> <code>optimize_jpg</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should optimize JPG files using Pillow, a Python image processing library. JPG optimization can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg: false\n</code></pre> <code>optimize_jpg_quality</code> <p> Default: <code>60</code> of <code>[0,100]</code> \u2013 This option specifies the image quality that Pillow uses when compressing. If the images look blurry, it's a good idea to tune and change this setting:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg_quality: 75\n</code></pre> <code>optimize_jpg_progressive</code> <p> Default: <code>true</code> \u2013 This option specifies whether Pillow should use progressive encoding (faster rendering) when compressing JPGs. Progressive encoding can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg_progressive: false\n</code></pre>"},{"location":"setup/building-an-optimized-site/#caching","title":"Caching","text":"<p>The built-in optimize plugin implements an intelligent caching mechanism, ensuring that media files are only pushed through the optimization pipeline when their contents change. If you swap out or update an image, the plugin will detect it and update the optimized version.</p> <p>The following configuration options are available for caching:</p> <code>cache</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin queries its cache for an existing artifact before starting an optimization job. It's normally not necessary to change this setting, except for when debugging the plugin itself. Caching can be disabled with:</p> <pre><code>plugins:\n- optimize:\ncache: false\n</code></pre> <code>cache_dir</code> <p> Default: <code>.cache/plugins/optimize</code> \u2013 This option specifies the file system location of the plugin's cache. It's normally not necessary to change this setting, except for when debugging the plugin itself. The cache directory can be changed with:</p> <pre><code>plugins:\n- optimize:\ncache_dir: .cache/plugins/optimize\n</code></pre> <p>By default, all built-in plugins that implement caching will create a <code>.cache</code> directory in the same folder your <code>mkdocs.yml</code> resides, and create subfolders to not interfere with each other. If you use multiple instances of this plugin, it could be necessary to change this setting.</p>"},{"location":"setup/building-for-offline-usage/","title":"Building for offline usage","text":"<p>If you want to ship your documentation together with your product, MkDocs has you covered \u2013 with support from themes, MkDocs allows for building offline-capable documentation. Notably, Material for MkDocs offers offline support for many of its features.</p>"},{"location":"setup/building-for-offline-usage/#configuration","title":"Configuration","text":""},{"location":"setup/building-for-offline-usage/#built-in-offline-plugin","title":"Built-in offline plugin","text":"<p> 9.0.0 \u00b7  Plugin</p> <p>The built-in offline plugin makes sure that the site search works when you distribute the contents of your site directory as a download. Simply add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- offline\n</code></pre> <p>The plugin will automatically disable the <code>use_directory_urls</code> setting, ensuring that users can open your documentation directly from the local file system.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- offline:\nenabled: !ENV [OFFLINE, false]\n</code></pre> <p>Now, after invoking <code>mkdocs build</code>, you can open <code>site/index.html</code> directly in your browser and the site search will work as if the documentation was hosted on a regular server.</p> <p>Automatically bundle all external assets</p> <p>The built-in privacy plugin makes it easy to use external assets while building documentation for offline usage, as it will automatically download all external assets to distribute them with your documentation.</p>"},{"location":"setup/building-for-offline-usage/#limitations","title":"Limitations","text":"<p>Material for MkDocs offers many interactive features, some of which will not work from the file system due to the restrictions of modern browsers: all features that use the <code>fetch</code> API will error.</p> <p>Thus, when building for offline usage, make sure to disable the following configuration settings: instant loading, site analytics, git repository, versioning and comment systems.</p>"},{"location":"setup/changing-the-colors/","title":"Changing the colors","text":"<p>As any proper Material Design implementation, Material for MkDocs supports Google's original color palette, which can be easily configured through  <code>mkdocs.yml</code>. Furthermore, colors can be customized with a few lines of CSS to fit your brand's identity by using CSS variables.</p>"},{"location":"setup/changing-the-colors/#configuration","title":"Configuration","text":""},{"location":"setup/changing-the-colors/#color-palette","title":"Color palette","text":""},{"location":"setup/changing-the-colors/#color-scheme","title":"Color scheme","text":"<p> 5.2.0 \u00b7  Default: <code>default</code></p> <p>Material for MkDocs supports two color schemes: a light mode, which is just called <code>default</code>, and a dark mode, which is called <code>slate</code>. The color scheme can be set via <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\nscheme: default\n</code></pre> <p>Click on a tile to change the color scheme:</p> <code>default</code> <code>slate</code>"},{"location":"setup/changing-the-colors/#primary-color","title":"Primary color","text":"<p> 0.2.0 \u00b7  Default: <code>indigo</code></p> <p>The primary color is used for the header, the sidebar, text links and several other components. In order to change the primary color, set the following value in <code>mkdocs.yml</code> to a valid color name:</p> <pre><code>theme:\npalette:\nprimary: indigo\n</code></pre> <p>Click on a tile to change the primary color:</p> <code>red</code> <code>pink</code> <code>purple</code> <code>deep purple</code> <code>indigo</code> <code>blue</code> <code>light blue</code> <code>cyan</code> <code>teal</code> <code>green</code> <code>light green</code> <code>lime</code> <code>yellow</code> <code>amber</code> <code>orange</code> <code>deep orange</code> <code>brown</code> <code>grey</code> <code>blue grey</code> <code>black</code> <code>white</code>    var buttons = document.querySelectorAll(\"button[data-md-color-primary]\")   buttons.forEach(function(button) {     button.addEventListener(\"click\", function() {       var attr = this.getAttribute(\"data-md-color-primary\")       document.body.setAttribute(\"data-md-color-primary\", attr)       var name = document.querySelector(\"#__code_1 code span.l\")       name.textContent = attr.replace(\"-\", \" \")     })   })  <p>See our guide below to learn how to set custom colors.</p>"},{"location":"setup/changing-the-colors/#accent-color","title":"Accent color","text":"<p> 0.2.0 \u00b7  Default: <code>indigo</code></p> <p>The accent color is used to denote elements that can be interacted with, e.g. hovered links, buttons and scrollbars. It can be changed in <code>mkdocs.yml</code> by choosing a valid color name:</p> <pre><code>theme:\npalette:\naccent: indigo\n</code></pre> <p>Click on a tile to change the accent color:</p> <code>red</code> <code>pink</code> <code>purple</code> <code>deep purple</code> <code>indigo</code> <code>blue</code> <code>light blue</code> <code>cyan</code> <code>teal</code> <code>green</code> <code>light green</code> <code>lime</code> <code>yellow</code> <code>amber</code> <code>orange</code> <code>deep orange</code>    var buttons = document.querySelectorAll(\"button[data-md-color-accent]\")   buttons.forEach(function(button) {     button.addEventListener(\"click\", function() {       var attr = this.getAttribute(\"data-md-color-accent\")       document.body.setAttribute(\"data-md-color-accent\", attr)       var name = document.querySelector(\"#__code_2 code span.l\")       name.textContent = attr.replace(\"-\", \" \")     })   })  <p>See our guide below to learn how to set custom colors.</p>"},{"location":"setup/changing-the-colors/#color-palette-toggle","title":"Color palette toggle","text":"<p> 7.1.0 \u00b7  Default: none</p> <p>Offering a light and dark color palette makes your documentation pleasant to read at different times of the day, so the user can choose accordingly. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette: # (1)!\n# Palette toggle for light mode\n- scheme: default\ntoggle:\nicon: material/brightness-7 # (2)!\nname: Switch to dark mode\n# Palette toggle for dark mode\n- scheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to light mode\n</code></pre> <ol> <li> <p>Note that the <code>theme.palette</code> setting is now defined as a list.</p> </li> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>This configuration will render a color palette toggle next to the search bar. Note that you can also define separate settings for <code>primary</code> and <code>accent</code> per color palette.</p> <p>The following properties must be set for each toggle:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations:</p> <ul> <li> +  \u2013 <code>material/brightness-7</code> + <code>material/brightness-4</code></li> <li> +  \u2013 <code>material/toggle-switch</code> + <code>material/toggle-switch-off-outline</code></li> <li> +  \u2013 <code>material/weather-night</code> + <code>material/weather-sunny</code></li> <li> +  \u2013 <code>material/eye</code> + <code>material/eye-outline</code></li> <li> +  \u2013 <code>material/lightbulb</code> + <code>material/lightbulb-outline</code></li> </ul> <code>name</code> <p> Default: none \u00b7  Required \u2013 This property is used as the toggle's <code>title</code> attribute and should be set to a discernable name to improve accessibility. It's rendered as a tooltip.</p>"},{"location":"setup/changing-the-colors/#system-preference","title":"System preference","text":"<p> 7.1.0 \u00b7  Default: none</p> <p>Each color palette can be linked to the user's system preference for light and dark appearance by using a media query. Simply add a <code>media</code> property next to the <code>scheme</code> definition in <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\n# Palette toggle for light mode\n- media: \"(prefers-color-scheme: light)\"\nscheme: default\ntoggle:\nicon: material/brightness-7\nname: Switch to dark mode\n# Palette toggle for dark mode\n- media: \"(prefers-color-scheme: dark)\"\nscheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to light mode\n</code></pre> <p>When the user first visits your site, the media queries are evaluated in the order of their definition. The first media query that matches selects the default color palette.</p>"},{"location":"setup/changing-the-colors/#automatic-light-dark-mode","title":"Automatic light / dark mode","text":"<p> Sponsors only \u00b7  insiders-4.18.0 \u00b7  Experimental</p> <p>Newer operating system allow to automatically switch between light and dark appearance during day and night times. Insiders adds support for automatic light / dark mode, delegating color palette selection to the user's operating system. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\n# Palette toggle for automatic mode\n- media: \"(prefers-color-scheme)\"\ntoggle:\nicon: material/brightness-auto\nname: Switch to light mode\n# Palette toggle for light mode\n- media: \"(prefers-color-scheme: light)\"\nscheme: default # (1)!\ntoggle:\nicon: material/brightness-7\nname: Switch to dark mode\n# Palette toggle for dark mode\n- media: \"(prefers-color-scheme: dark)\"\nscheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to system preference\n</code></pre> <ol> <li>You can also define separate settings for <code>primary</code> and     <code>accent</code> per color palette, i.e. different colors for     light and dark mode.</li> </ol> <p>Material for MkDocs will now change the color palette each time the operating system switches between light and dark appearance, even when the user doesn't reload the site.</p>"},{"location":"setup/changing-the-colors/#customization","title":"Customization","text":""},{"location":"setup/changing-the-colors/#custom-colors","title":"Custom colors","text":"<p>Material for MkDocs implements colors using CSS variables (custom properties). If you want to customize the colors beyond the palette (e.g. to use your brand-specific colors), you can add an additional style sheet and tweak the values of the CSS variables.</p> <p>First, set the <code>primary</code> or <code>accent</code> values in <code>mkdocs.yml</code> to <code>custom</code>, to signal to the theme that you want to define custom colors, e.g., when you want to override the <code>primary</code> color:</p> <pre><code>theme:\npalette:\nprimary: custom\n</code></pre> <p>Let's say you're  YouTube, and want to set the primary color to your brand's palette. Just add:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-primary-fg-color:        #EE0F0F;\n--md-primary-fg-color--light: #ECB7B7;\n--md-primary-fg-color--dark:  #90030C;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>See the file containing the color definitions for a list of all CSS variables.</p>"},{"location":"setup/changing-the-colors/#custom-color-schemes","title":"Custom color schemes","text":"<p>Besides overriding specific colors, you can create your own, named color scheme by wrapping the definitions in a <code>[data-md-color-scheme=\"...\"]</code> attribute selector, which you can then set via <code>mkdocs.yml</code> as described in the color schemes section:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>[data-md-color-scheme=\"youtube\"] {\n--md-primary-fg-color:        #EE0F0F;\n--md-primary-fg-color--light: #ECB7B7;\n--md-primary-fg-color--dark:  #90030C;\n}\n</code></pre> <pre><code>theme:\npalette:\nscheme: youtube\nextra_css:\n- stylesheets/extra.css\n</code></pre> <p>Additionally, the <code>slate</code> color scheme defines all of it's colors via <code>hsla</code> color functions and deduces its colors from the <code>--md-hue</code> CSS variable. You can tune the <code>slate</code> theme with:</p> <pre><code>[data-md-color-scheme=\"slate\"] {\n--md-hue: 210; /* (1)! */\n}\n</code></pre> <ol> <li>The <code>hue</code> value must be in the range of <code>[0, 360]</code></li> </ol>"},{"location":"setup/changing-the-fonts/","title":"Changing the fonts","text":"<p>Material for MkDocs makes it easy to change the typeface of your project documentation, as it directly integrates with Google Fonts. Alternatively, fonts can be custom-loaded if self-hosting is preferred for data privacy reasons or another destination should be used.</p>"},{"location":"setup/changing-the-fonts/#configuration","title":"Configuration","text":""},{"location":"setup/changing-the-fonts/#regular-font","title":"Regular font","text":"<p> 0.1.2 \u00b7  Default: <code>Roboto</code></p> <p>The regular font is used for all body copy, headlines, and essentially everything that does not need to be monospaced. It can be set to any valid Google Font via <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont:\ntext: Roboto\n</code></pre> <p>The typeface will be loaded in 300, 400, 400i and 700.</p>"},{"location":"setup/changing-the-fonts/#monospaced-font","title":"Monospaced font","text":"<p> 0.1.2 \u00b7  Default: <code>Roboto Mono</code></p> <p>The monospaced font is used for code blocks and can be configured separately. Just like the regular font, it can be set to any valid Google Font via <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont:\ncode: Roboto Mono\n</code></pre> <p>The typeface will be loaded in 400.</p>"},{"location":"setup/changing-the-fonts/#autoloading","title":"Autoloading","text":"<p> 1.0.0 \u00b7  Default: none</p> <p>If you want to prevent typefaces from being loaded from Google Fonts, e.g. to adhere to data privacy regulations, and fall back to system fonts, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont: false\n</code></pre> <p>Automatically bundle Google Fonts</p> <p>The built-in privacy plugin makes it easy to use Google Fonts while complying with the General Data Protection Regulation (GDPR), by automatically downloading and self-hosting the web font files.</p>"},{"location":"setup/changing-the-fonts/#customization","title":"Customization","text":""},{"location":"setup/changing-the-fonts/#additional-fonts","title":"Additional fonts","text":"<p>If you want to load an (additional) font from another destination or override the system font, you can use an additional style sheet to add the corresponding <code>@font-face</code> definition:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>@font-face {\nfont-family: \"&lt;font&gt;\";\nsrc: \"...\";\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>The font can then be applied to specific elements, e.g. only headlines, or  globally to be used as the site-wide regular or monospaced font:</p> Regular fontMonospaced font <pre><code>:root {\n--md-text-font: \"&lt;font&gt;\"; /* (1)! */\n}\n</code></pre> <ol> <li>Always define fonts through CSS variables and not <code>font-family</code>, as     this would disable the system font fallback.</li> </ol> <pre><code>:root {\n--md-code-font: \"&lt;font&gt;\";\n}\n</code></pre>"},{"location":"setup/changing-the-language/","title":"Changing the language","text":"<p>Material for MkDocs supports internationalization (i18n) and provides translations for template variables and labels in 60+ languages. Additionally, the site search can be configured to use a language-specific stemmer, if available.</p>"},{"location":"setup/changing-the-language/#configuration","title":"Configuration","text":""},{"location":"setup/changing-the-language/#site-language","title":"Site language","text":"<p> 1.12.0 \u00b7  Default: <code>en</code></p> <p>You can set the site language in <code>mkdocs.yml</code> with:</p> <pre><code>theme:\nlanguage: en # (1)!\n</code></pre> <ol> <li> <p>HTML5 only allows to set a single language per document, which is why     Material for MkDocs only supports setting a canonical language for the     entire project, i.e. one per <code>mkdocs.yml</code>.</p> <p>The easiest way to build a multi-language documentation is to create one project in a subfolder per language, and then use the language selector to interlink those projects.</p> </li> </ol> <p>The following languages are supported:</p> <p>Note that some languages will produce unreadable anchor links due to the way the default slug function works. Consider using a Unicode-aware slug function.</p> <p>Translations missing? Help us out, it takes only 5 minutes</p> <p>Material for MkDocs relies on outside contributions for adding and updating translations for the almost 60 languages it supports. If your language shows that some translations are missing, click on the link to add them. If your language is not in the list, click here to add a new language.</p>"},{"location":"setup/changing-the-language/#site-language-selector","title":"Site language selector","text":"<p> 7.0.0 \u00b7  Default: none</p> <p>If your documentation is available in multiple languages, a language selector pointing to those languages can be added to the header. Alternate languages can be defined via <code>mkdocs.yml</code>.</p> <pre><code>extra:\nalternate:\n- name: English\nlink: /en/ # (1)!\nlang: en\n- name: Deutsch\nlink: /de/\nlang: de\n</code></pre> <ol> <li>Note that this must be an absolute link. If it includes a domain part, it's     used as defined. Otherwise the domain part of the <code>site_url</code> as     set in <code>mkdocs.yml</code> is prepended to the link.</li> </ol> <p>The following properties are available for each alternate language:</p> <code>name</code> <p> Default: none \u00b7  Required \u2013 This value of this property is used inside the language selector as the name of the language and must be set to a non-empty string.</p> <code>link</code> <p> Default: none \u00b7  Required \u2013 This property must be set to an absolute link, which might also point to another domain or subdomain not necessarily generated with MkDocs.</p> <code>lang</code> <p> Default: none \u00b7  Required \u2013 This property must contain an ISO 639-1 language code and is used for the <code>hreflang</code> attribute of the link, improving discoverability via search engines.</p> <p></p>"},{"location":"setup/changing-the-language/#directionality","title":"Directionality","text":"<p> 2.5.0 \u00b7  Default: automatically set</p> <p>While many languages are read <code>ltr</code> (left-to-right), Material for MkDocs also supports <code>rtl</code> (right-to-left) directionality which is deduced from the selected language, but can also be set with:</p> <pre><code>theme:\ndirection: ltr\n</code></pre> <p>Click on a tile to change the directionality:</p> <code>ltr</code> <code>rtl</code>"},{"location":"setup/changing-the-language/#customization","title":"Customization","text":""},{"location":"setup/changing-the-language/#custom-translations","title":"Custom translations","text":"<p>If you want to customize some of the translations for a language, just follow the guide on theme extension and create a new partial in the <code>overrides</code> folder. Then, import the translations of the language as a fallback and only adjust the ones you want to override:</p> <code>overrides/partials/languages/custom.html</code> <code>mkdocs.yml</code> <pre><code>&lt;!-- Import translations for language and fallback --&gt;\n{% import \"partials/languages/de.html\" as language %}\n{% import \"partials/languages/en.html\" as fallback %} &lt;!-- (1)! --&gt;\n&lt;!-- Define custom translations --&gt;\n{% macro override(key) %}{{ {\n  \"source.file.date.created\": \"Erstellt am\", &lt;!-- (2)! --&gt;\n  \"source.file.date.updated\": \"Aktualisiert am\"\n}[key] }}{% endmacro %}\n\n&lt;!-- Re-export translations --&gt;\n{% macro t(key) %}{{\n  override(key) or language.t(key) or fallback.t(key)\n}}{% endmacro %}\n</code></pre> <ol> <li> <p>Note that <code>en</code> must always be used as a fallback language, as it's the     default theme language.</p> </li> <li> <p>Check the list of available languages, pick the translation you want     to override for your language and add them here.</p> </li> </ol> <pre><code>theme:\nlanguage: custom\n</code></pre>"},{"location":"setup/changing-the-logo-and-icons/","title":"Changing the logo and icons","text":"<p>When installing Material for MkDocs, you immediately get access to over 8,000  icons ready to be used for customization of specific parts of the theme and/or  when writing your documentation in Markdown. Not enough? You can also add additional icons with minimal effort.</p>"},{"location":"setup/changing-the-logo-and-icons/#configuration","title":"Configuration","text":""},{"location":"setup/changing-the-logo-and-icons/#logo","title":"Logo","text":"<p> 0.1.0 \u00b7  Default:  \u2013 <code>material/library</code></p> <p>The logo can be changed to a user-provided image (any type, incl. <code>*.png</code> and <code>*.svg</code>) located in the <code>docs</code> folder, or to any icon bundled with the theme. Add the following lines to <code>mkdocs.yml</code>:</p>  Image Icon, bundled <pre><code>theme:\nlogo: assets/logo.png\n</code></pre> <pre><code>theme:\nicon:\nlogo: material/library # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>Normally, the logo in the header and sidebar links to the homepage of the documentation, which is the same as <code>site_url</code>. This behavior can be changed with the following configuration:</p> <pre><code>extra:\nhomepage: https://example.com\n</code></pre>"},{"location":"setup/changing-the-logo-and-icons/#favicon","title":"Favicon","text":"<p> 0.1.0 \u00b7  Default: <code>assets/images/favicon.png</code></p> <p>The favicon can be changed to a path pointing to a user-provided image, which  must be located in the <code>docs</code> folder. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfavicon: images/favicon.png\n</code></pre>"},{"location":"setup/changing-the-logo-and-icons/#customization","title":"Customization","text":""},{"location":"setup/changing-the-logo-and-icons/#additional-icons","title":"Additional icons","text":"<p>In order to use custom icons, extend the theme and create a new folder named <code>.icons</code> in the <code>custom_dir</code> you want to use for overrides. Next, add your <code>*.svg</code> icons into a subfolder of the <code>.icons</code> folder. Let's say you downloaded and unpacked the Bootstrap icon set, and want to add it to your project documentation. The structure of your project should look like this:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 .icons/\n\u2502     \u2514\u2500 bootstrap/\n\u2502        \u2514\u2500 *.svg\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\noptions:\ncustom_icons:\n- overrides/.icons\n</code></pre> <p>You can now use all  Bootstrap icons anywhere in Markdown files, as well as everywhere icons can be used in <code>mkdocs.yml</code>. However, note that the syntaxes are slightly different:</p> <ul> <li> <p>Using icons in configuration: take the path of the <code>*.svg</code> icon file   starting at the <code>.icons</code> folder and drop the file extension, e.g. for   <code>.icons/bootstrap/envelope-paper.svg</code>, use:</p> <pre><code>theme:\nicon:\nlogo: bootstrap/envelope-paper\n</code></pre> </li> <li> <p>Using icons in Markdown files: additionally to taking the path from the   <code>.icons</code> folder as noted above, replace all <code>/</code> with <code>-</code> and enclose the icon   shortcode in two colons:</p> <pre><code>:bootstrap-envelope-paper:\n</code></pre> </li> </ul> <p>For further notes on icon usage, please consult the icon reference.</p>"},{"location":"setup/ensuring-data-privacy/","title":"Ensuring data privacy","text":"<p>Material for MkDocs makes compliance with data privacy regulations very easy,  as it offers a native cookie consent solution to seek explicit consent from users before setting up analytics. Additionally, external assets can be automatically downloaded for self-hosting.</p>"},{"location":"setup/ensuring-data-privacy/#configuration","title":"Configuration","text":""},{"location":"setup/ensuring-data-privacy/#cookie-consent","title":"Cookie consent","text":"<p> 8.4.0 \u00b7  Default: none \u00b7  Experimental</p> <p>Material for MkDocs ships a native and extensible cookie consent form which asks the user for consent prior to sending requests to third parties. Add the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nconsent:\ntitle: Cookie consent\ndescription: &gt;- # (1)!\nWe use cookies to recognize your repeated visits and preferences, as well\nas to measure the effectiveness of our documentation and whether users\nfind what they're searching for. With your consent, you're helping us to\nmake our documentation better.\n</code></pre> <ol> <li>You can add arbitrary HTML tags in the <code>description</code>, e.g. to link to your     terms of service or other parts of the site.</li> </ol> <p>The following properties are available:</p> <code>title</code> <p> Default: none \u00b7  Required \u2013 This property sets the title of the cookie consent, which is rendered at the  top of the form and must be set to a non-empty string.</p> <code>description</code> <p> Default: none \u00b7  Required \u2013 This property sets the description of the cookie consent, is rendered below the title, and may include raw HTML (e.g. a links to the terms of service).</p> <code>cookies</code> <p> Default: none \u2013 This property allows to add custom  cookies or change the initial <code>checked</code> state and name of built-in cookies. Currently, the following cookies are built-in:</p> <ul> <li>Google Analytics \u2013 <code>analytics</code> (enabled by default)</li> <li>GitHub \u2013 <code>github</code> (enabled by default)</li> </ul> <p>Each cookie must receive a unique identifier which is used as a key in the <code>cookies</code> map, and can be either set to a string, or to a map defining <code>name</code> and <code>checked</code> state:</p> Custom cookie nameCustom initial stateCustom cookie <pre><code>extra:\nconsent:\ncookies:\nanalytics: Custom name\n</code></pre> <pre><code>extra:\nconsent:\ncookies:\nanalytics:\nname: Google Analytics\nchecked: false\n</code></pre> <pre><code>extra:\nconsent:\ncookies:\nanalytics: Google Analytics # (1)!\ncustom: Custom cookie\n</code></pre> <ol> <li>If you define a custom cookie as part of the <code>cookies</code> property,     the <code>analytics</code> cookie must be added back explicitly, or analytics     won't be triggered.</li> </ol> <p>If Google Analytics was configured via <code>mkdocs.yml</code>, the cookie consent will automatically include a setting for the user to disable it. Custom cookies can be used from JavaScript.</p> <code>actions</code> <p> Default: <code>[accept, manage]</code> \u2013 This property defines which buttons are shown and in which order, e.g. to allow the user to accept  cookies and manage settings:</p> <pre><code>extra:\nconsent:\nactions:\n- accept\n- manage # (1)!\n</code></pre> <ol> <li>If the <code>manage</code> settings button is omitted from the <code>actions</code> property,     the settings are always shown.</li> </ol> <p>The cookie consent form includes three types of buttons:</p> <ul> <li><code>accept</code> \u2013 Button to accept selected cookies</li> <li><code>reject</code> \u2013 Button to reject all cookies</li> <li><code>manage</code> \u2013 Button to manage settings</li> </ul> <p>When a user first visits your site, a cookie consent form is rendered:</p> <p></p>"},{"location":"setup/ensuring-data-privacy/#change-cookie-settings","title":"Change cookie settings","text":"<p>In order to comply with GDPR, users must be able to change their cookie settings at any time. This can be done by adding a simple link to your copyright notice  in <code>mkdocs.yml</code>:</p> <pre><code>copyright: &gt;\nCopyright &amp;copy; 2016 - 2023 Martin Donath \u2013\n&lt;a href=\"#__consent\"&gt;Change cookie settings&lt;/a&gt;\n</code></pre>"},{"location":"setup/ensuring-data-privacy/#built-in-privacy-plugin","title":"Built-in privacy plugin","text":"<p> Sponsors only \u00b7  insiders-4.9.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in privacy plugin automatically identifies external assets as part of the build process and downloads all assets for very simple self-hosting. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- privacy\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- privacy:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when downloading external assets. With more CPUs, the plugin can do more work in the same time, thus complete its work faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- privacy:\nconcurrency: 1\n</code></pre>"},{"location":"setup/ensuring-data-privacy/#external-assets","title":"External assets","text":"<p>The following configuration options are available for external assets:</p> <code>assets</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should scan the HTML output to detect and process external assets:</p> <pre><code>plugins:\n- privacy:\nassets: true\n</code></pre> <p>If you've removed all external assets from your project via customization, it's still a good idea to enable the plugin, as the plugin will make sure that there are no hidden external links in any Markdown files that were  unintentionally added.</p> <p>Using <code>assets</code> in strict mode will make the build fail when external assets are detected.</p> <code>assets_fetch</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should download external assets it encountered and bundle them with your documentation:</p> <pre><code>plugins:\n- privacy:\nassets_fetch: true\n</code></pre> <code>assets_fetch_dir</code> <p> Default: <code>assets/external</code> \u2013 This option specifies where the downloaded external assets will be stored. It's normally not necessary to change this option:</p> <pre><code>plugins:\n- privacy:\nassets_fetch_dir: assets/external\n</code></pre> <p>The path must be defined relative to <code>docs_dir</code>.</p> <code>assets_include</code> <p> Default: none \u2013 This option allows to only include certain external assets for processing by the privacy plugin, so they will be downloaded and bundled during the build:</p> <pre><code>plugins:\n- privacy:\nassets_include:\n- unsplash.com/*\n</code></pre> <p>Hosting images externally and optimizing them automatically</p> <p>This option makes the built-in privacy plugin an excellent choice for when you want to host assets like images outside of your git repository in another location to keep them fresh and your repository lean.</p> <p>Additionally, as of  insiders-4.30.0, the built-in privacy plugin was entirely rewritten and now works perfectly with the built-in optimize plugin, which means that external assets can be passed through the same optimization pipeline as the rest of your documentation. This means you can store and edit unoptimized files outside of your repository, and let both plugins built a highly optimized site for you.</p> <p>If you want to implement separate pipelines, i.e., optimize some images differently from others or exclude some images from downloading, you can use multiple instances of the built-in privacy plugin.</p> <code>assets_exclude</code> <p> Default: none \u2013 This option allows to exclude certain external assets from processing by the privacy plugin, so they will not be downloaded and bundled during the build:</p> <pre><code>plugins:\n- privacy:\nassets_exclude: # (1)!\n- cdn.jsdelivr.net/npm/mathjax@3/* - giscus.app/*\n</code></pre> <ol> <li> <p>MathJax loads web fonts for typesetting of mathematical content     through relative URLs, and thus cannot be automatically bundled by the     privacy plugin. MathJax can be self-hosted.</p> <p>Giscus, which we recommend to use as a comment system, uses a technique called code-splitting to load only the code that is necessary, which is implemented via relative URLs. Giscus can be self-hosted as well.</p> </li> </ol> <p>Excluding specific external assets can be necessary if they contain dynamically created or relative URLs, which can't be resolved by the privacy plugin due to technical limitations.</p> <p>Why can't Material for MkDocs bundle all assets by design?</p> <p>The primary reason why Material for MkDocs can't just bundle all of its own assets is the integration with Google Fonts, which offers over a thousand different fonts that can be used to render your documentation. Most of the fonts include several weights and are split up into different character sets  to keep the download size small, so the browser only downloads what is really needed. For Roboto, our default regular font, this results in 42 <code>*.woff2</code> files in total.</p> <p>If Material for MkDocs would bundle all font files, the download size would be in the hundreds of megabytes, slowing down automated builds. Furthermore,  authors might add external assets like third-party scripts or style sheets  that would need to be remembered to be defined as further local assets.</p> <p>This is the very reason the built-in privacy plugin exists \u2014 it automates the process of downloading all external assets manually to ensure compliance with GDPR with some some technical limitations.</p>"},{"location":"setup/ensuring-data-privacy/#external-links","title":"External links","text":"<p> Sponsors only \u00b7  insiders-4.26.0 \u00b7  Experimental</p> <p>The following configuration options are available for external links:</p> <code>links</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should parse and process external links. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- privacy:\nlinks: !ENV [CI, false]\n</code></pre> <code>links_attr_map</code> <p> Default: None \u2013 This option specifies custom attributes that should be added to external links, like for example <code>target=\"_blank\"</code> so all external links open in a new window:</p> <pre><code>plugins:\n- privacy:\nlinks_attr_map:\ntarget: _blank\n</code></pre> <code>links_noopener</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should automatically add <code>rel=\"noopener\"</code> to all links with <code>target=\"_blank\"</code> for security reasons:</p> <pre><code>plugins:\n- privacy:\nlinks_noopener: true\n</code></pre>"},{"location":"setup/ensuring-data-privacy/#how-it-works","title":"How it works","text":"<p>The built-in privacy plugin scans the resulting HTML for links to external resources, including external scripts, style sheets, images and web fonts, and downloads them to bundle them with your documentation site. Every URL referring to an external resource, no matter if part of a template or Markdown file, is then replaced with the URL to the local copy. An example:</p> <pre><code>&lt;script src=\"https://example.com/script.js\"&gt;&lt;/script&gt;\n</code></pre> <p>The external script is downloaded, and the link is replaced with:</p> <pre><code>&lt;script src=\"assets/external/example.com/script.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Style sheets are scanned for external <code>url(...)</code> references, e.g. images and web fonts, which are then also downloaded and bundled with your documentation site. This means that Google Fonts can be configured in <code>mkdocs.yml</code> as usual, as the built-in privacy plugin automatically downloads and bundles all dependent resources.</p> <p>As a third measure, <code>preconnect</code> hints used for DNS pre-fetching which might also leak the visitors IP address to a third party are automatically removed during the build process.</p> Expand to inspect example <p>For the official documentation, the built-in privacy plugin downloads the following resources:</p> <pre><code>.\n\u2514\u2500 assets/external/\n   \u251c\u2500 unpkg.com/tablesort@5.3.0/dist/tablesort.min.js\n   \u251c\u2500 fonts.googleapis.com/css\n   \u251c\u2500 fonts.gstatic.com/s/\n   \u2502  \u251c\u2500 roboto/v29/\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc-CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc0CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc1CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc2CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc3CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc5CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc6CsQ.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic-CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic0CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic1CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic2CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic3CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic5CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic6CsQ.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xEIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xFIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xGIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xHIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xIIzI.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xLIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xMIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fABc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBBc4.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCRc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfABc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBBc4.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCBc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCRc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfChc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu4WxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu4mxK.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu5mxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu72xKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu7GxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu7WxKOzY.woff2\n   \u2502  \u2502  \u2514\u2500 KFOmCnqEu92Fr1Mu7mxKOzY.woff2\n   \u2502  \u2514\u2500 robotomono/v13/\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSV0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSZ0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSd0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSh0mQ.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSt0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSx0mf0h.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtElOUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEleUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEluUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEm-Ul.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEmOUlYIw.woff2\n   \u2502     \u2514\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEn-UlYIw.woff2\n   \u2514\u2500 polyfill.io/v3/polyfill.min.js\n</code></pre>"},{"location":"setup/ensuring-data-privacy/#caching","title":"Caching recommended","text":"<p>All downloaded files are written to the <code>.cache</code> directory, significantly  reducing the duration of subsequent builds as only replacements need to be  carried out. You might want to:</p> <ol> <li>Ignore the <code>.cache</code> directory in your project, by adding it to <code>.gitignore</code>.</li> <li> <p>When building your site for publishing, use a build cache to save the     <code>.cache</code> directory in between builds. Taking the example from the     publishing guide, add the following lines:</p> <pre><code>name: ci\non:\npush:\nbranches:\n- master\n- main\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: pip install mkdocs-material\n- run: mkdocs gh-deploy --force\n</code></pre> </li> </ol>"},{"location":"setup/ensuring-data-privacy/#limitations","title":"Limitations","text":"<p>Note that dynamically created URLs as part of scripts are not detected, and thus cannot be automatically downloaded. The built-in privacy plugin does not execute scripts \u2013 it can only detect fully qualified URLs to download and replace.</p> <p>In short, don't do this:</p> <pre><code>const cdn = \"https://polyfill.io\"\nconst url = `${cdn}/v3/polyfill.min.js`\n</code></pre> <p>Instead, always use fully qualified URLs:</p> <pre><code>const url =\"https://polyfill.io/v3/polyfill.min.js\"\n</code></pre>"},{"location":"setup/ensuring-data-privacy/#customization","title":"Customization","text":""},{"location":"setup/ensuring-data-privacy/#custom-cookies","title":"Custom cookies","text":"<p>If you've customized the cookie consent and added a <code>custom</code> cookie, the user will be prompted to accept or reject your custom cookie. Once the user accepts or rejects the cookie consent, or changes the settings, the page reloads1. Use additional JavaScript to query the result:</p> <code>docs/javascripts/consent.js</code> <code>mkdocs.yml</code> <pre><code>var consent = __md_get(\"__consent\")\nif (consent &amp;&amp; consent.custom) {\n/* The user accepted the cookie */\n} else {\n/* The user rejected the cookie */\n}\n</code></pre> <pre><code>extra_javascript:\n- javascripts/consent.js\n</code></pre> <ol> <li> <p>We reload the page to make interop with custom cookies simpler. If Material for MkDocs would implement a callback-based approach, the author would need to make sure to correctly update all scripts that use cookies. Additionally, the cookie consent is only answered initially, which is why we consider this to be a good trade-off of DX and UX.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/setting-up-a-blog/","title":"Setting up a blog","text":"<p>Material for MkDocs makes it very easy to build a blog, either as a sidecar to your documentation or standalone. Focus on your content while the engine does all the heavy lifting, automatically generating archive and category indexes, post slugs, configurable pagination and more.</p> <p>Check out our blog, which is created with the new built-in blog plugin!</p>"},{"location":"setup/setting-up-a-blog/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-a-blog/#built-in-blog-plugin","title":"Built-in blog plugin","text":"<p> 9.2.0b0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in blog plugin adds support for building a blog from a folder of posts, which are annotated with dates and other structured data. First, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- blog\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>By default, the built-in blog plugin assumes that your blog is hosted inside the <code>blog</code> subfolder of your documentation (this is configurable). Next, you need to create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Since the built-in blog plugin auto-generates archive and category indexes, it must know where to add those to the navigation. Thus, make sure to add a <code>blog/index.md</code> file in <code>mkdocs.yml</code>:</p> <pre><code>nav:\n- Blog:\n- blog/index.md # (1)!\n</code></pre> <ol> <li> <p>Within this file, you can specify the title of your blog, which is then     picked up and used by the built-in blog plugin:</p> <pre><code># Blog\n</code></pre> </li> </ol> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- blog:\nenabled: !ENV [CI, false]\n</code></pre> <code>blog_dir</code> <p> Default: <code>blog</code> \u2013 This option specifies the folder where your posts and metadata live. The name of the folder will also be included in the generated URLs as a prefix to all blog-related pages. If you want to build a standalone blog, change it to <code>.</code>:</p> SubdirectoryStandalone <pre><code>plugins:\n- blog:\nblog_dir: blog\n</code></pre> <pre><code>plugins:\n- blog:\nblog_dir: .\n</code></pre> <p>The path must be defined relative to <code>docs_dir</code>.</p> <code>blog_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether indexes include a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\nblog_toc: true\n</code></pre> <p>Note that this setting is also used as the default value for <code>archive_toc</code> and <code>categories_toc</code>, unless those settings are explicitly defined.</p> <p>The built-in blog plugin has dozens of options that allow for advanced configuration. It's a good idea to start writing your first post, and come back here later for fine-tuning the output.</p>"},{"location":"setup/setting-up-a-blog/#posts","title":"Posts","text":"<p>The following configuration options are available for posts:</p> <code>post_date_format</code> <p> Default: <code>long</code> \u2013 This option specifies the date format that is used when posts are rendered. Under the hood, the built-in blog plugin leverages Babel to render dates locale-aware using the configured site language. The following formats are supported:</p> Monday, January 31, 2022January 31, 2022Jan 31, 20221/31/22 <pre><code>plugins:\n- blog:\npost_date_format: full\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: long\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: medium\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: short\n</code></pre> <p>Note that depending on the site language, formats might look different for other languages. Additionally, Babel supports a pattern syntax which allows for custom formats.</p> <code>post_url_date_format</code> <p> Default: <code>yyyy/MM/dd</code> \u2013 This option specifies the date format that is used in the URL of the post. The format string must adhere to Babel's pattern syntax. Some examples:</p>  blog/2022/01/31// blog/2022/01// blog/2022// <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy/MM/dd\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy/MM\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy\n</code></pre> <p>If you want to exclude the date altogether, e.g. when your blog features mostly evergreen content, you can remove the <code>date</code> placeholder from the format string (see below).</p> <code>post_url_format</code> <p> Default: <code>{date}/{slug}</code> \u2013 This option specifies the format string that is used for the URL of the post. The following placeholders are currently supported:</p> <ul> <li> <p><code>categories</code> \u2013 Replaced with the post's slugified categories.</p> </li> <li> <p><code>date</code> \u2013 Replaced with the post's date, as configured in   <code>post_url_date_format</code>.</p> </li> <li> <p><code>slug</code> \u2013 Replaced with a slug generated from the post's title.</p> </li> <li> <p><code>file</code> \u2013 Replaced with the post's file name.</p> </li> </ul>  blog/2022// blog// <pre><code>plugins:\n- blog:\npost_url_format: \"{date}/{slug}\"\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_format: \"{slug}\"\n</code></pre> <p>If you remove the <code>date</code> placeholder, make sure that post URLs don't collide with other the URLs of other pages added to the blog section, as this leads to undefined behavior.</p> <code>post_url_max_categories</code> <p> Default: <code>1</code> \u2013 This option specifies the number of categories that are included in the URL if the <code>categories</code> placeholder is part of <code>post_url_format</code>. If a post is assigned to multiple categories, they are joined with <code>/</code>:</p> <pre><code>plugins:\n- blog:\npost_url_format: \"{categories}/{slug}\"\npost_url_max_categories: 2\n</code></pre> <code>post_slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for generating URL-compatible slugs from post titles.  Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- blog:\npost_slugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- blog:\npost_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>post_slugify_separator</code> <p> Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string:</p> <pre><code>plugins:\n- blog:\npost_slugify_separator: \"-\"\n</code></pre> <code>post_excerpt</code> <p> Default: <code>optional</code> \u2013 This option specifies whether post excerpts should be considered being optional or required by the built-in blog plugin when generating indexes. If excerpts are required, the plugin terminates with an error if a post doesn't define an excerpt:</p> OptionalRequired <pre><code>plugins:\n- blog:\npost_excerpt: optional\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt: required\n</code></pre> <code>post_excerpt_max_authors</code> <p> Default: <code>1</code> \u2013 This option specifies the number of authors rendered in post excerpts. While each post may be written by multiple authors, this setting allows to limit the display to just a few or even a single author, or disable authors in excerpts altogether:</p> Render up to 2 authors in excerptsDisable authors in excerpts <pre><code>plugins:\n- blog:\npost_excerpt_max_authors: 2\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt_max_authors: 0\n</code></pre> <code>post_excerpt_max_categories</code> <p> Default: <code>5</code> \u2013 This option specifies the number of categories rendered in post excerpts. While each post may be assigned to multiple categories, the built-in blog plugin can be instructed to only show the first <code>n</code> categories to keep it short and concise:</p> Render up to 2 categories in excerptsDisable categories in excerpts <pre><code>plugins:\n- blog:\npost_excerpt_max_categories: 2\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt_max_categories: 0\n</code></pre> <code>post_excerpt_separator</code> <p> Default: <code>&lt;!-- more --&gt;</code> \u2013 This option specifies the separator the built-in blog plugin will look for in a post's content when generating post excerpts. All content after the separator is not considered to be part of the excerpt.</p> <code>post_readtime</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should compute the reading time of a post automatically, which is then rendered in post excerpts, as well as in the posts themselves. If you want to disable reading time computation, add:</p> <pre><code>plugins:\n- blog:\npost_readtime: false\n</code></pre> <code>post_readtime_words_per_minute</code> <p> Default: <code>265</code> \u2013 This option specifies the number of words that a reader is expected to read per minute when computing the reading time of a post. If you feel that estimation is not quite right, you can fine-tune reading time computation with the following setting:</p> <pre><code>plugins:\n- blog:\npost_readtime_words_per_minute: 265\n</code></pre>"},{"location":"setup/setting-up-a-blog/#archive","title":"Archive","text":"<p>The following configuration options are available for archive index generation:</p> <code>archive</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate archive indexes. An archive indexes shows all posts for a specific interval (e.g. year, month, etc.) in reverse chronological order. If you want to disable archive index generation, add:</p> <pre><code>plugins:\n- blog:\narchive: false\n</code></pre> <code>archive_name</code> <p> Default: automatically set \u2013 This option specifies the title of the archive section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with:</p> <pre><code>plugins:\n- blog:\narchive_name: Archive\n</code></pre> <code>archive_date_format</code> <p> Default: <code>yyyy</code> \u2013 This option specifies the date format that is used when archive indexes are rendered. The format string must adhere to Babel's pattern syntax. Popular settings are:</p> 2022January 2022 <pre><code>plugins:\n- blog:\narchive_date_format: yyyy\n</code></pre> <pre><code>plugins:\n- blog:\narchive_date_format: MMMM yyyy\n</code></pre> <code>archive_url_date_format</code> <p> Default: <code>yyyy</code> \u2013 This option specifies the date format that is used in the archive index URL. The format string must adhere to Babel's pattern syntax. Some examples:</p>  blog/archive/2022/ blog/archive/2022/01/ <pre><code>plugins:\n- blog:\narchive_url_date_format: yyyy\n</code></pre> <pre><code>plugins:\n- blog:\narchive_url_date_format: yyyy/MM\n</code></pre> <code>archive_url_format</code> <p> Default: <code>archive/{date}</code> \u2013 This option specifies the format string that is used for the URL of the archive index, and can be used to localize the URL:</p>  blog/archive/2022/ blog/2022/ <pre><code>plugins:\n- blog:\narchive_url_format: \"archive/{date}\"\n</code></pre> <pre><code>plugins:\n- blog:\narchive_url_format: \"{date}\"\n</code></pre> <code>archive_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether an archive index includes a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\narchive_toc: true\n</code></pre>"},{"location":"setup/setting-up-a-blog/#categories","title":"Categories","text":"<p>The following configuration options are available for category index generation:</p> <code>categories</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate category indexes. A category index shows all posts for a specific category in reverse chronological order. If you want to disable category index generation, add:</p> <pre><code>plugins:\n- blog:\ncategories: false\n</code></pre> <code>categories_name</code> <p> Default: automatically set \u2013 This option specifies the title of the category section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with:</p> <pre><code>plugins:\n- blog:\ncategories_name: Categories\n</code></pre> <code>categories_url_format</code> <p> Default: <code>category/{slug}</code> \u2013 This option specifies the format string that is used for the URL of a category index, and can be used to localize the URL:</p>  blog/category// blog// <pre><code>plugins:\n- blog:\ncategories_url_format: \"category/{slug}\"\n</code></pre> <pre><code>plugins:\n- blog:\ncategories_url_format: \"{slug}\"\n</code></pre> <code>categories_slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for generating URL-compatible slugs from categories.  Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- blog:\ncategories_slugify: !!python/object/apply:pymdownx.slugs.slugify kwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- blog:\ncategories_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>categories_slugify_separator</code> <p> Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string:</p> <pre><code>plugins:\n- blog:\ncategories_slugify_separator: \"-\"\n</code></pre> <code>categories_allowed</code> <p> Default: none \u2013 This option specifies the categories that are allowed to be used in posts. If this setting is omitted, the built-in blog plugin will not check category names. Use this option to define a list of categories in order to catch typos:</p> <pre><code>plugins:\n- blog:\ncategories_allowed:\n- General\n- Search\n- Performance\n</code></pre> <code>categories_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether a category index includes a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\ncategories_toc: true\n</code></pre>"},{"location":"setup/setting-up-a-blog/#pagination","title":"Pagination","text":"<p>The following configuration options are available for index pagination:</p> <code>pagination</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should paginate the index. The index shows all posts in reverse chronological order, which can be many. If you want to disable index pagination, add:</p> <pre><code>plugins:\n- blog:\npagination: false\n</code></pre> <code>pagination_per_page</code> <p> Default: <code>10</code> \u2013 This option specifies the number of posts rendered on a single index page. If more posts are found, they are assigned to a 2nd page, and so on. If you have large post excerpts, it might be a good idea to reduce the number of posts per page:</p> <pre><code>plugins:\n- blog:\npagination_per_page: 5\n</code></pre> <code>pagination_url_format</code> <p> Default: <code>page/{page}</code> \u2013 This option specifies the format string that is used for the URL of the paginated index, and can be used to localize the URL:</p>  blog/page/n/ blog/n/ <pre><code>plugins:\n- blog:\npagination_url_format: \"page/{page}\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_url_format: \"{page}\"\n</code></pre> <code>pagination_template</code> <p> Default: <code>~2~</code> \u2013 This option specifies the format string that is provided to the paginate module, which allows to customize how pagination is constructed. Popular choices:</p> 1 2 3 .. n1 2 3 .. n  1  <pre><code>plugins:\n- blog:\npagination_template: \"~2~\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_template: \"$link_first $link_previous ~2~ $link_next $link_last\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_template: \"$link_previous $page $link_next\"\n</code></pre> <p>The paginate module exposes the following placeholders:</p> <ul> <li><code>$first_page</code> \u2013 number of first reachable page</li> <li><code>$last_page</code> \u2013 number of last reachable page</li> <li><code>$page</code> \u2013 number of currently selected page</li> <li><code>$page_count</code> \u2013 number of reachable pages</li> <li><code>$items_per_page</code> \u2013 maximal number of items per page</li> <li><code>$first_item</code> \u2013 index of first item on the current page</li> <li><code>$last_item</code> \u2013 index of last item on the current page</li> <li><code>$item_count</code> \u2013 total number of items</li> <li><code>$link_first</code> \u2013 link to first page (unless this is first page)</li> <li><code>$link_last</code> \u2013 link to last page (unless this is last page)</li> <li><code>$link_previous</code> \u2013 link to previous page (unless this is first page)</li> <li><code>$link_next</code> \u2013 link to next page (unless this is last page)</li> </ul> <code>pagination_keep_content</code> <p> Default: <code>false</code> \u2013 This option specifies whether paginated index pages should inherit the custom content from the index page, i.e. the content of <code>blog/index.md</code>:</p> <pre><code>plugins:\n- blog:\npagination_keep_content: true\n</code></pre>"},{"location":"setup/setting-up-a-blog/#authors","title":"Authors","text":"<p>The following configuration options are available for author info:</p> <code>authors</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate author info. If it is enabled, the plugin will look up authors in a file called <code>.authors.yml</code> and include authors in indexes and in posts. If you want to disable this behavior, add:</p> <pre><code>plugins:\n- blog:\nauthors: false\n</code></pre> <code>authors_file</code> <p> Default: <code>.authors.yml</code> \u2013 This option specifies the name of the file where the authors for your posts resides. The default settings assumes that the file is called <code>.authors.yml</code> (mind the <code>.</code> at the beginning):</p> <pre><code>plugins:\n- blog:\nauthors_file: .authors.yml\n</code></pre> <p>The path must be defined relative to <code>blog_dir</code>. Also see the section on adding authors.</p>"},{"location":"setup/setting-up-a-blog/#drafts","title":"Drafts","text":"<p>The following configuration options are available for drafts:</p> <code>draft</code> <p> Default: <code>false</code> \u2013 This option specifies whether the built-in blog plugin should also include posts marked as drafts when the site is being built. Including draft posts might be desired in deploy previews, which is why it exists in the first place:</p> Render draftsDon't render drafts <pre><code>plugins:\n- blog:\ndraft: true\n</code></pre> <pre><code>plugins:\n- blog:\ndraft: false\n</code></pre> <code>draft_on_serve</code> <p> Default: <code>true</code> \u2013 This option specifies whether posts marked as drafts should be included when previewing your site with <code>mkdocs serve</code>. By default, drafts are rendered when previewing, but skipped when the site is being built:</p> <pre><code>plugins:\n- blog:\ndraft_on_serve: true\n</code></pre> <code>draft_if_future_date</code> <p> Default: <code>false</code> \u2013 This option specifies whether the built-in blog plugin should mark posts with a future date as drafts. When the date passed today, the post is automatically unmarked and included when the site is being built:</p> <pre><code>plugins:\n- blog:\ndraft_if_future_date: true\n</code></pre>"},{"location":"setup/setting-up-a-blog/#rss","title":"RSS","text":"<p> Sponsors only \u00b7  insiders-4.23.0 \u00b7  Plugin</p> <p>The built-in blog plugin integrates seamlessly with the RSS plugin, which provides a simple way to add an RSS feed to your blog (or to your whole  documentation). Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-rss-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- rss:\nmatch_path: blog/posts/.* # (1)!\ndate_from_meta:\nas_creation: date\ncategories:\n- categories\n- tags # (2)!\n</code></pre> <ol> <li> <p>The RSS plugin allows to filter for URLs to be included in the feed. In     this example, only blog posts will be part of the feed.</p> </li> <li> <p>If you want to include a post's categories as well as its tags in the feed,     add both <code>categories</code> and <code>tags</code> here.</p> </li> </ol> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- rss:\nenabled: !ENV [CI, false]\n</code></pre> <code>match_path</code> <p> Default: <code>.*</code> \u2013 This option specifies which pages should be included in the feed. For example, to only include blog posts in the feed, use the following regular expression:</p> <pre><code>plugins:\n- rss:\nmatch_path: blog/posts/.*\n</code></pre> <code>date_from_meta</code> <p> Default: none \u2013 This option specifies which front matter property should be used as a creation date of a page in the  feed. It's recommended to use the <code>date</code> property:</p> <pre><code>plugins:\n- rss:\ndate_from_meta:\nas_creation: date\n</code></pre> <code>categories</code> <p> Default: none \u2013 This option specifies which front matter properties are used as categories as part of the feed. If you use categories and tags, add both with the following lines:</p> <pre><code>plugins:\n- rss:\ncategories:\n- categories\n- tags\n</code></pre> <code>comments_path</code> <p> Default: none \u2013 This option specifies the anchor at which comments for a post or page can be found. If you've integrated a comment system, add the following lines:</p> <pre><code>plugins:\n- rss:\ncomments_path: \"#__comments\"\n</code></pre> <p>Material for MkDocs will automatically add the necessary metadata to your site which will make the RSS feed discoverable by browsers and feed readers. Note that the RSS plugin comes with several other configuration options. For further information, see the documentation.</p>"},{"location":"setup/setting-up-a-blog/#usage","title":"Usage","text":""},{"location":"setup/setting-up-a-blog/#writing-your-first-post","title":"Writing your first post","text":"<p>After you've successfully set up the built-in blog plugin, it's time to write your first post. The plugin doesn't assume any specific directory structure, so you're completely free in how you organize your posts, as long as they are all located inside the <code>posts</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u2502  \u2514\u2500 hello-world.md # (1)!\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li>If you'd like to arrange posts differently, you're free to do so. The URLs     are built from the format specified in <code>post_url_format</code> and     the titles and dates of posts, no matter how they are organized     inside the <code>posts</code> directory.</li> </ol> <p>Create a new file called <code>hello-world.md</code> and add the following lines:</p> <pre><code>---\ndraft: true # (1)!\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\n...\n</code></pre> <ol> <li>If you mark a post as a draft, a red marker appears next to the post date      on index pages. When the site is built, drafts are not included in the      output. This behavior can be changed, e.g. for rendering drafts when      building deploy previews.</li> </ol> <p>When you spin up the live preview server, you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you.</p>"},{"location":"setup/setting-up-a-blog/#adding-an-excerpt","title":"Adding an excerpt","text":"<p>The blog index, as well as archive and category indexes can either list the entire content of each post, or excerpts of posts. An excerpt can be created by adding a <code>&lt;!-- more --&gt;</code> separator after the first few paragraphs of a post:</p> <pre><code># Hello world!\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n&lt;!-- more --&gt;\n...\n</code></pre> <p>When the built-in blog plugin generates all indexes, the content before the excerpt separator is automatically extracted, allowing the user to start reading a post before deciding to jump in.</p>"},{"location":"setup/setting-up-a-blog/#adding-authors","title":"Adding authors","text":"<p>In order to add a little more personality to your posts, you can associate each post with one or multiple authors. First, create the <code>.authors.yml</code> file in your blog directory, and add an author:</p> <pre><code>squidfunk:\nname: Martin Donath\ndescription: Creator\navatar: https://github.com/squidfunk.png\n</code></pre> <p>The <code>.authors.yml</code> file associates each author with an identifier (in this example <code>squidfunk</code>), which can then be used in posts. The following properties are available for each author:</p> <code>name</code> <p> Default: none \u00b7  Required \u2013 This property must define a name for the author. The name is displayed in the left sidebar of each post as part of the author info.</p> <code>description</code> <p> Default: none \u00b7  Required \u2013 This property can be used to add a short description for the author, e.g. the role or profession of the author, or any other title.</p> <code>avatar</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid image URL, internal or external, and is used as part of posts and excerpts as the author's avatar.</p> <p>Now, you can assign one or more authors to a post by referencing their identifiers in the front matter of the Markdown file under the <code>authors</code> property. For each author, a small profile is rendered in the left sidebar of each post, as well as in post excerpts on index pages:</p> <pre><code>---\ndate: 2022-01-31\nauthors:\n- squidfunk\n...\n---\n# Hello world!\n...\n</code></pre>"},{"location":"setup/setting-up-a-blog/#adding-categories","title":"Adding categories","text":"<p>Categories are an excellent way for grouping your posts thematically on dedicated index pages. This way, a user interested in a specific topic can explore all of your posts on this topic. Make sure categories are enabled and add them to the front matter <code>categories</code> property:</p> <pre><code>---\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\n...\n</code></pre> <p>If you want to save yourself from typos when typing out categories, you can define your desired categories in <code>mkdocs.yml</code> as part of the <code>categories_allowed</code> configuration option. The built-in blog plugin will stop the build if a category is not found within the list.</p>"},{"location":"setup/setting-up-a-blog/#adding-tags","title":"Adding tags","text":"<p>Besides categories, the built-in blog plugin also integrates with the built-in tags plugin. If you add tags in the front matter <code>tags</code> property as part of a post, the post is linked from the tags index:</p> <pre><code>---\ndate: 2022-01-31\ntags:\n- Foo\n- Bar\n---\n# Hello world!\n...\n</code></pre> <p>As usual, the tags are rendered above the main headline and posts are linked  on the tags index page, if configured. Note that posts are, as pages, only linked with their titles.</p>"},{"location":"setup/setting-up-a-blog/#adding-related-links","title":"Adding related links","text":"<p> Sponsors only \u00b7  insiders-4.23.0 \u00b7  Experimental</p> <p>Related links offer the perfect way to prominently add a further reading  section to your post that is included in the left sidebar, guiding the user to  other destinations of your documentation. Use the front matter <code>links</code> property  to add related links to a post:</p> <pre><code>---\ndate: 2022-01-31\nlinks:\n- setup/setting-up-site-search.md#built-in-search-plugin\n- insiders/index.md#how-to-become-a-sponsor\n---\n# Hello world!\n...\n</code></pre> <p>You can use the exact same syntax as for the <code>nav</code> section in <code>mkdocs.yml</code>, which means you can set explicit titles for links, add external links and even use nesting:</p> <pre><code>---\ndate: 2022-01-31\nlinks:\n- setup/setting-up-site-search.md#built-in-search-plugin\n- insiders/index.md#how-to-become-a-sponsor\n- Nested section:\n- External link: https://example.com\n- setup/setting-up-site-search.md\n---\n# Hello world!\n...\n</code></pre> <p>If you look closely, you'll realize that you can even use an anchor to link to a specific section of a document, extending the possibilities of the <code>nav</code>  syntax in <code>mkdocs.yml</code>. The built-in blog plugin resolves the anchor and sets  the title of the anchor as a subtitle of the related link.</p> <p>Note that all links must be relative to <code>docs_dir</code>, as is also the case for the <code>nav</code> setting.</p>"},{"location":"setup/setting-up-a-blog/#linking-from-and-to-posts","title":"Linking from and to posts","text":"<p>While post URLs are dynamically computed, the built-in blog  plugin ensures that all links from and to posts and a post's assets are  correct. If you want to link to a post, just use the path to the Markdown file  as a link reference (links must be relative):</p> <pre><code>[Hello World!](blog/posts/hello-world.md)\n</code></pre> <p>Linking from a post to a page, e.g. the index, follows the same method:</p> <pre><code>[Blog](../index.md)\n</code></pre> <p>All assets inside the <code>posts</code> directory are copied to the <code>blog/assets</code> folder  when the site is being built. Of course, you can also reference assets from posts outside of the <code>posts</code> directory. The built-in blog plugin ensures that all links are correct.</p>"},{"location":"setup/setting-up-a-blog/#setting-the-reading-time","title":"Setting the reading time","text":"<p>When enabled, the readtime package is used to compute the expected reading time of each post, which is rendered as part of the post and post excerpt. Nowadays, many blogs show reading times, which is why the built-in blog plugin  offers this capability as well.</p> <p>Sometimes, however, the computed reading time might not feel accurate, or result in odd and unpleasant numbers. For this reason, reading time can be  overridden and explicitly set with the front matter <code>readtime</code> property for a post:</p> <pre><code>---\ndate: 2022-01-31\nreadtime: 15\n---\n# Hello world!\n...\n</code></pre> <p>This will disable automatic reading time computation.</p>"},{"location":"setup/setting-up-a-blog/#setting-defaults","title":"Setting defaults","text":"<p>If you have a lot of posts, it might feel redundant to define all of the above for each post. Luckily, the built-in meta plugin allows to set default front matter properties per folder. You can group your posts by categories, or authors, and add a <code>.meta.yml</code> file to set common properties:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u251c\u2500 .meta.yml # (1)!\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li> <p>As already noted, you can also place a <code>.meta.yml</code> file in nested folders     of the <code>posts</code> directory. This file then can define all front matter     properties that are valid in posts, e.g.:</p> <pre><code>authors:\n- squidfunk\ncategories:\n- Hello\n- World\n</code></pre> </li> </ol> <p>Note that order matters \u2013 the built-in meta plugin must be defined before the blog plugin in <code>mkdocs.yml</code>, so that all set defaults are correctly picked up by the built-in blog plugin:</p> <pre><code>plugins:\n- meta\n- blog\n</code></pre> <p>Lists and dictionaries in <code>.meta.yml</code> files are merged and deduplicated with the values defined for a post, which means you can define common properties in <code>.meta.yml</code> and then add specific properties or overrides for each post.</p>"},{"location":"setup/setting-up-a-blog/#adding-pages","title":"Adding pages","text":"<p>Besides posts, it's also possible to add static pages to your blog by listing the pages in the <code>nav</code> section of <code>mkdocs.yml</code>. All generated indexes are included after the last specified page. For example, to add a page on the  authors of the blog, add the following to <code>mkdocs.yml</code>:</p> <pre><code>nav:\n- Blog:\n- blog/index.md\n- blog/authors.md\n...\n</code></pre>"},{"location":"setup/setting-up-a-blog/#customization","title":"Customization","text":""},{"location":"setup/setting-up-a-blog/#custom-index-pages","title":"Custom index pages","text":"<p> Sponsors only \u00b7  insiders-4.24.0 \u00b7  Experimental</p> <p>If you want to add custom content to automatically generated archive and  category indexes, e.g. to add a category description prior to the list of posts, you can manually create the category page in the same location where the built-in blog plugin would create it:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 category/\n\u2502     \u2502  \u2514\u2500 hello.md # (1)!\n\u2502     \u251c\u2500 posts/\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li> <p>The easiest way is to first add the category to the blog post, then take     the URL generated by the built-in blog plugin and create the file at the     corresponding location in the <code>blog_dir</code> folder.</p> <p>Note that the shown directory listing is based on the default configuration. If you specify different values for the following options, be sure to adjust the path accordingly:</p> <ul> <li><code>blog_dir</code></li> <li><code>categories_url_format</code></li> <li><code>categories_slugify</code></li> </ul> </li> </ol> <p>You can now add arbitrary content to the newly created file, or set specific front matter properties for this page, e.g. to change the page description:</p> <pre><code>---\ndescription: Nullam urna elit, malesuada eget finibus ut, ac tortor.\n---\n# Hello\n...\n</code></pre> <p>All post excerpts belonging to the category are automatically appended.</p>"},{"location":"setup/setting-up-a-blog/#overriding-templates","title":"Overriding templates","text":"<p>The built-in blog plugin is built on the same basis as Material for MkDocs, which means you can override all templates used for the blog by using theme extension as usual.</p> <p>The following templates are added by the built-in blog plugin:</p> <ul> <li><code>blog.html</code> \u2013 Template for blog index</li> <li><code>blog-post.html</code> \u2013 Template for blog post</li> <li><code>blog-archive.html</code> \u2013 Template for blog archive index</li> <li><code>blog-category.html</code> \u2013 Template for blog category index</li> </ul>"},{"location":"setup/setting-up-navigation/","title":"Setting up navigation","text":"<p>A clear and concise navigation structure is an important aspect of good project  documentation. Material for MkDocs provides a multitude of options to configure the behavior of navigational elements, including tabs and sections, and one of its flagship features: instant loading.</p>"},{"location":"setup/setting-up-navigation/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-navigation/#instant-loading","title":"Instant loading","text":"<p> 5.0.0 \u00b7  Feature flag</p> <p>When instant loading is enabled, clicks on all internal links will be intercepted and dispatched via XHR without fully reloading the page. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.instant\n</code></pre> <p>The resulting page is parsed and injected and all event handlers and components are rebound automatically, i.e., Material for MkDocs now behaves like a Single Page Application. Now, the search index survives navigation, which is especially useful for large documentation sites.</p>"},{"location":"setup/setting-up-navigation/#instant-prefetching","title":"Instant prefetching","text":"<p> Sponsors only \u00b7  insiders-4.36.0 \u00b7  Experimental</p> <p>Instant prefetching is a new experimental feature that will start to fetch a page once the user hovers over a link. This will reduce the perceived loading time for the user, especially on slow connections, as the page will be available immediately upon navigation. Enable it with:</p> <pre><code>theme:\nfeatures:\n- navigation.instant\n- navigation.instant.prefetch\n</code></pre>"},{"location":"setup/setting-up-navigation/#anchor-tracking","title":"Anchor tracking","text":"<p> 8.0.0 \u00b7  Feature flag</p> <p>When anchor tracking is enabled, the URL in the address bar is automatically updated with the active anchor as highlighted in the table of contents. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tracking\n</code></pre>"},{"location":"setup/setting-up-navigation/#navigation-tabs","title":"Navigation tabs","text":"<p> 1.1.0 \u00b7  Feature flag</p> <p>When tabs are enabled, top-level sections are rendered in a menu layer below the header for viewports above <code>1220px</code>, but remain as-is on mobile.1 Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tabs\n</code></pre> With tabsWithout <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#sticky-navigation-tabs","title":"Sticky navigation tabs","text":"<p> 7.3.0 \u00b7  Feature flag</p> <p>When sticky tabs are enabled, navigation tabs will lock below the header and always remain visible when scrolling down. Just add the following two feature flags to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tabs\n- navigation.tabs.sticky\n</code></pre> With sticky tabsWithout <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#navigation-sections","title":"Navigation sections","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When sections are enabled, top-level sections are rendered as groups in the sidebar for viewports above <code>1220px</code>, but remain as-is on mobile. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.sections\n</code></pre> With sectionsWithout <p></p> <p></p> <p>Both feature flags, <code>navigation.tabs</code> and <code>navigation.sections</code>, can be combined with each other. If both feature flags are enabled, sections are rendered for level 2 navigation items.</p>"},{"location":"setup/setting-up-navigation/#navigation-expansion","title":"Navigation expansion","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When expansion is enabled, the left sidebar will expand all collapsible subsections by default, so the user doesn't have to open subsections manually. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.expand\n</code></pre> With expansionWithout <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#navigation-path","title":"Navigation path Breadcrumbs","text":"<p> Sponsors only \u00b7  insiders-4.28.0 \u00b7  Experimental</p> <p>When navigation paths are activated, a breadcrumb navigation is rendered above the title of each page, which might make orientation easier for users visiting your documentation on devices with smaller screens. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.path\n</code></pre> With navigation pathWithout <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#navigation-pruning","title":"Navigation pruning","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>When pruning is enabled, only the visible navigation items are included in the  rendered HTML, reducing the size of the built site by 33% or more. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.prune # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with     <code>navigation.expand</code>, as navigation expansion requires     the complete navigation structure.</li> </ol> <p>This feature flag is especially useful for documentation sites with 100+ or even 1,000+ of pages, as the navigation makes up a significant fraction of the HTML. Navigation pruning will replace all expandable sections with links to the first page in that section (or the section index page).</p>"},{"location":"setup/setting-up-navigation/#section-index-pages","title":"Section index pages","text":"<p> 7.3.0 \u00b7  Feature flag</p> <p>When section index pages are enabled, documents can be directly attached to sections, which is particularly useful for providing overview pages. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.indexes # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with <code>toc.integrate</code>,     as sections cannot host the table of contents due to missing space.</li> </ol> With section index pagesWithout <p></p> <p></p> <p>In order to link a page to a section, create a new document with the name <code>index.md</code> in the respective folder, and add it to the beginning of your navigation section:</p> <pre><code>nav:\n- Section:\n- section/index.md # (1)!\n- Page 1: section/page-1.md\n...\n- Page n: section/page-n.md\n</code></pre> <ol> <li>MkDocs also considers files called <code>README.md</code> as index pages.</li> </ol>"},{"location":"setup/setting-up-navigation/#table-of-contents","title":"Table of contents","text":""},{"location":"setup/setting-up-navigation/#anchor-following","title":"Anchor following","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>When anchor following for the table of contents is enabled, the sidebar is automatically scrolled so that the active anchor is always visible. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- toc.follow\n</code></pre>"},{"location":"setup/setting-up-navigation/#navigation-integration","title":"Navigation integration","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When navigation integration for the table of contents is enabled, it is always rendered as part of the navigation sidebar on the left. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- toc.integrate # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with     <code>navigation.indexes</code>, as sections cannot host the     table of contents due to missing space.</li> </ol> With navigation integrationWithout <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#back-to-top-button","title":"Back-to-top button","text":"<p> 7.1.0 \u00b7  Feature flag</p> <p>A back-to-top button can be shown when the user, after scrolling down, starts to scroll up again. It's rendered centered and just below the header. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.top\n</code></pre>"},{"location":"setup/setting-up-navigation/#usage","title":"Usage","text":""},{"location":"setup/setting-up-navigation/#hiding-the-sidebars","title":"Hiding the sidebars","text":"<p>The navigation and/or table of contents sidebars can be hidden for a document with the front matter <code>hide</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nhide:\n- navigation\n- toc\n---\n# Document title\n...\n</code></pre> Hide navigationHide table of contentsHide both <p></p> <p></p> <p></p>"},{"location":"setup/setting-up-navigation/#hiding-the-navigation-path","title":"Hiding the navigation path","text":"<p>While the navigation path is rendered above the main headline, sometimes, it might be desirable to hide it for a specific page, which can be achieved with the front matter <code>hide</code> property:</p> <pre><code>---\nhide:\n- path\n---\n# Document title\n...\n</code></pre>"},{"location":"setup/setting-up-navigation/#customization","title":"Customization","text":""},{"location":"setup/setting-up-navigation/#keyboard-shortcuts","title":"Keyboard shortcuts","text":"<p>Material for MkDocs includes several keyboard shortcuts that make it possible to navigate your project documentation via keyboard. There are two modes:</p> <code>search</code> <p>This mode is active when the search is focused. It provides several key bindings to make search accessible and navigable via keyboard:</p> <ul> <li>Down , Up : select next / previous result</li> <li>Esc , Tab : close search dialog</li> <li>Enter : follow selected result</li> </ul> <code>global</code> <p>This mode is active when search is not focussed and when there's no other focussed element that is susceptible to keyboard input. The following keys are bound:</p> <ul> <li>F , S , / : open search dialog</li> <li>P , , : go to previous page</li> <li>N , . : go to next page</li> </ul> <p>Let's say you want to bind some action to the X key. By using additional JavaScript, you can subscribe to the <code>keyboard$</code> observable and attach your custom event listener:</p> <code>docs/javascripts/shortcuts.js</code> <code>mkdocs.yml</code> <pre><code>keyboard$.subscribe(function(key) {\nif (key.mode === \"global\" &amp;&amp; key.type === \"x\") {\n/* Add custom keyboard handler here */\nkey.claim() // (1)!\n}\n})\n</code></pre> <ol> <li>The call to <code>key.claim()</code> will execute <code>preventDefault()</code> on the     underlying event, so the keypress will not propagate further and     touch other event listeners.</li> </ol> <pre><code>extra_javascript:\n- javascripts/shortcuts.js\n</code></pre>"},{"location":"setup/setting-up-navigation/#content-area-width","title":"Content area width","text":"<p>The width of the content area is set so the length of each line doesn't exceed 80-100 characters, depending on the width of the characters. While this is a reasonable default, as longer lines tend to be harder to read, it may be desirable to increase the overall width of the content area, or even make it stretch to the entire available space.</p> <p>This can easily be achieved with an additional style sheet and a few lines of CSS:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-grid {\nmax-width: 1440px; /* (1)! */\n}\n</code></pre> <ol> <li> <p>If you want the content area to always stretch to the available screen     space, reset <code>max-width</code> with the following CSS:</p> <pre><code>.md-grid {\nmax-width: initial;\n}\n</code></pre> </li> </ol> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <ol> <li> <p>Prior to  6.2.0, navigation tabs had a slightly different behavior. All top-level pages (i.e. all top-level entries directly referring to a <code>*.md</code> file) defined inside the <code>nav</code> entry of <code>mkdocs.yml</code> were grouped under the first tab which received the title of the first page. This made it impossible to include a top-level page (or external link) as a tab item, as was reported in #1884 and #2072. From  6.2.0 on, navigation tabs include all top-level pages and sections.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/setting-up-site-analytics/","title":"Setting up site analytics","text":"<p>As with any other service offered on the web, understanding how your project documentation is actually used can be an essential success factor. Material for MkDocs natively integrates with Google Analytics and offers a customizable cookie consent and a feedback widget.</p>"},{"location":"setup/setting-up-site-analytics/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-site-analytics/#google-analytics","title":"Google Analytics","text":"<p> 7.1.8 \u00b7  Default: none</p> <p>Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. Depending on the given property prefix, add the following lines to <code>mkdocs.yml</code>:</p>  Google Analytics 4 Universal Analytics <pre><code>extra:\nanalytics:\nprovider: google\nproperty: G-XXXXXXXXXX\n</code></pre> <pre><code>extra:\nanalytics:\nprovider: google\nproperty: UA-XXXXXXXX-X\n</code></pre> How to measure site search usage? <p>Besides page views and events, site search can be tracked to better understand how people use your documentation and what they expect to find. In order to enable site search tracking, the following steps are required:</p>  Google Analytics 4 Universal Analytics <ol> <li>Go to your Google Analytics admin settings</li> <li>Select the property for the respective tracking code</li> <li>Select the data streams tab and click the corresponding URL</li> <li>Click the gear icon within the enhanced measurement section</li> <li>Ensure that site search is enabled</li> </ol> <ol> <li>Go to your Google Analytics admin settings</li> <li>Select the property for the respective tracking code</li> <li>Go to the view settings tab</li> <li>Scroll down and enable site search settings</li> <li>Set the query parameter to <code>q</code></li> </ol>"},{"location":"setup/setting-up-site-analytics/#was-this-page-helpful","title":"Was this page helpful?","text":"<p> 8.4.0 \u00b7  Default: none</p> <p>A simple feedback widget can be included at the bottom of each page, encouraging users to give instant feedback whether a page was helpful or not. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nanalytics: # (1)!\nfeedback:\ntitle: Was this page helpful?\nratings:\n- icon: material/emoticon-happy-outline\nname: This page was helpful\ndata: 1\nnote: &gt;-\nThanks for your feedback!\n- icon: material/emoticon-sad-outline\nname: This page could be improved\ndata: 0\nnote: &gt;- # (2)!\nThanks for your feedback! Help us improve this page by\nusing our &lt;a href=\"...\" target=\"_blank\" rel=\"noopener\"&gt;feedback form&lt;/a&gt;.\n</code></pre> <ol> <li> <p>This feature is natively integrated with Google Analytics,     which is why <code>provider</code> and <code>property</code> are also required. However, it's also     possible to provide a custom feedback integration.</p> </li> <li> <p>You can add arbitrary HTML tags to the note which is shown after the user     submitted the feedback, e.g. to link to a feedback form.</p> </li> </ol> <p>Both properties, <code>title</code> and <code>ratings</code>, are required. Note that it's allowed to define more than two ratings, e.g. to implement a 1-5 star rating. Since the feedback widget sends data to a third-party service, it is, of course, natively  integrated with the cookie consent feature1.</p> How to visualize the collected feedback ratings? <p>To visualize feedback ratings you'll need to create a custom report with Google Analytics that will quickly show you the worst- and best-rated pages of your project documentation.</p>  Google Analytics 4 Universal Analytics <ol> <li> <p>Go to your Google Analytics dashboard</p> </li> <li> <p>Go to the configure page on the left hand menu, then select     custom definitions</p> </li> <li> <p>Click the custom metrics tab and then create custom metrics,      enter the following values:</p> <ul> <li>Metric name: Page helpful</li> <li>Description: Was this page helpful?</li> <li>Event parameter: <code>data</code></li> <li>Unit of measurement: Standard</li> </ul> </li> <li> <p>Go to the explore page on the left hand menu, create a new     blank exploration</p> </li> <li> <p>Configure the report as follows:</p> <ul> <li>Dimensions: Add <code>Event name</code> and <code>Page location</code></li> <li>Metrics: Add <code>Event count</code> and <code>Page helpful</code>   (the custom metric created in step 3)</li> <li>Rows: <code>Page location</code></li> <li>Values: Drag in both <code>Event count</code> and <code>Page helpful</code></li> <li>Filters: Add a new filter for    <code>Event name / exactly matches / feedback</code></li> </ul> </li> </ol> <p>Delay in data availability</p> <p>The report may take 24 hours or longer to begin displaying data</p> <ol> <li>Go to your Google Analytics dashboard</li> <li>Open the customization panel on the left and go to custom reports</li> <li>Create a new custom report and set a custom title and name</li> <li>Add <code>Avg. Value</code> and <code>Total Events</code> to metric group</li> <li>Add <code>Event Label</code> to dimension drilldown</li> <li>Add <code>Event Category</code> to filters and filter for the value feedback</li> </ol> <p>Now, after you've saved the report and collected some feedback ratings, you'll have a list of all pages with the total number of ratings, and an average rating per page. This should help you identify pages that need to be improved:</p> <p></p> <p>The following properties are available for each rating:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations:</p> <ul> <li> +  \u2013 <code>material/emoticon-happy-outline</code> + <code>material/emoticon-sad-outline</code></li> <li> +  \u2013 <code>material/thumb-up-outline</code> + <code>material/thumb-down-outline</code></li> <li> +  \u2013 <code>material/heart</code> + <code>material/heart-broken</code></li> </ul> <code>name</code> <p> Default: none \u00b7  Required \u2013 The value of this property is shown on user interaction (i.e. keyboard focus or mouse hover), explaining the meaning of the rating behind the icon.</p> <code>data</code> <p> Default: none \u00b7  Required \u2013 The value of this property is sent as a data value with the custom event that is transmitted to Google Analytics2 (or any custom integration).</p> <code>note</code> <p> Default: none \u00b7  Required \u2013 The value of this property is shown after the user selected the rating. It may contain arbitrary HTML tags, which is especially useful to ask the user to provide more detailed feedback for the current page through a form. It's also possible to pre-fill forms with the URL and title of the current page by using the following placeholders:</p> <ul> <li><code>{url}</code> \u2013 Page URL</li> <li><code>{title}</code> \u2013 Page title</li> </ul> <pre><code>https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url}\n</code></pre> <p>In this example, when clicking the link, the user is redirected to the \"new  issue\" form of your repository, with a pre-filled title including the path of the current document, e.g.:</p> <pre><code>[Feedback] Setting up site analytics \u2013 /setup/setting-up-site-analytics/\n</code></pre> <p>An alternative to GitHub issues is Google Forms.</p>"},{"location":"setup/setting-up-site-analytics/#usage","title":"Usage","text":""},{"location":"setup/setting-up-site-analytics/#hiding-the-feedback-widget","title":"Hiding the feedback widget","text":"<p>The feedback widget can be hidden for a document with the front matter <code>hide</code> property. Add the following lines at the top of a Markdown file:</p> <pre><code>---\nhide:\n- feedback\n---\n# Document title\n...\n</code></pre>"},{"location":"setup/setting-up-site-analytics/#customization","title":"Customization","text":""},{"location":"setup/setting-up-site-analytics/#custom-site-analytics","title":"Custom site analytics","text":"<p>In order to integrate another analytics service provider offering a  JavaScript-based tracking solution, just follow the guide on theme extension and create a new partial in the <code>overrides</code> folder. The name of the partial is used to configure the custom integration via <code>mkdocs.yml</code>:</p> <code>overrides/partials/integrations/analytics/custom.html</code> <code>mkdocs.yml</code> <pre><code>&lt;script&gt;\n/* Add custom analytics integration here, e.g. */\nvar property = \"{{ config.extra.analytics.property }}\" // (1)!\n/* Wait for page to load and application to mount */\ndocument.addEventListener(\"DOMContentLoaded\", function() {\nlocation$.subscribe(function(url) {\n/* Add custom page event tracking here */ // (2)!\n})\n})\n&lt;/script&gt;\n</code></pre> <ol> <li>As an example, this variable receives the value set in <code>mkdocs.yml</code>,     which is <code>\"foobar\"</code> for <code>property</code>.</li> <li>If you're using instant loading, you can use the <code>location$</code>     observable to listen for navigation events, which always emits the     current <code>URL</code>.</li> </ol> <pre><code>extra:\nanalytics:\nprovider: custom\nproperty: foobar # (1)!\n</code></pre> <ol> <li>You can add arbitrary key-value combinations to configure your     custom integration. This is especially useful if you're sharing the     custom integration across multiple repositories.</li> </ol>"},{"location":"setup/setting-up-site-analytics/#custom-site-feedback","title":"Custom site feedback","text":"<p>A custom feedback widget integration just needs to process the events that are generated by users interacting with the feedback widget with the help of some additional JavaScript:</p> <code>docs/javascripts/feedback.js</code> <code>mkdocs.yml</code> <pre><code>var feedback = document.forms.feedback\nfeedback.addEventListener(\"submit\", function(ev) {\nev.preventDefault()\n/* Retrieve page and feedback value */\nvar page = document.location.pathname\nvar data = ev.submitter.getAttribute(\"data-md-value\")\n/* Send feedback value */\nconsole.log(page, data)\n})\n</code></pre> <pre><code>extra_javascript:\n- javascripts/feedback.js\n</code></pre> <p> </p> <ol> <li> <p>If the user doesn't accept the <code>analytics</code> cookie, the feedback widget is not shown.\u00a0\u21a9</p> </li> <li> <p>Note that for Google Analytics, the data value must be an integer.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/setting-up-site-search/","title":"Setting up site search","text":"<p>Material for MkDocs provides an excellent client-side search implementation, omitting the need for the integration of third-party services, which might not be compliant with privacy regulations. Moreover, search even works offline, allowing users to download your documentation.</p>","boost":1.05},{"location":"setup/setting-up-site-search/#configuration","title":"Configuration","text":"","boost":1.05},{"location":"setup/setting-up-site-search/#built-in-search-plugin","title":"Built-in search plugin","text":"<p> 0.1.0 \u00b7  Plugin</p> <p>The built-in search plugin integrates seamlessly with Material for MkDocs, adding multilingual client-side search with lunr and lunr-languages. It's  enabled by default, but must be re-added to <code>mkdocs.yml</code> when other plugins are used:</p> <pre><code>plugins:\n- search\n</code></pre> <p>The following configuration options are supported:</p> <code>lang</code> <p> Default: automatically set \u2013 This option allows to include the language-specific stemmers provided by lunr-languages. Note that Material for MkDocs will set this automatically based on the site language, but it may be overridden, e.g. to support multiple languages:</p> A single languageMultiple languages <pre><code>plugins:\n- search:\nlang: en\n</code></pre> <pre><code>plugins:\n- search:\nlang: # (1)!\n- en\n- de\n</code></pre> <ol> <li>Be aware that including support for other languages increases the     general JavaScript payload by around 20kb (before <code>gzip</code>) and by     another 15-30kb per language.</li> </ol> <p>The following languages are supported by lunr-languages:</p> <ul> <li><code>ar</code> \u2013 Arabic</li> <li><code>da</code> \u2013 Danish</li> <li><code>de</code> \u2013 German</li> <li><code>du</code> \u2013 Dutch</li> <li><code>en</code> \u2013 English</li> <li><code>es</code> \u2013 Spanish</li> <li><code>fi</code> \u2013 Finnish</li> <li><code>fr</code> \u2013 French</li> <li><code>hi</code> \u2013 Hindi</li> <li><code>hu</code> \u2013 Hungarian</li> <li><code>hy</code> \u2013 Armenian</li> <li><code>it</code> \u2013 Italian</li> <li><code>ja</code> \u2013 Japanese</li> <li><code>kn</code> - Kannada</li> <li><code>ko</code> \u2013 Korean</li> <li><code>no</code> \u2013 Norwegian</li> <li><code>pt</code> \u2013 Portuguese</li> <li><code>ro</code> \u2013 Romanian</li> <li><code>ru</code> \u2013 Russian</li> <li><code>sa</code> \u2013 Sanskrit</li> <li><code>sv</code> \u2013 Swedish</li> <li><code>ta</code> \u2013 Tamil</li> <li><code>te</code> \u2013 Telugu</li> <li><code>th</code> \u2013 Thai</li> <li><code>tr</code> \u2013 Turkish</li> <li><code>vi</code> \u2013 Vietnamese</li> <li><code>zh</code> \u2013 Chinese</li> </ul> <p>Material for MkDocs goes to great lengths to support languages that are not part of this list by automatically falling back to the stemmer yielding the best result.</p> <code>separator</code> <p> Default: automatically set \u2013 The separator for indexing and query tokenization can be customized, making it possible to index parts of words separated by other characters than whitespace and <code>-</code>, e.g. by including <code>.</code>:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\-\\.]+'\n</code></pre> <p>With  9.0.0, a faster and more flexible tokenizer method is shipped, allowing for tokenizing with lookahead, which yields more influence on the way documents are indexed. As a result, we use the following separator setting for this site's search:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&amp;[lg]t;'\n</code></pre> <p>Broken into its parts, the separator induces the following behavior:</p> Special charactersCase changesVersion stringsHTML/XML tags <pre><code>[\\s\\-,:!=\\[\\]()\"/]+\n</code></pre> <p>The first part of the expression inserts token boundaries for each document before and after whitespace, hyphens, commas, brackets and other special characters. If several of those special characters are adjacent, they are treated as one.</p> <pre><code>(?!\\b)(?=[A-Z][a-z])\n</code></pre> <p>Many programming languages have naming conventions like <code>PascalCase</code> or <code>camelCase</code>. By adding this subexpression to the separator, words are split at case changes, tokenizing the word <code>PascalCase</code> into <code>Pascal</code> and <code>Case</code>.</p> <p> Read more on tokenizing case changes</p> <pre><code>\\.(?!\\d)\n</code></pre> <p>When adding <code>.</code> to the separator, version strings like <code>1.2.3</code> are split into <code>1</code>, <code>2</code> and <code>3</code>, which makes them undiscoverable via search. When using this subexpression, a small lookahead is introduced which will preserve version strings and keep them discoverable.</p> <p> Read more on tokenizing version numbers</p> <pre><code>&amp;[lg]t;\n</code></pre> <p>If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the <code>&lt;</code> and <code>&gt;</code> control characters are encoded in code blocks as <code>&amp;lt;</code> and <code>&amp;gt;</code>. Adding this subexpression to the separator allows for just that.</p> <p> Read more on tokenizing HTML/XML tags</p>","boost":1.05},{"location":"setup/setting-up-site-search/#chinese-language-support","title":"Chinese language support","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>In order to add support for Chinese languages to the built-in search plugin, install the text segmentation library jieba via <code>pip</code>, and the plugin will run all text through the segmenter:</p> <pre><code>pip install jieba\n</code></pre> <p>The following configuration options are available:</p> <code>jieba_dict</code> <p> Default: none \u2013 This option allows for specifying a custom dictionary to be used by jieba for segmenting text, replacing the default dictionary:</p> <pre><code>plugins:\n- search:\njieba_dict: dict.txt # (1)!\n</code></pre> <ol> <li> <p>The following alternative dictionaries are provided by jieba:</p> <ul> <li>dict.txt.small \u2013 \u5360\u7528\u5185\u5b58\u8f83\u5c0f\u7684\u8bcd\u5178\u6587\u4ef6</li> <li>dict.txt.big \u2013 \u652f\u6301\u7e41\u4f53\u5206\u8bcd\u66f4\u597d\u7684\u8bcd\u5178\u6587\u4ef6</li> </ul> </li> </ol> <code>jieba_dict_user</code> <p> Default: none \u2013 This option allows for specifying an additional user dictionary to be used by jieba for segmenting text,  augmenting the default dictionary:</p> <pre><code>plugins:\n- search:\njieba_dict_user: user_dict.txt\n</code></pre> <p>User dictionaries can be used for tuning the segmenter to preserve technical terms.</p>","boost":1.05},{"location":"setup/setting-up-site-search/#search-suggestions","title":"Search suggestions","text":"<p> 7.2.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>When search suggestions are enabled, the search will display the likeliest completion for the last word which can be accepted with the Right key. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.suggest\n</code></pre> <p>Searching for  search su yields search suggestions as a suggestion.</p>","boost":1.05},{"location":"setup/setting-up-site-search/#search-highlighting","title":"Search highlighting","text":"<p> 7.2.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>When search highlighting is enabled and a user clicks on a search result, Material for MkDocs will highlight all occurrences after following the link. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.highlight\n</code></pre> <p>Searching for  code blocks highlights all occurrences of both terms.</p>","boost":1.05},{"location":"setup/setting-up-site-search/#search-sharing","title":"Search sharing","text":"<p> 7.2.0 \u00b7  Feature flag</p> <p>When search sharing is activated, a  share button is rendered next to the reset button, which allows to deep link to the current search query and result. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.share\n</code></pre> <p>When a user clicks the share button, the URL is automatically copied to the clipboard.</p>","boost":1.05},{"location":"setup/setting-up-site-search/#usage","title":"Usage","text":"","boost":1.05},{"location":"setup/setting-up-site-search/#search-boosting","title":"Search boosting","text":"<p> 8.3.0</p> <p>Pages can be boosted in search with the front matter <code>search.boost</code> property, which will make them rank higher. Add the following lines at the top of a Markdown file:</p>  Rank up Rank down <pre><code>---\nsearch:\nboost: 2 # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li> When boosting pages, be gentle and start with     low values.</li> </ol> <pre><code>---\nsearch:\nboost: 0.5\n---\n# Document title\n...\n</code></pre>","boost":1.05},{"location":"setup/setting-up-site-search/#search-exclusion","title":"Search exclusion","text":"<p> 9.0.0 \u00b7  Experimental</p> <p>Pages can be excluded from search with the front matter <code>search.exclude</code> property, removing them from the index. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nsearch:\nexclude: true\n---\n# Document title\n...\n</code></pre>","boost":1.05},{"location":"setup/setting-up-site-search/#excluding-sections","title":"Excluding sections","text":"<p>When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the <code>data-search-exclude</code> pragma after a Markdown heading:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\n## Section 1\nThe content of this section is included\n\n## Section 2 { data-search-exclude }\nThe content of this section is excluded\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"\",\n\"title\":\"Document title\"\n},\n{\n\"location\":\"page/#section-1\",\n\"text\":\"&lt;p&gt;The content of this section is included&lt;/p&gt;\",\n\"title\":\"Section 1\"\n}\n]\n}\n</code></pre>","boost":1.05},{"location":"setup/setting-up-site-search/#excluding-blocks","title":"Excluding blocks","text":"<p>When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the <code>data-search-exclude</code> pragma after a Markdown inline- or block-level element:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\nThe content of this block is included\n\nThe content of this block is excluded\n{ data-search-exclude }\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"&lt;p&gt;The content of this block is included&lt;/p&gt;\",\n\"title\":\"Document title\"\n}\n]\n}\n</code></pre>","boost":1.05},{"location":"setup/setting-up-social-cards/","title":"Setting up social cards","text":"<p>Material for MkDocs can automatically create beautiful social cards for your  documentation, which appear as link previews on social media platforms. You  can select from several pre-designed layouts or create custom layouts to match your unique style and branding.</p> <p> How to build custom social cards by @james-willett \u2013  24m \u2013 Learn how to create entirely custom social cards perfectly matching your branding for each page automatically!</p> <p></p> <p>Social card of our formatting reference</p>"},{"location":"setup/setting-up-social-cards/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-social-cards/#built-in-social-plugin","title":"Built-in social plugin","text":"<p> 8.5.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in social plugin automatically generate a custom preview image for  each page. Install all dependencies for image processing1 and add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- social\n</code></pre> <p>Note that Insiders contains a ground up rewrite of the social plugin that  generates images much more efficiently in parallel and allows to build  entirely custom layouts.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- social:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> insiders-4.33.0 \u00b7   Default: number of CPUs \u2013 How many CPUs the plugin is allowed to use when generating social cards. With more CPUs, the plugin can do more work in the same time, thus complete generation faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- social:\nconcurrency: 1\n</code></pre>"},{"location":"setup/setting-up-social-cards/#social-cards","title":"Social cards","text":"<p>The following configuration options are available for card generation:</p> <code>cards</code> <p> Default: <code>true</code> \u2013 This option specifies whether to generate social card images. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable:</p> <pre><code>plugins:\n- social:\ncards: !ENV [CI, false]\n</code></pre> <code>cards_dir</code> <p> Default: <code>assets/images/social</code> \u2013 This option specifies where the generated social cards will be stored. While it's usually not necessary to change this option, change it with:</p> <pre><code>plugins:\n- social:\ncards_dir: assets/images/social\n</code></pre> <code>cards_color</code> \u2013  Deprecated, use <code>cards_layout_options</code> <p> Default: <code>theme.palette.primary</code> \u2013  This option specifies the colors for the background <code>fill</code> and foreground <code>text</code> when generating the social card:</p> <pre><code>plugins:\n- social:\ncards_color:\nfill: \"#0FF1CE\"\ntext: \"#FFFFFF\"\n</code></pre> <code>cards_font</code> \u2013  Deprecated, use <code>cards_layout_options</code> <p> Default: <code>theme.font.text</code> \u2013 This option specifies which font to use for rendering the social card, which can be any font hosted on Google Fonts:</p> <pre><code>plugins:\n- social:\ncards_font: Ubuntu\n</code></pre> <code>cards_layout_dir</code> <p> insiders-4.33.0 \u00b7  Default: none \u2013 This option specifies where the social plugin should try to resolve custom layouts from, taking precedence over the included layouts:</p> <pre><code>plugins:\n- social:\ncards_layout_dir: layouts\n</code></pre> <code>cards_layout</code> <p> insiders-4.33.0 \u00b7  Default: <code>default</code> \u2013 Layout specification the social card should use. The plugin includes the following layouts which make use of the color palette and font:</p> <code>default</code><code>default/variant</code><code>default/accent</code><code>default/invert</code><code>default/only/image</code> <pre><code>plugins:\n- social:\ncards_layout: default\n</code></pre> <p>This layout uses the configured primary color as a background:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/variant\n</code></pre> <p>This layout includes the page icon as a watermark, if defined:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/accent\n</code></pre> <p>This layout uses the configured accent color as a background:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/invert\n</code></pre> <p>This layout inverts the background and foreground colors:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/only/image\ncards_layout_options:\nbackground_image: layouts/background.png\n</code></pre> <p>This layout will only show the given background image and scale to fit:</p> <p></p> <p>All <code>default</code> layouts make use of the following template variables:</p> <ul> <li> \u2013 <code>config.site_name</code></li> <li> \u2013 <code>page.meta.title</code> or <code>page.title</code></li> <li> \u2013 <code>page.meta.description</code> or <code>config.site_description</code></li> <li> \u2013 <code>theme.logo</code> or <code>theme.icon.logo</code></li> </ul> <code>cards_layout_options</code> <p> 9.1.10 \u00b7  Default: none \u2013 This option allows to set parameters as provided by the layout specification. For custom layouts, this key can be used to provide layout-specific options, making layouts entirely configurable.</p> <p>All <code>default</code> layouts expose the following parameters:</p> <code>background_color</code> <p>Set a background color, which can be a CSS color keyword, or a 3, 4, 6 or 8 letter HEX color code. Alpha channels are supported as well:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nbackground_color: \"#0FF1CE\"\n</code></pre> <code>background_image</code> <p> insiders-4.33.0 \u2013 Set a background image.  If a <code>background_color</code> is set, like for the <code>default</code> layouts, the image is tinted (overlayed) with the color. Thus, the background color must be (partially) transparent for the image to become visible:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nbackground_color: \"#00000000\"\nbackground_image: layouts/background.png\n</code></pre> <p>The path of the image must be defined relative to the project root.</p> <code>color</code> <p>Set a foreground color, which can be a CSS color keyword, or a 3, 4, 6 or 8 letter HEX color code. The color is primarily used to tint text and icons:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\ncolor: \"#0FF1CE\"\n</code></pre> <code>font_family</code> <p>Set a font family. This overrides the font that is set as part of the theme configuration. The built-in social plugin will automatically download the font from Google Fonts:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Ubuntu\n</code></pre> <code>cards_include</code> <p> insiders-4.35.0 \u00b7  Default: none \u2013 This option allows to only generate social cards for certain subsections of your documentation, e.g. to generate different cards for different subfolders with multiple instances of the plugin:</p> <pre><code>plugins:\n- social:\ncards_include:\n- blog/*\n</code></pre> <code>cards_exclude</code> <p> Default: none \u2013 This option allows to exclude certain subsections of your documentation from generating social cards:</p> <pre><code>plugins:\n- social:\ncards_exclude:\n- changelog/*.md\n</code></pre>"},{"location":"setup/setting-up-social-cards/#debugging","title":"Debugging","text":"<p>The following configuration options are available for debugging:</p> <code>debug</code> <p> insiders-4.33.0 \u00b7  Default: <code>false</code> \u2013 This option enables a special debug mode, which renders each layer with an outline and its <code>x</code> and <code>y</code> offset in order to understand how the layout is composed, and optionally renders a grid for easier alignment:</p> <pre><code>plugins:\n- social:\ndebug: true\n</code></pre> With debug modeWithout <p></p> <p></p> <code>debug_on_build</code> <p> insiders-4.34.1 \u00b7  Default: <code>false</code> \u2013 Whether debug mode should be automatically disabled when building your site with <code>mkdocs build</code>. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_on_build: true\n</code></pre> <p>This setting is just intended to be a safety net, so that when building your site social cards definitely won't contain the dot grid or layer outlines by accident.</p> <code>debug_grid</code> <p> insiders-4.33.0 \u00b7  Default: <code>true</code> \u2013 This option enables the rendering of a dot grid when <code>debug</code> is enabled (see screenshot above). The grid can be switched off with:</p> <pre><code>plugins:\n- social:\ndebug_grid: false\n</code></pre> <code>debug_grid_step</code> <p> insiders-4.33.0 \u00b7  Default: <code>32</code> \u2013 This option specifies the step size of the grid in pixels, if enabled, which can be used to align elements. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_grid_step: 64\n</code></pre> <code>debug_color</code> <p> insiders-4.33.0 \u00b7  Default: <code>grey</code> \u2013 This option sets the color of the layer outlines and the grid which are rendered when <code>debug</code> is enabled. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_color: yellow\n</code></pre>"},{"location":"setup/setting-up-social-cards/#caching","title":"Caching","text":"<p>The built-in social plugin implements an intelligent caching mechanism, ensuring that social cards are only re-generated when they're not contained in the cache or their contents change. If any of the variables used in a layout  changes, the plugin will detect it and re-generate the card.</p> <p>The following configuration options are available for caching:</p> <code>cache</code> <p> insiders-4.33.0 \u00b7  Default: <code>true</code> \u2013 Whether the plugin queries its cache for an existing artifact before starting a generation job. It's normally not necessary to change this setting, except for when debugging the plugin itself. Caching can be disabled with:</p> <pre><code>plugins:\n- social:\ncache: false\n</code></pre> <code>cache_dir</code> <p> Default: <code>.cache/plugins/social</code> \u2013 This option specifies the file system location of the plugin's cache. It's normally not necessary to change this setting, except for when debugging the plugin itself. The cache directory can be changed with:</p> <pre><code>plugins:\n- social:\ncache_dir: .cache/plugins/social\n</code></pre> <p>By default, all built-in plugins that implement caching will create a <code>.cache</code> directory in the same folder your <code>mkdocs.yml</code> resides, and create subfolders to not interfere with each other. If you use multiple instances of this plugin, it could be necessary to change this setting.</p>"},{"location":"setup/setting-up-social-cards/#usage","title":"Usage","text":"<p>If you want to adjust the title or set a custom description for the social card, you can set the front matter <code>title</code> and <code>description</code> properties, which take  precedence over the default values.</p> <ul> <li>Changing the title</li> <li>Changing the description</li> </ul>"},{"location":"setup/setting-up-social-cards/#choosing-a-font","title":"Choosing a font","text":"<p>Some fonts do not contain CJK characters, like for example the default font, <code>Roboto</code>. In case your <code>site_name</code>, <code>site_description</code>, or page title contain CJK characters, choose another font from Google Fonts which comes with CJK characters, e.g. one from the <code>Noto Sans</code> font family:</p> Chinese (Simplified)Chinese (Traditional)JapaneseKorean <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans SC\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans TC\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans JP\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans KR\n</code></pre>"},{"location":"setup/setting-up-social-cards/#changing-the-layout","title":"Changing the layout","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>If you want to use a different layout for a single page (e.g. your landing page), you can use the <code>social</code> front matter property together with the <code>cards_layout</code> key, exactly as in <code>mkdocs.yml</code>:</p> <pre><code>---\nsocial:\ncards_layout: custom\n---\n# Headline\n...\n</code></pre> <p>You can apply those changes for entire subtrees of your documentation, e.g., to generate different social cards for your blog and API reference, by using the built-in meta plugin.</p>"},{"location":"setup/setting-up-social-cards/#parametrizing-the-layout","title":"Parametrizing the layout","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>Besides changing the entire layout, you can override all options that a layout exposes. This means you can parametrize social cards with custom front matter properties, such as <code>tags</code>, <code>date</code>, <code>author</code> or anything you can think of. Simply define <code>cards_layout_options</code>:</p> <pre><code>---\nsocial:\ncards_layout_options:\nbackground_color: blue # Change background color\nbackground_image: null # Remove background image\n---\n# Headline\n...\n</code></pre> <p>You can apply those changes for entire subtrees of your documentation, e.g., to generate different social cards for your blog and API reference, by using the built-in meta plugin.</p>"},{"location":"setup/setting-up-social-cards/#disabling-social-cards","title":"Disabling social cards","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>If you wish to disable social cards for a page, simply add the following to the front matter of the Markdown document:</p> <pre><code>---\nsocial:\ncards: false\n---\n# Headline\n...\n</code></pre>"},{"location":"setup/setting-up-social-cards/#customization","title":"Customization","text":"<p> Sponsors only \u00b7  insiders-4.33.0 \u00b7  Experimental</p> <p>Insiders ships a ground up rewrite of the built-in social plugin and introduces a brand new layout system based on a combination of YAML and Jinja templates \u2013 the same engine Material for MkDocs uses for HTML templating \u2013 allowing for the creation of complex custom layouts:</p> Layer 0 Layer 1 Layer 2 Layer 3 Layer 4 Layer 5 <p>Social cards are composed of layers, analogous to how they are represented in graphic design software such as Adobe Photoshop. As many layers are common across the cards generated for each page (e.g., backgrounds or logos), the built-in social plugin can automatically deduplicate layers and render them just once, substantially accelerating card generation. The generated cards are cached to ensure they are only regenerated when their contents change.</p> <p>Layouts are written in YAML syntax. Before starting to create a custom layout, it is a good idea to study the pre-designed layouts (link to Insiders repository), in order to get a better understanding of how they work. Then, create a new layout and reference it in <code>mkdocs.yml</code>:</p> <code>layouts/custom.yml</code> <code>mkdocs.yml</code> <pre><code>size: { width: 1200, height: 630 }\nlayers: []\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_dir: layouts\ncards_layout: custom\ndebug: true\n</code></pre> <p>Note that the <code>.yml</code> file extension should be omitted. Next, run <code>mkdocs serve</code>, and see how the <code>.cache</code> directory is populated with the generated cards. Open any card in your editor, so you can see your changes immediately. Since we haven't defined any layers, the cards are transparent.</p> <p>The following sections explain how to create custom layouts.</p>"},{"location":"setup/setting-up-social-cards/#size-and-offset","title":"Size and offset","text":"<p>Each layer has an associated size and offset, which is defined in pixels. The <code>size</code> is defined by a <code>width</code> and <code>height</code> property, and the <code>offset</code> by <code>x</code> and <code>y</code> properties:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 1200, height: 630 }\noffset: { x: 0, y: 0 }\n</code></pre> <p>If the <code>size</code> is omitted, it defaults to the size of the layout. If the <code>offset</code> is omitted, it defaults to the top left corner, which is the defaut <code>origin</code>. Saving the layout and reloading renders:</p> <p></p> <p>The layer outline and grid are visible because we enabled <code>debug</code> mode in <code>mkdocs.yml</code>. The top left shows the layer index and offset, which is useful for alignment and composition.</p>"},{"location":"setup/setting-up-social-cards/#origin","title":"Origin","text":"<p> insiders-4.35.0 \u00b7  Experimental</p> <p>The <code>origin</code> for the <code>x</code> and <code>y</code> values can be changed, so that the layer is aligned to one of the edges or corners of the layout, e.g., to the bottom right corner of the layout:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 1200, height: 630 }\noffset: { x: 0, y: 0 }\norigin: end bottom\n</code></pre> <p>The following table shows the supported values:</p> Origin <code>start top</code> <code>center top</code> <code>end top</code> <code>start center</code> <code>center</code> <code>end center</code> <code>start bottom</code> <code>center bottom</code> <code>end bottom</code>      Supported values for origin"},{"location":"setup/setting-up-social-cards/#backgrounds","title":"Backgrounds","text":"<p>Each layer can be assigned a background color and image. If both are given, the color is rendered on top of the image, allowing for semi-transparent, tinted backgrounds:</p> Background colorBackground imageBackground image, tinted <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n</code></pre> <p></p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\nimage: layouts/background.png\n</code></pre> <p></p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\nimage: layouts/background.png\ncolor: \"#4051b5ee\" # (1)!\n</code></pre> <ol> <li>The color value can be set to a CSS color keyword, or a 3, 4, 6 or 8     letter HEX color code, allowing for semi-transparent layers.</li> </ol> <p></p> <p>Background images are automatically scaled to fit the layer while preserving aspect-ratio. Notice how we omitted <code>size</code> and <code>offset</code>, because we want to fill the entire area of the social card.</p>"},{"location":"setup/setting-up-social-cards/#typography","title":"Typography","text":"<p>Now, we can add dynamic typography that is sourced from Markdown files - this is the actual raison d'\u00eatre of the built-in social plugin. Jinja templates are used to render a text string that is then added to the image:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 832, height: 310 }\noffset: { x: 62, y: 160 }\ntypography:\ncontent: \"{{ page.title }}\" # (1)!\nalign: start\ncolor: white\nline:\namount: 3\nheight: 1.25\nfont:\nfamily: Roboto\nstyle: Bold\n</code></pre> <ol> <li> <p>The following variables can be used in Jinja templates:</p> <ul> <li><code>config.*</code></li> <li><code>page.*</code></li> <li><code>layout.*</code></li> </ul> <p>The author is free in defining <code>layout.*</code> options, which can be used to pass arbitrary data to the layout from <code>mkdocs.yml</code>.</p> </li> </ol> <p>This renders a text layer with the title of the page with a line height of 1.25, and a maximum number of 3 lines. The plugin automatically computes the font size from the line height, the number of lines, and font metrics like ascender and descender.2 This renders:</p> <p></p>"},{"location":"setup/setting-up-social-cards/#overflow","title":"Overflow","text":"<p>If the text overflows the layer, there are two possible behaviors: either the text is automatically truncated and shortened with an ellipsis, or the text is automatically scaled down to fit the layer:</p> <pre><code># If we use a very long headline, we can see how the text will be truncated\n</code></pre>  Ellipsis Shrink <p></p> <p></p> <p>While truncating with an ellipsis is the default, auto-shrinking can be enabled  by setting <code>overflow</code> to <code>shrink</code>:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 832, height: 310 }\noffset: { x: 62, y: 160 }\ntypography:\ncontent: \"{{ page.title }}\"\noverflow: shrink\nalign: start\ncolor: white\nline:\namount: 3\nheight: 1.25\nfont:\nfamily: Roboto\nstyle: Bold\n</code></pre>"},{"location":"setup/setting-up-social-cards/#alignment","title":"Alignment","text":"<p>Text can be aligned to all corners and edges of the layer. For example, if we want to align the text to the middle of the layer, we can set <code>align</code> to  <code>start center</code>, which will render as:</p> <p></p> <p>The following table shows the supported values:</p> Alignment <code>start top</code> <code>center top</code> <code>end top</code> <code>start center</code> <code>center</code> <code>end center</code> <code>start bottom</code> <code>center bottom</code> <code>end bottom</code>      Supported values for text alignment"},{"location":"setup/setting-up-social-cards/#font","title":"Font","text":"<p>The built-in social plugin integrates with Google Fonts and will automatically download the font files for you. The <code>font</code> property accepts a <code>family</code> and <code>style</code> property, where the <code>family</code> must be set to the name of the font, and the <code>style</code> to one of the supported font styles. For example, setting <code>family</code> to <code>Roboto</code> will automatically download the following files:</p> <pre><code>.cache/plugins/social/fonts\n\u2514\u2500 Roboto/\n    \u251c\u2500 Black.ttf\n    \u251c\u2500 Black Italic.ttf\n    \u251c\u2500 Bold.ttf\n    \u251c\u2500 Bold Italic.ttf\n    \u251c\u2500 Italic.ttf\n    \u251c\u2500 Light.ttf\n    \u251c\u2500 Light Italic.ttf\n    \u251c\u2500 Medium.ttf\n    \u251c\u2500 Medium Italic.ttf\n    \u251c\u2500 Regular.ttf\n    \u251c\u2500 Thin.ttf\n    \u2514\u2500 Thin Italic.ttf\n</code></pre> <p>In that case, the author can use <code>Bold</code> or <code>Medium Italic</code> as the <code>style</code>. If the font style specified in the layer is not part of the font family, the font always falls back to <code>Regular</code> and prints a warning in <code>debug</code> mode, as <code>Regular</code> is included with all font families.</p>"},{"location":"setup/setting-up-social-cards/#icons","title":"Icons","text":"<p>Authors can leverage the full range of icons that are shipped with Material for MkDocs, or even provide custom icons by using theme extension and going through the process described in the guide on additional icons. Icons can even be tinted by using the <code>color</code> property:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n- size: { width: 144, height: 144 }\noffset: { x: 992, y: 64 }\nicon:\nvalue: material/cat\ncolor: white\n</code></pre> <p>This will render the icon in the top right corner of the social card:</p> <p></p> <p>The possibilities are endless. For example, icons can be used to draw shapes like circles:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n- size: { width: 2400, height: 2400 }\noffset: { x: -1024, y: 64 }\nicon:\nvalue: material/circle\ncolor: \"#5c6bc0\"\n- size: { width: 1800, height: 1800 }\noffset: { x: 512, y: -1024 }\nicon:\nvalue: material/circle\ncolor: \"#3949ab\"\n</code></pre> <p>This will add two circles to the background:</p> <p></p>"},{"location":"setup/setting-up-social-cards/#tags","title":"Tags","text":"<p>The new built-in social plugin gives full flexibility of the meta tags that are added to your site, which are necessary to instruct services like Twitter or Discord how to display your social card. All default layouts use the following set of tags, which you can copy to your layout and adapt:</p> <pre><code>definitions:\n- &amp;page_title_with_site_name &gt;-\n{%- if not page.is_homepage -%}\n{{ page.meta.get(\"title\", page.title) }} - {{ config.site_name }}\n{%- else -%}\n{{ page.meta.get(\"title\", page.title) }}\n{%- endif -%}\n- &amp;page_description &gt;-\n{{ page.meta.get(\"description\", config.site_description) or \"\" }}\ntags:\nog:type: website\nog:title: *page_title_with_site_name\nog:description: *page_description\nog:image: \"{{ image.url }}\"\nog:image:type: \"{{ image.type }}\"\nog:image:width: \"{{ image.width }}\"\nog:image:height: \"{{ image.height }}\"\nog:url: \"{{ page.canonical_url }}\"\ntwitter:card: summary_large_image\ntwitter.title: *page_title_with_site_name\ntwitter:description: *page_description\ntwitter:image: \"{{ image.url }}\"\n</code></pre> <p>Note that this examples makes use of YAML anchors to minify repetition. The  <code>definitions</code> property is solely intended for the definition on aliases that  can then be referenced with anchors.</p> <p>Are you missing something? Please open a discussion and let us know!</p> <ol> <li> <p>The awesome thing about social cards is that they are generated during  build time and directly distributed with your documentation, no external  services involved. While it would technically be simpler to generate  social cards using a web browser and an automation framework like  Puppeteer, it would add further liabilities to the toolchain, with the  potential to make build pipelines more complex and resource intense.</p> <p>For this reason, Material for MkDocs again follows its core principle of  making it as simple and powerful as possible, providing an easy-to-use  framework for building custom layouts using Python image processing  libraries.\u00a0\u21a9</p> </li> <li> <p>If the plugin would require the author to specify the font size and line height manually, it would be impossible to guarantee that the text fits into the layer. For this reason we implemented a declarative approach, where the author specifies the desired line height and number of lines, and the plugin computes the font size automatically.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/setting-up-tags/","title":"Setting up tags","text":"<p>Material for MkDocs adds first-class support for categorizing pages with tags, which adds the possibility to group related pages and make them discoverable via search and a dedicated tags index. If your documentation is large, tags can help to discover relevant information faster.</p>"},{"location":"setup/setting-up-tags/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-tags/#built-in-tags-plugin","title":"Built-in tags plugin","text":"<p> 8.2.0 \u00b7  Plugin</p> <p>The built-in tags plugin adds the ability to categorize any page with tags as part of the front matter of the page. In order to add support for tags, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- tags\n</code></pre> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- tags:\nenabled: !ENV [CI, false]\n</code></pre> <code>tags_file</code> <p> Default: none \u2013 This option specifies which page should be used to render the tags index. See the section on adding a tags  index for more information. If this option is specified, tags become clickable, pointing to the corresponding section in the tags index:</p> <pre><code>plugins:\n- tags:\ntags_file: tags.md\n</code></pre> <p>The page holding the tags index can be linked anywhere in the <code>nav</code> section of <code>mkdocs.yml</code>. Note, however, that this options is not required \u2013 only use it if you want a tags index page.</p> <code>tags_extra_files</code> <p> insiders-4.20.0 \u00b7   Default: none \u2013 This option specifies additional pages, i.e. to render subsets of the tags index, in order to provide scoped tags indexes for  specific sections:</p> <pre><code>plugins:\n- tags:\ntags_extra_files:\ncompatibility.md:\n- compat # (1)!\nweb.md:\n- html\n- js\n- css\n</code></pre> <ol> <li> <p>Each page can be assigned a list of tag identifiers, which must be     defined as part of <code>extra.tags</code> in <code>mkdocs.yml</code>:</p> <pre><code>extra:\ntags:\nCompatibility: compat\nHTML5: html\nJavaScript: js\nCSS: css\n</code></pre> <p>In this example, all pages with the tag <code>Compatibility</code> will be included  in the additional tags index on <code>compatibility.md</code>, all pages defining at least one of the tags <code>HTML5</code>, <code>JavaScript</code> or <code>CSS</code> will be included in the additional tags index on <code>web.md</code>.</p> </li> </ol> <p>Note that the values listed under each tags extra file must be alphanumeric tag identifiers, not tags themselves. See #3864 for more information.</p> <code>tags_slugify</code> <p> insiders-4.25.0 \u00b7   Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for  generating URL-compatible slugs from tags. Python Markdown Extensions  includes several Unicode-aware slug functions which are a good choice for  non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- tags:\ntags_slugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- tags:\ntags_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>tags_slugify_separator</code> <p> insiders-4.25.0 \u00b7   Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string:</p> <pre><code>plugins:\n- tags:\ntags_slugify_separator: \"-\"\n</code></pre> <code>tags_compare</code> <p> insiders-4.26.2 \u00b7  Default: <code>None</code> \u2013 This option specifies which function to use when comparing tag values for sorting. If you wish to compare tags irregardless of casing, use:</p> <pre><code>plugins:\n- tags:\ntags_compare: !!python/name:material.plugins.tags.casefold\n</code></pre> <p>You can also define your own comparison function which must return a tag value (as a string) that is used for sorting, and reference it accordingly.</p> <code>tags_compare_reverse</code> <p> insiders-4.26.2 \u00b7  Default: <code>false</code> \u2013 This option specifies whether tags are sorted in reverse order. It is mainly provided for completeness. To change direction, use:</p> <pre><code>plugins:\n- tags:\ntags_compare_reverse: true\n</code></pre> <code>tags_allowed</code> <p> insiders-4.25.0 \u00b7   Default: none \u2013 This option allows the author to define explicitly which tags are allowed to be used on pages. If this setting is omitted, the built-in tags plugin won't check tag names. Use this option to define a list of tags in order to catch typos:</p> <pre><code>plugins:\n- tags:\ntags_allowed:\n- HTML5\n- JavaScript\n- CSS\n</code></pre>"},{"location":"setup/setting-up-tags/#tag-icons-and-identifiers","title":"Tag icons and identifiers","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>Each tag can be associated with an icon, which is then rendered inside the tag. Before assigning icons to tags, associate each tag with a unique identifier, by adding the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\ntags:\n&lt;tag&gt;: &lt;identifier&gt; # (1)!\n</code></pre> <ol> <li> <p>The identifier can only include alphanumeric characters, as well as dashes     and underscores. For example, if you have a tag <code>Compatibility</code>, you can     set <code>compat</code> as an identifier:</p> <pre><code>extra:\ntags:\nCompatibility: compat\n</code></pre> <p>Identifiers can be reused between tags. Tags which are not explicitly associated will use the default tag icon which is </p> </li> </ol> <p>Next, each identifier can be associated with an icon, even a custom icon, by adding the following lines to <code>mkdocs.yml</code> under the <code>theme.icon</code> configuration  setting:</p> Tag iconTag default icon <pre><code>theme:\nicon:\ntag:\n&lt;identifier&gt;: &lt;icon&gt; # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <pre><code>theme:\nicon:\ntag:\ndefault: &lt;icon&gt;\n</code></pre> Expand to inspect example <pre><code>theme:\nicon:\ntag:\nhtml: fontawesome/brands/html5\njs: fontawesome/brands/js\ncss:  fontawesome/brands/css3\nextra:\ntags:\nHTML5: html\nJavaScript: js\nCSS: css\n</code></pre>"},{"location":"setup/setting-up-tags/#usage","title":"Usage","text":""},{"location":"setup/setting-up-tags/#adding-tags","title":"Adding tags","text":"<p>When the built-in tags plugin is enabled, tags can be added for a document with the front matter <code>tags</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\ntags:\n  - HTML5\n  - JavaScript\n  - CSS\n---\n\n...\n</code></pre> <p>The page will now render with those tags above the main headline and within the search preview, which now allows to find pages by tags.</p> How to set tags for an entire folder? <p>With the help of the built-in meta plugin, you can ensure that tags are set for an entire section and all nested pages, by creating a <code>.meta.yml</code> file in the corresponding folder with the following content:</p> <pre><code>tags:\n- HTML5\n- JavaScript\n- CSS\n</code></pre> <p>The tags set in <code>.meta.yml</code> are merged and deduplicated with the tags defined for a page, which means you can define common tags in <code>.meta.yml</code> and then add specific tags for each page. The tags in <code>.meta.yml</code> are appended.</p>"},{"location":"setup/setting-up-tags/#adding-a-tags-index","title":"Adding a tags index","text":"<p>The built-in tags plugin allows to define a file to render a tags index, which can be any page that is part of the <code>nav</code> section. To add a tags index, create a page, e.g. <code>tags.md</code>:</p> <pre><code># Tags\nFollowing is a list of relevant tags:\n\n[TAGS]\n</code></pre> <p>The <code>[TAGS]</code> marker specifies the position of the tags index, i.e. it is replaced with the actual tags index when the page is rendered. You can include arbitrary content before and after the marker:</p> <p></p>"},{"location":"setup/setting-up-tags/#hiding-tags-on-a-page","title":"Hiding tags on a page","text":"<p>While the tags are rendered above the main headline, sometimes, it might be desirable to hide them for a specific page, which can be achieved with the front matter <code>hide</code> property:</p> <pre><code>---\nhide:\n- tags\n---\n# Document title\n...\n</code></pre>"},{"location":"setup/setting-up-the-footer/","title":"Setting up the footer","text":"<p>The footer of your project documentation is a great place to add links to websites or platforms you or your company are using as additional marketing  channels, e.g.  or , which you can easily configure via <code>mkdocs.yml</code>.</p>"},{"location":"setup/setting-up-the-footer/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-the-footer/#navigation","title":"Navigation","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>The footer can include links to the previous and next page of the current page. If you wish to enable this behavior, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.footer\n</code></pre>"},{"location":"setup/setting-up-the-footer/#social-links","title":"Social links","text":"<p> 1.0.0 \u00b7  Default: none</p> <p>Social links are rendered next to the copyright notice as part of the  footer of your project documentation. Add a list of social links in <code>mkdocs.yml</code>  with:</p> <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon # (1)!\nlink: https://fosstodon.org/@squidfunk\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>The following properties are available for each link:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must contain a valid path to any icon bundled with the theme, or the build will not succeed. Some popular choices:</p> <ul> <li> \u2013 <code>fontawesome/brands/mastodon</code> automatically adds <code>rel=me</code></li> <li> \u2013 <code>fontawesome/brands/twitter</code></li> <li> \u2013 <code>fontawesome/brands/github</code></li> <li> \u2013 <code>fontawesome/brands/docker</code></li> <li> \u2013 <code>fontawesome/brands/facebook</code></li> <li> \u2013 <code>fontawesome/brands/medium</code></li> <li> \u2013 <code>fontawesome/brands/instagram</code></li> <li> \u2013 <code>fontawesome/brands/linkedin</code></li> <li> \u2013 <code>fontawesome/brands/pied-piper-alt</code></li> <li> \u2013 <code>fontawesome/brands/slack</code></li> <li> \u2013 <code>fontawesome/brands/discord</code></li> </ul> <code>link</code> <p> Default: none \u00b7  Required \u2013 This property must be set to a relative or absolute URL including the URI  scheme. All URI schemes are supported, including <code>mailto</code> and <code>bitcoin</code>:</p>  Mastodon Email <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon\nlink: https://fosstodon.org/@squidfunk\n</code></pre> <pre><code>extra:\nsocial:\n- icon: fontawesome/solid/paper-plane\nlink: mailto:&lt;email-address&gt;\n</code></pre> <code>name</code> <p> Default: domain name from <code>link</code>, if available \u2013 This property is used as the link's <code>title</code> attribute and can be set to a  discernable name to improve accessibility:</p> <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon\nlink: https://fosstodon.org/@squidfunk\nname: squidfunk on Fosstodon\n</code></pre>"},{"location":"setup/setting-up-the-footer/#copyright-notice","title":"Copyright notice","text":"<p> 0.1.0 \u00b7  Default: none</p> <p>A custom copyright banner can be rendered as part of the footer, which is displayed next to the social links. It can be defined as part of <code>mkdocs.yml</code>:</p> <pre><code>copyright: Copyright &amp;copy; 2016 - 2020 Martin Donath\n</code></pre>"},{"location":"setup/setting-up-the-footer/#generator-notice","title":"Generator notice","text":"<p> 7.3.0 \u00b7  Default: <code>true</code></p> <p>The footer displays a Made with Material for MkDocs notice to denote how the site was generated. The notice can be removed with the following option via <code>mkdocs.yml</code>:</p> <pre><code>extra:\ngenerator: false\n</code></pre> <p>Please read this before removing the generator notice</p> <p>The subtle Made with Material for MkDocs hint in the footer is one of the reasons why this project is so popular, as it tells the user how the site is generated, helping new users to discover this project. Before removing please consider that you're enjoying the benefits of @squidfunk's work for free, as this project is Open Source and has a permissive license. Thousands of hours went into this project, most of them without any financial return.</p> <p>Thus, if you remove this notice, please consider sponsoring the project. Thank you </p>"},{"location":"setup/setting-up-the-footer/#usage","title":"Usage","text":""},{"location":"setup/setting-up-the-footer/#hiding-prevnext-links","title":"Hiding prev/next links","text":"<p>The footer navigation showing links to the previous and next page can be hidden with the front matter <code>hide</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nhide:\n- footer\n---\n# Document title\n...\n</code></pre>"},{"location":"setup/setting-up-the-footer/#customization","title":"Customization","text":""},{"location":"setup/setting-up-the-footer/#custom-copyright","title":"Custom copyright","text":"<p> 8.0.0 \u00b7  Customization</p> <p>In order to customize and override the copyright notice, extend the theme and override the <code>copyright.html</code> partial, which normally includes the <code>copyright</code> property set in <code>mkdocs.yml</code>.</p>"},{"location":"setup/setting-up-the-header/","title":"Setting up the header","text":"<p>Material for MkDocs' header can be customized to show an announcement bar that  disappears upon scrolling, and provides some options for further configuration. It also includes the search bar and a place to display your project's git repository, as explained in those dedicated guides.</p>"},{"location":"setup/setting-up-the-header/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-the-header/#automatic-hiding","title":"Automatic hiding","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When autohiding is enabled, the header is automatically hidden when the user scrolls past a certain threshold, leaving more space for content. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- header.autohide\n</code></pre>"},{"location":"setup/setting-up-the-header/#announcement-bar","title":"Announcement bar","text":"<p> 5.0.0 \u00b7  Customization</p> <p>Material for MkDocs includes an announcement bar, which is the perfect place to display project news or other important information to the user. When the user scrolls past the header, the bar will automatically disappear. In order to add an announcement bar, extend the theme and override the <code>announce</code> block, which is empty by default:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block announce %}\n  &lt;!-- Add announcement here, including arbitrary HTML --&gt;\n{% endblock %}\n</code></pre>"},{"location":"setup/setting-up-the-header/#mark-as-read","title":"Mark as read","text":"<p> 8.4.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>In order to render temporary announcements that can be marked as read by the user, a button to dismiss the current announcement can be included. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- announce.dismiss\n</code></pre> <p>When the user clicks the button, the current announcement is dismissed and not displayed again until the content of the announcement changes. This is handled automatically.</p> <p>Scroll to the top of this page to see it in action.</p>"},{"location":"setup/setting-up-versioning/","title":"Setting up versioning","text":"<p>Material for MkDocs makes it easy to deploy multiple versions of your project documentation by integrating with external utilities that add those capabilities to MkDocs, i.e. mike. When deploying a new version, older versions of your documentation remain untouched.</p>"},{"location":"setup/setting-up-versioning/#configuration","title":"Configuration","text":""},{"location":"setup/setting-up-versioning/#versioning","title":"Versioning","text":"<p> 7.0.0 \u00b7  Utility</p> <p>mike makes it easy to deploy multiple versions of your project documentation. It integrates natively with Material for MkDocs and can be enabled via <code>mkdocs.yml</code>:</p> <pre><code>extra:\nversion:\nprovider: mike\n</code></pre> <p>This renders a version selector in the header:</p> <p></p> <p>Check out the versioning example to see it in action \u2013 squidfunk.github.io/mkdocs-material-example-versioning</p> <p>Why use mike?</p> <p>mike is built around the idea that once you've generated your docs for a particular version, you should never need to touch that version again. This means you never have to worry about breaking changes in MkDocs, since your old docs (built with an old version of MkDocs) are already generated and sitting in your <code>gh-pages</code> branch.</p> <p>While mike is flexible, it's optimized around putting your docs in a <code>&lt;major&gt;.&lt;minor&gt;</code> directory, with optional aliases (e.g. <code>latest</code> or <code>dev</code>) to particularly notable versions. This makes it easy to make permalinks to whatever version of the documentation you want to direct people to.</p>"},{"location":"setup/setting-up-versioning/#version-warning","title":"Version warning","text":"<p> 8.0.0 \u00b7  Customization</p> <p>If you're using versioning, you might want to display a warning when the user visits any other version than the latest version. Using theme extension, you can override the <code>outdated</code> block:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block outdated %}\n  You're not viewing the latest version.\n  &lt;a href=\"{{ '../' ~ base_url }}\"&gt; &lt;!-- (1)! --&gt;\n&lt;strong&gt;Click here to go to latest.&lt;/strong&gt;\n&lt;/a&gt;\n{% endblock %}\n</code></pre> <ol> <li>Given this value for the <code>href</code> attribute, the link will always redirect to      the root of your site, which will then redirect to the latest version. This     ensures that older versions of your site do not depend on a specific alias,     e.g. <code>latest</code>, to allow for changing the alias later on without breaking     earlier versions.</li> </ol> <p>This will render a version warning above the header:</p> <p></p> <p>The default version is identified by the <code>latest</code> alias. If you wish to set another alias as the latest version, e.g. <code>stable</code>, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nversion:\ndefault: stable # (1)!\n</code></pre> <ol> <li> <p>You can also define multiple aliases as the default version, e.g. <code>stable</code>     and <code>development</code>.</p> <pre><code>extra:\nversion:\ndefault:\n- stable\n- development\n</code></pre> <p>Now every version that has the <code>stable</code> and <code>development</code> aliases will not display the version warning.</p> </li> </ol> <p>Make sure one alias matches the default version, as this is where users are redirected to.</p>"},{"location":"setup/setting-up-versioning/#usage","title":"Usage","text":"<p>While this section outlines the basic workflow for publishing new versions,  it's best to check out mike's documentation to make yourself familiar with its mechanics.</p>"},{"location":"setup/setting-up-versioning/#publishing-a-new-version","title":"Publishing a new version","text":"<p>If you want to publish a new version of your project documentation, choose a version identifier and update the alias set as the default version with:</p> <pre><code>mike deploy --push --update-aliases 0.1 latest\n</code></pre> <p>Note that every version will be deployed as a subdirectory of your <code>site_url</code>, e.g.:</p> <ul> <li>docs.example.com/0.1/</li> <li>docs.example.com/0.2/</li> <li>...</li> </ul>"},{"location":"setup/setting-up-versioning/#setting-a-default-version","title":"Setting a default version","text":"<p>When starting with mike, a good idea is to set an alias as a default version, e.g. <code>latest</code>, and when publishing a new version, always update the alias to point to the latest version:</p> <pre><code>mike set-default --push latest\n</code></pre> <p>When publishing a new version, mike will create a redirect in the root of your project documentation to the version associated with the alias:</p> <p>docs.example.com docs.example.com/0.1</p>"},{"location":"setup/dependencies/image-processing/","title":"Image processing","text":"<p>Material for MkDocs depends on several libraries to allow for image processing as part of the build pipeline, including social cards and image optimization. For this reason, a few external libraries must be installed on the host system. This section explains how to install them.</p>"},{"location":"setup/dependencies/image-processing/#dependencies","title":"Dependencies","text":"<p>Install the Python dependencies for image processing with:</p> <pre><code>pip install pillow cairosvg\n</code></pre>"},{"location":"setup/dependencies/image-processing/#cairo-graphics","title":"Cairo Graphics","text":"<p>Cairo Graphics is a graphics library and dependency of Pillow, which Material for MkDocs makes use of for generating social cards and performing image optimization. See the following section which explains how to install Cairo Graphics and its dependencies on your system:</p>  macOS Windows Linux <p>Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>As stated in the installation guide, the easiest way to get up and running with the Cairo Graphics library on Windows is by installing GTK+, since it has Cairo as a dependency. You can also download and install a precompiled GTK runtime.</p> <p>There are several package managers for Linux with varying availability per distribution. The installation guide explains how to install the Cairo Graphics library for your distribution:</p>  Ubuntu Fedora openSUSE <pre><code>apt-get install libcairo2-dev libfreetype6-dev libffi-dev libjpeg-dev libpng-dev libz-dev\n</code></pre> <pre><code>yum install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel\n</code></pre> <pre><code>zypper install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel\n</code></pre> <p>The following environments come with a preinstalled version of Cairo Graphics:</p> <ul> <li> No installation needed in Docker image</li> <li> No installation needed in GitHub Actions (Ubuntu)</li> </ul>"},{"location":"setup/dependencies/image-processing/#pngquant","title":"pngquant","text":"<p>pngquant is an excellent library for lossy PNG compression, and a direct dependency of the built-in optimize plugin. See the following section which  explains how to install pngquant system:</p>  macOS Windows Linux <p>Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies:</p> <pre><code>brew install pngquant\n</code></pre> <p>Installing pngquant on Windows is a little more involved. The  pngquant-winbuild repository contains a guide on how to set up an  environment for building pngquant on Windows.</p> <p>All popular Linux distributions, regardless of package manager, should allow to install pngquant with the bundled package manager. For example, on Ubuntu, pngquant can be installed with:</p> <pre><code>apt-get install pngquant\n</code></pre> <p>The same is true for <code>yum</code> and <code>zypper</code>.</p>"},{"location":"setup/extensions/","title":"Extensions","text":"<p>Markdown is a very small language with a kind-of reference implementation called John Gruber's Markdown. Python Markdown and Python Markdown Extensions are two packages that enhance the Markdown writing experience, adding useful syntax extensions for technical writing.</p>"},{"location":"setup/extensions/#supported-extensions","title":"Supported extensions","text":"<p>The following extensions are all supported by Material for MkDocs and therefore  strongly recommended. Click on each extension to learn about its purpose and configuration:</p> <ul> <li>Abbreviations</li> <li>Admonition</li> <li>Arithmatex</li> <li>Attribute Lists</li> <li>BetterEm</li> <li>Caret, Mark &amp; Tilde</li> <li>Critic</li> <li>Definition Lists</li> <li>Details</li> <li>Emoji</li> <li>Footnotes</li> <li>Highlight</li> <li>Keys</li> <li>Markdown in HTML</li> <li>SmartSymbols</li> <li>Snippets</li> <li>SuperFences</li> <li>Tabbed</li> <li>Table of Contents</li> <li>Tables</li> <li>Tasklist</li> </ul>"},{"location":"setup/extensions/#configuration","title":"Configuration","text":"<p>Extensions are configured as part of <code>mkdocs.yml</code> \u2013 the MkDocs configuration file. The following sections contain two example configurations to bootstrap your documentation project.</p>"},{"location":"setup/extensions/#minimal-configuration","title":"Minimal configuration","text":"<p>This configuration is a good starting point for when you're using Material for  MkDocs for the first time. The best idea is to explore the reference, and  gradually add what you want to use:</p> <pre><code>markdown_extensions:\n# Python Markdown\n- toc:\npermalink: true\n# Python Markdown Extensions\n- pymdownx.highlight\n- pymdownx.superfences\n</code></pre>"},{"location":"setup/extensions/#recommended-configuration","title":"Recommended configuration","text":"<p>This configuration enables all Markdown-related features of Material for MkDocs and is great for experienced users bootstrapping a new documentation project:</p> <pre><code>markdown_extensions:\n# Python Markdown\n- abbr\n- admonition\n- attr_list\n- def_list\n- footnotes\n- md_in_html\n- toc:\npermalink: true\n# Python Markdown Extensions\n- pymdownx.arithmatex:\ngeneric: true\n- pymdownx.betterem:\nsmart_enable: all\n- pymdownx.caret\n- pymdownx.details\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\n- pymdownx.highlight\n- pymdownx.inlinehilite\n- pymdownx.keys\n- pymdownx.mark\n- pymdownx.smartsymbols\n- pymdownx.superfences\n- pymdownx.tabbed:\nalternate_style: true\n- pymdownx.tasklist:\ncustom_checkbox: true\n- pymdownx.tilde\n</code></pre>"},{"location":"setup/extensions/python-markdown-extensions/","title":"Python Markdown Extensions","text":"<p>The Python Markdown Extensions package is an excellent collection of additional extensions perfectly suited for advanced technical writing. Material for MkDocs lists this package as an explicit dependency, so it's automatically installed with a supported version.</p>"},{"location":"setup/extensions/python-markdown-extensions/#supported-extensions","title":"Supported extensions","text":"<p>In general, all extensions that are part of Python Markdown Extensions should work with Material for MkDocs. The following list includes all extensions that are natively supported, meaning they work without any further adjustments.</p>"},{"location":"setup/extensions/python-markdown-extensions/#arithmatex","title":"Arithmatex","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Arithmatex extension allows for rendering of block and inline block equations and integrates seamlessly with MathJax1 \u2013 a library for mathematical typesetting. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.arithmatex:\ngeneric: true\n</code></pre> <p>Besides enabling the extension in <code>mkdocs.yml</code>, a MathJax configuration and  the JavaScript runtime need to be included, which can be done with a few lines of additional JavaScript:</p> <code>docs/javascripts/mathjax.js</code> <code>mkdocs.yml</code> <pre><code>window.MathJax = {\ntex: {\ninlineMath: [[\"\\\\(\", \"\\\\)\"]],\ndisplayMath: [[\"\\\\[\", \"\\\\]\"]],\nprocessEscapes: true,\nprocessEnvironments: true\n},\noptions: {\nignoreHtmlClass: \".*|\",\nprocessHtmlClass: \"arithmatex\"\n}\n};\ndocument$.subscribe(() =&gt; {\nMathJax.typesetPromise()\n})\n</code></pre> <pre><code>extra_javascript:\n- javascripts/mathjax.js\n- https://polyfill.io/v3/polyfill.min.js?features=es6\n- https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using block syntax</li> <li>Using inline block syntax</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#betterem","title":"BetterEm","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The BetterEm extension improves the detection of Markup to emphasize text in Markdown using special characters, i.e. for <code>**bold**</code> and <code>_italic_</code> formatting. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.betterem\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the BetterEm  documentation for more information.</p>"},{"location":"setup/extensions/python-markdown-extensions/#caret-mark-tilde","title":"Caret, Mark &amp; Tilde","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Caret, Mark and Tilde extensions add the ability to highlight text and define sub- and superscript using a simple syntax. Enable them together via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.caret\n- pymdownx.mark\n- pymdownx.tilde\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Caret, Mark and Tilde documentation for guidance.</p> <p>See reference for usage:</p> <ul> <li>Highlighting text</li> <li>Sub- and superscripts</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#critic","title":"Critic","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Critic extension allows for the usage of Critic Markup to highlight added, deleted or updated sections in a document, i.e. for tracking changes in Markdown syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.critic\n</code></pre> <p>The following configuration options are supported:</p> <code>mode</code> <p> Default: <code>view</code> \u2013 This option defines how the markup  should be parsed, i.e. whether to just <code>view</code> all suggested changes, or alternatively <code>accept</code> or <code>reject</code> them:</p> View changesAccept changesReject changes <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: view\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: accept\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: reject\n</code></pre> <p>See reference for usage:</p> <ul> <li>Highlighting changes</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#details","title":"Details","text":"<p> 1.9.0 \u00b7  Extension</p> <p>The Details extension supercharges the Admonition extension, making the resulting call-outs collapsible, allowing them to be opened and closed by the user. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.details\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Collapsible blocks</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#emoji","title":"Emoji","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Emoji extension automatically inlines bundled and custom icons and emojis in <code>*.svg</code> file format into the resulting HTML page. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji # (1)!\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <ol> <li>Python Markdown Extensions uses the <code>pymdownx</code> namespace, but in order to     support the inlining of icons, the <code>materialx</code> namespace must be used, as it     extends the functionality of <code>pymdownx</code>.</li> </ol> <p>The following configuration options are supported:</p> <code>emoji_index</code> <p> Default: <code>emojione</code> \u2013 This option defines which set of emojis is used for rendering. Note that the use of <code>emojione</code> is not recommended due to restrictions in licensing:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\n</code></pre> <code>emoji_generator</code> <p> Default: <code>to_png</code> \u2013 This option defines how the resolved emoji or icon shortcode is render. Note that icons can only be used together with the <code>to_svg</code> configuration:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <code>options.custom_icons</code> <p> Default: none \u2013 This option allows to list folders with additional icon sets to be used in Markdown or <code>mkdocs.yml</code>, which is  explained in more detail in the icon customization guide:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\noptions:\ncustom_icons:\n- overrides/.icons\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using emojis</li> <li>Using icons</li> <li>Using icons in templates</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#highlight","title":"Highlight","text":"<p> 5.0.0 \u00b7  Extension \u00b7  Supersedes CodeHilite</p> <p>The Highlight extension adds support for syntax highlighting of code blocks (with the help of SuperFences) and inline code blocks (with the help of InlineHilite). Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\n- pymdownx.superfences # (1)!\n</code></pre> <ol> <li>Highlight is used by the SuperFences extension to     perform syntax highlighting on code blocks, not the other way round, which     is why this extension also needs to be enabled.</li> </ol> <p>The following configuration options are supported:</p> <code>use_pygments</code> <p> Default: <code>true</code> \u2013 This option allows to control whether highlighting should be carried out during build time using Pygments or in the browser with a JavaScript syntax highlighter:</p> PygmentsJavaScript <pre><code>markdown_extensions:\n- pymdownx.highlight:\nuse_pygments: true\n- pymdownx.superfences\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nuse_pygments: false\n</code></pre> <p>As an example, Highlight.js, a JavaScript syntax highlighter, can be  integrated with some additional JavaScript and an additional style sheet in <code>mkdocs.yml</code>:</p> <code>docs/javascripts/highlight.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(() =&gt; {\nhljs.highlightAll()\n})\n</code></pre> <pre><code>extra_javascript:\n- https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js\n- javascripts/highlight.js\nextra_css:\n- https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css\n</code></pre> <p>Note that Highlight.js has no affiliation with the Highlight extension.</p> <p>All following configuration options are only compatible with build-time syntax highlighting using Pygments, so they don't apply if <code>use_pygments</code> is set to <code>false</code>.</p> <code>pygments_lang_class</code> <p> Default: <code>false</code> \u2013 This option instructs Pygments to add a CSS class to identify the language of the code block, which is essential for custom annotation markers to function:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\npygments_lang_class: true\n</code></pre> <code>auto_title</code> <p> Default: <code>false</code> \u2013 This option will automatically add a title to all code blocks that shows the name of the language being used, e.g. <code>Python</code> is printed for a <code>py</code> block:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nauto_title: true\n</code></pre> <code>linenums</code> <p> Default: <code>false</code> \u2013 This option will add line numbers to all code blocks. If you wish to add line numbers to some, but not all code blocks, consult the section on adding line numbers in the code block reference, which also contains some tips on working with line numbers:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nlinenums: true\n</code></pre> <code>linenums_style</code> <p> Default: <code>table</code> \u2013 The Highlight extension provides three ways to add line numbers, two of which are supported by Material for MkDocs. While <code>table</code> wraps a code block in a <code>&lt;table&gt;</code> element, <code>pymdownx-inline</code> renders line numbers as part of the line itself:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nlinenums_style: pymdownx-inline\n</code></pre> <p>Note that <code>inline</code> will put line numbers next to the actual code, which means that they will be included when selecting text with the cursor or  copying a code block to the clipboard. Thus, the usage of either <code>table</code> or <code>pymdownx-inline</code> is recommended.</p> <code>anchor_linenums</code> <p> 8.1.0 \u00b7  Default: <code>false</code> \u2013 If a code blocks contains line numbers, enabling this setting will wrap them with anchor links, so they can be hyperlinked and shared more easily:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\n</code></pre> <code>line_spans</code> <p> Default: none \u2013 When this option is set, each line of a code block is wrapped in a <code>span</code>, which is essential for features like line highlighting to work correctly:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nline_spans: __span\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using code blocks</li> <li>Adding a title</li> <li>Adding line numbers</li> <li>Highlighting specific lines</li> <li>Custom syntax theme</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#inlinehilite","title":"InlineHilite","text":"<p> 5.0.0 \u00b7  Extension</p> <p>The InlineHilite extension add support for syntax highlighting of inline code  blocks. It's built on top of the Highlight extension, from which it sources its configuration. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight\n- pymdownx.inlinehilite\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the <code>css_class</code> option, which must not be changed. See the  InlineHilite documentation for guidance.</p> <p>See reference for usage:</p> <ul> <li>Highlighting inline code blocks</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#keys","title":"Keys","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Keys extension adds a simple syntax to allow for the rendering of keyboard  keys and combinations, e.g. Ctrl+Alt+Del. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.keys\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the <code>class</code> option, which must not be changed. See the  Keys documentation for more information.</p> <p>See reference for usage:</p> <ul> <li>Adding keyboard keys</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#smartsymbols","title":"SmartSymbols","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The SmartSymbols extension converts some sequences of characters into their  corresponding symbols, e.h. copyright symbols or fractions. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.smartsymbols\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the SmartSymbols  documentation for guidance.</p>"},{"location":"setup/extensions/python-markdown-extensions/#snippets","title":"Snippets","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Snippets extension adds the ability to embed content from arbitrary files into a document, including other documents or source files, by using a simple syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.snippets\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Snippets  documentation for more information.</p> <p>See reference for usage:</p> <ul> <li>Adding a glossary</li> <li>Embedding external files</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#superfences","title":"SuperFences","text":"<p> 0.1.0 \u00b7  Extension \u00b7  Supersedes Fenced Code Blocks</p> <p>The SuperFences extension allows for arbitrary nesting of code and content blocks inside each other, including admonitions, tabs, lists and all other elements. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences\n</code></pre> <p>The following configuration options are supported:</p> <code>custom_fences</code> <p> Default: none \u2013 This option allows to define a handler for custom fences, e.g. to preserve the definitions of Mermaid.js diagrams to be interpreted in the browser:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <p>Note that this will primarily prevent syntax highlighting from being applied. See the reference on diagrams to learn how Mermaid.js is integrated with Material for MkDocs.</p> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using code blocks</li> <li>Using content tabs</li> <li>Using flowcharts</li> <li>Using sequence diagrams</li> <li>Using state diagrams</li> <li>Using class diagrams</li> <li>Using entity-relationship diagrams</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#tabbed","title":"Tabbed","text":"<p> 5.0.0 \u00b7  Extension</p> <p>The Tabbed extension allows the usage of content tabs, a simple way to group related content and code blocks under accessible tabs. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true\n</code></pre> <p>The following configuration options are supported:</p> <code>alternate_style</code> <p> 7.3.1 \u00b7  Default: <code>false</code> \u00b7  Required \u2013  This option enables the content tabs alternate style, which has better behavior on mobile viewports, and is the only supported style:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true\n</code></pre> <code>slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions:</p> UnicodeUnicode, case-sensitive <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Grouping code blocks</li> <li>Grouping other content</li> <li>Embedded content</li> </ul>"},{"location":"setup/extensions/python-markdown-extensions/#tasklist","title":"Tasklist","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Tasklist extension allows for the usage of GitHub Flavored Markdown inspired task lists, following the same syntactical conventions. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <p>The following configuration options are supported:</p> <code>custom_checkbox</code> <p> Default: <code>false</code> \u00b7 This option toggles the rendering style of checkboxes, replacing native checkbox styles with beautiful icons,  and is therefore recommended:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <code>clickable_checkbox</code> <p> Default: <code>false</code> \u00b7 This option toggles whether checkboxes are clickable. As the state is not persisted, the use of this  option is rather discouraged from a user experience perspective:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\nclickable_checkbox: true\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using task lists</li> </ul> <ol> <li> <p>Other libraries like KaTeX are also supported and can be integrated with some additional effort. See the Arithmatex documentation on KaTeX for further guidance, as this is beyond the scope of Material for MkDocs.\u00a0\u21a9</p> </li> </ol>"},{"location":"setup/extensions/python-markdown/","title":"Python Markdown","text":"<p>Material for MkDocs supports a large number of Python Markdown extensions, which is part of what makes it so attractive for technical writing. Following is a list of all supported extensions, linking to the relevant sections of the reference for which features they need to be enabled.</p>"},{"location":"setup/extensions/python-markdown/#supported-extensions","title":"Supported extensions","text":""},{"location":"setup/extensions/python-markdown/#abbreviations","title":"Abbreviations","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Abbreviations extension adds the ability to add a small tooltip to an element, by wrapping it with an <code>abbr</code> tag. Only plain text (no markup) is supported. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- abbr\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Adding abbreviations</li> <li>Adding a glossary</li> </ul>"},{"location":"setup/extensions/python-markdown/#admonition","title":"Admonition","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Admonition extension adds support for admonitions, more commonly known as  call-outs, which can be defined in Markdown by using a simple syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- admonition\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Adding admonitions</li> <li>Changing the title</li> <li>Removing the title</li> <li>Supported types</li> </ul>"},{"location":"setup/extensions/python-markdown/#attribute-lists","title":"Attribute Lists","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Attribute Lists extension allows to add HTML attributes and CSS classes to almost every Markdown inline- and block-level element with a special syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using grids</li> <li>Adding buttons</li> <li>Adding tooltips</li> <li>Using icons with colors</li> <li>Using icons with animations</li> <li>Image alignment</li> <li>Image lazy-loading</li> </ul>"},{"location":"setup/extensions/python-markdown/#definition-lists","title":"Definition Lists","text":"<p> 1.1.0 \u00b7  Extension</p> <p>The Definition Lists extension adds the ability to add definition lists (more commonly known as description lists \u2013 <code>dl</code> in HTML) via Markdown to a document. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- def_list\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using definition lists</li> </ul>"},{"location":"setup/extensions/python-markdown/#footnotes","title":"Footnotes","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Footnotes extension allows to define inline footnotes, which are then rendered below all Markdown content of a document. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- footnotes\n</code></pre> <p>No configuration options are supported. See reference for usage:</p> <ul> <li>Adding footnote references</li> <li>Adding footnote content</li> </ul>"},{"location":"setup/extensions/python-markdown/#markdown-in-html","title":"Markdown in HTML","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Markdown in HTML extension allows for writing Markdown inside of HTML, which is useful for wrapping Markdown content with custom elements. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- md_in_html\n</code></pre> <p>By default, Markdown ignores any content within a raw HTML block-level element. With the <code>md_in_html</code> extension enabled, the content of a raw HTML block-level element can be parsed as Markdown by including a <code>markdown</code> attribute on the opening tag. The <code>markdown</code> attribute will be stripped from the output, while all other attributes will be preserved.</p> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using grids</li> <li>Image captions</li> </ul>"},{"location":"setup/extensions/python-markdown/#table-of-contents","title":"Table of Contents","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Table of Contents extension automatically generates a table of contents from a document, which Material for MkDocs will render as part of the resulting  page. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- toc:\npermalink: true\n</code></pre> <p>The following configuration options are supported:</p> <code>title</code> <p> 7.3.5 \u00b7  Default: automatically set \u2013 This option sets the title of the table of contents in the right navigation sidebar, which is normally automatically sourced from the translations for the site language as set in <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- toc:\ntitle: On this page\n</code></pre> <code>permalink</code> <p> Default: <code>false</code> \u2013 This option adds an anchor link containing the paragraph symbol <code>\u00b6</code> or another custom symbol at the end of each headline, exactly like on the page you're currently viewing, which Material for MkDocs will make appear on hover:</p> \u00b6\u2693\ufe0e <pre><code>markdown_extensions:\n- toc:\npermalink: true\n</code></pre> <pre><code>markdown_extensions:\n- toc:\npermalink: \u2693\ufe0e\n</code></pre> <code>permalink_title</code> <p> Default: <code>Permanent link</code> \u2013 This option sets the title of the anchor link which is shown on hover and read by screen readers. For accessibility reasons, it might be beneficial to change it to a more  discernable name, stating that the anchor links to the section itself:</p> <pre><code>markdown_extensions:\n- toc:\npermalink_title: Anchor link to this section for reference\n</code></pre> <code>slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions:</p> UnicodeUnicode, case-sensitive <pre><code>markdown_extensions:\n- toc:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>markdown_extensions:\n- toc:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>toc_depth</code> <p> Default: <code>6</code> \u2013 Define the range of levels to be included in the table of contents. This may be useful for project documentation with deeply structured headings to decrease the length of the table of contents, or to remove the table of contents altogether:</p> Hide levels 4-6Hide table of contents <pre><code>markdown_extensions:\n- toc:\ntoc_depth: 3\n</code></pre> <pre><code>markdown_extensions:\n- toc:\ntoc_depth: 0\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"setup/extensions/python-markdown/#tables","title":"Tables","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Tables extension adds the ability to create tables in Markdown by using a  simple syntax. Enable it via <code>mkdocs.yml</code> (albeit it should be enabled by default):</p> <pre><code>markdown_extensions:\n- tables\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using data tables</li> <li>Column alignment</li> </ul>"},{"location":"setup/extensions/python-markdown/#superseded-extensions","title":"Superseded extensions","text":"<p>The following Python Markdown extensions are not (or might not be) supported  anymore, and are therefore not recommended for use. Instead, the alternatives should be considered.</p>"},{"location":"setup/extensions/python-markdown/#fenced-code-blocks","title":"Fenced Code Blocks","text":"<p> 0.1.0 \u00b7  Extension</p> <p>Superseded by SuperFences. This extension might still work, but the SuperFences extension is superior in many ways, as it allows for arbitrary  nesting, and is therefore recommended.</p>"},{"location":"setup/extensions/python-markdown/#codehilite","title":"CodeHilite","text":"<p> 0.1.0 ... 5.5.14 \u00b7  Extension</p> <p>Superseded by Highlight. Support for CodeHilite was dropped in  6.0.0, as Highlight has a better integration with other  essential extensions like SuperFences and InlineHilite.</p>"},{"location":"v10/","title":"Index","text":"<p>Welcome to Material for MkDocs.</p>"},{"location":"v10/alternatives/","title":"Alternatives","text":"<p>There are tons of static site generators and themes out there and choosing the right one for your tech stack is a tough decision. If you're unsure if Material for MkDocs is the right solution for you, this section should help you evaluate alternative solutions.</p>"},{"location":"v10/alternatives/#docusaurus","title":"Docusaurus","text":"<p>Docusaurus by Facebook is a very popular documentation generator and a good choice if you or your company are already using React to build your site. It will generate a single page application which is fundamentally different from the site Material for MkDocs generates for you.</p> <p>Advantages</p> <ul> <li>Very powerful, customizable and extendable</li> <li>Provides many components that aid in technical writing</li> <li>Large and rich ecosystem, backed by Facebook</li> </ul> <p>Challenges</p> <ul> <li>High learning curve, JavaScript knowledge mandatory</li> <li>JavaScript ecosystem is very volatile, rather high maintenance</li> <li>More time needed to get up and running</li> </ul> <p>While Docusaurus is one of the best choices when it comes to documentation sites that output a single page application, there are many more solutions, including Docz, Gatsby, Vuepress and Docsify that approach this problem similarly.</p>"},{"location":"v10/alternatives/#jekyll","title":"Jekyll","text":"<p>Jekyll is probably one of the most mature and widespread static site generators and is written in Ruby. It is not specifically geared towards technical project documentation and has many themes to choose from, which can be challenging.</p> <p>Advantages</p> <ul> <li>Battle-tested, rich ecosystem, many themes to choose from</li> <li>Brings great capabilities for blogging  (permalinks, tags, etc.)</li> <li>Generates a SEO-friendly site, similar to Material for MkDocs</li> </ul> <p>Challenges</p> <ul> <li>Not specifically geared towards technical project documentation</li> <li>Limited Markdown capabilities, not as advanced as Python Markdown</li> <li>More time needed to get up and running</li> </ul>"},{"location":"v10/alternatives/#sphinx","title":"Sphinx","text":"<p>Sphinx is an alternative static site generator specifically geared towards generating reference documentation, offering powerful capabilities that are lacking in MkDocs. It uses reStructured text, a format similar to Markdown, which some users find harder to use.</p> <p>Advantages</p> <ul> <li>Very powerful, customizable and extendable</li> <li>Generates reference documentation from Python docstrings</li> <li>Large and rich ecosystem, used by many Python projects</li> </ul> <p>Challenges</p> <ul> <li>High learning curve, reStructured text syntax might be challenging</li> <li>Search is less powerful than the one provided by MkDocs</li> <li>More time needed to get up and running</li> </ul> <p>If you're considering using Sphinx because you need to generate reference documentation, you should give mkdocstrings a try \u2013 an actively maintained and popular framework building on top of MkDocs, implementing Sphinx-like functionality.</p>"},{"location":"v10/alternatives/#gitbook","title":"GitBook","text":"<p>GitBook offers a hosted documentation solution that generates a beautiful and functional site from Markdown files in your GitHub repository. However, it was once Open Source, but turned into a closed source solution some time ago.</p> <p>Advantages</p> <ul> <li>Hosted solution, minimal technical knowledge required</li> <li>Custom domains, authentication and other enterprise features</li> <li>Great collaboration features for teams</li> </ul> <p>Challenges</p> <ul> <li>Closed source, not free for proprietary projects</li> <li>Limited Markdown capabilities, not as advanced as Python Markdown</li> <li>Many Open Source projects moved away from GitBook</li> </ul> <p>Many users switched from GitBook to Material for MkDocs, as they want to keep control and ownership of their documentation, favoring an Open Source solution.</p>"},{"location":"v10/browser-support/","title":"Browser support","text":"<p>Material for MkDocs goes at great lengths to support the largest possible range of browsers while retaining the simplest possibilities for customization via modern CSS features like custom properties and mask images.</p>"},{"location":"v10/browser-support/#supported-browsers","title":"Supported browsers","text":"<p>The following table lists all browsers for which Material for MkDocs offers full support, so it can be assumed that all features work without degradation. If you find that something doesn't look right in a browser which is in the supported version range, please open an issue:</p> Browser Version Release date Usage desktop mobile overall  Chrome 49+ 03/2016 25.65% 38.33% 63.98%  Safari 10+ 09/2016 4.63% 14.96% 19.59%  Edge 79+ 01/2020 3.95% n/a 3.95%  Firefox 53+ 04/2017 3.40% .30% 3.70%  Opera 36+ 03/2016 1.44% .01% 1.45% 92.67% <p>Browser support matrix sourced from caniuse.com.1</p> <p>Note that the usage data is based on global browser market share, so it could in fact be entirely different for your target demographic. It's a good idea to check the distribution of browser types and versions among your users.</p>"},{"location":"v10/browser-support/#other-browsers","title":"Other browsers","text":"<p>Albeit your site might not look as perfect as when viewed with a modern browser, the following older browser versions might work with some additional effort:</p> <ul> <li> Firefox 31-52 \u2013 icons will render as little   boxes due to missing support for mask images. While this cannot be   polyfilled, it might be mitigated by hiding the icons altogether.</li> <li> Edge 16-18 \u2013 the spacing of some elements might   be a little off due to missing support for the :is pseudo selector, which   can be mitigated with some additional effort.</li> <li> Internet Explorer - no support,   mainly due to missing support for custom properties. The last version of   Material for MkDocs to support Internet Explorer is    4.6.3.</li> </ul> <ol> <li> <p>The data was collected from caniuse.com in January 2022, and is primarily based on browser support for custom properties, mask images and the :is pseudo selector which are not entirely polyfillable. Browsers with a cumulated market share of less than 1% were not considered, but might still be fully or partially supported.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/creating-your-site/","title":"Creating your site","text":"<p>After you've installed Material for MkDocs, you can bootstrap your project  documentation using the <code>mkdocs</code> executable. Go to the directory where you want your project to be located and enter:</p> <pre><code>mkdocs new .\n</code></pre> <p>Alternatively, if you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material new .\n</code></pre> <pre><code>docker run --rm -it -v \"%cd%\":/docs squidfunk/mkdocs-material new .\n</code></pre> <p>This will create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre>"},{"location":"v10/creating-your-site/#configuration","title":"Configuration","text":""},{"location":"v10/creating-your-site/#minimal-configuration","title":"Minimal configuration","text":"<p>Simply add the following lines to <code>mkdocs.yml</code> to enable the theme:</p> <pre><code>theme:\nname: material\n</code></pre> Recommended: configuration validation and auto-complete <p>In order to minimize friction and maximize productivity, Material for MkDocs  provides its own schema.json1 for <code>mkdocs.yml</code>. If your editor supports YAML schema validation, it's definitely recommended to set it up:</p> Visual Studio CodeOther <ol> <li>Install <code>vscode-yaml</code> for YAML language support.</li> <li> <p>Add the schema under the <code>yaml.schemas</code> key in your user or     workspace <code>settings.json</code>:</p> <pre><code>{\n\"yaml.schemas\": {\n\"https://squidfunk.github.io/mkdocs-material/schema.json\": \"mkdocs.yml\"\n},\n\"yaml.customTags\": [ // (1)!\n\"!ENV scalar\",\n\"!ENV sequence\",\n\"tag:yaml.org,2002:python/name:materialx.emoji.to_svg\",\n\"tag:yaml.org,2002:python/name:materialx.emoji.twemoji\",\n\"tag:yaml.org,2002:python/name:pymdownx.superfences.fence_code_format\"\n]\n}\n</code></pre> <ol> <li>This setting is necessary if you plan to use icons and emojis,     or Visual Studio Code will show errors on certain lines.</li> </ol> </li> </ol> <ol> <li>Ensure your editor of choice has support for YAML schema validation.</li> <li> <p>Add the following lines at the top of <code>mkdocs.yml</code>:</p> <pre><code># yaml-language-server: $schema=https://squidfunk.github.io/mkdocs-material/schema.json\n</code></pre> </li> </ol>"},{"location":"v10/creating-your-site/#advanced-configuration","title":"Advanced configuration","text":"<p>Material for MkDocs comes with many configuration options. The setup section explains in great detail how to configure and customize colors, fonts, icons and much more:</p> <ul> <li>Changing the colors</li> <li>Changing the fonts</li> <li>Changing the language</li> <li>Changing the logo and icons</li> <li>Ensuring data privacy</li> <li>Setting up navigation</li> <li>Setting up site search</li> <li>Setting up site analytics</li> <li>Setting up social cards</li> <li>Setting up a blog</li> <li>Setting up tags</li> <li>Setting up versioning</li> <li>Setting up the header</li> <li>Setting up the footer</li> <li>Adding a git repository</li> <li>Adding a comment system</li> <li>Building an optimized site</li> <li>Building for offline usage</li> </ul> <p>Furthermore, see the list of supported Markdown extensions that are natively integrated with Material for MkDocs, delivering an unprecedented low-effort technical writing experience.</p>"},{"location":"v10/creating-your-site/#previewing-as-you-write","title":"Previewing as you write","text":"<p>MkDocs includes a live preview server, so you can preview your changes as you write your documentation. The server will automatically rebuild the site upon saving. Start it with:</p> <pre><code>mkdocs serve # (1)!\n</code></pre> <ol> <li> <p>If you have a large documentation project, it might take minutes until     MkDocs has rebuilt all pages for you to preview. If you're only interested     in the current page, the <code>--dirtyreload</code> flag will make     rebuilds much faster:</p> <pre><code>mkdocs serve --dirtyreload\n</code></pre> </li> </ol> <p>If you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material\n</code></pre> <pre><code>docker run --rm -it -p 8000:8000 -v \"%cd%\":/docs squidfunk/mkdocs-material\n</code></pre> <p>Point your browser to localhost:8000 and you should see:</p> <p></p>"},{"location":"v10/creating-your-site/#building-your-site","title":"Building your site","text":"<p>When you're finished editing, you can build a static site from your Markdown files with:</p> <pre><code>mkdocs build\n</code></pre> <p>If you're running Material for MkDocs from within Docker, use:</p> Unix, PowershellWindows <pre><code>docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material build\n</code></pre> <pre><code>docker run --rm -it -v \"%cd%\":/docs squidfunk/mkdocs-material build\n</code></pre> <p>The contents of this directory make up your project documentation. There's no need for operating a database or server, as it is completely self-contained. The site can be hosted on GitHub Pages, GitLab Pages, a CDN of your choice or your private web space.</p> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>If you're a MkDocs plugin or Markdown extension author and your project works with Material for MkDocs, you're very much invited to contribute a schema for your extension or plugin as part of a pull request on GitHub. If you already have a schema defined, or wish to self-host your schema to reduce duplication, you can add it via $ref.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/customization/","title":"Customization","text":"<p>Project documentation is as diverse as the projects themselves and Material for MkDocs is a great starting point for making it look beautiful. However, as you write your documentation, you may reach a point where small adjustments are necessary to preserve your brand's style.</p>"},{"location":"v10/customization/#adding-assets","title":"Adding assets","text":"<p>MkDocs provides several ways to customize a theme. In order to make a few small tweaks to Material for MkDocs, you can just add CSS and JavaScript files to the <code>docs</code> directory.</p>"},{"location":"v10/customization/#additional-css","title":"Additional CSS","text":"<p>If you want to tweak some colors or change the spacing of certain elements, you can do this in a separate style sheet. The easiest way is by creating a new style sheet file in the <code>docs</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 stylesheets/\n\u2502     \u2514\u2500 extra.css\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"v10/customization/#additional-javascript","title":"Additional JavaScript","text":"<p>If you want to integrate another syntax highlighter or add some custom logic to your theme, create a new JavaScript file in the <code>docs</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 javascripts/\n\u2502     \u2514\u2500 extra.js\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra_javascript:\n- javascripts/extra.js\n</code></pre>"},{"location":"v10/customization/#extending-the-theme","title":"Extending the theme","text":"<p>If you want to alter the HTML source (e.g. add or remove some parts), you can extend the theme. MkDocs supports theme extension, an easy way to override parts of Material for MkDocs without forking from git. This ensures that you can update to the latest version more easily.</p>"},{"location":"v10/customization/#setup-and-theme-structure","title":"Setup and theme structure","text":"<p>Enable Material for MkDocs as usual in <code>mkdocs.yml</code>, and create a new folder for <code>overrides</code> which you then reference using the <code>custom_dir</code> setting:</p> <pre><code>theme:\nname: material\ncustom_dir: overrides\n</code></pre> <p>Theme extension prerequisites</p> <p>As the <code>custom_dir</code> setting is used for the theme extension process, Material for MkDocs needs to be installed via <code>pip</code> and referenced with the <code>name</code> setting in <code>mkdocs.yml</code>. It will not work when cloning from <code>git</code>.</p> <p>The structure in the <code>overrides</code> directory must mirror the directory structure of the original theme, as any file in the <code>overrides</code> directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 .icons/                             # Bundled icon sets\n\u251c\u2500 assets/\n\u2502  \u251c\u2500 images/                          # Images and icons\n\u2502  \u251c\u2500 javascripts/                     # JavaScript files\n\u2502  \u2514\u2500 stylesheets/                     # Style sheets\n\u251c\u2500 partials/\n\u2502  \u251c\u2500 integrations/                    # Third-party integrations\n\u2502  \u2502  \u251c\u2500 analytics/                    # Analytics integrations\n\u2502  \u2502  \u2514\u2500 analytics.html                # Analytics setup\n\u2502  \u251c\u2500 languages/                       # Translation languages\n\u2502  \u251c\u2500 actions.html                     # Actions\n\u2502  \u251c\u2500 comments.html                    # Comment system (empty by default)\n\u2502  \u251c\u2500 consent.html                     # Consent\n\u2502  \u251c\u2500 content.html                     # Page content\n\u2502  \u251c\u2500 copyright.html                   # Copyright and theme information\n\u2502  \u251c\u2500 feedback.html                    # Was this page helpful?\n\u2502  \u251c\u2500 footer.html                      # Footer bar\n\u2502  \u251c\u2500 header.html                      # Header bar\n\u2502  \u251c\u2500 icons.html                       # Custom icons\n\u2502  \u251c\u2500 language.html                    # Translation setup\n\u2502  \u251c\u2500 logo.html                        # Logo in header and sidebar\n\u2502  \u251c\u2500 nav.html                         # Main navigation\n\u2502  \u251c\u2500 nav-item.html                    # Main navigation item\n\u2502  \u251c\u2500 pagination.html                  # Pagination (used for blog)\n\u2502  \u251c\u2500 post.html                        # Blog post excerpt\n\u2502  \u251c\u2500 search.html                      # Search interface\n\u2502  \u251c\u2500 social.html                      # Social links\n\u2502  \u251c\u2500 source.html                      # Repository information\n\u2502  \u251c\u2500 source-file.html                 # Source file information\n\u2502  \u251c\u2500 tabs.html                        # Tabs navigation\n\u2502  \u251c\u2500 tabs-item.html                   # Tabs navigation item\n\u2502  \u251c\u2500 tags.html                        # Tags\n\u2502  \u251c\u2500 toc.html                         # Table of contents\n\u2502  \u2514\u2500 toc-item.html                    # Table of contents item\n\u251c\u2500 404.html                            # 404 error page\n\u251c\u2500 base.html                           # Base template\n\u251c\u2500 blog.html                           # Blog index page\n\u251c\u2500 blog-archive.html                   # Blog archive index page\n\u251c\u2500 blog-category.html                  # Blog category index page\n\u251c\u2500 blog-post.html                      # Blog post page\n\u2514\u2500 main.html                           # Default page\n</code></pre>"},{"location":"v10/customization/#overriding-partials","title":"Overriding partials","text":"<p>In order to override a partial, we can replace it with a file of the same name and location in the <code>overrides</code> directory. For example, to replace the original <code>footer.html</code> partial, create a new <code>footer.html</code> partial in the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 partials/\n\u2502     \u2514\u2500 footer.html\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>MkDocs will now use the new partial when rendering the theme. This can be done with any file.</p>"},{"location":"v10/customization/#overriding-blocks","title":"Overriding blocks recommended","text":"<p>Besides overriding partials, it's also possible to override (and extend) template blocks, which are defined inside the templates and wrap specific features. In order to set up block overrides, create a <code>main.html</code> file inside the <code>overrides</code> directory:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 main.html\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, e.g. to override the site title, add the following lines to <code>main.html</code>:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block htmltitle %}\n  &lt;title&gt;Lorem ipsum dolor sit amet&lt;/title&gt;\n{% endblock %}\n</code></pre> <p>If you intend to add something to a block rather than to replace it altogether with new content, use <code>{{ super() }}</code> inside the block to include the  original block content. This is particularly useful when adding third-party scripts to your docs, e.g.</p> <pre><code>{% extends \"base.html\" %}\n\n{% block scripts %}\n  &lt;!-- Add scripts that need to run before here --&gt;\n  {{ super() }}\n  &lt;!-- Add scripts that need to run afterwards here --&gt;\n{% endblock %}\n</code></pre> <p>The following template blocks are provided by the theme:</p> Block name Purpose <code>analytics</code> Wraps the Google Analytics integration <code>announce</code> Wraps the announcement bar <code>config</code> Wraps the JavaScript application config <code>container</code> Wraps the main content container <code>content</code> Wraps the main content <code>extrahead</code> Empty block to add custom meta tags <code>fonts</code> Wraps the font definitions <code>footer</code> Wraps the footer with navigation and copyright <code>header</code> Wraps the fixed header bar <code>hero</code> Wraps the hero teaser (if available) <code>htmltitle</code> Wraps the <code>&lt;title&gt;</code> tag <code>libs</code> Wraps the JavaScript libraries (header) <code>outdated</code> Wraps the version warning <code>scripts</code> Wraps the JavaScript application (footer) <code>site_meta</code> Wraps the meta tags in the document head <code>site_nav</code> Wraps the site navigation and table of contents <code>styles</code> Wraps the style sheets (also extra sources) <code>tabs</code> Wraps the tabs navigation (if available)"},{"location":"v10/customization/#theme-development","title":"Theme development","text":"<p>Material for MkDocs is built on top of TypeScript, RxJS and SASS, and uses a lean, custom build process to put everything together.1 If you want to make more fundamental changes, it may be necessary to make the adjustments directly in the source of the theme and recompile it.</p>"},{"location":"v10/customization/#environment-setup","title":"Environment setup","text":"<p>In order to start development on Material for MkDocs, a Node.js version of at least 14 is required. First, clone the repository:</p> <pre><code>git clone https://github.com/squidfunk/mkdocs-material\n</code></pre> <p>Next, all dependencies need to be installed, which is done with:</p> <pre><code>cd mkdocs-material\npip install -e .\npip install mkdocs-minify-plugin\npip install mkdocs-redirects\nnpm install\n</code></pre>"},{"location":"v10/customization/#development-mode","title":"Development mode","text":"<p>Start the watcher with:</p> <pre><code>npm start\n</code></pre> <p>Then, in a second terminal window, start the MkDocs live preview server with:</p> <pre><code>mkdocs serve --watch-theme\n</code></pre> <p>Point your browser to localhost:8000 and you should see this very documentation in front of you.</p> <p>Automatically generated files</p> <p>Never make any changes in the <code>material</code> directory, as the contents of this directory are automatically generated from the <code>src</code> directory and will be overwritten when the theme is built.</p>"},{"location":"v10/customization/#building-the-theme","title":"Building the theme","text":"<p>When you're finished making your changes, you can build the theme by invoking:</p> <pre><code>npm run build # (1)!\n</code></pre> <ol> <li> <p>While this command will build all theme files, it will skip the overrides     used in Material for MkDocs' own documentation which are not distributed     with the theme. If you forked the theme and want to build the overrides     as well, use:</p> <pre><code>npm run build:all\n</code></pre> <p>This will take longer, as now the icon search index, schema files, as well as additional style sheet and JavaScript files are built.</p> </li> </ol> <p>This triggers the production-level compilation and minification of all style sheets and JavaScript files. After the command exits, the compiled files are located in the <code>material</code> directory. When running <code>mkdocs build</code>, you should now see your changes to the original theme.</p> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>Prior to  7.0.0 the build was based on Webpack, resulting in occasional broken builds due to incompatibilities with loaders and plugins. Therefore, we decided to swap Webpack for a leaner solution which is now based on RxJS as the application itself. This allowed for the pruning of more than 500 dependencies (~30% less).\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/getting-started/","title":"Getting started","text":"<p>Material for MkDocs is a powerful documentation framework on top of MkDocs, a static site generator for project documentation.1 If you're familiar with  Python, you can install Material for MkDocs with <code>pip</code>, the Python package manager. If not, we recommend using <code>docker</code>.</p>"},{"location":"v10/getting-started/#installation","title":"Installation","text":""},{"location":"v10/getting-started/#with-pip","title":"with pip recommended","text":"<p>Material for MkDocs is published as a Python package and can be installed with <code>pip</code>, ideally by using a virtual environment. Open up a terminal and install Material for MkDocs with:</p> Latest9.x <pre><code>pip install mkdocs-material\n</code></pre> <pre><code>pip install mkdocs-material==\"9.*\" # (1)!\n</code></pre> <ol> <li> <p>Material for MkDocs uses semantic versioning2, which is why it's a     good idea to limit upgrades to the current major version.</p> <p>This will make sure that you don't accidentally upgrade to the next major version, which may include breaking changes that silently corrupt your site. Additionally, you can use <code>pip freeze</code> to create a lockfile, so builds are reproducible at all times:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>Now, the lockfile can be used for installation:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> </ol> <p>This will automatically install compatible versions of all dependencies: MkDocs, Markdown, Pygments and Python Markdown Extensions. Material for MkDocs always strives to support the latest versions, so there's no need to install those packages separately.</p> <p> How to set up Material for MkDocs by @james-willett \u2013  15m \u2013 Learn how to create and host a documentation site using Material for  MkDocs on GitHub Pages in a step-by-step guide.</p> <p>Tip: If you don't have prior experience with Python, we recommend reading  Using Python's pip to Manage Your Projects' Dependencies, which is a really good introduction on the mechanics of Python package management and helps you troubleshoot if you run into errors.</p>"},{"location":"v10/getting-started/#with-docker","title":"with docker","text":"<p>The official Docker image is a great way to get up and running in a few minutes, as it comes with all dependencies pre-installed. Open up a terminal and pull the image with:</p> Latest9.x <pre><code>docker pull squidfunk/mkdocs-material\n</code></pre> <pre><code>docker pull squidfunk/mkdocs-material:9\n</code></pre> <p>The <code>mkdocs</code> executable is provided as an entry point and <code>serve</code> is the  default command. If you're not familiar with Docker don't worry, we have you covered in the following sections.</p> <p>The following plugins are bundled with the Docker image:</p> <ul> <li>mkdocs-minify-plugin</li> <li>mkdocs-redirects</li> </ul> How to add plugins to the Docker image? <p>Material for MkDocs only bundles selected plugins in order to keep the size of the official image small. If the plugin you want to use is not included, you can add them easily:</p> Material for MkDocsInsiders <p>Create a <code>Dockerfile</code> and extend the official image:</p> Dockerfile<pre><code>FROM squidfunk/mkdocs-material\nRUN pip install mkdocs-macros-plugin\nRUN pip install mkdocs-glightbox\n</code></pre> <p>Clone or fork the Insiders repository, and create a file called <code>user-requirements.txt</code> in the root of the repository. Then, add the plugins that should be installed to the file, e.g.:</p> user-requirements.txt<pre><code>mkdocs-macros-plugin\nmkdocs-glightbox\n</code></pre> <p>Next, build the image with the following command:</p> <pre><code>docker build -t squidfunk/mkdocs-material .\n</code></pre> <p>The new image will have additional packages installed and can be used exactly like the official image.</p>"},{"location":"v10/getting-started/#with-git","title":"with git","text":"<p>Material for MkDocs can be directly used from GitHub by cloning the repository into a subfolder of your project root which might be useful if you want to use the very latest version:</p> <pre><code>git clone https://github.com/squidfunk/mkdocs-material.git\n</code></pre> <p>The theme will reside in the folder <code>mkdocs-material/material</code>. After cloning from <code>git</code>, you must install all required dependencies with:</p> <pre><code>pip install -e mkdocs-material\n</code></pre> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p> <ol> <li> <p>In 2016, Material for MkDocs started out as a simple theme for MkDocs, but over the course of several years, it's now much more than that \u2013 with the many built-in plugins, settings, and countless customization abilities, Material for MkDocs is now one of the simplest and most powerful frameworks for creating documentation for your project.\u00a0\u21a9</p> </li> <li> <p>Note that improvements of existing features are sometimes released as patch releases, like for example improved rendering of content tabs, as they're not considered to be new features.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/license/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2016-2023 Martin Donath</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"v10/philosophy/","title":"Philosophy","text":"<p>Before settling for Material for MkDocs, it's a good idea to understand the philosophy behind the project, in order to make sure it aligns with your goals. This page explains the design principles anchored in Material for MkDocs, and discusses the conventions used in this documentation.</p>"},{"location":"v10/philosophy/#design-principles","title":"Design principles","text":"<ul> <li> <p>It's just Markdown: Focus on the content of your documentation and create   a professional static site in minutes. No need to know HTML,CSS or JavaScript   \u2013 let Material for MkDocs do the heavy lifting for you.</p> </li> <li> <p>Works on all devices: Serve your documentation with confidence \u2013 the    underlying layout automatically adapts to perfectly fit the available screen    estate, no matter the type or size of the viewing device.</p> </li> <li> <p>Made to measure: Change the colors, fonts, language, icons, logo and much   more with a few lines of configuration. Material for MkDocs can be easily    extended and provides tons of options to alter appearance and behavior.</p> </li> <li> <p>Fast and lightweight: Don't let your users wait \u2013 get incredible value   with a small footprint, by using one of the fastest themes around with   excellent performance, yielding great search engine rankings and happy   users that return.</p> </li> <li> <p>Accessible: Make accessibility a priority \u2013 users can navigate your   documentation with touch devices, keyboard, and screen readers. Semantic   markup ensures that your documentation works for everyone.</p> </li> <li> <p>Open Source: Trust 20,000+ users \u2013 choose a mature and well-funded   solution built with state-of-the-art Open Source technologies. Keep ownership   of your content without fear of vendor lock-in. Licensed under MIT.</p> </li> </ul>"},{"location":"v10/philosophy/#conventions","title":"Conventions","text":""},{"location":"v10/philosophy/#symbols","title":"Symbols","text":"<p>This documentation use some symbols for illustration purposes. Before you read on, please make sure you've made yourself familiar with the following list of conventions:</p>  \u00a0 Insiders <p>Some features are not yet available in the community edition, but only as part of the Insiders build of Material for MkDocs. Please consult the  Insiders guide to learn how to get access.</p> {x.x.x} <p>The tag icon in conjunction with a version number denotes when a specific  feature or behavior was added. Make sure you're at least on this version if you want to use it.</p> {file.ext} <p>The source file icon together with a file name is sometimes used in code examples which span multiple files. The file name (or path) always starts from the location of <code>mkdocs.yml</code>.</p> Default: value <p>Some properties in <code>mkdocs.yml</code> have default values for when the author does not explicitly define them. The default value of the property is always included.</p> Feature flag <p>Most of the features are hidden behind feature flags, which means they must be explicitly enabled via <code>mkdocs.yml</code>. This allows for the existence of potentially orthogonal features.</p> Experimental <p>Some newer features are still considered experimental, which means they might (although rarely) change at any time, including their complete removal  (which hasn't happened yet).</p> Plugin <p>Several features are implemented through MkDocs excellent plugin architecture, some of which are built-in and distributed with Material for MkDocs, so no installation is required.</p> Utility <p>Besides plugins, there are some utilities that build on top of MkDocs in order to provide extended functionality, like for example support for versioning.</p>"},{"location":"v10/publishing-your-site/","title":"Publishing your site","text":"<p>The great thing about hosting project documentation in a <code>git</code> repository is the ability to deploy it automatically when new changes are pushed. MkDocs makes this ridiculously simple.</p>"},{"location":"v10/publishing-your-site/#github-pages","title":"GitHub Pages","text":"<p>If you're already hosting your code on GitHub, GitHub Pages is certainly the most convenient way to publish your project documentation. It's free of charge and pretty easy to set up.</p>"},{"location":"v10/publishing-your-site/#with-github-actions","title":"with GitHub Actions","text":"<p>Using GitHub Actions you can automate the deployment of your project documentation. At the root of your repository, create a new GitHub Actions workflow, e.g. <code>.github/workflows/ci.yml</code>, and copy and paste the following contents:</p> Material for MkDocsInsiders <pre><code>name: ci # (1)!\non:\npush:\nbranches:\n- master # (2)!\n- main\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV # (3)!\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: pip install mkdocs-material # (4)!\n- run: mkdocs gh-deploy --force\n</code></pre> <ol> <li> <p>You can change the name to your liking. </p> </li> <li> <p>At some point, GitHub renamed <code>master</code> to <code>main</code>. If your default branch     is named <code>master</code>, you can safely remove <code>main</code>, vice versa.</p> </li> <li> <p>Store the <code>cache_id</code> environmental variable to access it later during cache     <code>key</code> creation. The name is case-sensitive, so be sure to align it with <code>${{ env.cache_id }}</code>.</p> <ul> <li>The <code>--utc</code> option makes sure that each workflow runner uses the same time zone.</li> <li>The <code>%V</code> format assures a cache update once a week. </li> <li>You can change the format to <code>%F</code> to have daily cache updates. </li> </ul> <p>You can read the manual page to learn more about the formatting options of the <code>date</code> command.</p> </li> <li> <p>This is the place to install further MkDocs plugins or Markdown     extensions with <code>pip</code> to be used during the build:</p> <pre><code>pip install \\\nmkdocs-material \\\nmkdocs-awesome-pages-plugin \\\n...\n</code></pre> </li> </ol> <pre><code>name: ci\non:\npush:\nbranches:\n- master\n- main\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nif: github.event.repository.fork == false\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: apt-get install pngquant # (1)!\n- run: pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n- run: mkdocs gh-deploy --force\nenv:\nGH_TOKEN: ${{ secrets.GH_TOKEN }} # (2)!\n</code></pre> <ol> <li> <p>This step is only necessary if you want to use the     built-in optimize plugin to automatically compress images.</p> </li> <li> <p>Remember to set the <code>GH_TOKEN</code> environment variable to the value of your     personal access token when deploying Insiders, which can be done     using GitHub secrets.</p> </li> </ol> <p>Now, when a new commit is pushed to either the <code>master</code> or <code>main</code> branches, the static site is automatically built and deployed. Push your changes to see the workflow in action.</p> <p>If the GitHub Page doesn't show up after a few minutes, go to the settings of your repository and ensure that the publishing source branch for your GitHub Page is set to <code>gh-pages</code>.</p> <p>Your documentation should shortly appear at <code>&lt;username&gt;.github.io/&lt;repository&gt;</code>.</p>"},{"location":"v10/publishing-your-site/#with-mkdocs","title":"with MkDocs","text":"<p>If you prefer to deploy your project documentation manually, you can just invoke the following command from the directory containing the <code>mkdocs.yml</code> file:</p> <pre><code>mkdocs gh-deploy --force\n</code></pre>"},{"location":"v10/publishing-your-site/#gitlab-pages","title":"GitLab Pages","text":"<p>If you're hosting your code on GitLab, deploying to GitLab Pages can be done by using the GitLab CI task runner. At the root of your repository, create a task definition named <code>.gitlab-ci.yml</code> and copy and paste the following contents:</p> Material for MkDocsInsiders <pre><code>image: python:latest\npages:\nstage: deploy\nscript:\n- pip install mkdocs-material\n- mkdocs build --site-dir public\nartifacts:\npaths:\n- public\nrules:\n- if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'\n</code></pre> <pre><code>image: python:latest\npages:\nstage: deploy\nscript: # (1)!\n- pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n- mkdocs build --site-dir public\nartifacts:\npaths:\n- public\nrules:\n- if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'\n</code></pre> <ol> <li>Remember to set the <code>GH_TOKEN</code> environment variable to the value of your     personal access token when deploying Insiders, which can be done     using masked custom variables.</li> </ol> <p>Now, when a new commit is pushed to <code>master</code>, the static site is automatically built and deployed. Commit and push the file to your repository to see the workflow in action.</p> <p>Your documentation should shortly appear at <code>&lt;username&gt;.gitlab.io/&lt;repository&gt;</code>.</p>"},{"location":"v10/publishing-your-site/#other","title":"Other","text":"<p>Since we can't cover all possible platforms, we rely on community contributed guides that explain how to deploy websites built with Material for MkDocs to other providers:</p> <ul> <li> Azure</li> <li> Cloudflare Pages</li> <li> DigitalOcean</li> <li> Netlify</li> <li> Vercel</li> </ul> <p>Enterprise support</p> <p>If you're using Material for MkDocs in your organization and need assistance, e.g., to reduce build times, improve performance or ensure compliance, get in touch to discuss our enterprise support offerings. We're happy to help!</p>"},{"location":"v10/upgrade/","title":"How to upgrade","text":"<p>Upgrade to the latest version with:</p> <pre><code>pip install --upgrade --force-reinstall mkdocs-material\n</code></pre> <p>Show the currently installed version with:</p> <pre><code>pip show mkdocs-material\n</code></pre>"},{"location":"v10/upgrade/#upgrading-from-8x-to-9x","title":"Upgrading from 8.x to 9.x","text":"<p>This major release includes a brand new search implementation that is faster and allows for rich previews, advanced tokenization and better highlighting. It was available as part of Insiders for over a year, and now that the funding goal was hit, makes its way into the community edition.</p>"},{"location":"v10/upgrade/#changes-to-mkdocsyml","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"v10/upgrade/#contentcodecopy","title":"<code>content.code.copy</code>","text":"<p>The copy-to-clipboard buttons are now opt-in and can be enabled or disabled per block. If you wish to enable them for all code blocks, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.code.copy\n</code></pre>"},{"location":"v10/upgrade/#contentaction","title":"<code>content.action.*</code>","text":"<p>A \"view source\" button can be shown next to the \"edit this page\" button, both of which must now be explicitly enabled. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.action.edit\n- content.action.view\n</code></pre>"},{"location":"v10/upgrade/#navigationfooter","title":"<code>navigation.footer</code>","text":"<p>The previous and next buttons in the footer are now opt-in. If you wish to keep them for your documentation, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.footer\n</code></pre>"},{"location":"v10/upgrade/#themelanguage","title":"<code>theme.language</code>","text":"<p>The Korean and Norwegian language codes were renamed, as they were non-standard:</p> <ul> <li><code>kr</code> to <code>ko</code></li> <li><code>no</code> to <code>nb</code></li> </ul>"},{"location":"v10/upgrade/#feedbackratings","title":"<code>feedback.ratings</code>","text":"<p>The old, nameless placeholders were removed (after being deprecated for several months). Make sure to switch to the new named placeholders <code>{title}</code> and <code>{url}</code>:</p> <pre><code>https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url}\n</code></pre>"},{"location":"v10/upgrade/#changes-to-html-files","title":"Changes to <code>*.html</code> files","text":"<p>The templates have undergone a series of changes. If you have customized Material for MkDocs with theme extension, be sure to incorporate the latest changes into your templates. A good starting point is to inspect the diff.</p> <p>Built-in plugins not working after upgrade?</p> <p>If one of the built-in plugins (search or tags) doesn't work anymore without any apparent error or cause, it is very likely related to custom overrides. MkDocs 1.4.1 and above allow themes to namespace built-in plugins, which Material for MkDocs 9 now does in order to allow authors to use third-party plugins with the same name as built-in plugins. Search your overrides for <code>\"in config.plugins\"</code> and add the <code>material/</code> namespace. Affected partials:</p> <ul> <li><code>content.html</code></li> <li><code>header.html</code></li> </ul>"},{"location":"v10/upgrade/#upgrading-from-7x-to-8x","title":"Upgrading from 7.x to 8.x","text":""},{"location":"v10/upgrade/#whats-new","title":"What's new?","text":"<ul> <li>Added support for code annotations</li> <li>Added support for anchor tracking</li> <li>Added support for version warning</li> <li>Added <code>copyright</code> partial for easier override</li> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integration \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"v10/upgrade/#changes-to-mkdocsyml_1","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"v10/upgrade/#pymdownxtabbed","title":"<code>pymdownx.tabbed</code>","text":"<p>Support for the legacy style of the Tabbed extension was dropped in favor of the new, alternate implementation which has better behavior on mobile  viewports:</p> 8.x7.x <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true </code></pre> <pre><code>markdown_extensions:\n- pymdownx.tabbed\n</code></pre>"},{"location":"v10/upgrade/#pymdownxsuperfences","title":"<code>pymdownx.superfences</code>","text":"<p>The <code>*-experimental</code> suffix must be removed from the custom fence class property, which is used to target code blocks to be rendered as diagrams using Mermaid.js:</p> 8.x7.x <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid-experimental\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre>"},{"location":"v10/upgrade/#google_analytics","title":"<code>google_analytics</code>","text":"<p>This option was deprecated in MkDocs 1.2.0, as the implementation of a JavaScript-based analytics integration is the responsibility of a theme. The following lines must be changed:</p> 8.x7.x <pre><code>extra:\nanalytics:\nprovider: google\nproperty: UA-XXXXXXXX-X\n</code></pre> <pre><code>google_analytics:\n- UA-XXXXXXXX-X\n- auto\n</code></pre>"},{"location":"v10/upgrade/#upgrading-from-6x-to-7x","title":"Upgrading from 6.x to 7.x","text":""},{"location":"v10/upgrade/#whats-new_1","title":"What's new?","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Added support for integrating a language selector</li> <li>Added support for rendering admonitions as inline blocks</li> <li>Rewrite of the underlying reactive architecture</li> <li>Removed Webpack in favor of reactive build strategy (\u2013480 dependencies)</li> <li>Fixed keyboard navigation for code blocks after content tabs switch</li> </ul>"},{"location":"v10/upgrade/#changes-to-mkdocsyml_2","title":"Changes to <code>mkdocs.yml</code>","text":""},{"location":"v10/upgrade/#extraversionmethod","title":"<code>extra.version.method</code>","text":"<p>The versioning method configuration was renamed to <code>extra.version.provider</code> to allow for different versioning strategies in the future:</p> 7.x6.x <pre><code>extra:\nversion:\nprovider: mike\n</code></pre> <pre><code>extra:\nversion:\nmethod: mike\n</code></pre>"},{"location":"v10/upgrade/#upgrading-from-5x-to-6x","title":"Upgrading from 5.x to 6.x","text":""},{"location":"v10/upgrade/#whats-new_2","title":"What's new?","text":"<ul> <li>Improved search result look and feel</li> <li>Improved search result stability while typing</li> <li>Improved search result grouping (pages + headings)</li> <li>Improved search result relevance and scoring</li> <li>Added display of missing query terms to search results</li> <li>Reduced size of vendor bundle by 25% (84kb \u2192 67kb)</li> <li>Reduced size of the Docker image to improve CI build performance</li> <li>Removed hero partial in favor of custom implementation</li> <li>Removed deprecated front matter features</li> </ul>"},{"location":"v10/upgrade/#changes-to-mkdocsyml_3","title":"Changes to <code>mkdocs.yml</code>","text":"<p>Following is a list of changes that need to be made to <code>mkdocs.yml</code>. Note that you only have to adjust the value if you defined it, so if your configuration does not contain the key, you can skip it.</p>"},{"location":"v10/upgrade/#themefeatures","title":"<code>theme.features</code>","text":"<p>All feature flags that can be set from <code>mkdocs.yml</code>, like tabs and instant loading, are now prefixed with the name of the component or function they apply to, e.g. <code>navigation.*</code>:</p> 6.x5.x <pre><code>theme:\nfeatures:\n- navigation.tabs\n- navigation.instant\n</code></pre> <pre><code>theme:\nfeatures:\n- tabs\n- instant\n</code></pre>"},{"location":"v10/upgrade/#upgrading-from-4x-to-5x","title":"Upgrading from 4.x to 5.x","text":""},{"location":"v10/upgrade/#whats-new_3","title":"What's new?","text":"<ul> <li>Reactive architecture \u2013 try <code>app.dialog$.next(\"Hi!\")</code> in the console</li> <li>Instant loading \u2013 make Material behave like a Single Page Application</li> <li>Improved CSS customization with CSS variables \u2013 set your brand's colors</li> <li>Improved CSS resilience, e.g. proper sidebar locking for customized headers</li> <li>Improved icon integration and configuration \u2013 now including over 5k icons</li> <li>Added possibility to use any icon for logo, repository and social links</li> <li>Search UI does not freeze anymore (moved to web worker)</li> <li>Search index built only once when using instant loading</li> <li>Improved extensible keyboard handling</li> <li>Support for prebuilt search indexes</li> <li>Support for displaying stars and forks for GitLab repositories</li> <li>Support for scroll snapping of sidebars and search results</li> <li>Reduced HTML and CSS footprint due to deprecation of Internet Explorer support</li> <li>Slight facelifting of some UI elements (admonitions, tables, ...)</li> </ul>"},{"location":"v10/upgrade/#changes-to-mkdocsyml_4","title":"Changes to <code>mkdocs.yml</code>","text":"<p>Following is a list of changes that need to be made to <code>mkdocs.yml</code>. Note that you only have to adjust the value if you defined it, so if your configuration does not contain the key, you can skip it.</p>"},{"location":"v10/upgrade/#themefeature","title":"<code>theme.feature</code>","text":"<p>Optional features like tabs and instant loading are now implemented as flags and can be enabled by listing them in <code>mkdocs.yml</code> under <code>theme.features</code>:</p> 5.x4.x <pre><code>theme:\nfeatures:\n- tabs\n- instant\n</code></pre> <pre><code>theme:\nfeature:\ntabs: true\n</code></pre>"},{"location":"v10/upgrade/#themelogoicon","title":"<code>theme.logo.icon</code>","text":"<p>The logo icon configuration was centralized under <code>theme.icon.logo</code> and can now be set to any of the icons bundled with the theme:</p> 5.x4.x <pre><code>theme:\nicon:\nlogo: material/cloud\n</code></pre> <pre><code>theme:\nlogo:\nicon: cloud\n</code></pre>"},{"location":"v10/upgrade/#extrarepo_icon","title":"<code>extra.repo_icon</code>","text":"<p>The repo icon configuration was centralized under <code>theme.icon.repo</code> and can now be set to any of the icons bundled with the theme:</p> 5.x4.x <pre><code>theme:\nicon:\nrepo: fontawesome/brands/gitlab\n</code></pre> <pre><code>extra:\nrepo_icon: gitlab\n</code></pre>"},{"location":"v10/upgrade/#extrasearch","title":"<code>extra.search.*</code>","text":"<p>Search is now configured as part of the plugin options. Note that the search languages must now be listed as an array of strings and the <code>tokenizer</code> was renamed to <code>separator</code>:</p> 5.x4.x <pre><code>plugins:\n- search:\nseparator: '[\\s\\-\\.]+'\nlang:\n- en\n- de\n- ru\n</code></pre> <pre><code>extra:\nsearch:\nlanguage: en, de, ru\ntokenizer: '[\\s\\-\\.]+'\n</code></pre>"},{"location":"v10/upgrade/#extrasocial","title":"<code>extra.social.*</code>","text":"<p>Social links stayed in the same place, but the <code>type</code> key was renamed to <code>icon</code> in order to match the new way of specifying which icon to be used:</p> 5.x4.x <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/github-alt\nlink: https://github.com/squidfunk\n</code></pre> <pre><code>extra:\nsocial:\n- type: github\nlink: https://github.com/squidfunk\n</code></pre>"},{"location":"v10/upgrade/#upgrading-from-3x-to-4x","title":"Upgrading from 3.x to 4.x","text":""},{"location":"v10/upgrade/#whats-new_4","title":"What's new?","text":"<p>Material for MkDocs 4 fixes incorrect layout on Chinese systems. The fix includes a mandatory change of the base font-size from <code>10px</code> to <code>20px</code> which means all <code>rem</code> values needed to be updated. Within the theme, <code>px</code> to <code>rem</code>  calculation is now encapsulated in a new function called <code>px2rem</code> which is part of the SASS code base.</p> <p>If you use Material for MkDocs with custom CSS that is based on <code>rem</code> values, note that those values must now be divided by 2. Now, <code>1.0rem</code> doesn't map to <code>10px</code>, but <code>20px</code>. To learn more about the problem and implications, please refer to #911 in which the problem was discovered and fixed.</p>"},{"location":"v10/upgrade/#changes-to-mkdocsyml_5","title":"Changes to <code>mkdocs.yml</code>","text":"<p>None.</p>"},{"location":"v10/upgrade/#changes-to-html-files_5","title":"Changes to <code>*.html</code> files","text":"<p>None.</p>"},{"location":"v10/blog/","title":"Blog","text":""},{"location":"v10/blog/posts/blog-support-just-landed/","title":"Blog support just landed","text":"<p>Hey there! You're looking at our new blog, built with the brand new built-in blog plugin. With this plugin, you can easily build a blog alongside your documentation or standalone.</p> <p>Proper support for blogging, as requested by many users over the past few years, was something that was desperately missing from Material for MkDocs' feature set. While everybody agreed that blogging support was a blind spot, it was not obvious whether MkDocs could be extended in a way to allow for blogging as we know it from Jekyll and friends. The built-in blog plugin proves that it is, after all, possible to build a blogging engine on top of MkDocs, in order to create a technical blog alongside your documentation, or as the main thing.</p> <p>This article explains how to build a standalone blog with Material for MkDocs. If you want to build a blog alongside your documentation, please refer to the plugin's documentation.</p>"},{"location":"v10/blog/posts/blog-support-just-landed/#quick-start","title":"Quick start","text":""},{"location":"v10/blog/posts/blog-support-just-landed/#setting-up-insiders","title":"Setting up Insiders","text":"<p>Before we can start bootstrapping a blog and write our first post, we need to set up Insiders, since the built-in blog plugin is currently reserved to sponsors. Without the funds this project receives through sponsorships, this plugin wouldn't exist. Three steps are necessary:</p> <ol> <li>Subscribe to a monthly sponsorship</li> <li>Create a personal access token</li> <li>Install Insiders</li> </ol>"},{"location":"v10/blog/posts/blog-support-just-landed/#creating-a-standalone-blog","title":"Creating a standalone blog","text":"<p>After Insiders is installed, you can bootstrap a new project using the <code>mkdocs</code> executable:</p> <pre><code>mkdocs new .\n</code></pre> <p>This will create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre>"},{"location":"v10/blog/posts/blog-support-just-landed/#configuration","title":"Configuration","text":"<p>In this article, we're going to build a standalone blog, which means that the blog lives at the root of your project. For this reason, open <code>mkdocs.yml</code>, and replace its contents with:</p> <pre><code>site_name: My Blog\ntheme:\nname: material\nfeatures:\n- navigation.sections\nplugins:\n- meta\n- blog:\nblog_dir: . # (1)!\n- search\n- tags\nnav:\n- index.md\n</code></pre> <ol> <li>This is the important part \u2013 we're hosting the blog at the root of the     project, and not in a subdirectory. For more information, see the     <code>blog_dir</code> configuration option.</li> </ol>"},{"location":"v10/blog/posts/blog-support-just-landed/#blog-setup","title":"Blog setup","text":"<p>The blog index page lives in <code>docs/index.md</code>. This page was pre-filled by MkDocs with some content, so we're going to replace it with what we need to bootstrap the blog:</p> <pre><code># Blog\n</code></pre> <p>That's it.</p>"},{"location":"v10/blog/posts/blog-support-just-landed/#writing-your-first-post","title":"Writing your first post","text":"<p>Now that we have set up the built-in blog plugin, we can start writing our first post. All blog posts are written with the exact same Markdown flavor as already included with Material for MkDocs. First, create a folder called <code>posts</code> with a file called <code>hello-world.md</code>:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u251c\u2500 posts/\n\u2502  \u2502  \u2514\u2500 hello-world.md # (1)!\n\u2502  \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li>If you'd like to arrange posts differently, you're free to do so. The URLs     are built from the format specified in <code>post_url_format</code> and     the titles and dates of posts, no matter how they are organized     inside the <code>posts</code> directory.</li> </ol> <p>Then, open up <code>hello-world.md</code>, and add the following lines:</p> <pre><code>---\ndraft: true # (1)!\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque nec\nmaximus ex. Sed consequat, nulla quis malesuada dapibus, elit metus vehicula\nerat, ut egestas tellus eros at risus. In hac habitasse platea dictumst.\nPhasellus id lacus pulvinar erat consequat pretium. Morbi malesuada arcu mauris\nNam vel justo sem. Nam placerat purus non varius luctus. Integer pretium leo in\nsem rhoncus, quis gravida orci mollis. Proin id aliquam est. Vivamus in nunc ac\nmetus tristique pellentesque. Suspendisse viverra urna in accumsan aliquet.\n&lt;!-- more --&gt;\nDonec volutpat, elit ac volutpat laoreet, turpis dolor semper nibh, et dictum\nmassa ex pulvinar elit. Curabitur commodo sit amet dolor sed mattis. Etiam\ntempor odio eu nisi gravida cursus. Maecenas ante enim, fermentum sit amet\nmolestie nec, mollis ac libero. Vivamus sagittis suscipit eros ut luctus.\nNunc vehicula sagittis condimentum. Cras facilisis bibendum lorem et feugiat.\nIn auctor accumsan ligula, at consectetur erat commodo quis. Morbi ac nunc\npharetra, pellentesque risus in, consectetur urna. Nulla id enim facilisis\narcu tincidunt pulvinar. Vestibulum laoreet risus scelerisque porta congue.\nIn velit purus, dictum quis neque nec, molestie viverra risus. Nam pellentesque\ntellus id elit ultricies, vel finibus erat cursus.\n</code></pre> <ol> <li>If you mark a post as a draft, a red marker appears next to the post date      on index pages. When the site is built, drafts are not included in the      output. This behavior can be changed, e.g. for rendering drafts when      building deploy previews.</li> </ol> <p>When you spin up the live preview server, you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you:</p> <p></p> <p>However, this is just the start. The built-in blog plugin packs a lot of functionality needed in day-to-day blogging. Visit the documentation of the plugin to learn about the following topics:</p> <ul> <li>Adding an excerpt</li> <li>Adding authors</li> <li>Adding categories</li> <li>Adding tags</li> <li>Adding related links</li> <li>Linking from and to posts</li> <li>Setting the reading time</li> <li>Setting defaults</li> </ul> <p>Additionally, the built-in blog plugin has dozens of configuration options which allow for fine-tuning the output. You can configure post slugs, general behavior and much more.</p>"},{"location":"v10/blog/posts/blog-support-just-landed/#whats-next","title":"What's next?","text":"<p>Getting basic blogging support out the door was quite a challenge \u2013 the built-in blog plugin is probably the biggest release this year and already packs a lot of functionality. However, Material for MkDocs is used in many different contexts, which is why we'd expect to iterate, as always.</p> <p>Some ideas already proposed by users:</p> <ul> <li> <p>Blog series: Authors should be able to create so called blog series and   assign posts to a blog series using simple identifiers. For each post that is   part of a series, a list with links to all other posts should be included in   the post's content.</p> </li> <li> <p>Author indexes: Besides archive and category indexes, authors should    be able to create per-author indexes, which list all posts linked to an   author. Additionally, a profile should be created for each author and linked   from posts.</p> </li> <li> <p>Social share buttons: It should be easy to share blog posts via social   media or other ways. For this reason, it should be possible to automatically   include social sharing buttons with each post.</p> </li> </ul> <p>What's still missing from the brand new built-in blog plugin? Feel free to share your ideas in the comments. Together, we can build one of the best modern engines for technical blogging!</p>"},{"location":"v10/blog/posts/chinese-search-support/","title":"Chinese search support \u2013 \u4e2d\u6587\u641c\u7d22\u200b\u652f\u6301","text":"<p>Insiders adds experimental Chinese language support for the built-in search  plugin \u2013 a feature that has been requested for a long time given the large number of Chinese users.</p> <p>After the United States and Germany, the third-largest country of origin of Material for MkDocs users is China. For a long time, the built-in search plugin didn't allow for proper segmentation of Chinese characters, mainly due to  missing support in lunr-languages which is used for search tokenization and stemming. The latest Insiders release adds long-awaited Chinese language support for the built-in search plugin, something that has been requested by many users.</p> <p>Material for MkDocs\u7d42\u65bc\u200b\u652f\u6301\u200b\u4e2d\u6587\u200b\u4e86\uff01\u6587\u672c\u200b\u88ab\u200b\u6b63\u78ba\u200b\u5206\u5272\u200b\u4e26\u4e14\u200b\u66f4\u200b\u5bb9\u6613\u200b\u627e\u5230\u3002</p> <p>This article explains how to set up Chinese language support for the built-in search plugin in a few minutes.</p>"},{"location":"v10/blog/posts/chinese-search-support/#configuration","title":"Configuration","text":"<p>Chinese language support for Material for MkDocs is provided by jieba, an excellent Chinese text segmentation library. If jieba is installed, the built-in search plugin automatically detects Chinese characters and runs them through the segmenter. You can install jieba with:</p> <pre><code>pip install jieba\n</code></pre> <p>The next step is only required if you specified the <code>separator</code>  configuration in <code>mkdocs.yml</code>. Text is segmented with zero-width whitespace  characters, so it renders exactly the same in the search modal. Adjust <code>mkdocs.yml</code> so that the <code>separator</code> includes the <code>\\u200b</code> character:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\u200b\\-]'\n</code></pre> <p>That's all that is necessary.</p>"},{"location":"v10/blog/posts/chinese-search-support/#usage","title":"Usage","text":"<p>If you followed the instructions in the configuration guide, Chinese words will  now be tokenized using jieba. Try searching for  \u652f\u6301 to see how it integrates with the  built-in search plugin.</p> <p>Note that this is an experimental feature, and I, @squidfunk, am not  proficient in Chinese (yet?). If you find a bug or think something can be improved, please open an issue.</p>"},{"location":"v10/blog/posts/excluding-content-from-search/","title":"Excluding content from search","text":"<p>The latest Insiders release brings three new simple ways to exclude dedicated parts of a document from the search index, allowing for more fine-grained control.</p> <p>Two weeks ago, Material for MkDocs Insiders shipped a brand new search plugin, yielding massive improvements in usability, but also in speed and size of the search index. Interestingly, as discussed in the previous blog article, we only scratched the surface of what's now possible. This release brings some useful features that enhance the writing experience, allowing for more fine-grained control of what pages, sections and blocks of a Markdown file should be indexed by the built-in search functionality.</p> <p>The following section discusses existing solutions for excluding pages and sections from the search index. If you immediately want to learn what's new, skip to the section just after that.</p>"},{"location":"v10/blog/posts/excluding-content-from-search/#prior-art","title":"Prior art","text":"<p>MkDocs has a rich and thriving ecosystem of plugins, and it comes as no surprise that there's already a fantastic plugin by @chrieke to exclude specific sections of a Markdown file \u2013 the mkdocs-exclude-search plugin. It can be installed with:</p> <pre><code>pip install mkdocs-exclude-search\n</code></pre> <p>How it works: the plugin post-processes the <code>search_index.json</code> file that is generated by the built-in search plugin, giving the author the ability to exclude certain pages and sections by adding a few lines of configuration to <code>mkdocs.yml</code>. An example:</p> <pre><code>plugins:\n- search\n- exclude-search:\nexclude:\n- page.md\n- page.md#section\n- directory/*\n- /*/page.md\n</code></pre> <p>It's easy to see that the plugin follows a configuration-centric approach, which adds support for advanced filtering techniques like infix- and suffix-filtering using wildcards. While this is a very powerful idea, it comes with some downsides:</p> <ol> <li> <p>Exclusion patterns and content are not co-located: exclusion patterns     need to be defined in <code>mkdocs.yml</code>, and not as part of the respective     document or section to be excluded. This might result in stale exclusion     patterns, leading to unintended behavior:</p> <ul> <li> <p>When a headline is changed, its slug (permalink) also changes, which might   suddenly match (or unmatch) a pattern, e.g., when an author fixes a typo   in a headline.</p> </li> <li> <p>As exclusion patterns support the use of wildcards, different authors   might overwrite each other's patterns without any immediate feedback since   the plugin does only report the number of excluded documents \u2013 not what   has been excluded.1</p> </li> </ul> </li> <li> <p>Exclusion control might be too coarse: The mkdocs-exclude-search     plugin only allows for the exclusion of pages and sections. It's not     possible to exclude parts of a section, e.g., content that is irrelevant     to search but must be included as part of the documentation.</p> </li> </ol>"},{"location":"v10/blog/posts/excluding-content-from-search/#whats-new","title":"What's new?","text":"<p>The latest Insiders release brings fine-grained control for excluding pages, sections, and blocks from the search index, implemented through front matter, as well as the Attribute Lists. Note that it doesn't replace the mkdocs-exclude-search plugin but complements it.</p>"},{"location":"v10/blog/posts/excluding-content-from-search/#excluding-pages","title":"Excluding pages","text":"<p>An entire page can be excluded from the search index by adding a simple directive to the front matter of the respective Markdown file. The good thing is that the author now only has to check the top of the document to learn whether it is excluded or not:</p> <pre><code>---\nsearch:\nexclude: true\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/blog/posts/excluding-content-from-search/#excluding-sections","title":"Excluding sections","text":"<p>If a section should be excluded, the author can use the Attribute Lists extension to add a pragma called <code>data-search-exclude</code> at the end of a heading. The pragma is not included in the final HTML, as search pragmas are filtered by the search plugin before the page is rendered:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\n## Section 1\nThe content of this section is included\n\n## Section 2 { data-search-exclude }\nThe content of this section is excluded\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"\",\n\"title\":\"Document title\"\n},\n{\n\"location\":\"page/#section-1\",\n\"text\":\"&lt;p&gt;The content of this section is included&lt;/p&gt;\",\n\"title\":\"Section 1\"\n}\n]\n}\n</code></pre>"},{"location":"v10/blog/posts/excluding-content-from-search/#excluding-blocks","title":"Excluding blocks","text":"<p>If even more fine-grained control is desired, the pragma can be added to any block-level element or inline-level element that is officially supported by the Attribute Lists extension:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\nThe content of this block is included\n\nThe content of this block is excluded\n{ data-search-exclude }\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"&lt;p&gt;The content of this block is included&lt;/p&gt;\",\n\"title\":\"Document title\"\n},\n]\n}\n</code></pre>"},{"location":"v10/blog/posts/excluding-content-from-search/#conclusion","title":"Conclusion","text":"<p>The latest release brings three simple ways to control more precisely what goes into the search index and what doesn't. It complements the already very powerful mkdocs-exclude-search plugin, allowing for new methods of shaping the structure, size and content of the search index.</p> <ol> <li> <p>When the log level is set to <code>DEBUG</code>, the plugin will report exactly which pages and sections have been excluded from the search index, but MkDocs will now flood the terminal with debug output from its core and other plugins.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/blog/posts/search-better-faster-smaller/","title":"Search: better, faster, smaller","text":"<p>This is the story of how we managed to completely rebuild client-side search, delivering a significantly better user experience while making it faster and smaller at the same time.</p> <p>The search of Material for MkDocs is by far one of its best and most-loved assets: multilingual, offline-capable, and most importantly: all client-side. It provides a solution to empower the users of your documentation to find what they're searching for instantly without the headache of managing additional servers. However, even though several iterations have been made, there's still some room for improvement, which is why we rebuilt the search plugin and integration from the ground up. This article shines some light on the internals of the new search, why it's much more powerful than the previous version, and what's about to come.</p> <p>The next section discusses the architecture and issues of the current search implementation. If you immediately want to learn what's new, skip to the section just after that.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#architecture","title":"Architecture","text":"<p>Material for MkDocs uses lunr together with lunr-languages to implement its client-side search capabilities. When a documentation page is loaded and JavaScript is available, the search index as generated by the built-in search plugin during the build process is requested from the server:</p> <pre><code>const index$ = document.forms.namedItem(\"search\")\n? __search?.index || requestJSON&lt;SearchIndex&gt;(\nnew URL(\"search/search_index.json\", config.base)\n)\n: NEVER\n</code></pre>"},{"location":"v10/blog/posts/search-better-faster-smaller/#search-index","title":"Search index","text":"<p>The search index includes a stripped-down version of all pages. Let's take a look at an example to understand precisely what the search index contains from the original Markdown file:</p> Expand to inspect example <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Example\n## Text\nIt's very easy to make some words **bold** and other words *italic*\nwith Markdown. You can even add [links](#), or even `code`:\n\n```\nif (isAwesome) {\n  return true\n}\n```\n## Lists\nSometimes you want numbered lists:\n\n1. One\n2. Two\n3. Three\n\nSometimes you want bullet points:\n\n* Start a line with a star\n* Profit!\n</code></pre> <pre><code>{\n\"config\": {\n\"indexing\": \"full\",\n\"lang\": [\n\"en\"\n],\n\"min_search_length\": 3,\n\"prebuild_index\": false,\n\"separator\": \"[\\\\s\\\\-]+\"\n},\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"Example Text It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true } Lists Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n},\n{\n\"location\": \"page/#example\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true }\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n}\n]\n}\n</code></pre> <p>If we inspect the search index, we immediately see several problems:</p> <ol> <li> <p>All content is included twice: the search index contains one entry       with the entire contents of the page, and one entry for each section of       the page, i.e., each block preceded by a headline or subheadline. This       significantly contributes to the size of the search index.</p> </li> <li> <p>All structure is lost: when the search index is built, all structural       information like HTML tags and attributes are stripped from the content.       While this approach works well for paragraphs and inline formatting, it       might be problematic for lists and code blocks. An excerpt:</p> <pre><code>\u2026 links , or even code : if (isAwesome) { \u2026 } Lists Sometimes you want \u2026\n</code></pre> <ul> <li> <p>Context: for an untrained eye, the result can look like gibberish, as   it's not immediately apparent what classifies as text and what as code.   Furthermore, it's not clear that <code>Lists</code> is a headline as it's merged   with the code block before and the paragraph after it.</p> </li> <li> <p>Punctuation: inline elements like links that are immediately followed   by punctuation are separated by whitespace (see <code>,</code> and <code>:</code> in the   excerpt). This is because all extracted text is joined with a whitespace   character during the construction of the search index.</p> </li> </ul> </li> </ol> <p>It's not difficult to see that it can be quite challenging to implement a good search experience for theme authors, which is why Material for MkDocs (up to now) did some monkey patching to be able to render slightly more meaningful search previews.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#search-worker","title":"Search worker","text":"<p>The actual search functionality is implemented as part of a web worker1, which creates and manages the lunr search index. When search is initialized, the following steps are taken:</p> <ol> <li> <p>Linking sections with pages: The search index is parsed, and each     section is linked to its parent page. The parent page itself is not     indexed, as it would lead to duplicate results, so only the sections     remain. Linking is necessary, as search results are grouped by page.</p> </li> <li> <p>Tokenization: The <code>title</code> and <code>text</code> values of each section are split     into tokens by using the <code>separator</code> as configured in     <code>mkdocs.yml</code>. Tokenization itself is carried out by     lunr's default tokenizer, which doesn't allow for     lookahead or separators spanning multiple characters.</p> <p>Why is this important and a big deal? We will see later how much more we can achieve with a tokenizer that is capable of separating strings with lookahead.</p> </li> <li> <p>Indexing: As a final step, each section is indexed. When querying the     index, if a search query includes one of the tokens as returned by step 2.,     the section is considered to be part of the search result and passed to the     main thread.</p> </li> </ol> <p>Now, that's basically how the search worker operates. Sure, there's a little more magic involved, e.g., search results are post-processed and rescored to account for some shortcomings of lunr, but in general, this is how data gets into and out of the index.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#search-previews","title":"Search previews","text":"<p>Users should be able to quickly scan and evaluate the relevance of a search result in the given context, which is why a concise summary with highlighted occurrences of the search terms found is an essential part of a great search experience.</p> <p>This is where the current search preview generation falls short, as some of the search previews appear not to include any occurrence of any of the search terms. This was due to the fact that search previews were truncated after a maximum of 320 characters, as can be seen here:</p> <p></p> <p>The first two results look like they're not relevant, as they don't seem to include the query string the user just searched for. Yet, they are.</p> <p>A better solution to this problem has been on the roadmap for a very, very long time, but in order to solve this once and for all, several factors need to be carefully considered:</p> <ol> <li> <p>Word boundaries: some themes2 for static site generators generate    search previews by expanding the text left and right next to an occurrence,    stopping at a whitespace character when enough words have been consumed. A    preview might look like this:</p> <pre><code>\u2026 channels, e.g., or which can be configured via mkdocs.yml \u2026\n</code></pre> <p>While this may work for languages that use whitespace as a separator between words, it breaks down for languages like Japanese or Chinese3, as they have non-whitespace word boundaries and use dedicated segmenters to split strings into tokens.</p> </li> <li> <p>Context-awareness: Although whitespace doesn't work for all languages,     one could argue that it could be a good enough solution. Unfortunately, this     is not necessarily true for code blocks, as the removal of whitespace might     change meaning in some languages.</p> </li> <li> <p>Structure: Preserving structural information is not a must, but     apparently beneficial to build more meaningful search previews which allow     for a quick evaluation of relevance. If a word occurrence is part of a code     block, it should be rendered as a code block.</p> </li> </ol>"},{"location":"v10/blog/posts/search-better-faster-smaller/#whats-new","title":"What's new?","text":"<p>After we built a solid understanding of the problem space and before we dive into the internals of our new search implementation to see which of the problems it already solves, a quick overview of what features and improvements it brings:</p> <ul> <li>Better: support for rich search previews, preserving the structural   information of code blocks, inline code, and lists, so they are rendered   as-is, as well as lookahead tokenization, more accurate highlighting, and    improved stability of typeahead. Also, a slightly better UX.</li> <li>Faster and smaller: significant decrease in search index size of up   to 48% due to improved extraction and construction techniques, resulting in a   search experience that is up to 95% faster, which is particularly helpful for   large documentation projects.</li> </ul>"},{"location":"v10/blog/posts/search-better-faster-smaller/#rich-search-previews","title":"Rich search previews","text":"<p>As we rebuilt the search plugin from scratch, we reworked the construction of the search index to preserve the structural information of code blocks, inline code, as well as unordered and ordered lists. Using the example from the search index section, here's how it looks:</p> NowBefore <p></p> <p></p> <p>Now, code blocks are first-class citizens of search previews, and even inline code formatting is preserved. Let's take a look at the new structure of the search index to understand why:</p> Expand to inspect search index NowBefore <pre><code>{\n...\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"&lt;p&gt;It's very easy to make some words bold and other words italic with Markdown. You can even add links, or even &lt;code&gt;code&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;if (isAwesome){\\n  return true\\n}\\n&lt;/code&gt;&lt;/pre&gt;\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"&lt;p&gt;Sometimes you want numbered lists:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;One&lt;/li&gt; &lt;li&gt;Two&lt;/li&gt; &lt;li&gt;Three&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Sometimes you want bullet points:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Start a line with a star&lt;/li&gt; &lt;li&gt;Profit!&lt;/li&gt; &lt;/ul&gt;\"\n}\n]\n}\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\": \"page/\",\n\"title\": \"Example\",\n\"text\": \"Example Text It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true } Lists Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n},\n{\n\"location\": \"page/#example\",\n\"title\": \"Example\",\n\"text\": \"\"\n},\n{\n\"location\": \"page/#text\",\n\"title\": \"Text\",\n\"text\": \"It's very easy to make some words bold and other words italic with Markdown. You can even add links , or even code : if (isAwesome) { return true }\"\n},\n{\n\"location\": \"page/#lists\",\n\"title\": \"Lists\",\n\"text\": \"Sometimes you want numbered lists: One Two Three Sometimes you want bullet points: Start a line with a star Profit!\"\n}\n]\n}\n</code></pre> <p>If we inspect the search index again, we can see how the situation improved:</p> <ol> <li> <p>Content is included only once: the search index does not include the     content of the page twice, as only the sections of a page are part of the     search index. This leads to a significant reduction in size, fewer bytes to     transfer, and a smaller search index.</p> </li> <li> <p>Some structure is preserved: each section of the search index includes     a small subset of HTML to provide the necessary structure to allow for more     sophisticated search previews. Revisiting our example from before, let's     look at an excerpt:</p> NowBefore <pre><code>\u2026 links, or even &lt;code&gt;code&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;if (isAwesome){ \u2026 }\\n&lt;/code&gt;&lt;/pre&gt;\n</code></pre> <pre><code>\u2026 links , or even code : if (isAwesome) { \u2026 }\n</code></pre> <p>The punctuation issue is gone, as no additional whitespace is inserted, and the preserved markup yields additional context to make scanning search results more effective.</p> </li> </ol> <p>On to the next step in the process: tokenization.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#tokenizer-lookahead","title":"Tokenizer lookahead","text":"<p>The default tokenizer of lunr uses a regular expression to split a given string by matching each character against the <code>separator</code> as defined in <code>mkdocs.yml</code>. This doesn't allow for more complex separators based on lookahead or multiple characters.</p> <p>Fortunately, our new search implementation provides an advanced tokenizer that doesn't have these shortcomings and supports more complex regular expressions. As a result, Material for MkDocs just changed its own separator configuration to the following value:</p> <pre><code>[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&amp;[lg]t;\n</code></pre> <p>While the first part up to the first <code>|</code> contains a list of single control characters at which the string should be split, the following three sections explain the remainder of the regular expression.4</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#case-changes","title":"Case changes","text":"<p>Many programming languages use <code>PascalCase</code> or <code>camelCase</code> naming conventions. When a user searches for the term <code>case</code>, it's quite natural to expect for <code>PascalCase</code> and <code>camelCase</code> to show up. By adding the following match group to the separator, this can now be achieved with ease:</p> <pre><code>(?!\\b)(?=[A-Z][a-z])\n</code></pre> <p>This regular expression is a combination of a negative lookahead (<code>\\b</code>, i.e., not a word boundary) and a positive lookahead (<code>[A-Z][a-z]</code>, i.e., an uppercase character followed by a lowercase character), and has the following behavior:</p> <ul> <li><code>PascalCase</code> <code>Pascal</code>, <code>Case</code></li> <li><code>camelCase</code> <code>camel</code>, <code>Case</code></li> <li><code>UPPERCASE</code> <code>UPPERCASE</code></li> </ul> <p>Searching for  searchHighlight now brings up the section discussing the <code>search.highlight</code> feature flag, which also demonstrates that this now even works properly for search queries.5</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#version-numbers","title":"Version numbers","text":"<p>Indexing version numbers is another problem that can be solved with a small lookahead. Usually, <code>.</code> should be considered a separator to split words like <code>search.highlight</code>. However, splitting version numbers at <code>.</code> will make them undiscoverable. Thus, the following expression:</p> <pre><code>\\.(?!\\d)\n</code></pre> <p>This regular expression matches a <code>.</code> only if not immediately followed by a digit <code>\\d</code>, which leaves version numbers discoverable. Searching for  7.2.6 brings up the 7.2.6 release notes.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#htmlxml-tags","title":"HTML/XML tags","text":"<p>If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the <code>&lt;</code> and <code>&gt;</code> control characters are encoded in code blocks as <code>&amp;lt;</code> and <code>&amp;gt;</code>. Now, adding the following expression to the separator allows for just that:</p> <pre><code>&amp;[lg]t;\n</code></pre> <p>Searching for  custom search worker script  brings up the section on custom search and matches the <code>script</code> tag among the other search terms discovered.</p> <p>We've only just begun to scratch the surface of the new possibilities tokenizer lookahead brings. If you found other useful expressions, you're invited to share them in the comment section.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#accurate-highlighting","title":"Accurate highlighting","text":"<p>Highlighting is the last step in the process of search and involves the highlighting of all search term occurrences in a given search result. For a long time, highlighting was implemented through dynamically generated regular expressions.6</p> <p>This approach has some problems with non-whitespace languages like Japanese or Chinese3 since it only works if the highlighted term is at a word boundary. However, Asian languages are tokenized using a dedicated segmenter, which cannot be modeled with regular expressions.</p> <p>Now, as a direct result of the new tokenization approach, our new search implementation uses token positions for highlighting, making it exactly as powerful as tokenization:</p> <ol> <li> <p>Word boundaries: as the new highlighter uses token positions, word     boundaries are equal to token boundaries. This means that more complex cases     of tokenization (e.g., case changes, version numbers, HTML/XML tags),     are now all highlighted accurately.</p> </li> <li> <p>Context-awareness: as the new search index preserves some of the     structural information of the original document, the content of a section     is now divided into separate content blocks \u2013 paragraphs, code blocks, and     lists.</p> <p>Now, only the content blocks that actually contain occurrences of one of the search terms are considered for inclusion into the search preview. If a term only occurs in a code block, it's the code block that gets rendered, see, for example, the results of   twitter.</p> </li> </ol>"},{"location":"v10/blog/posts/search-better-faster-smaller/#benchmarks","title":"Benchmarks","text":"<p>We conducted two benchmarks \u2013 one with the documentation of Material for MkDocs itself, and one with a very massive corpus of Markdown files with more than 800,000 words \u2013 a size most documentation projects will likely never reach:</p> Before Now Relative Material for MkDocs Index size 573 kB 335 kB \u201342% Index size (<code>gzip</code>) 105 kB 78 kB \u201327% Indexing time7 265 ms 177 ms \u201334% KJV Markdown8 Index size 8.2 MB 4.4 MB \u201347% Index size (<code>gzip</code>) 2.3 MB 1.2 MB \u201348% Indexing time 2,700 ms 1,390 ms \u201348% <p>Benchmark results</p> <p>The results show that indexing time, which is the time that it takes to set up the search when the page is loaded, has dropped by up to 48%, which means the new search is up to 95% faster. This is a significant improvement, particularly relevant for large documentation projects.</p> <p>While 1,3s still may sound like a long time, using the new client-side search together with instant loading only creates the search index on the initial page load. When navigating, the search index is preserved across pages, so the cost does only have to be paid once.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#user-interface","title":"User interface","text":"<p>Additionally, some small improvements have been made, most prominently the more results on this page button, which now sticks to the top of the search result list when open. This enables the user to jump out of the list more quickly.</p>"},{"location":"v10/blog/posts/search-better-faster-smaller/#whats-next","title":"What's next?","text":"<p>Our new search implementation is a big improvement to Material for MkDocs. It solves some long-standing issues which needed to be tackled for years. Yet, it's only the start of a search experience that is going to get better and better. Next up:</p> <ul> <li> <p>Context-aware search summarization: currently, the first two matching   content blocks are rendered as a search preview. With the new tokenization   technique, we laid the groundwork for more sophisticated shortening and   summarization methods, which we're tackling next.</p> </li> <li> <p>User interface improvements: as we now gained full control over the   search plugin, we can now add meaningful metadata to provide more context and   a better experience. We'll explore some of those paths in the future.</p> </li> </ul> <p>If you've made it this far, thank you for your time and interest in Material for MkDocs! This is the first blog article that I decided to write after a short Twitter survey made me to. You're invited to leave a comment to share your experiences with the new search implementation.</p> <ol> <li> <p>Prior to  5.0.0, search was carried out in the main thread  which locked up the browser, rendering it unusable. This problem was first reported in #904 and, after some back and forth, fixed and released in  5.0.0.\u00a0\u21a9</p> </li> <li> <p>At the time of writing, Just the Docs and Docusaurus use this method for generating search previews. Note that the latter also integrates with Algolia, which is a fully managed server-based solution.\u00a0\u21a9</p> </li> <li> <p>China and Japan are both within the top 5 countries of origin of users of Material for MkDocs.\u00a0\u21a9\u21a9</p> </li> <li> <p>As a fun fact: the <code>separator</code> default value of the search plugin being <code>[\\s\\-]+</code> always has been kind of irritating, as it suggests that multiple characters can be considered being a separator. However, the <code>+</code> is completely irrelevant, as regular expression groups involving multiple characters were never supported by lunr's default tokenizer.\u00a0\u21a9</p> </li> <li> <p>Previously, the search query was not correctly tokenized due to the way lunr treats wildcards, as it disables the pipeline for search terms that  contain wildcards. In order to provide a good typeahead experience, Material for MkDocs adds wildcards to the end of each search term not explicitly preceded with <code>+</code> or <code>-</code>, effectively disabling tokenization.\u00a0\u21a9</p> </li> <li> <p>Using the separator as defined in <code>mkdocs.yml</code>, a regular expression was constructed that was trying to mimic the tokenizer. As an example, the search query <code>search highlight</code> was transformed into the rather cumbersome regular expression <code>(^|&lt;separator&gt;)(search|highlight)</code>, which only matches at word boundaries.\u00a0\u21a9</p> </li> <li> <p>Smallest value of ten distinct runs.\u00a0\u21a9</p> </li> <li> <p>We agnostically use KJV Markdown as a tool for testing to learn how Material for MkDocs behaves on large corpora, as it's a very large set of Markdown files with over 800k words.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/blog/posts/the-past-present-and-future/","title":"The past, present and future","text":"<p>2021 was a fantastic year for this project as we shipped many new awesome features, saw significant user growth and leveraged GitHub Sponsors to make the project sustainable.</p> <p>Today, together, MkDocs and Material for MkDocs are among the most popular options when it comes to choosing a static site generator and theme for your technical documentation project. Material for MkDocs ensures that your content is always perfectly presented to your audience, regardless of screen resolution or device capabilities. It has evolved to a framework for technical writing, offering many features, some of which are yet to be found in other static site generators. However, we're far from the end, as 2022 is going to bring some interesting new capabilities.</p> <p>This article showcases all features that were added in 2021 and gives an outlook on what's going to drop in 2022. Additionally, it provides some context on the history of the project.</p>"},{"location":"v10/blog/posts/the-past-present-and-future/#a-little-history","title":"A little history","text":"<p>In 2015, albeit 10 years in the industry, I was still quite new in Open Source. I wanted to release my latest Open Source project protobluff, a zero-copy Protocol Buffers implementation for C, which I've created as part of my former startup. As the project has a significant degree of complexity, I quickly realized that I was in need of good user documentation.</p> <p>After evaluating static site generators in general and Hugo, Sphinx and MkDocs in particular, I quickly decided that MkDocs seemed a good choice, as it was specifically aimed at technical project documentation and easy to use. Unfortunately, all of the available themes looked dated and given that I'm a very visual person, I just couldn't convince myself to call it a day.</p> <p>I had to build a theme.</p> <p>Months later, in February 2016, I released the first version of Material for MkDocs (and with it, protobluff, the project I wanted to release in the first place), and it looked like this:</p> <p></p> <p>It was already fully responsive and overall, well, quite okayish, but barely customizable, as only the logo could be changed. Beyond that, it had no options: No color or navigation options, no instant loading, etc. The search was very rudimentary and only supported section titles:</p> <p></p> <p>It's important to know that at this point in time I've built Material for MkDocs for protobluff, the project I was really caring about. Almost 6 years later, nobody knows protobluff, but this little side project has taken off. If back in those days, you would've told me big organizations like AWS, Microsoft and CERN, as well as extremely popular Open Source projects like FastAPI and Kubernetes will be using this project in the future \u2013 I would've declared you insane.</p> <p>I still find the success of this project quite surprising, as I thought that themes exist in abundance and are very much a solved problem. There's no glory in themes, no stars to earn (remember that I was new in Open Source, so this was the metric I was optimizing for), as there are thousands and thousands of options. However, as the years progressed, I learned that execution matters: although Material for MkDocs solves a problem for which thousands of solutions exist, it excels in a specific niche, and that niche is to be known as technical project documentation.</p> <p>Today, this project is not only popular but funded by almost 300 individuals and organizations, resulting in a yearly budget of more than $50,000. This allows me to set aside enough time for the development of new features, bug fixing, stability improvement, issue triage and general support and still feels like a dream to me, as there are many failed stories of Open Source funding and people telling you: don't do Open Source, you'll be working for free.</p> <p>Making Open Source sustainable is, after all, possible in 2021.</p>"},{"location":"v10/blog/posts/the-past-present-and-future/#2021-in-numbers","title":"2021 in numbers","text":"<p>2021 was an exciting year, as the project has seen significant growth.</p> <p>166k people visited the official documentation in 2021, totalling in 1,6m page views which is an increase of 83% when compared to 2020. The average visitor spends 1,5min on the site. While mobile phones make up 12% of visits, tablets only account for 0.6%. Visitors come from as many as 213 countries, which covers almost the whole world.</p>"},{"location":"v10/blog/posts/the-past-present-and-future/#features","title":"Features","text":"<p>It's absolutely mind-blowing that 38 new features were added to Material for MkDocs throughout 2021 \u2013 that's a new feature every 9,6 days \u2013 which was only possible because of the constantly improving funding situation. Following is a list of all features shipped in alphabetical order, some of which are still exclusively available to sponsors as part of Insiders:</p> <ul> <li>Admonition inline blocks</li> <li>Advanced search highlighting</li> <li>Anchor tracking</li> <li>Back-to-top button</li> <li>Boosting pages in search</li> <li>Brand new search plugin</li> <li>Code annotations</li> <li>Code annotations: anchor links</li> <li>Code annotations: strip comments</li> <li>Code block titles</li> <li>Code block line anchors</li> <li>Color palette toggle</li> <li>Content tabs: improved support</li> <li>Content tabs: auto-linking</li> <li>Content tabs: animated indicator</li> <li>Cookie consent</li> <li>Custom admonition icons</li> <li>Dark mode support for images</li> <li>Dismissable announcement bar</li> <li>Excluding content from search</li> <li>Latest release tag</li> <li>Mermaid.js integration</li> <li>Navigation icons</li> <li>Remove generator notice</li> <li>Rich search previews</li> <li>Stay on page when switching versions</li> <li>Search highlighting</li> <li>Search sharing</li> <li>Search suggestions</li> <li>Section index pages</li> <li>Site language selection</li> <li>Social cards</li> <li>Sticky navigation tabs</li> <li>Tags with search integration</li> <li>Tokenizer with lookahead</li> <li>Versioning</li> <li>Version warning</li> <li>Was this page helpful?</li> </ul> <p>Additionally, a lot of bugs were fixed in the 1,000 commits that were pushed to the repository this year. The changelog includes a list of all fixes. Furthermore, a large amount of time was invested into refactoring the code base to keep it in good shape. While the <code>mkdocs-material</code> package was released 55 times, <code>mkdocs-material-insiders</code> was shipped 72 times.</p>"},{"location":"v10/blog/posts/the-past-present-and-future/#funding","title":"Funding","text":"<p>In 2021, monthly funding increased from $1,050 in the beginning of January to more than $4,300 (Dec 27, 2021), totaling in a yearly budget of more than $50,000. Compared to last year, revenue from funding has increased by 617% \u2013 which is absolutely unbelievable:</p> <p></p> <p>I'm solely providing these numbers to fulfill the transparency pledge I'm giving to my awesome sponsors, and to show that it's possible to make existing Open Source projects sustainable by following a well-designed release strategy.</p> <p>You can learn about the strategy in the Insiders guide.</p>"},{"location":"v10/blog/posts/the-past-present-and-future/#2022","title":"2022","text":"<p>Standing at the verge of the next year, it's safe to say that the project will continue to prosper and evolve, yielding many awesome features that will make technical writing more comfortable and flexible. Here's an excerpt of the features that will see the light of day in 2022:</p> <ul> <li> <p>Instant previews: instant previews will render a specific page section   inside a tooltip when hovering an internal link, which will allow to implement   things like glossaries. Further support for improving glossary functionality   will also be investigated.</p> </li> <li> <p>Text annotations: as a logical progression of code annotations which   were added in 2021, authors will be able to add annotations to plain text,   yielding excellent opportunities for side content. Of course, text annotations   will be as easy to use as code annotations.</p> </li> <li> <p>Navigation pruning: to optimize large documentation projects, Material   for MkDocs will introduce a new feature flag called <code>navigation.prune</code> that   will lead to significantly smaller HTML files for documentation projects with   huge navigation hierarchies.</p> </li> <li> <p>Navigation status badge: as an addition to the recently added   navigation icon support, a status will be attributable to   each page, allowing to mark a page in the navigation tree with an icon as    new or  deprecated.   Custom status types will also be supported.</p> </li> <li> <p>Card grids: as a further component in the toolkit of technical writing,   card grids will allow arranging content in grids, which is especially   useful for overview pages. They will allow to arrange arbitrary content,   including code blocks, admonitions, etc.</p> </li> <li> <p>Blog support: blogging support is still under investigation and expected   to be one of the major additions in 2022. Blogging will perfectly integrate   with writing documentation, allowing to use all components available in   Material for MkDocs.</p> </li> </ul> <p>This list is incomplete. Additionally, many new smaller features will be added next year, just as in 2021. You can follow @squidfunk on Twitter to stay updated.</p> <p>Happy new year! </p>"},{"location":"v10/changelog/","title":"Changelog","text":""},{"location":"v10/changelog/#material-for-mkdocs","title":"Material for MkDocs","text":""},{"location":"v10/changelog/#9.1.20","title":"9.1.21 July 27, 2023","text":"<ul> <li>Fixed MkDocs 1.4 compat issue in social plugin (9.1.20 regression)</li> </ul>"},{"location":"v10/changelog/#9.1.20","title":"9.1.20 July 27, 2023","text":"<ul> <li>Updated Sanskrit translations</li> <li>Fixed deprecation warnings for social plugin</li> </ul>"},{"location":"v10/changelog/#9.1.19","title":"9.1.19 July 18, 2023","text":"<ul> <li>Added support for MkDocs 1.5+</li> <li>Fixed #5699: Improve error reporting in social plugin</li> </ul>"},{"location":"v10/changelog/#9.1.18","title":"9.1.18 July 3, 2023","text":"<ul> <li>Updated Danish translations</li> <li>Added support for installing user requirements in Docker image</li> <li>Fixed #5655: Search separator with lookbehind breaks highlighting</li> </ul>"},{"location":"v10/changelog/#9.1.17","title":"9.1.17 June 23, 2023","text":"<ul> <li>Fixed #5633: Code annotations with nested lists incorrectly mounted</li> <li>Fixed #5628: Regression in new social plugin configuration scheme</li> </ul>"},{"location":"v10/changelog/#9.1.16","title":"9.1.16 June 15, 2023","text":"<ul> <li>Updated Indonesian translations</li> <li>Ensure scroll bar follows color scheme of operating system</li> </ul>"},{"location":"v10/changelog/#9.1.15","title":"9.1.15 May 29, 2023","text":"<ul> <li>Fixed #5566: Indicate color scheme to operating system</li> <li>Fixed #5565: Update <code>Dockerfile</code> to latest version of base image</li> <li>Fixed #5554: Add additional version tags (<code>9</code>, <code>9.1</code>) to Docker image</li> <li>Fixed #5536: Strip tags of ARIA labels in table of contents</li> </ul>"},{"location":"v10/changelog/#9.1.14","title":"9.1.14 May 20, 2023","text":"<ul> <li>Updated Armenian and Greek translations</li> </ul>"},{"location":"v10/changelog/#9.1.13","title":"9.1.13 May 16, 2023","text":"<ul> <li>Fixed #5517: Social plugin crashes for some fonts (e.g. Open Sans)</li> </ul>"},{"location":"v10/changelog/#9.1.12","title":"9.1.12 May 12, 2023","text":"<ul> <li>Updated Bengali (Bangla) translations</li> <li>Fixed #5503: Docker image publish errors on uppercase characters</li> <li>Fixed #5407: Auto-pause media when in hidden content tabs</li> </ul>"},{"location":"v10/changelog/#9.1.11","title":"9.1.11 May 8, 2023","text":"<ul> <li>Fixed #5487: Social plugin crashes without options (9.1.10 regression)</li> </ul>"},{"location":"v10/changelog/#9.1.10","title":"9.1.10 May 8, 2023","text":"<ul> <li>Added <code>cards_layout_options</code> setting for social cards</li> <li>Deprecated <code>cards_color</code> and <code>cards_font</code> setting for social cards</li> </ul>"},{"location":"v10/changelog/#9.1.9","title":"9.1.9 May 2, 2023","text":"<ul> <li>Added Telugu, Kannada and Sanskrit translations</li> <li>Fixed #5428: Fixed margins for light/dark mode images in figures</li> <li>Fixed #5420: Social plugin crashing for some specific Google Fonts</li> <li>Fixed #5160: Instant loading makes code annotations jump (9.1.1 regression)</li> <li>Fixed #4920: Social plugin not loading logo from custom icon set</li> <li>Fixed social plugin crashing when only code font is specified</li> </ul>"},{"location":"v10/changelog/#9.1.8","title":"9.1.8 April 24, 2023","text":"<ul> <li>Fixed #5417: Theme breaks when <code>palette</code> is not defined (9.1.7 regression)</li> </ul>"},{"location":"v10/changelog/#9.1.7","title":"9.1.7 April 22, 2023","text":"<ul> <li>Updated Persian (Farsi) and Turkish translations</li> <li>Fixed #5401: Added missing flag to disable built-in tags plugin</li> <li>Fixed #5206: Ensure defaults are set for primary and accent colors</li> <li>Fixed unnecessary inclusion of palette CSS when unused</li> </ul>"},{"location":"v10/changelog/#9.1.6","title":"9.1.6 April 7, 2023","text":"<ul> <li>Updated Persian (Farsi) translations</li> <li>Fixed #5300: Boxes in Mermaid sequence diagrams not color-abiding</li> </ul>"},{"location":"v10/changelog/#9.1.5","title":"9.1.5 March 31, 2023","text":"<ul> <li>Updated Lithuanian and Japanese translations</li> <li>Updated Mermaid.js to version 9.4.3</li> <li>Fixed #5290: Footer previous/next labels cut-off for short page titles</li> </ul>"},{"location":"v10/changelog/#9.1.4","title":"9.1.4 March 24, 2023","text":"<ul> <li>Fixed #5239: Instant loading breaks anchors in details (9.1.1 regression)</li> <li>Fixed #5211: Anchor following not working for Chinese (9.1.2 regression)</li> </ul>"},{"location":"v10/changelog/#9.1.3","title":"9.1.3 March 14, 2023","text":"<ul> <li>Added Kurdish (Soran\u00ee) translations</li> <li>Updated Norwegian (Bokm\u00e5l), Portuguese and Romanian translations</li> <li>Improved compatibility with <code>mkdocs-jupyter</code> plugin</li> <li>Fixed #5198: Built-in search plugin not filtering <code>script</code> and <code>style</code> tags</li> <li>Fixed #5176: Back-to-top + instant loading not working (9.1.1 regression)</li> </ul>"},{"location":"v10/changelog/#9.1.2","title":"9.1.2 March 9, 2023","text":"<ul> <li>Updated Icelandic, Korean and Swedish translations</li> <li>Fixed #5168: Mermaid text boxes overflow (9.0.13 regression)</li> <li>Fixed #5155: Table of contents not highlighting percent-encoded URLs</li> </ul>"},{"location":"v10/changelog/#9.1.1","title":"9.1.1 March 5, 2023","text":"<ul> <li>Updated Czech and Thai translations</li> <li>Improved instant loading (scroll restoration, slow connections)</li> <li>Fixed #5023: Instant loading not allowing to go back to initial page</li> <li>Fixed #3797: Instant loading does not work with section anchors in Safari</li> </ul>"},{"location":"v10/changelog/#9.1.0","title":"9.1.0 March 2, 2023","text":"<ul> <li>Docker image now available for <code>amd64</code>, <code>arm64</code> and <code>arm/v7</code></li> <li>Updated Chinese (Taiwanese) translations</li> <li>Generalized tag identifier implementation</li> <li>Fixed flickering of header shadow on load</li> <li>Fixed occasional flickering of announcement bar</li> </ul>"},{"location":"v10/changelog/#9.0.15","title":"9.0.15 February 26, 2023","text":"<ul> <li>Updated Chinese (Traditional) translations</li> <li>Updated Hebrew translations</li> </ul>"},{"location":"v10/changelog/#9.0.14","title":"9.0.14 February 23, 2023","text":"<ul> <li>Fixed #5072: Rendering bug on navigation expand button in Firefox</li> </ul>"},{"location":"v10/changelog/#9.0.13","title":"9.0.13 February 18, 2023","text":"<ul> <li>Updated Uzbek translations</li> <li>Switched back to pre-9.0.0 headline detection in <code>content</code> partial</li> <li>Fixed #5062: Version warning not readable when using slate scheme</li> <li>Fixed #5061: Improved discernibility of table row hover color</li> <li>Fixed #5034: Sequence actors in Mermaid diagrams not color-abiding</li> <li>Fixed #4919: Allow to hide version warning in multiple versions</li> </ul>"},{"location":"v10/changelog/#9.0.12","title":"9.0.12 February 9, 2023","text":"<ul> <li>Updated Catalan translations</li> <li>Fixed #4975: Mermaid entity relationship rendering diagrams bug</li> <li>Fixed #4924: Header title not reset when using instant loading</li> </ul>"},{"location":"v10/changelog/#9.0.11","title":"9.0.11 February 3, 2023","text":"<ul> <li>Added Mastodon verification for social links (<code>rel=me</code>)</li> <li>Updated Italian translations</li> </ul>"},{"location":"v10/changelog/#9.0.10","title":"9.0.10 February 2, 2023","text":"<ul> <li>Updated Arabic translations</li> <li>Updated Korean translations</li> <li>Updated Hungarian translations</li> <li>Updated Russian translations</li> <li>Fixed #4977: Improved accessibility for content tabs</li> <li>Fixed #4960: Sometimes anchor following doesn't bring last item into view</li> </ul>"},{"location":"v10/changelog/#9.0.9","title":"9.0.9 January 30, 2023","text":"<ul> <li>Updated Bulgarian translations</li> <li>Updated Chinese (Simplified) translations</li> <li>Updated Dutch translations</li> <li>Updated Hindi translations</li> <li>Updated Japanese translations</li> <li>Updated Polish translations</li> </ul>"},{"location":"v10/changelog/#9.0.8","title":"9.0.8 January 29, 2023","text":"<ul> <li>Updated Croatian translations</li> <li>Updated French translations</li> <li>Updated Hungarian translations</li> <li>Updated Portuguese (Brasilian) translations</li> <li>Updated Spanish translations</li> <li>Updated Ukrainian translations</li> <li>Updated Urdu translations</li> <li>Updated Vietnamese translations</li> </ul>"},{"location":"v10/changelog/#9.0.7","title":"9.0.7 January 28, 2023","text":"<ul> <li>Improved accessibility of sidebar navigation</li> <li>Moved all translations into community edition</li> <li>Updated Polish and Portuguese (Brasilian) translations</li> <li>Fixed info plugin terminating on subsequent reload when serving</li> <li>Fixed #4910: Sidebar navigation labels have invalid ARIA roles</li> <li>Fixed #4884: Search query terms can't be separated by colons</li> </ul>"},{"location":"v10/changelog/#9.0.6","title":"9.0.6 January 19, 2023","text":"<ul> <li>Fixed #4883: Automatically disable info plugin when serving</li> <li>Fixed #4885: Search plugin crashes in some exotic cases (9.0.3 regression)</li> </ul>"},{"location":"v10/changelog/#9.0.5","title":"9.0.5 January 14, 2023","text":"<ul> <li>Fixed #4842: Improved accessibility of search result list</li> </ul>"},{"location":"v10/changelog/#9.0.4","title":"9.0.4 January 12, 2023","text":"<ul> <li>Fixed #4823: Improved contrast ratio in footer (9.0.2 regression)</li> <li>Fixed #4832: Set navigation items back to black (9.0.3 regression)</li> <li>Fixed #4843: Emojis broken due to maxcdn.com shutting down</li> <li>Upgraded Python Markdown Extensions to 9.9.1</li> </ul>"},{"location":"v10/changelog/#9.0.3","title":"9.0.3 January 8, 2023","text":"<ul> <li>Improved discernibility of section index pages in navigation</li> <li>Improved collapsing of adjacent whitespace in search plugin</li> <li>Updated Indonesian translations</li> <li>Fixed view source of this page button when edit URL points to blob</li> <li>Fixed #4829: Search overlay does not close for active anchor result</li> <li>Fixed #4824: Search plugin crashes for <code>h[1-6]</code> contained in other elements</li> <li>Fixed #4804: Nested navigation items not expandable with keyboard</li> <li>Fixed #4689: anchor tracking not working for anchors in tables</li> <li>Upgraded to Mermaid 9.3.0</li> </ul>"},{"location":"v10/changelog/#9.0.2","title":"9.0.2 January 4, 2023","text":"<ul> <li>Fixed #4823: Improved contrast ratio in footer to meet WCAG guidelines</li> <li>Fixed #4819: Social plugin crashes when card generation is disabled</li> <li>Fixed #4817: Search plugin crashes on numeric page titles in <code>nav</code></li> </ul>"},{"location":"v10/changelog/#9.0.1","title":"9.0.1 January 3, 2023","text":"<ul> <li>Removed <code>pipdeptree</code> dependency for built-in info plugin</li> <li>Fixed appearance of linked tags when hovered (9.0.0 regression)</li> <li>Fixed #4810: Abbreviations run out of screen on touch devices</li> <li>Fixed #4813: View source and edit button links are the same</li> </ul>"},{"location":"v10/changelog/#9.0.0","title":"9.0.0 January 2, 2023","text":"<p>Additions and improvements</p> <ul> <li>Added support for rich search previews</li> <li>Added support for tokenizer lookahead</li> <li>Added support for better search highlighting</li> <li>Added support for excluding content from search</li> <li>Added support for configurable search pipeline</li> <li>Added support for offline search via offline plugin</li> <li>Added support for multiple instances of built-in tags plugin</li> <li>Added support for removing copy-to-clipboard button</li> <li>Added support for removing footer navigation</li> <li>Added support for button to view the source of a page</li> <li>Improved readability of query string for search sharing</li> <li>Improved stability of search plugin when using <code>--dirtyreload</code></li> <li>Improved search result group button, now sticky and stable</li> <li>Updated Norwegian translations</li> <li>Updated MkDocs to 1.4.2</li> </ul> <p>Removals</p> <ul> <li>Removed deprecated alternative admonition qualifiers</li> <li>Removed <code>:is()</code> selectors (in output) for easier overriding</li> <li>Removed <code>.title</code> suffix on translations</li> <li>Removed legacy method for providing page title in feedback URL</li> <li>Removed support for indexing only titles in search</li> <li>Removed support for custom search transforms</li> <li>Removed support for custom search workers</li> <li>Removed temporary snow feature (easter egg)</li> </ul> <p>Fixes</p> <ul> <li>Fixed Norwegian and Korean language code</li> <li>Fixed detection of composition events in search interface</li> <li>Fixed search plugin not using title set via front matter</li> <li>Fixed search highlighting of tags</li> <li>Fixed search sharing URL using post transformed string</li> <li>Fixed theme-color meta tag getting out-of-sync with palette toggle</li> <li>Fixed prev/next page keyboard navigation when footer is not present</li> <li>Fixed overflowing navigation tabs not being scrollable</li> <li>Fixed inclusion of code block line numbers from search</li> </ul>"},{"location":"v10/changelog/#8.5.11","title":"8.5.11 November 30, 2022","text":"<ul> <li>Let it snow, see https://twitter.com/squidfunk/status/1597939243090788352</li> </ul>"},{"location":"v10/changelog/#8.5.10","title":"8.5.10 November 11, 2022","text":"<ul> <li>Adjusted CSS to better allow for custom primary and accent colors</li> <li>Fixed #4620: Primary color is not applied (8.5.9 regression)</li> </ul>"},{"location":"v10/changelog/#8.5.9","title":"8.5.9 November 8, 2022","text":"<ul> <li>Fixed #4600: Illegible link colors for black and white primary colors</li> <li>Fixed #4594: Need to set schema to change link color</li> </ul>"},{"location":"v10/changelog/#8.5.8","title":"8.5.8 November 3, 2022","text":"<ul> <li>Added support for always showing settings in cookie consent</li> <li>Fixed #4571: Buttons invisible if primary color is <code>white</code> or <code>black</code></li> <li>Fixed #4517: Illegible note in sequence diagram when using <code>slate</code> scheme</li> </ul>"},{"location":"v10/changelog/#8.5.7","title":"8.5.7 October 22, 2022","text":"<ul> <li>Deprecated additional admonition qualifiers to reduce size of CSS</li> <li>Fixed #4511: Search boost does not apply to sections</li> </ul>"},{"location":"v10/changelog/#8.5.6","title":"8.5.6 October 2, 2022","text":"<ul> <li>Modernized appearance of admonitions (with fallback, see docs)</li> <li>Improved appearance of inline code blocks in admonition titles</li> </ul>"},{"location":"v10/changelog/#8.5.5","title":"8.5.5 October 1, 2022","text":"<ul> <li>Updated MkDocs to 1.4</li> <li>Fixed compatibility issues with MkDocs 1.4</li> <li>Fixed #4430: build error when enabling consent without repository URL</li> </ul>"},{"location":"v10/changelog/#8.5.4","title":"8.5.4 September 30, 2022","text":"<ul> <li>Fixed expand icons shift on sidebar overflow (using <code>scrollbar-gutter</code>)</li> <li>Fixed #4429: Text in sequence diagrams overflows in Firefox</li> </ul>"},{"location":"v10/changelog/#8.5.3","title":"8.5.3 September 20, 2022","text":"<ul> <li>Fixed build error when enabling cookie consent without analytics</li> <li>Fixed #4381: Code blocks render ligatures for some fonts</li> </ul>"},{"location":"v10/changelog/#8.5.2","title":"8.5.2 September 18, 2022","text":"<ul> <li>Updated Mermaid.js to version 9.1.7</li> <li>Fixed overly large headlines in search results (8.5.0 regression)</li> <li>Fixed #4358: Navigation sections appear as clickable (8.5.0 regression)</li> <li>Fixed #4356: GitHub repository statistics fetched before cookie consent</li> </ul>"},{"location":"v10/changelog/#8.5.1","title":"8.5.1 September 15, 2022","text":"<ul> <li>Fixed #4366: Removed dependencies with native extensions</li> </ul>"},{"location":"v10/changelog/#8.5.0","title":"8.5.0 September 13, 2022","text":"<ul> <li>Added support for social cards</li> <li>Added support for code annotation anchor links (deep linking)</li> <li>Added support for code annotation comment stripping (syntax modifier)</li> <li>Added support for sidebars scrolling automatically to active item</li> <li>Added support for anchor following table of contents (= auto scroll)</li> <li>Added support for tag icons</li> </ul>"},{"location":"v10/changelog/#8.4.4","title":"8.4.4 September 12, 2022","text":"<ul> <li>Moved comments integration to separate partial (<code>comments.html</code>)</li> </ul>"},{"location":"v10/changelog/#8.4.3","title":"8.4.3 September 7, 2022","text":"<ul> <li>Added Simple Icons to bundled icons (+2,300 icons)</li> <li>Added support for changing edit icon</li> <li>Moved page actions to separate partial (<code>actions.html</code>)</li> <li>Fixed #4291: Version switching doesn't stay on page when anchors are used</li> <li>Fixed #4327: Links in data tables do not receive link styling</li> </ul>"},{"location":"v10/changelog/#8.4.2","title":"8.4.2 August 27, 2022","text":"<ul> <li>Updated Slovenian translations</li> <li>Fixed #4277: Feedback widget hidden after navigation with instant loading</li> <li>Fixed numeric tags in front matter breaking search functionality</li> </ul>"},{"location":"v10/changelog/#8.4.1","title":"8.4.1 August 21, 2022","text":"<ul> <li>Updated Croatian and Hebrew translations</li> </ul>"},{"location":"v10/changelog/#8.4.0","title":"8.4.0 August 13, 2022","text":"<ul> <li>Added support for cookie consent</li> <li>Added support for feedback widget (Was this page helpful?)</li> <li>Added support for dismissible announcement bar</li> <li>Added Armenian, Lithuanian, Tagalog, and Urdu translations</li> </ul>"},{"location":"v10/changelog/#8.3.9","title":"8.3.9 July 4, 2022","text":"<ul> <li>Updated Taiwanese translations for search</li> <li>Allow ids for content tabs with special characters (for mkdocstrings)</li> <li>Fixed #4083: home not clickable when using versioning (8.3.5 regression)</li> </ul>"},{"location":"v10/changelog/#8.3.8","title":"8.3.8 June 24, 2022","text":"<ul> <li>Fixed #4053: Limit width of videos to content area</li> <li>Fixed empty tags in front matter breaking search</li> </ul>"},{"location":"v10/changelog/#8.3.7","title":"8.3.7 June 22, 2022","text":"<ul> <li>Fixed search being stuck initializing when using tags (8.3.4 regression)</li> </ul>"},{"location":"v10/changelog/#8.3.6","title":"8.3.6 June 16, 2022","text":"<ul> <li>Fixed #4028: Links not clickable when using versioning (8.3.5 regression)</li> </ul>"},{"location":"v10/changelog/#8.3.5","title":"8.3.5 June 14, 2022","text":"<ul> <li>Fixed #4012: Stay on page not working for alias of active version</li> </ul>"},{"location":"v10/changelog/#8.3.4","title":"8.3.4 June 11, 2022","text":"<ul> <li>Fixed #4004: Tags with multiple words not searchable</li> </ul>"},{"location":"v10/changelog/#8.3.3","title":"8.3.3 June 7, 2022","text":"<ul> <li>Fixed #4000: Mermaid diagrams too dark in dark mode (8.3.0 regression)</li> </ul>"},{"location":"v10/changelog/#8.3.2","title":"8.3.2 June 5, 2022","text":"<ul> <li>Fixed #3987: Custom admonition icons don't work when defining color palette</li> </ul>"},{"location":"v10/changelog/#8.3.1","title":"8.3.1 June 4, 2022","text":"<ul> <li>Bump required Jinja version to 3.0.2</li> <li>Removed unnecessary conditions in templates</li> <li>Fixed scroll offset when content tabs are brought into view</li> <li>Fixed #3977: Content tabs snapping oddly in Firefox</li> <li>Fixed #3983: Missing condition in footer partial (8.3.0 regression)</li> </ul>"},{"location":"v10/changelog/#8.3.0","title":"8.3.0 June 2, 2022","text":"<ul> <li>Added support for custom admonition icons</li> <li>Added support for linking of content tabs</li> <li>Added support for boosting pages in search</li> <li>Added support for hiding footer navigation</li> <li>Added previous/next indicators to content tabs</li> <li>Improved typeset link colors in light and dark modes</li> </ul>"},{"location":"v10/changelog/#8.2.16","title":"8.2.16 May 28, 2022","text":"<ul> <li>Fixed #3957: Only animate code annotations when visible (save CPU cycles)</li> </ul>"},{"location":"v10/changelog/#8.2.15","title":"8.2.15 May 14, 2022","text":"<ul> <li>Added Uzbek translations</li> <li>Fixed spacing for code block results in content tabs</li> </ul>"},{"location":"v10/changelog/#8.2.14","title":"8.2.14 May 8, 2022","text":"<ul> <li>Fixed missing top right rounded border on admonition</li> <li>Fixed #3886: <code>4xx</code> status codes not handled when using instant loading</li> </ul>"},{"location":"v10/changelog/#8.2.13","title":"8.2.13 May 2, 2022","text":"<ul> <li>Fixed #3865: Tags index links to tagged pages 404 on Windows</li> <li>Fixed #3866: Bump required Python version from 3.6+ to 3.7+</li> </ul>"},{"location":"v10/changelog/#8.2.12","title":"8.2.12 April 30, 2022","text":"<ul> <li>Added support for GitHub-style hash fragments for dark/light images</li> <li>Improved rendering of nested code blocks in content tabs and annotations</li> <li>Fixed #3862: Upgraded to latest Pygments and Python Markdown Extensions</li> </ul>"},{"location":"v10/changelog/#8.2.11","title":"8.2.11 April 25, 2022","text":"<ul> <li>Temporarily pinned Pygments to <code>&lt;2.12</code></li> <li>Temporarily pinned Python Markdown Extensions to <code>&lt;9.4</code></li> <li>Improved rendering of code annotation markers</li> </ul>"},{"location":"v10/changelog/#8.2.10","title":"8.2.10 April 24, 2022","text":"<ul> <li>Added Macedonian translations</li> <li>Updated Mermaid.js to version 9.0.1</li> <li>Switched sidebar title in mobile navigation to bold font</li> <li>Fixed color of arrows in class and state diagrams for dark mode</li> <li>Fixed #3836: Inline admonitions overlayed by code block titles</li> </ul>"},{"location":"v10/changelog/#8.2.9","title":"8.2.9 April 8, 2022","text":"<ul> <li>Mitigate flicker on color palette switch by disabling all transitions</li> <li>Fixed search suggestions not triggered when following deep link</li> <li>Fixed incorrectly computed header height when using instant loading</li> <li>Fixed #3782: Admonition titles have extra pixels on wide screens in Firefox</li> <li>Fixed #3802: Always render table of contents container (except when hidden)</li> </ul>"},{"location":"v10/changelog/#8.2.8","title":"8.2.8 March 27, 2022","text":"<ul> <li>Bumped MkDocs version to 1.3.0 to mitigate breaking changes in Jinja</li> <li>Reverted Jinja version range limitation (added in 8.2.7)</li> <li>Improved styling of annotations and fixed borders of code blocks in tabs</li> <li>Added background color to code blocks in focused/hovered links</li> <li>Added check in tags plugin whether tags overview page exists</li> <li>Fixed #3744: Content tab indicator on wrong position when using back button</li> </ul>"},{"location":"v10/changelog/#8.2.7","title":"8.2.7 March 24, 2022","text":"<ul> <li>Temporarily limit Jinja version range to &lt; 3.1 due to breaking changes</li> </ul>"},{"location":"v10/changelog/#8.2.6","title":"8.2.6 March 23, 2022","text":"<ul> <li>Fixed #3695: Deprecation warning for unescaped backslashes in templates</li> <li>Fixed #3696: Annotations not mounted in some Terraform code blocks</li> <li>Fixed #3698: Annotations not mounted in long code blocks (8.2.5 regression)</li> </ul>"},{"location":"v10/changelog/#8.2.5","title":"8.2.5 March 6, 2022","text":"<ul> <li>Fixed #3596: Mermaid not working when headline with name 'Mermaid' present</li> <li>Fixed #3643: Reduce time to render pages with thousands of code blocks</li> <li>Fixed #3665: Missing styles for Mermaid.js flowcharts cluster labels</li> </ul>"},{"location":"v10/changelog/#8.2.4","title":"8.2.4 March 2, 2022","text":"<ul> <li>Fixed malformed Google Fonts URL when a font setting was omitted</li> <li>Fixed #3648: Fixed specificity issue with admonitions in lists</li> <li>Fixed #3653: Invalid outdated version banner URL when using instant loading</li> </ul>"},{"location":"v10/changelog/#8.2.3","title":"8.2.3 February 27, 2022","text":"<ul> <li>Fixed #3578: Active element in table of contents off-by-one on large screens</li> </ul>"},{"location":"v10/changelog/#8.2.2","title":"8.2.2 February 26, 2022","text":"<ul> <li>Added automatic removal of query parameter when search is closed</li> <li>Fixed #3599: Anchors always overridden when using navigation tracking</li> </ul>"},{"location":"v10/changelog/#8.2.1","title":"8.2.1 February 17, 2022","text":"<ul> <li>Fixed module <code>material.plugins</code> not being found (8.2.0 regression)</li> </ul>"},{"location":"v10/changelog/#8.2.0","title":"8.2.0 February 17, 2022","text":"<ul> <li>Added native support for Mermaid.js diagrams</li> <li>Added native support for tags (with search integration)</li> <li>Added support for staying on page when switching versions</li> </ul>"},{"location":"v10/changelog/#8.1.11","title":"8.1.11 February 10, 2022","text":"<ul> <li>Added Portuguese (Brasilian) translations</li> <li>Updated FontAwesome to v6 \u2013 check which icons were renamed here</li> <li>Fixed #3545: Color palette toggle and search overlaying version selector</li> </ul>"},{"location":"v10/changelog/#8.1.10","title":"8.1.10 February 6, 2022","text":"<ul> <li>Fixed cutoff of very wide logos in the sidebar on mobile</li> </ul>"},{"location":"v10/changelog/#8.1.9","title":"8.1.9 January 30, 2022","text":"<ul> <li>Added support for <code>mkdocs.yml</code> validation and auto-complete</li> <li>Fixed errors in Latvian translations</li> </ul>"},{"location":"v10/changelog/#8.1.8","title":"8.1.8 January 23, 2022","text":"<ul> <li>Added Latvian translations</li> <li>Updated Giscus example integration with dynamic theme change support</li> <li>Fixed #3479: Back-to-top button not hidden when using sticky navigation tabs</li> <li>Fixed #3491: Logo in header and drawer doesn't honor aspect ratio</li> </ul>"},{"location":"v10/changelog/#8.1.7","title":"8.1.7 January 16, 2022","text":"<ul> <li>Improved back-to-top button behavior - now not shown on anchor jump</li> </ul>"},{"location":"v10/changelog/#8.1.6","title":"8.1.6 January 11, 2022","text":"<ul> <li>Fixed spacing of blockquotes (8.1.5 regression)</li> <li>Fixed edge cases for rounded corners on code blocks (8.1.5 regression)</li> <li>Fixed issues with code annotation line heights</li> </ul>"},{"location":"v10/changelog/#8.1.5","title":"8.1.5 January 9, 2022","text":"<ul> <li>Improved browser support: Chrome 49+, Safari 10+, Firefox 53+, Edge 79+</li> <li>Improved rendering of inline code blocks in headlines</li> <li>Added Bahasa Malaysian translations</li> <li>Fixed #3354: MathJax formulas show vertical scrollbar</li> </ul>"},{"location":"v10/changelog/#8.1.4","title":"8.1.4 January 2, 2022","text":"<ul> <li>Added indicator to navigation expander icon</li> <li>Improved support for reduced motion preference</li> <li>Fixed jitter of active content tab indicator</li> </ul>"},{"location":"v10/changelog/#8.1.3","title":"8.1.3 December 19, 2021","text":"<ul> <li>Added animation to active content tab indicator</li> <li>Fixed #3360: Highlighted lines add blank lines in copied text</li> <li>Fixed usage of subsequent index files when using section index pages</li> </ul>"},{"location":"v10/changelog/#8.1.2","title":"8.1.2 December 15, 2021","text":"<ul> <li>Switched CSS sources to logical properties</li> <li>Added transformation of logical properties to <code>ltr</code>/<code>rtl</code> equivalents</li> <li>Fixed spacing for admonitions inside lists (8.1.1 regression)</li> </ul>"},{"location":"v10/changelog/#8.1.1","title":"8.1.1 December 13, 2021","text":"<ul> <li>Added support for <code>#only-light</code> and <code>#only-dark</code> image hash fragments</li> <li>Fixed copy-to-clipboard adding blank lines when using line anchors</li> <li>Fixed code annotation directionality for right-to-left languages</li> <li>Fixed header title positioning for right-to-left languages</li> <li>Fixed admonition borders for right-to-left languages (8.0.0 regression)</li> <li>Fixed footer navigation link positioning (8.0.0 regression)</li> <li>Fixed footer navigation title breaking out of container when too long</li> <li>Fixed shrinking arrow in navigation title when too long</li> <li>Fixed #3343: Filtered stopwords appear as missing search terms</li> <li>Fixed #3346: Site unusable due to usage of <code>:not()</code> (Firefox 78 ESR)</li> </ul>"},{"location":"v10/changelog/#8.1.0","title":"8.1.0 December 10, 2021","text":"<ul> <li>Added basic support for code block line anchors</li> <li>Switched code annotation markers to <code>+</code> signs to improve usability</li> <li>Switched main site title to bold font</li> <li>Improved admonition icon positioning to align when <code>font-size</code> is increased</li> <li>Improved and simplified footnotes CSS</li> <li>Improved and simplified code annotation positioning</li> <li>Fixed syntax error in Russian translations</li> </ul>"},{"location":"v10/changelog/#8.0.5","title":"8.0.5 December 6, 2021","text":"<ul> <li>Fixed #3302: Footer refactoring induced ellipsis in some browsers</li> <li>Fixed #3313: Details always rendered closed on load (8.0.4 regression)</li> </ul>"},{"location":"v10/changelog/#8.0.4","title":"8.0.4 December 4, 2021","text":"<ul> <li>Improved support for deeply nested code annotations</li> <li>Improved code annotation and copy-to-clipboard interop</li> <li>Improved styling for code annotations inside admonitions</li> <li>Fixed #3274: Invalid anchor positioning when using instant loading</li> <li>Fixed #3294: Lists after code blocks without code annotations disappearing</li> <li>Fixed several positioning issues for code annotations</li> <li>Fixed JavaScript source map roots</li> </ul>"},{"location":"v10/changelog/#8.0.3","title":"8.0.3 December 2, 2021","text":"<ul> <li>Removed deprecated <code>google_analytics</code> setting (was forgotten in 8.0.0)</li> <li>Fixed syntax error in Swedish and Polish translations</li> <li>Fixed #3283: Invalid back-to-top button position with sticky navigation tabs</li> <li>Fixed #3285: Default details marker showing due to Safari bug</li> </ul>"},{"location":"v10/changelog/#8.0.2","title":"8.0.2 November 30, 2021","text":"<ul> <li>Fixed #3275: Code annotations always disappear on click</li> </ul>"},{"location":"v10/changelog/#8.0.1","title":"8.0.1 November 28, 2021","text":"<ul> <li>Improved rendering of code annotation markers</li> <li>Fixed #3265: Wrong margin on nested admonitions</li> <li>Fixed wrong <code>box-sizing</code> for code annotations in details</li> </ul>"},{"location":"v10/changelog/#8.0.0","title":"8.0.0 November 28, 2021","text":"<ul> <li>Added support for code annotations</li> <li>Added support for anchor tracking</li> <li>Added support for version warning</li> <li>Added <code>copyright</code> partial for easier override</li> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integation \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"v10/changelog/#7.3.6","title":"7.3.6 October 30, 2021","text":"<ul> <li>Added support for adding titles to code blocks</li> </ul>"},{"location":"v10/changelog/#7.3.5","title":"7.3.5 October 27, 2021","text":"<ul> <li>Added support for setting table of contents title via <code>mkdocs.yml</code></li> <li>Fixed back-to-top button position for right-to-left languages</li> </ul>"},{"location":"v10/changelog/#7.3.4","title":"7.3.4 October 17, 2021","text":"<ul> <li>Bumped MkDocs version to 1.2.3 to mitigate CVE-2021-40978</li> <li>Fixed spacing issues when using integrate table of contents with tabs</li> <li>Fixed some spacings issues for right-to-left languages</li> <li>Fixed race condition in search initialization</li> </ul>"},{"location":"v10/changelog/#7.3.3","title":"7.3.3 October 11, 2021","text":"<ul> <li>Rewrite of entire documentation</li> <li>Adjusted height of new content tabs to match single line code blocks</li> <li>Fixed new content tabs missing right padding in some browsers on overflow</li> <li>Fixed new content tabs bleeding out of flex container on overflow</li> <li>Fixed new content tabs overflow scrolling bugs on some browsers</li> <li>Fixed new content tabs stealing keyboard access when active</li> <li>Fixed some spacings issues for right-to-left languages</li> </ul>"},{"location":"v10/changelog/#7.3.2","title":"7.3.2 October 6, 2021","text":"<ul> <li>Deprecated prebuilding of search index</li> <li>Improved graceful handling of broken search for <code>file://</code></li> <li>Added minimum Jinja version to list of requirements</li> <li>Fixed #3071: Section index pages render empty directories</li> <li>Fixed margin issues when using navigation tabs (7.3.1 regression)</li> <li>Fixed search placeholder sometimes being shown too early</li> </ul>"},{"location":"v10/changelog/#7.3.1","title":"7.3.1 October 2, 2021","text":"<ul> <li>Added new experimental content tabs implementation</li> <li>Fixed #3069: GitHub stats broken for users/orgs (7.1.0 regression)</li> <li>Fixed #3070: Sections not linking to index page</li> <li>Fixed title not linking to index page when using tabs</li> <li>Fixed Disqus integration when using instant loading</li> <li>Fixed some spacing issues for right-to-left languages</li> <li>Fixed syntax error in Serbian translations</li> </ul>"},{"location":"v10/changelog/#7.3.0","title":"7.3.0 September 23, 2021","text":"<ul> <li>Added support for sticky navigation tabs</li> <li>Added support for section index pages</li> <li>Added support for removing generator notice</li> </ul>"},{"location":"v10/changelog/#7.2.8","title":"7.2.8 September 20, 2021","text":"<ul> <li>Fixed #3039: Search modal overlays menu on mobile (7.2.7 regression)</li> </ul>"},{"location":"v10/changelog/#7.2.7","title":"7.2.7 September 19, 2021","text":"<ul> <li>Updated Serbian and Serbo-Croatian translations</li> <li>Improved appearance of outline on details</li> <li>Fixed #2934: Scrollbar when header is hidden on some mobile browsers</li> <li>Fixed #3032: Anchor in details doesn't open on load (7.0.0 regression)</li> <li>Fixed back-to-top button being focusable when invisible</li> <li>Fixed broken admonition icons (removed in upstream)</li> </ul>"},{"location":"v10/changelog/#7.2.6","title":"7.2.6 September 1, 2021","text":"<ul> <li>Fixed rendering of <code>blockquote</code> elements (7.0.0 regression)</li> <li>Fixed #2973: Custom search worker setting ignored</li> </ul>"},{"location":"v10/changelog/#7.2.5","title":"7.2.5 August 25, 2021","text":"<ul> <li>Updated Portuguese translations</li> <li>Fixed execution of RxJS teardown logic (7.2.3 regression)</li> <li>Fixed #2970: Search results show escaped characters (7.2.2 regression)</li> </ul>"},{"location":"v10/changelog/#7.2.4","title":"7.2.4 August 11, 2021","text":"<ul> <li>Fixed #2926: Version selector not working (7.2.3 regression)</li> <li>Fixed #2929: Missing CSS class for banner (consistency with Insiders)</li> </ul>"},{"location":"v10/changelog/#7.2.3","title":"7.2.3 August 9, 2021","text":"<ul> <li>Slight facelift of data tables, now closer to Material Design</li> <li>Fixed instant loading not respecting clicks on search results</li> <li>Fixed #2881: Invalid anchor offsets when using instant loading</li> </ul>"},{"location":"v10/changelog/#7.2.2","title":"7.2.2 July 31, 2021","text":"<ul> <li>Updated Korean translations</li> <li>Fixed #2879: Search highlighting does not properly escape HTML</li> </ul>"},{"location":"v10/changelog/#7.2.1","title":"7.2.1 July 25, 2021","text":"<ul> <li>Fixed #2862: Back-to-top button overlays active search bar</li> </ul>"},{"location":"v10/changelog/#7.2.0","title":"7.2.0 July 21, 2021","text":"<ul> <li>Added support for search suggestions to save keystrokes</li> <li>Added support for search highlighting</li> <li>Added support for search sharing (i.e. deep linking)</li> </ul>"},{"location":"v10/changelog/#7.1.11","title":"7.1.11 July 18, 2021","text":"<ul> <li>Updated Spanish and Galician translations</li> </ul>"},{"location":"v10/changelog/#7.1.10","title":"7.1.10 July 10, 2021","text":"<ul> <li>Refactored appearance of back-to-top button</li> <li>Fixed graceful handling of search when browsing locally</li> </ul>"},{"location":"v10/changelog/#7.1.9","title":"7.1.9 June 25, 2021","text":"<ul> <li>Improved search language support for Thai and Hindi</li> <li>Fixed #2761: License comments lined up at end of file</li> </ul>"},{"location":"v10/changelog/#7.1.8","title":"7.1.8 June 12, 2021","text":"<ul> <li>Refactored analytics integration (because of MkDocs 1.2)</li> <li>Added support for Google Analytics 4 (<code>gtag.js</code>)</li> <li>Fixed missing escape for <code>aria-label</code> in footer links</li> </ul>"},{"location":"v10/changelog/#7.1.7","title":"7.1.7 June 6, 2021","text":"<ul> <li>Improved screen reader support</li> </ul>"},{"location":"v10/changelog/#7.1.6","title":"7.1.6 May 30, 2021","text":"<ul> <li>Deprecated <code>seealso</code> admonition qualifier</li> <li>Added Mongolian and updated Chinese translations</li> <li>Fixed #2429: Version selector not touch-friendly on Android devices</li> <li>Fixed #2703: Printed 'Initializing search' albeit ready on mobile</li> </ul>"},{"location":"v10/changelog/#7.1.5","title":"7.1.5 May 19, 2021","text":"<ul> <li>Fixed #2655: Details breaking page margins on print</li> </ul>"},{"location":"v10/changelog/#7.1.4","title":"7.1.4 May 6, 2021","text":"<ul> <li>Added support for git-revision-date-localized plugin creation date</li> <li>Improved footnote styles on <code>:target</code> and <code>:focus</code></li> </ul>"},{"location":"v10/changelog/#7.1.3","title":"7.1.3 April 24, 2021","text":"<ul> <li>Fixed #2586: Empty table of contents shown (7.1.2 regression)</li> </ul>"},{"location":"v10/changelog/#7.1.2","title":"7.1.2 April 18, 2021","text":"<ul> <li>Fixed #2554: List markers sometimes overlap floated elements</li> <li>Fixed #2563: Adding a class to a <code>h1</code> breaks the table of contents</li> <li>Fixed #2566: Back-to-top button clickable when invisible</li> </ul>"},{"location":"v10/changelog/#7.1.1","title":"7.1.1 April 10, 2021","text":"<ul> <li>Fixed #2501: Nested definition lists compound bottom margin</li> <li>Fixed #2508: Switch <code>extracopyright</code> block to template variable</li> <li>Fixed #2533: Search (and other parts) not working in Safari &lt;14</li> <li>Fixed #2538: Visual quirk when opening language selector</li> </ul>"},{"location":"v10/changelog/#7.1.0","title":"7.1.0 March 29, 2021","text":"<ul> <li>Added support for back-to-top button</li> <li>Added support for color palette toggle</li> <li>Added latest release to repository info (GitHub)</li> <li>Slight facelift of repository info (lighter fonts, spacing and icons)</li> </ul>"},{"location":"v10/changelog/#7.0.7","title":"7.0.7 March 28, 2021","text":"<ul> <li>Updated Hungarian translations</li> <li>Fixed #2466: Docker image not based on latest Python and Alpine</li> <li>Fixed #2488: Inconsistent header shadow behavior</li> <li>Fixed #2492: Inline code blocks in admonition titles missing background</li> </ul>"},{"location":"v10/changelog/#7.0.6","title":"7.0.6 March 14, 2021","text":"<ul> <li>Added trailing slash to version selector URL</li> <li>Added support for out-of-order anchors in table of contents</li> <li>Added <code>extra.homepage</code> option to link logo to arbitrary URL</li> <li>Improved security of Docker image (always update apk)</li> <li>Fixed horizontal spacing for nested inline admonitions</li> <li>Fixed text color of nested code blocks inside links</li> <li>Fixed version selector to always use version title</li> <li>Fixed logo link when using versioning with instant loading</li> </ul>"},{"location":"v10/changelog/#7.0.5","title":"7.0.5 March 7, 2021","text":"<ul> <li>Added <code>extracopyright</code> block to allow for custom copyright info</li> <li>Fixed evaluation of third-party scripts when using instant loading</li> <li>Fixed edge cases when using instant loading without directory URLs</li> <li>Fixed handling of version selector when using instant loading</li> <li>Fixed regression with header title not being updated correctly</li> <li>Fixed expanded sections not opening on first click (7.0.4 regression)</li> </ul>"},{"location":"v10/changelog/#7.0.4","title":"7.0.4 March 4, 2021","text":"<ul> <li>Added Icelandic translations</li> <li>Fixed #2386: Section close requires two clicks (navigation expansion)</li> <li>Fixed console error when search is disabled (7.0.0 regression)</li> <li>Fixed localsearch integration (7.0.0 regression)</li> </ul>"},{"location":"v10/changelog/#7.0.3","title":"7.0.3 February 26, 2021","text":"<ul> <li>Fixed JavaScript errors in older browsers (target ES2020 -&gt; ES2015)</li> </ul>"},{"location":"v10/changelog/#7.0.2","title":"7.0.2 February 25, 2021","text":"<ul> <li>Fixed #2343: Invalid source map URLs for JS and CSS files</li> <li>Fixed #2347: Version selector missing when using versioning</li> </ul>"},{"location":"v10/changelog/#7.0.1","title":"7.0.1 February 24, 2021","text":"<ul> <li>Fixed #2334: Google Analytics triggers page view twice (7.0.0 regression)</li> <li>Fixed #2336: Details bleed into inline admonitions</li> <li>Fixed #2337: Images don't align correctly (7.0.0 regression)</li> </ul>"},{"location":"v10/changelog/#7.0.0","title":"7.0.0 February 22, 2021","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Added support for integrating a language selector</li> <li>Added support for rendering admonitions as inline blocks</li> <li>Rewrite of the underlying reactive architecture</li> <li>Removed Webpack in favor of reactive build strategy (-480 dependencies)</li> <li>Fixed keyboard navigation for code blocks after content tabs switch</li> </ul>"},{"location":"v10/changelog/#6.2.8","title":"6.2.8 February 4, 2021","text":"<ul> <li>Updated Japanese and Polish translations</li> <li>Fixed #2261: Print dialog auto-closing when using instant loading</li> </ul>"},{"location":"v10/changelog/#6.2.7","title":"6.2.7 January 31, 2021","text":"<ul> <li>Fixed #2251: Updated Docker image to latest Alpine Linux</li> </ul>"},{"location":"v10/changelog/#6.2.6","title":"6.2.6 January 26, 2021","text":"<ul> <li>Added Bulgarian translations</li> <li>Fixed #2233: Search not shown when using header autohiding</li> </ul>"},{"location":"v10/changelog/#6.2.5","title":"6.2.5 January 17, 2021","text":"<ul> <li>Fixed syntax error in Swedish translations</li> <li>Optimized navigation partials to improve build speed for huge docs</li> </ul>"},{"location":"v10/changelog/#6.2.4","title":"6.2.4 January 9, 2021","text":"<ul> <li>Fixed #2156: Missing syntax highlighting for binary numbers</li> <li>Fixed #2186: Disqus showing on 404 page</li> </ul>"},{"location":"v10/changelog/#6.2.3","title":"6.2.3 December 27, 2020","text":"<ul> <li>Added back hidden overflow on root container</li> <li>Fixed #2142: MathJax formulas sometimes have vertical scrollbars</li> </ul>"},{"location":"v10/changelog/#6.2.2","title":"6.2.2 December 22, 2020","text":"<ul> <li>Removed Markdown version range limit (6.2.0 regression)</li> </ul>"},{"location":"v10/changelog/#6.2.1","title":"6.2.1 December 22, 2020","text":"<ul> <li>Fixed all import and asset paths in templates (6.2.0 regression)</li> <li>Downgraded webpack-asset-manifest-plugin - broke all asset paths</li> </ul>"},{"location":"v10/changelog/#6.2.0","title":"6.2.0 December 22, 2020","text":"<ul> <li>Added support for navigation sections</li> <li>Added support for navigation expansion</li> <li>Added support for integrating table of contents into navigation</li> <li>Added support for autohiding header on scroll</li> <li>Added support for hiding navigation and table of contents per page</li> <li>Added support for arbitrary items in navigation tabs</li> <li>Refactored navigation tabs to simplify grouping behavior</li> <li>Fixed anchor offset for permalinks in Safari (partial revert)</li> <li>Fixed #2098: Active tab sometimes not highlighted correctly</li> <li>Improved appearance for horizontal rulers</li> <li>Improved Spanish and Swedish translations</li> </ul>"},{"location":"v10/changelog/#6.1.7","title":"6.1.7 December 6, 2020","text":"<ul> <li>Fixed #2081: Fixed stats for private GitHub repositories</li> <li>Fixed alignment for admonition icon alignment for right-to-left languages</li> </ul>"},{"location":"v10/changelog/#6.1.6","title":"6.1.6 November 22, 2020","text":"<ul> <li>Fixed #2048: Math formulas show scrollbars (Windows)</li> </ul>"},{"location":"v10/changelog/#6.1.5","title":"6.1.5 November 15, 2020","text":"<ul> <li>Fixed search reset button not showing/hiding correctly</li> </ul>"},{"location":"v10/changelog/#6.1.4","title":"6.1.4 November 7, 2020","text":"<ul> <li>Fixed sidebar jitter when scrolling footer into view</li> </ul>"},{"location":"v10/changelog/#6.1.3","title":"6.1.3 November 5, 2020","text":"<ul> <li>Added support for keywords <code>meta</code> tag</li> <li>Fixed #2027: Line numbers don't scale with smaller font size</li> <li>Fixed link colors for black and white on <code>slate</code> color scheme</li> <li>Removed focus outline on scrolling code blocks for pointer devices</li> </ul>"},{"location":"v10/changelog/#6.1.2","title":"6.1.2 October 31, 2020","text":"<ul> <li>Fixed sizing of icons in admonitions, task lists, etc. (6.1.1 regression)</li> </ul>"},{"location":"v10/changelog/#6.1.1","title":"6.1.1 October 31, 2020","text":"<ul> <li>Fixed #2019: Page title not correctly updated when using instant loading</li> </ul>"},{"location":"v10/changelog/#6.1.0","title":"6.1.0 October 17, 2020","text":"<ul> <li>Fixed #1973: Added support for printing in dark mode</li> <li>Fixed #1974: Added support for printing content tabs</li> <li>Fixed #1995: Improved customizability of details extension</li> </ul>"},{"location":"v10/changelog/#6.0.2","title":"6.0.2 October 4, 2020","text":"<ul> <li>Added Georgian translations</li> <li>Added escaping for link <code>title</code> attributes where necessary</li> <li>Fixed #1956: Pages with whitespace in names have invalid links in search</li> <li>Removed unnecessary (duplicated) link <code>title</code> attributes</li> </ul>"},{"location":"v10/changelog/#6.0.1","title":"6.0.1 September 26, 2020","text":"<ul> <li>Fixed stemmer support for <code>file://</code> protocol through <code>iframe-worker</code></li> <li>Fixed details marker showing for search result in Firefox</li> <li>Fixed tabbing behavior when search query is not empty</li> <li>Switched TypeScript compilation target to ES2015</li> <li>Reduced size of JavaScript by 30% (<code>176kb</code> \u2192 <code>124kb</code>)</li> <li>Removed <code>mkdocs</code> and <code>readthedocs</code> themes from Docker image</li> </ul>"},{"location":"v10/changelog/#6.0.0","title":"6.0.0 September 25, 2020","text":"<ul> <li>Improved search result look and feel</li> <li>Improved search result stability while typing</li> <li>Improved search result grouping (pages + headings)</li> <li>Improved search result relevance and scoring</li> <li>Added display of missing query terms to search results</li> <li>Reduced size of vendor bundle by 25% (<code>84kb</code> \u2192 <code>67kb</code>)</li> <li>Reduced size of the Docker image to improve CI build performance</li> <li>Removed hero partial in favor of custom implementation</li> <li>Removed deprecated front matter features</li> </ul>"},{"location":"v10/changelog/#5.5.14","title":"5.5.14 September 23, 2020","text":"<ul> <li>Improved spacing around image captions</li> <li>Fixed #1939: Long tables cause header overlap in print view</li> </ul>"},{"location":"v10/changelog/#5.5.13","title":"5.5.13 September 19, 2020","text":"<ul> <li>Improved abbreviations on touch devices</li> </ul>"},{"location":"v10/changelog/#5.5.12","title":"5.5.12 August 31, 2020","text":"<ul> <li>Fixed #1638: occasional <code>404</code> for images when using instant loading</li> </ul>"},{"location":"v10/changelog/#5.5.11","title":"5.5.11 August 28, 2020","text":"<ul> <li>Fixed Disqus integration, as the minifier killed the config</li> </ul>"},{"location":"v10/changelog/#5.5.10","title":"5.5.10 August 28, 2020","text":"<ul> <li>Improved rendering by moving Disqus integration after page load</li> <li>Fixed #1887: Moved navigation icons to CSS to reduce size of HTML</li> </ul>"},{"location":"v10/changelog/#5.5.9","title":"5.5.9 August 26, 2020","text":"<ul> <li>Added Esperanto translations</li> <li>Fixed #1884: External links not included in navigation tabs</li> </ul>"},{"location":"v10/changelog/#5.5.8","title":"5.5.8 August 23, 2020","text":"<ul> <li>Removed focus outline on <code>details</code> and content tabs for pointer devices</li> <li>Improved accessibility of content tabs (now navigable via arrow keys)</li> <li>Fixed #1877: <code>404</code> on search index when search is disabled</li> <li>Fixed some memleaks in observable subscriptions</li> <li>Fixed color definitions for <code>theme-color</code> meta tag</li> </ul>"},{"location":"v10/changelog/#5.5.7","title":"5.5.7 August 16, 2020","text":"<ul> <li>Improved contrast ratio to 4.5:1 for syntax highlighting</li> <li>Improved contrast ratio to 4.5:1 for table of contents</li> </ul>"},{"location":"v10/changelog/#5.5.6","title":"5.5.6 August 12, 2020","text":"<ul> <li>Switched base template for <code>404.html</code> to <code>main.html</code></li> <li>Fixed #1864: GitHub organisation stats not loading</li> </ul>"},{"location":"v10/changelog/#5.5.5","title":"5.5.5 August 11, 2020","text":"<ul> <li>Fixed missing vendor and worker distribution files</li> </ul>"},{"location":"v10/changelog/#5.5.4","title":"5.5.4 August 11, 2020","text":"<ul> <li>Added support for sortable data tables</li> </ul>"},{"location":"v10/changelog/#5.5.3","title":"5.5.3 August 4, 2020","text":"<ul> <li>Fixed search for languages other than English (5.5.1 regression)</li> </ul>"},{"location":"v10/changelog/#5.5.2","title":"5.5.2 August 3, 2020","text":"<ul> <li>Improved highlight colors and spacing for <code>ins</code>, <code>del</code> and <code>mark</code></li> <li>Changed some keyboard symbols for better equivalents</li> <li>Removed focus <code>outline</code> for details and code blocks on touch devices</li> <li>Fixed margins for admonitions (5.5.1 regression)</li> <li>Fixed too small content tab labels (5.5.1 regression)</li> <li>Fixed icon repeating for custom admonition icons</li> </ul>"},{"location":"v10/changelog/#5.5.1","title":"5.5.1 August 1, 2020","text":"<ul> <li>Improved typesetting by basing <code>font-size</code> and spacings on <code>em</code></li> <li>Improved print view by slightly scaling down <code>font-size</code></li> <li>Changed custom site title (metadata) to be suffixed with site name</li> <li>Fixed top- and bottom spacing of paragraphs inside table cells</li> </ul>"},{"location":"v10/changelog/#5.5.0","title":"5.5.0 July 24, 2020","text":"<ul> <li>Rewrite of entire documentation</li> <li>Rewrite of syntax highlighting to be customizable with CSS variables</li> <li>Improved syntax highlighting to work with light and dark theme</li> <li>Improved <code>slate</code> color scheme to be more customizable and easier on the eyes</li> <li>Added licenses of icon sets to distribution files</li> <li>Fixed stale document titles in Google Analytics when using instant loading</li> <li>Fixed width of previous and next footer links for tablet and above</li> <li>Fixed issues with top scroll margin for footnotes</li> <li>Fixed top margin for tabbed content when using a JavaScript highlighter</li> <li>Deprecated metadata-based redirects, source links and heroes</li> </ul>"},{"location":"v10/changelog/#5.4.0","title":"5.4.0 June 29, 2020","text":"<ul> <li>Added support to wrap searches in quotes to switch from <code>OR</code> to <code>AND</code></li> <li>Fixed highlighting of numbers in search results</li> </ul>"},{"location":"v10/changelog/#5.3.3","title":"5.3.3 June 24, 2020","text":"<ul> <li>Added Bengali translations</li> <li>Fixed #1773: Search for numbers does not return any result (regression)</li> </ul>"},{"location":"v10/changelog/#5.3.2","title":"5.3.2 June 21, 2020","text":"<ul> <li>Improved search typeahead experience with non-Latin characters</li> <li>Fixed #1753: Japanese search doesn't work anymore</li> </ul>"},{"location":"v10/changelog/#5.3.1","title":"5.3.1 June 20, 2020","text":"<ul> <li>Fixed #1761: Duplication of search worker when subscribing to observable</li> </ul>"},{"location":"v10/changelog/#5.3.0","title":"5.3.0 June 15, 2020","text":"<ul> <li>Added support for color schemes based on user preference</li> <li>Fixed #1755: Tokenizer separator setting ignored</li> </ul>"},{"location":"v10/changelog/#5.2.3","title":"5.2.3 June 6, 2020","text":"<ul> <li>Improved search typeahead behavior for some languages (<code>de</code>, <code>fr</code>, ...)</li> <li>Improved styles for scrollbars on Firefox</li> <li>Fixed #1741: Removed <code>preconnect</code> hint for Google Analytics</li> </ul>"},{"location":"v10/changelog/#5.2.2","title":"5.2.2 May 26, 2020","text":"<ul> <li>Fixed #1728: Legacy Edge doesn't support <code>deg</code> values in <code>hsla</code> colors</li> </ul>"},{"location":"v10/changelog/#5.2.1","title":"5.2.1 May 22, 2020","text":"<ul> <li>Fixed color of links in table headers, e.g. footnotes</li> <li>Fixed color scheme not being applied without primary or accent color</li> <li>Fixed hover delay for links inside code blocks</li> </ul>"},{"location":"v10/changelog/#5.2.0","title":"5.2.0 May 18, 2020","text":"<ul> <li>Added color schemes implementation + dark mode</li> <li>Fixed #1583: Missing option for separate link colors</li> </ul>"},{"location":"v10/changelog/#5.1.7","title":"5.1.7 May 16, 2020","text":"<ul> <li>Added keyboard focus support for overflowing code blocks</li> <li>Fixed #1696: Infinite loop in some cases when using instant loading</li> </ul>"},{"location":"v10/changelog/#5.1.6","title":"5.1.6 May 9, 2020","text":"<ul> <li>Added Burmese translations</li> <li>Added general anchor offset solution using <code>scroll-margin-top</code></li> <li>Fixed #1653: Instant loading shouldn't intercept links to <code>*.html</code> files</li> </ul>"},{"location":"v10/changelog/#5.1.5","title":"5.1.5 May 3, 2020","text":"<ul> <li>Added <code>name</code> attribute for social links to set link <code>title</code></li> <li>Fixed #1623: Allow arbitrary links in social links</li> <li>Fixed #1664: Height of <code>iframe</code> is not adjustable</li> <li>Fixed #1667: Sidebars are scrolled to bottom on load (bug in Chrome 81+)</li> </ul>"},{"location":"v10/changelog/#5.1.4","title":"5.1.4 April 30, 2020","text":"<ul> <li>Switched to @mdi/svg Material Design icon package</li> <li>Fixed #1655: Navigation may disappear after switching viewports</li> <li>Fixed #1659: Unnecessary scrollbar for search results on Windows</li> <li>Fixed occasional distortions for images with explicit dimensions</li> <li>Fixed errors in German translations</li> </ul>"},{"location":"v10/changelog/#5.1.3","title":"5.1.3 April 26, 2020","text":"<ul> <li>Fixed overflowing content area after switch to flexbox</li> </ul>"},{"location":"v10/changelog/#5.1.2","title":"5.1.2 April 26, 2020","text":"<ul> <li>Added status information to search observable</li> <li>Added status information to search modal</li> <li>Removed announcement bar from print media</li> <li>Removed media query packing logic due to race conditions</li> <li>Fixed #1520: Gracefully disable search on <code>file://</code> if Worker fails</li> <li>Fixed re-submission of query after search is initialized</li> <li>Fixed jitter of sidebars on all browsers by switching to <code>sticky</code></li> </ul>"},{"location":"v10/changelog/#5.1.1","title":"5.1.1 April 17, 2020","text":"<ul> <li>Added new FontAwesome icons</li> <li>Fixed #1609: Instant loading doesn't honor <code>target=_blank</code></li> <li>Fixed GitHub stars count rounding errors</li> <li>Fixed GitLab stars count retrieval</li> </ul>"},{"location":"v10/changelog/#5.1.0","title":"5.1.0 April 12, 2020","text":"<ul> <li>Added support for icons from Markdown through mkdocs-material-extensions</li> </ul>"},{"location":"v10/changelog/#5.0.2","title":"5.0.2 April 10, 2020","text":"<ul> <li>Added CSS source maps to distribution files</li> <li>Fixed errors in Chinese (Traditional) translations</li> <li>Fixed creation of stale directory on installation from git</li> <li>Improved overflow scrolling behavior on iOS (reduced bundle size by <code>4kb</code>)</li> </ul>"},{"location":"v10/changelog/#5.0.1","title":"5.0.1 April 7, 2020","text":"<ul> <li>Fixed syntax error in Spanish translation</li> </ul>"},{"location":"v10/changelog/#5.0.0","title":"5.0.0 April 7, 2020","text":"<ul> <li>Reactive architecture \u2013 try <code>app.dialog$.next(\"Hi!\")</code> in the console</li> <li>Instant loading \u2013 make Material behave like a Single Page Application</li> <li>Improved CSS customization with CSS variables \u2013 set your brand's colors</li> <li>Improved CSS resilience, e.g. proper sidebar locking for customized headers</li> <li>Improved icon integration and configuration \u2013 now including over 5k icons</li> <li>Added possibility to use any icon for logo, repository and social links</li> <li>Search UI does not freeze anymore (moved to web worker)</li> <li>Search index built only once when using instant loading</li> <li>Improved extensible keyboard handling</li> <li>Support for prebuilt search indexes</li> <li>Support for displaying stars and forks for GitLab repositories</li> <li>Support for scroll snapping of sidebars and search results</li> <li>Reduced HTML and CSS footprint due to deprecation of Internet Explorer support</li> <li>Slight facelifting of some UI elements (admonitions, tables, ...)</li> </ul>"},{"location":"v10/changelog/#4.6.3","title":"4.6.3 February 14, 2020","text":"<ul> <li>Removed optional third-party plugins from <code>requirements.txt</code></li> <li>Updated Docker image to contain all supported third-party plugins</li> </ul>"},{"location":"v10/changelog/#4.6.2","title":"4.6.2 February 8, 2020","text":"<ul> <li>Added Romanian translations</li> <li>Fixed #1451: Inconsistent spacing for fenced code blocks</li> </ul>"},{"location":"v10/changelog/#4.6.1","title":"4.6.1 February 8, 2020","text":"<ul> <li>Fixed #1324: Metadata author only rendering first character</li> <li>Fixed #1393: Set <code>tabindex</code> to <code>0</code> for skip to content link</li> <li>Fixed code blocks after Markdown 3.2 release</li> <li>Fixed errors in Japanese translations</li> <li>Improved Google Lighthouse score</li> </ul>"},{"location":"v10/changelog/#4.6.0","title":"4.6.0 December 11, 2019","text":"<ul> <li>Added support for git-revision-date-localized-plugin</li> <li>Fixed invalid character in Google Fonts URL</li> </ul>"},{"location":"v10/changelog/#4.5.1","title":"4.5.1 December 2, 2019","text":"<ul> <li>Added Thai translations</li> <li>Fixed missing assets in GitHub release <code>.zip</code> and <code>.tar.gz</code></li> </ul>"},{"location":"v10/changelog/#4.5.0","title":"4.5.0 November 16, 2019","text":"<ul> <li>Fixed #1330: Upgraded EmojiOne to Tweomji due to licensing issues</li> <li>Fixed #1339: Temporarily pinned PyMdown and Markdown due to</li> <li>Fixed errors in Greek translations</li> <li>Improved GitHub statistics retrieval</li> </ul>"},{"location":"v10/changelog/#4.4.3","title":"4.4.3 October 3, 2019","text":"<ul> <li>Added Estonian translations</li> <li>Fixed removal of copyright banners in minified JavaScript</li> <li>Removed unnecessary title attributes from links in table of contents</li> </ul>"},{"location":"v10/changelog/#4.4.2","title":"4.4.2 August 27, 2019","text":"<ul> <li>Added Afrikaans translations</li> <li>Fixed broken page title when <code>h1</code> contained HTML tags</li> <li>Improved accessibility for IE users</li> <li>Removed unnecessary <code>title</code> attributes from links in navigation</li> </ul>"},{"location":"v10/changelog/#4.4.1","title":"4.4.1 August 22, 2019","text":"<ul> <li>Added support for <code>black</code> as a primary color</li> <li>Fixed broken footer bar when <code>h1</code> contained HTML tags</li> </ul>"},{"location":"v10/changelog/#4.4.0","title":"4.4.0 June 15, 2019","text":"<ul> <li>Added Slovenian translations</li> <li>Reverted template minification in favor of <code>mkdocs-minify-plugin</code></li> <li>Fixed #1114: Tabs don't reappear when default <code>font-size</code> is smaller than <code>16</code></li> </ul>"},{"location":"v10/changelog/#4.3.1","title":"4.3.1 May 23, 2019","text":"<ul> <li>Fixed spelling error in Danish translations</li> </ul>"},{"location":"v10/changelog/#4.3.0","title":"4.3.0 May 17, 2019","text":"<ul> <li>Added support for changing header through metadata title property</li> <li>Added <code>font-display: swap</code> to Google Font loading logic</li> <li>Removed whitespace from templates, saving <code>4kb</code> (<code>.7kb</code> gzipped) per request</li> <li>Fixed alignment of repository icons on tablet and desktop</li> </ul>"},{"location":"v10/changelog/#4.2.0","title":"4.2.0 April 28, 2019","text":"<ul> <li>Added Norwegian (Nynorsk) translations</li> <li>Fixed loss of focus in non-form input elements due to search hotkeys</li> <li>Fixed #1067: Search hotkeys not working for mobile/tablet screensize</li> <li>Fixed #1068: Search not correctly aligned for tablet screensize</li> </ul>"},{"location":"v10/changelog/#4.1.2","title":"4.1.2 April 16, 2019","text":"<ul> <li>Fixed #1072: HTML tags appearing in navigation link titles</li> </ul>"},{"location":"v10/changelog/#4.1.1","title":"4.1.1 March 28, 2019","text":"<ul> <li>Fixed minor CSS errors detected during validation</li> </ul>"},{"location":"v10/changelog/#4.1.0","title":"4.1.0 March 22, 2019","text":"<ul> <li>Fixed #1023: Search for Asian languages broken after Lunr.js update</li> <li>Fixed #1026: contenteditable elements loose focus on hotkeys</li> </ul>"},{"location":"v10/changelog/#4.0.2","title":"4.0.2 March 1, 2019","text":"<ul> <li>Fixed #1012: HTML character entities appear in search result titles</li> </ul>"},{"location":"v10/changelog/#4.0.1","title":"4.0.1 February 13, 2019","text":"<ul> <li>Fixed #762, #816: Glitch in sidebar when collapsing items</li> <li>Fixed #869: Automatically expand details before printing</li> </ul>"},{"location":"v10/changelog/#4.0.0","title":"4.0.0 February 13, 2019","text":"<ul> <li>Added background on hover for table rows</li> <li>Removed Google Tag Manager and reverted to Google Analytics</li> <li>Removed blocks in partials - Jinja doesn't support them</li> <li>Fixed #911: Chrome breaks layout if system language is Chinese (BREAKING)</li> <li>Fixed #976: Removed FastClick</li> </ul>"},{"location":"v10/changelog/#3.3.0","title":"3.3.0 January 29, 2019","text":"<ul> <li>Moved Google Analytics integration into <code>head</code> using Google Tag Manager</li> <li>Fixed #972: Unicode slugifier breaks table of contents blur on scroll</li> <li>Fixed #974: Additional links in table of contents break blur on scroll</li> </ul>"},{"location":"v10/changelog/#3.2.0","title":"3.2.0 December 28, 2018","text":"<ul> <li>Added support for redirects using metadata refresh</li> <li>Fixed #921: Load Google Analytics snippet asynchronously</li> </ul>"},{"location":"v10/changelog/#3.1.0","title":"3.1.0 November 17, 2018","text":"<ul> <li>Added support for Progressive Web App Manifest</li> <li>Fixed #915: Search bug in Safari (upgraded Lunr.js)</li> </ul>"},{"location":"v10/changelog/#3.0.6","title":"3.0.6 October 26, 2018","text":"<ul> <li>Added Taiwanese translations</li> <li>Fixed #906: JavaScript code blocks evaluated in search results</li> </ul>"},{"location":"v10/changelog/#3.0.5","title":"3.0.5 October 23, 2018","text":"<ul> <li>Added Croatian and Indonesian translations</li> <li>Fixed #899: Skip-to-content link invalid from 2nd level on</li> <li>Fixed #902: Missing URL filter in footer for FontAwesome link</li> </ul>"},{"location":"v10/changelog/#3.0.4","title":"3.0.4 September 3, 2018","text":"<ul> <li>Updated Dutch translations</li> <li>Fixed #856: Removed preconnect meta tag if Google Fonts are disabled</li> </ul>"},{"location":"v10/changelog/#3.0.3","title":"3.0.3 August 7, 2018","text":"<ul> <li>Fixed #841: Additional path levels for extra CSS and JS</li> </ul>"},{"location":"v10/changelog/#3.0.2","title":"3.0.2 August 6, 2018","text":"<ul> <li>Fixed #839: Lunr.js stemmer imports incorrect</li> </ul>"},{"location":"v10/changelog/#3.0.1","title":"3.0.1 August 5, 2018","text":"<ul> <li>Fixed #838: Search result links incorrect</li> </ul>"},{"location":"v10/changelog/#3.0.0","title":"3.0.0 August 5, 2018","text":"<ul> <li>Upgraded MkDocs to 1.0 (BREAKING)</li> <li>Upgraded Python in official Docker image to 3.6</li> <li>Added Serbian and Serbo-Croatian translations</li> </ul>"},{"location":"v10/changelog/#2.9.4","title":"2.9.4 July 29, 2018","text":"<ul> <li>Fixed build error after MkDocs upgrade</li> </ul>"},{"location":"v10/changelog/#2.9.3","title":"2.9.3 July 29, 2018","text":"<ul> <li>Added link to home for logo in drawer</li> <li>Fixed dependency problems between MkDocs and Tornado</li> </ul>"},{"location":"v10/changelog/#2.9.2","title":"2.9.2 June 29, 2018","text":"<ul> <li>Added Hindi and Czech translations</li> </ul>"},{"location":"v10/changelog/#2.9.1","title":"2.9.1 June 18, 2018","text":"<ul> <li>Added support for different spellings for theme color</li> <li>Fixed #799: Added support for webfont minification in production</li> <li>Fixed #800: Added <code>.highlighttable</code> as an alias for <code>.codehilitetable</code></li> </ul>"},{"location":"v10/changelog/#2.9.0","title":"2.9.0 June 13, 2018","text":"<ul> <li>Added support for theme color on Android</li> <li>Fixed #796: Rendering of nested tabbed code blocks</li> </ul>"},{"location":"v10/changelog/#2.8.0","title":"2.8.0 June 10, 2018","text":"<ul> <li>Added support for grouping code blocks with tabs</li> <li>Added Material and FontAwesome icon fonts to distribution files (GDPR)</li> <li>Added note on compliance with GDPR</li> <li>Added Slovak translations</li> <li>Fixed #790: Prefixed <code>id</code> attributes with <code>__</code> to avoid name clashes</li> </ul>"},{"location":"v10/changelog/#2.7.3","title":"2.7.3 April 26, 2018","text":"<ul> <li>Added Finnish translations</li> </ul>"},{"location":"v10/changelog/#2.7.2","title":"2.7.2 April 9, 2018","text":"<ul> <li>Fixed rendering issue for <code>details</code> on Edge</li> </ul>"},{"location":"v10/changelog/#2.7.1","title":"2.7.1 March 21, 2018","text":"<ul> <li>Added Galician translations</li> <li>Fixed #730: Scroll chasing error on home page if Disqus is enabled</li> <li>Fixed #736: Reset drawer and search upon back button invocation</li> </ul>"},{"location":"v10/changelog/#2.7.0","title":"2.7.0 March 6, 2018","text":"<ul> <li>Added ability to set absolute URL for logo</li> <li>Added Hebrew translations</li> </ul>"},{"location":"v10/changelog/#2.6.6","title":"2.6.6 February 22, 2018","text":"<ul> <li>Added preconnect for Google Fonts for faster loading</li> <li>Fixed #710: With tabs sidebar disappears if JavaScript is not available</li> </ul>"},{"location":"v10/changelog/#2.6.5","title":"2.6.5 February 22, 2018","text":"<ul> <li>Reverted <code>--dev-addr</code> flag removal from <code>Dockerfile</code></li> </ul>"},{"location":"v10/changelog/#2.6.4","title":"2.6.4 February 21, 2018","text":"<ul> <li>Added Catalan translations</li> <li>Fixed incorrect margins for buttons in Firefox and Safari</li> <li>Replaced package manager <code>yarn</code> with <code>npm 5.6</code></li> <li>Reverted GitHub stars rounding method</li> <li>Removed <code>--dev-addr</code> flag from <code>Dockerfile</code> for Windows compatibility</li> </ul>"},{"location":"v10/changelog/#2.6.3","title":"2.6.3 February 18, 2018","text":"<ul> <li>Added Vietnamese translations</li> </ul>"},{"location":"v10/changelog/#2.6.2","title":"2.6.2 February 12, 2018","text":"<ul> <li>Added Arabic translations</li> <li>Fixed incorrect rounding of amount of GitHub stars</li> <li>Fixed double-layered borders for tables</li> </ul>"},{"location":"v10/changelog/#2.6.1","title":"2.6.1 February 11, 2018","text":"<ul> <li>Added ability to override Disqus integration using metadata</li> <li>Fixed #690: Duplicate slashes in source file URLs</li> <li>Fixed #696: Active page highlight not working with default palette</li> <li>Adjusted German translations</li> </ul>"},{"location":"v10/changelog/#2.6.0","title":"2.6.0 February 2, 2018","text":"<ul> <li>Moved default search configuration to default translation (English)</li> <li>Added support to automatically set text direction from translation</li> <li>Added support to disable search stop word filter in translation</li> <li>Added support to disable search trimmer in translation</li> <li>Added Persian translations</li> <li>Fixed support for Polish search</li> <li>Fixed disappearing GitHub, GitLab and Bitbucket repository icons</li> </ul>"},{"location":"v10/changelog/#2.5.5","title":"2.5.5 January 31, 2018","text":"<ul> <li>Added Hungarian translations</li> </ul>"},{"location":"v10/changelog/#2.5.4","title":"2.5.4 January 29, 2018","text":"<ul> <li>Fixed #683: <code>gh-deploy</code> fails inside Docker</li> </ul>"},{"location":"v10/changelog/#2.5.3","title":"2.5.3 January 25, 2018","text":"<ul> <li>Added Ukrainian translations</li> </ul>"},{"location":"v10/changelog/#2.5.2","title":"2.5.2 January 22, 2018","text":"<ul> <li>Added default search language mappings for all localizations</li> <li>Fixed #673: Error loading non-existent search language</li> <li>Fixed #675: Uncaught reference error when search plugin disabled</li> </ul>"},{"location":"v10/changelog/#2.5.1","title":"2.5.1 January 20, 2018","text":"<ul> <li>Fixed permalink for main headline</li> <li>Improved missing translation handling with English as a fallback</li> <li>Improved accessibility with skip-to-content link</li> </ul>"},{"location":"v10/changelog/#2.5.0","title":"2.5.0 January 13, 2018","text":"<ul> <li>Added support for right-to-left languages</li> </ul>"},{"location":"v10/changelog/#2.4.0","title":"2.4.0 January 11, 2018","text":"<ul> <li>Added focus state for clipboard buttons</li> <li>Fixed #400: Search bar steals tab focus</li> <li>Fixed search not closing on Enter when result is selected</li> <li>Fixed search not closing when losing focus due to Tab</li> <li>Fixed collapsed navigation links getting focus</li> <li>Fixed <code>outline</code> being cut off on Tab focus of navigation links</li> <li>Fixed bug with first search result navigation being ignored</li> <li>Removed search result navigation via Tab (use Up and Down)</li> <li>Removed <code>outline</code> resets for links</li> <li>Improved general tabbing behavior on desktop</li> </ul>"},{"location":"v10/changelog/#2.3.0","title":"2.3.0 January 9, 2018","text":"<ul> <li>Added <code>example</code> (synonym: <code>snippet</code>) style for admonitions</li> <li>Added synonym <code>abstract</code> for <code>summary</code> style for admonitions</li> </ul>"},{"location":"v10/changelog/#2.2.6","title":"2.2.6 December 27, 2017","text":"<ul> <li>Added Turkish translations</li> <li>Fixed unclickable area below header in case JavaScript is not available</li> </ul>"},{"location":"v10/changelog/#2.2.5","title":"2.2.5 December 18, 2017","text":"<ul> <li>Fixed #639: Broken default favicon</li> </ul>"},{"location":"v10/changelog/#2.2.4","title":"2.2.4 December 18, 2017","text":"<ul> <li>Fixed #638: Build breaks with Jinja &lt; 2.9</li> </ul>"},{"location":"v10/changelog/#2.2.3","title":"2.2.3 December 13, 2017","text":"<ul> <li>Fixed #630: Admonition sets padding on any last child</li> <li>Adjusted Chinese (Traditional) translations</li> </ul>"},{"location":"v10/changelog/#2.2.2","title":"2.2.2 December 8, 2017","text":"<ul> <li>Added Dutch translations</li> <li>Adjusted targeted link and footnote offsets</li> <li>Simplified admonition styles and fixed padding bug</li> </ul>"},{"location":"v10/changelog/#2.2.1","title":"2.2.1 December 2, 2017","text":"<ul> <li>Fixed #616: Minor styling error with title-only admonitions</li> <li>Removed border for table of contents and improved spacing</li> </ul>"},{"location":"v10/changelog/#2.2.0","title":"2.2.0 November 22, 2017","text":"<ul> <li>Added support for hero teaser</li> <li>Added Portuguese translations</li> <li>Fixed #586: Footnote backref target offset regression</li> <li>Fixed #605: Search stemmers not correctly loaded</li> </ul>"},{"location":"v10/changelog/#2.1.1","title":"2.1.1 November 21, 2017","text":"<ul> <li>Replaced deprecated <code>babel-preset-es2015</code> with <code>babel-preset-env</code></li> <li>Refactored Gulp build pipeline with Webpack</li> <li>Removed right border on sidebars</li> <li>Fixed broken color transition on header</li> </ul>"},{"location":"v10/changelog/#2.1.0","title":"2.1.0 November 19, 2017","text":"<ul> <li>Added support for <code>white</code> as a primary color</li> <li>Added support for sliding site name and title</li> <li>Fixed redundant clipboard button when using line numbers on code blocks</li> <li>Improved header appearance by making it taller</li> <li>Improved tabs appearance</li> <li>Improved CSS customizability by leveraging inheritance</li> <li>Removed scroll shadows via <code>background-attachment</code></li> </ul>"},{"location":"v10/changelog/#2.0.4","title":"2.0.4 November 5, 2017","text":"<ul> <li>Fixed <code>details</code> not opening with footnote reference</li> </ul>"},{"location":"v10/changelog/#2.0.3","title":"2.0.3 November 5, 2017","text":"<ul> <li>Added Japanese translations</li> <li>Fixed #540: Jumping to anchor inside <code>details</code> doesn't open it</li> <li>Fixed active link colors in footer</li> </ul>"},{"location":"v10/changelog/#2.0.2","title":"2.0.2 November 1, 2017","text":"<ul> <li>Added Russian translations</li> <li>Fixed #542: Horizontal scrollbar between <code>1220px</code> and <code>1234px</code></li> <li>Fixed #553: Metadata values only rendering first character</li> <li>Fixed #558: Flash of unstyled content</li> <li>Fixed favicon regression caused by deprecation upstream</li> </ul>"},{"location":"v10/changelog/#2.0.1","title":"2.0.1 October 31, 2017","text":"<ul> <li>Fixed error when initializing search</li> <li>Fixed styles for link to edit the current page</li> <li>Fixed styles on nested admonition in details</li> </ul>"},{"location":"v10/changelog/#2.0.0","title":"2.0.0 October 31, 2017","text":"<ul> <li>Upgraded MkDocs to 0.17.1 (BREAKING)</li> <li>Added support for easier configuration of search tokenizer</li> <li>Added support to disable search</li> <li>Added Korean translations</li> </ul>"},{"location":"v10/changelog/#1.12.2","title":"1.12.2 October 26, 2017","text":"<ul> <li>Added Italian, Norwegian, French and Chinese translations</li> </ul>"},{"location":"v10/changelog/#1.12.1","title":"1.12.1 October 22, 2017","text":"<ul> <li>Added Polish, Swedish and Spanish translations</li> <li>Improved downward compatibility with custom partials</li> <li>Temporarily pinned MkDocs version within Docker image to 0.16.3</li> <li>Fixed #519: Missing theme configuration file</li> </ul>"},{"location":"v10/changelog/#1.12.0","title":"1.12.0 October 20, 2017","text":"<ul> <li>Added support for setting language(s) via <code>mkdocs.yml</code></li> <li>Added support for default localization</li> <li>Added German and Danish translations</li> <li>Fixed #374: Search bar misalignment on big screens</li> </ul>"},{"location":"v10/changelog/#1.11.0","title":"1.11.0 October 19, 2017","text":"<ul> <li>Added localization to clipboard</li> <li>Refactored localization logic</li> </ul>"},{"location":"v10/changelog/#1.10.4","title":"1.10.4 October 18, 2017","text":"<ul> <li>Improved print styles of code blocks</li> <li>Improved search UX (don't close on enter if no selection)</li> <li>Fixed #495: Vertical scrollbar on short pages</li> </ul>"},{"location":"v10/changelog/#1.10.3","title":"1.10.3 October 11, 2017","text":"<ul> <li>Fixed #484: Vertical scrollbar on some MathJax formulas</li> <li>Fixed #483: Footnote backref target offset regression</li> </ul>"},{"location":"v10/changelog/#1.10.2","title":"1.10.2 October 6, 2017","text":"<ul> <li>Fixed #468: Sidebar shows scrollbar if content is shorter (in Safari)</li> </ul>"},{"location":"v10/changelog/#1.10.1","title":"1.10.1 September 14, 2017","text":"<ul> <li>Fixed #455: Bold code blocks rendered with normal font weight</li> </ul>"},{"location":"v10/changelog/#1.10.0","title":"1.10.0 September 1, 2017","text":"<ul> <li>Added support to make logo default icon configurable</li> <li>Fixed uninitialized overflow scrolling on main pane for iOS</li> <li>Fixed error in mobile navigation in case JavaScript is not available</li> <li>Fixed incorrect color transition for nested panes in mobile navigation</li> <li>Improved checkbox styles for Tasklist from PyMdown Extension package</li> </ul>"},{"location":"v10/changelog/#1.9.0","title":"1.9.0 August 29, 2017","text":"<ul> <li>Added <code>info</code> (synonym: <code>todo</code>) style for admonitions</li> <li>Added <code>question</code> (synonym: <code>help</code>, <code>faq</code>) style for admonitions</li> <li>Added support for Details from PyMdown Extensions package</li> <li>Improved admonition styles to match details</li> <li>Improved styles for social links in footer</li> <li>Replaced ligatures with Unicode code points to avoid broken layout</li> <li>Upgraded PyMdown Extensions package dependency to &gt;= 3.4</li> </ul>"},{"location":"v10/changelog/#1.8.1","title":"1.8.1 August 7, 2017","text":"<ul> <li>Fixed #421: Missing pagination for GitHub API</li> </ul>"},{"location":"v10/changelog/#1.8.0","title":"1.8.0 August 2, 2017","text":"<ul> <li>Added support for lazy-loading of search results for better performance</li> <li>Added support for customization of search tokenizer/separator</li> <li>Fixed #424: Search doesn't handle capital letters anymore</li> <li>Fixed #419: Search doesn't work on whole words</li> </ul>"},{"location":"v10/changelog/#1.7.5","title":"1.7.5 July 25, 2017","text":"<ul> <li>Fixed #398: Forms broken due to search shortcuts</li> <li>Improved search overall user experience</li> <li>Improved search matching and highlighting</li> <li>Improved search accessibility</li> </ul>"},{"location":"v10/changelog/#1.7.4","title":"1.7.4 June 21, 2017","text":"<ul> <li>Fixed functional link colors in table of contents for active palette</li> <li>Fixed #368: Compatibility issues with IE11</li> </ul>"},{"location":"v10/changelog/#1.7.3","title":"1.7.3 June 7, 2017","text":"<ul> <li>Fixed error when setting language to Japanese for site search</li> </ul>"},{"location":"v10/changelog/#1.7.2","title":"1.7.2 June 6, 2017","text":"<ul> <li>Fixed offset of search box when <code>repo_url</code> is not set</li> <li>Fixed non-disappearing tooltip</li> </ul>"},{"location":"v10/changelog/#1.7.1","title":"1.7.1 June 1, 2017","text":"<ul> <li>Fixed wrong <code>z-index</code> order of header, overlay and drawer</li> <li>Fixed wrong offset of targeted footnote back references</li> </ul>"},{"location":"v10/changelog/#1.7.0","title":"1.7.0 June 1, 2017","text":"<ul> <li>Added \"copy to clipboard\" buttons to code blocks</li> <li>Added support for multilingual site search</li> <li>Fixed search term highlighting for non-latin languages</li> </ul>"},{"location":"v10/changelog/#1.6.4","title":"1.6.4 May 24, 2017","text":"<ul> <li>Fixed #337: JavaScript error for GitHub organization URLs</li> </ul>"},{"location":"v10/changelog/#1.6.3","title":"1.6.3 May 16, 2017","text":"<ul> <li>Fixed #329: Broken source stats for private or unknown GitHub repos</li> </ul>"},{"location":"v10/changelog/#1.6.2","title":"1.6.2 May 15, 2017","text":"<ul> <li>Fixed #316: Fatal error for git clone on Windows</li> <li>Fixed #320: Chrome 58 creates double underline for <code>abbr</code> tags</li> <li>Fixed #323: Ligatures rendered inside code blocks</li> <li>Fixed miscalculated sidebar height due to missing margin collapse</li> <li>Changed deprecated MathJax CDN to Cloudflare</li> </ul>"},{"location":"v10/changelog/#1.6.1","title":"1.6.1 April 23, 2017","text":"<ul> <li>Fixed following of active/focused element if search input is focused</li> <li>Fixed layer order of search component elements</li> </ul>"},{"location":"v10/changelog/#1.6.0","title":"1.6.0 April 22, 2017","text":"<ul> <li>Added build test for Docker image on Travis</li> <li>Added search overlay for better user experience (focus)</li> <li>Added language from localizations to <code>html</code> tag</li> <li>Fixed #270: source links broken for absolute URLs</li> <li>Fixed missing top spacing for first targeted element in content</li> <li>Fixed too small footnote divider when using larger font sizes</li> </ul>"},{"location":"v10/changelog/#1.5.5","title":"1.5.5 April 20, 2017","text":"<ul> <li>Fixed #282: Browser search (Meta+F) is hijacked</li> </ul>"},{"location":"v10/changelog/#1.5.4","title":"1.5.4 April 8, 2017","text":"<ul> <li>Fixed broken highlighting for two or more search terms</li> <li>Fixed missing search results when only a <code>h1</code> is present</li> <li>Fixed unresponsive overlay on Android</li> </ul>"},{"location":"v10/changelog/#1.5.3","title":"1.5.3 April 7, 2017","text":"<ul> <li>Fixed deprecated calls for template variables</li> <li>Fixed wrong palette color for focused search result</li> <li>Fixed JavaScript errors on 404 page</li> <li>Fixed missing top spacing on 404 page</li> <li>Fixed missing right spacing on overflow of source container</li> </ul>"},{"location":"v10/changelog/#1.5.2","title":"1.5.2 April 5, 2017","text":"<ul> <li>Added requirements as explicit dependencies in <code>setup.py</code></li> <li>Fixed non-synchronized transitions in search form</li> </ul>"},{"location":"v10/changelog/#1.5.1","title":"1.5.1 March 30, 2017","text":"<ul> <li>Fixed rendering and offset of targeted footnotes</li> <li>Fixed #238: Link on logo is not set to <code>site_url</code></li> </ul>"},{"location":"v10/changelog/#1.5.0","title":"1.5.0 March 24, 2017","text":"<ul> <li>Added support for localization of search placeholder</li> <li>Added keyboard events for quick access of search</li> <li>Added keyboard events for search control</li> <li>Added opacity on hover for search buttons</li> <li>Added git hook to skip CI build on non-src changes</li> <li>Fixed non-resetting search placeholder when input is cleared</li> <li>Fixed error for unescaped parentheses in search term</li> <li>Fixed #229: Button to clear search missing</li> <li>Fixed #231: Escape key doesn't exit search</li> <li>Removed old-style figures from font feature settings</li> </ul>"},{"location":"v10/changelog/#1.4.1","title":"1.4.1 March 16, 2017","text":"<ul> <li>Fixed invalid destructuring attempt on NodeList (in Safari, Edge, IE)</li> </ul>"},{"location":"v10/changelog/#1.4.0","title":"1.4.0 March 16, 2017","text":"<ul> <li>Added support for grouping searched sections by documents</li> <li>Added support for highlighting of search terms</li> <li>Added support for localization of search results</li> <li>Fixed #216: table of contents icon doesn't show if <code>h1</code> is not present</li> <li>Reworked style and layout of search results for better usability</li> </ul>"},{"location":"v10/changelog/#1.3.0","title":"1.3.0 March 11, 2017","text":"<ul> <li>Added support for page-specific title and description using metadata</li> <li>Added support for linking source files to documentation</li> <li>Fixed jitter and offset of sidebar when zooming browser</li> <li>Fixed incorrectly initialized tablet sidebar height</li> <li>Fixed regression for #1: GitHub stars break if <code>repo_url</code> ends with a <code>/</code></li> <li>Fixed undesired white line below copyright footer due to base font scaling</li> <li>Fixed issue with whitespace in path for scripts</li> <li>Fixed #205: support non-fixed (static) header</li> <li>Refactored footnote references for better visibility</li> <li>Reduced repaints to a minimum for non-tabs configuration</li> <li>Reduced contrast of edit button (slightly)</li> </ul>"},{"location":"v10/changelog/#1.2.0","title":"1.2.0 March 3, 2017","text":"<ul> <li>Added <code>quote</code> (synonym: <code>cite</code>) style for admonitions</li> <li>Added help message to build pipeline</li> <li>Fixed wrong navigation link colors when applying palette</li> <li>Fixed #197: Link missing in tabs navigation on deeply nested items</li> <li>Removed unnecessary dev dependencies</li> </ul>"},{"location":"v10/changelog/#1.1.1","title":"1.1.1 February 26, 2017","text":"<ul> <li>Fixed incorrectly displayed nested lists when using tabs</li> </ul>"},{"location":"v10/changelog/#1.1.0","title":"1.1.0 February 26, 2017","text":"<ul> <li>Added tabs navigation feature (optional)</li> <li>Added Disqus integration (optional)</li> <li>Added a high resolution Favicon with the new logo</li> <li>Added static type checking using Facebook's Flow</li> <li>Fixed #173: Dictionary elements have no bottom spacing</li> <li>Fixed #175: Tables cannot be set to 100% width</li> <li>Fixed race conditions in build related to asset revisioning</li> <li>Fixed accidentally re-introduced Permalink on top-level headline</li> <li>Fixed alignment of logo in drawer on IE11</li> <li>Refactored styles related to tables</li> <li>Refactored and automated Docker build and PyPI release</li> <li>Refactored build scripts</li> </ul>"},{"location":"v10/changelog/#1.0.5","title":"1.0.5 February 18, 2017","text":"<ul> <li>Fixed #153: Sidebar flows out of constrained area in Chrome 56</li> <li>Fixed #159: Footer jitter due to JavaScript if content is short</li> </ul>"},{"location":"v10/changelog/#1.0.4","title":"1.0.4 February 16, 2017","text":"<ul> <li>Fixed #142: Documentation build errors if <code>h1</code> is defined as raw HTML</li> <li>Fixed #164: PyPI release does not build and install</li> <li>Fixed offsets of targeted headlines</li> <li>Increased sidebar font size by <code>0.12rem</code></li> </ul>"},{"location":"v10/changelog/#1.0.3","title":"1.0.3 January 22, 2017","text":"<ul> <li>Fixed #117: Table of contents items don't blur on fast scrolling</li> <li>Refactored sidebar positioning logic</li> <li>Further reduction of repaints</li> </ul>"},{"location":"v10/changelog/#1.0.2","title":"1.0.2 January 15, 2017","text":"<ul> <li>Fixed #108: Horizontal scrollbar in content area</li> </ul>"},{"location":"v10/changelog/#1.0.1","title":"1.0.1 January 14, 2017","text":"<ul> <li>Fixed massive repaints happening when scrolling</li> <li>Fixed footer back reference positions in case of overflow</li> <li>Fixed header logo from showing when the menu icon is rendered</li> <li>Changed scrollbar behavior to only show when content overflows</li> </ul>"},{"location":"v10/changelog/#1.0.0","title":"1.0.0 January 13, 2017","text":"<ul> <li>Introduced Webpack for more sophisticated JavaScript bundling</li> <li>Introduced ESLint and Stylelint for code style checks</li> <li>Introduced more accurate Material Design colors and shadows</li> <li>Introduced modular scales for harmonic font sizing</li> <li>Introduced git-hooks for better development workflow</li> <li>Rewrite of CSS using the BEM methodology and SassDoc guidelines</li> <li>Rewrite of JavaScript using ES6 and Babel as a transpiler</li> <li>Rewrite of Admonition, Permalinks and CodeHilite integration</li> <li>Rewrite of the complete typographical system</li> <li>Rewrite of Gulp asset pipeline in ES6 and separation of tasks</li> <li>Removed Bower as a dependency in favor of NPM</li> <li>Removed custom icon build in favor of the Material Design icon set</li> <li>Removed <code>_blank</code> targets on links due to vulnerability: http://bit.ly/1Mk2Rtw</li> <li>Removed unversioned assets from build directory</li> <li>Restructured templates into base templates and partials</li> <li>Added build and watch scripts in <code>package.json</code></li> <li>Added support for Metadata and Footnotes Markdown extensions</li> <li>Added support for PyMdown Extensions package</li> <li>Added support for collapsible sections in navigation</li> <li>Added support for separate table of contents</li> <li>Added support for better accessibility through REM-based layout</li> <li>Added icons for GitHub, GitLab and BitBucket integrations</li> <li>Added more detailed documentation on specimen, extensions etc.</li> <li>Added a <code>404.html</code> error page for deployment on GitHub Pages</li> <li>Fixed live reload chain in watch mode when saving a template</li> <li>Fixed variable references to work with MkDocs 0.16</li> </ul>"},{"location":"v10/changelog/#0.2.4","title":"0.2.4 June 26, 2016","text":"<ul> <li>Fixed improperly set default favicon</li> <li>Fixed #33: Protocol relative URL for webfonts doesn't work with <code>file://</code></li> <li>Fixed #34: IE11 on Windows 7 doesn't honor <code>max-width</code> on <code>main</code> tag</li> <li>Fixed #35: Add styling for blockquotes</li> </ul>"},{"location":"v10/changelog/#0.2.3","title":"0.2.3 May 16, 2016","text":"<ul> <li>Fixed #25: Highlight inline fenced blocks</li> <li>Fixed #26: Better highlighting for keystrokes</li> <li>Fixed #30: Suboptimal syntax highlighting for PHP</li> </ul>"},{"location":"v10/changelog/#0.2.2","title":"0.2.2 March 20, 2016","text":"<ul> <li>Fixed #15: Document Pygments dependency for CodeHilite</li> <li>Fixed #16: Favicon could not be set through <code>mkdocs.yml</code></li> <li>Fixed #17: Put version into own container for styling</li> <li>Fixed #20: Fix rounded borders for tables</li> </ul>"},{"location":"v10/changelog/#0.2.1","title":"0.2.1 March 12, 2016","text":"<ul> <li>Fixed #10: Invisible header after closing search bar with ESC key</li> <li>Fixed #13: Table cells don't wrap</li> <li>Fixed empty list in table of contents when no headline is defined</li> <li>Corrected wrong path for static asset monitoring in Gulpfile.js</li> <li>Set up tracking of site search for Google Analytics</li> </ul>"},{"location":"v10/changelog/#0.2.0","title":"0.2.0 February 24, 2016","text":"<ul> <li>Fixed #6: Include multiple color palettes via <code>mkdocs.yml</code></li> <li>Fixed #7: Better colors for links inside admonition notes and warnings</li> <li>Fixed #9: Text for prev/next footer navigation should be customizable</li> <li>Refactored templates (replaced <code>if</code>/<code>else</code> with modifiers where possible)</li> </ul>"},{"location":"v10/changelog/#0.1.3","title":"0.1.3 February 21, 2016","text":"<ul> <li>Fixed #3: Ordered lists within an unordered list have <code>::before</code> content</li> <li>Fixed #4: Click on Logo/Title without Github-Repository: <code>\"None\"</code></li> <li>Fixed #5: Page without headlines renders empty list in table of contents</li> <li>Moved Modernizr to top to ensure basic usability in IE8</li> </ul>"},{"location":"v10/changelog/#0.1.2","title":"0.1.2 February 16, 2016","text":"<ul> <li>Fixed styles for deep navigational hierarchies</li> <li>Fixed webfont delivery problem when hosted in subdirectories</li> <li>Fixed print styles in mobile/tablet configuration</li> <li>Added option to configure fonts in <code>mkdocs.yml</code> with fallbacks</li> <li>Changed styles for admonition notes and warnings</li> <li>Set download link to latest version if available</li> <li>Set up tracking of outgoing links and actions for Google Analytics</li> </ul>"},{"location":"v10/changelog/#0.1.1","title":"0.1.1 February 11, 2016","text":"<ul> <li>Fixed #1: GitHub stars don't work if the repo_url ends with a <code>/</code></li> <li>Updated NPM and Bower dependencies to most recent versions</li> <li>Changed footer/copyright link to Material theme to GitHub pages</li> <li>Made MkDocs building/serving in build process optional</li> <li>Set up continuous integration with Travis</li> </ul>"},{"location":"v10/changelog/#0.1.0","title":"0.1.0 February 9, 2016","text":"<ul> <li>Initial release</li> </ul>"},{"location":"v10/contributing/","title":"Contributing","text":"<p>Material for MkDocs is an actively maintained and constantly improved project  that caters to a diverse user base with varying backgrounds and needs. In order to effectively address the needs of all our users, evaluate requests, and fix  bugs, a lot of work from us maintainers is required.</p>"},{"location":"v10/contributing/#how-to-contribute","title":"How to contribute","text":"<p>We have invested quite a lot of time in creating better templates for our issue tracker, optimizing the processes for our users to report bugs, request features or changes, contribute to the project, or exchange with our community.  This section of the documentation explains each process.</p>"},{"location":"v10/contributing/#creating-an-issue","title":"Creating an issue","text":"<ul> <li> <p> Something is not working?</p> <p>Report a bug in Material for MkDocs by creating an issue and a reproduction</p> <p> Report a bug</p> </li> <li> <p> Missing information in our docs?</p> <p>Report missing information or potential inconsistencies in our documentation</p> <p> Report a docs issue</p> </li> <li> <p> Want to submit an idea?</p> <p>Propose a change or feature request or suggest an improvement</p> <p> Request a change</p> </li> <li> <p> Have a question or need help?</p> <p>Ask questions on our discussion board and get in touch with our community</p> <p> Ask a question</p> </li> </ul>"},{"location":"v10/contributing/reporting-a-bug/","title":"Reporting a bug","text":"<p>Material for MkDocs is an actively maintained project that we constantly strive to improve. With a project of this size and complexity, bugs may occur. If you think you have discovered a bug, you can help us by submitting an issue in our public issue tracker by following this guide.</p>"},{"location":"v10/contributing/reporting-a-bug/#before-creating-an-issue","title":"Before creating an issue","text":"<p>With more than 20,000 users, issues are created every other day. The maintainers of this project are trying very hard to keep the number of open issues down by fixing bugs as fast as possible. By following this guide, you will know exactly what information we need to help you quickly.</p> <p>But first, please try the following things before creating an issue.</p>"},{"location":"v10/contributing/reporting-a-bug/#upgrade-to-latest-version","title":"Upgrade to latest version","text":"<p>Chances are that the bug you discovered was already fixed in a subsequent version. Thus, before reporting an issue, ensure that you're running the latest version of Material for MkDocs. Please consult our upgrade guide to learn how to upgrade to the latest version.</p> <p>Bug fixes are not backported</p> <p>Please understand that only bugs that occur in the latest version of Material for MkDocs will be addressed. Also, to reduce duplicate efforts, fixes cannot be backported to earlier versions.</p>"},{"location":"v10/contributing/reporting-a-bug/#remove-customizations","title":"Remove customizations","text":"<p>If you're using customizations like additional CSS, JavaScript, or theme extension, please remove them from <code>mkdocs.yml</code> before reporting a bug. We can't offer official support for bugs that might hide in your overrides, so make sure to omit the following settings from <code>mkdocs.yml</code>:</p> <ul> <li><code>theme.custom_dir</code></li> <li><code>theme.hooks</code></li> <li><code>extra_css</code></li> <li><code>extra_javascript</code></li> </ul> <p>If, after removing those settings, the bug is gone, the bug is likely caused by your customizations. A good idea is to add them back gradually to narrow down the root cause of the problem. If you did a major version upgrade, make sure you adjusted all partials you have overridden.</p> <p>Customizations mentioned in our documentation</p> <p>A handful of the features Material for MkDocs offers can only be implemented with customizations. If you find a bug in any of the customizations that our documentation explicitly mentions, you are, of course, encouraged to report it.</p> <p>Don't be shy to ask on our discussion board for help if you run into problems.</p>"},{"location":"v10/contributing/reporting-a-bug/#search-for-solutions","title":"Search for solutions","text":"<p>At this stage, we know that the problem persists in the latest version and is not caused by any of your customizations. However, the problem might result from a small typo or a syntactical error in a configuration file, e.g., <code>mkdocs.yml</code>.</p> <p>Now, before you go through the trouble of creating a bug report that is answered and closed right away with a link to the relevant documentation section or another already reported or closed issue or discussion, you can save time for us and yourself by doing some research:</p> <ol> <li> <p>Search our documentation and look for the relevant sections that could     be related to your problem. If found, make sure that you configured     everything correctly.1</p> </li> <li> <p>Search our issue tracker, as another user might already     have reported the same problem, and there might even be a known workaround     or fix for it. Thus, no need to create a new issue.</p> </li> <li> <p>Search our discussion board to learn if other users     are struggling with similar problems and work together with our great     community towards a solution. Many problems are solved here.</p> </li> </ol> <p>Keep track of all search terms and relevant links, you'll need them in the bug report.2</p> <p>At this point, when you still haven't found a solution to your problem, we encourage you to create an issue because it's now very likely that you stumbled over something we don't know yet. Read the following section to learn how to create a complete and helpful bug report.</p>"},{"location":"v10/contributing/reporting-a-bug/#issue-template","title":"Issue template","text":"<p>We have created a new issue template to make the bug reporting process as simple as possible and more efficient for the community and us. It is the result of our experience answering and fixing more than 1,600 issues (and counting) and consists of the following parts:</p> <ul> <li>Title</li> <li>Context optional</li> <li>Description</li> <li>Related links</li> <li>Reproduction</li> <li>Steps to reproduce</li> <li>Browser optional</li> <li>Checklist</li> </ul>"},{"location":"v10/contributing/reporting-a-bug/#title","title":"Title","text":"<p>A good title is short and descriptive. It should be a one-sentence executive summary of the issue, so the impact and severity of the bug you want to report can be inferred from the title.</p> Example Clear Built-in <code>typeset</code> plugin changes precedence of nav title over <code>h1</code> Wordy The built-in <code>typeset</code> plugin changes the precedence of the nav title over the document headline Unclear Title does not work Generic Please help"},{"location":"v10/contributing/reporting-a-bug/#context","title":"Context optional","text":"<p>Before describing the bug, you can provide additional context for us to understand what you are trying to achieve. Explain the circumstances in which you're using Material for MkDocs, and what you think might be relevant. Don't write about the bug here.</p> <p>Why this might be helpful: some errors only manifest in specific settings, environments or edge cases, for example, when your documentation contains thousands of documents.</p>"},{"location":"v10/contributing/reporting-a-bug/#description","title":"Description","text":"<p>Now, to the bug you want to report. Provide a clear, focused, specific, and concise summary of the bug you encountered. Explain why you think this is a bug that should be reported to Material for MkDocs, and not to one of its dependencies.3 Adhere to the following principles:</p> <ul> <li> <p>Explain the what, not the how \u2013 don't explain     how to reproduce the bug here, we're getting there.     Focus on articulating the problem and its impact as clearly as possible.</p> </li> <li> <p>Keep it short and concise \u2013 if the bug can be precisely explained in one     or two sentences, perfect. Don't inflate it \u2013 maintainers and future users     will be grateful for having to read less.</p> </li> <li> <p>One bug at a time \u2013 if you encounter several unrelated bugs, please     create separate issues for them. Don't report them in the same issue, as     this makes attribution difficult.</p> </li> </ul> <p> Stretch goal \u2013 if you found a workaround or a way to fix the bug, you can help other users temporarily mitigate the problem before we maintainers can fix the bug in our code base.</p> <p>Why we need this: in order for us to understand the problem, we need a clear description of it and quantify its impact, which is essential for triage and prioritization.</p>"},{"location":"v10/contributing/reporting-a-bug/#related-links","title":"Related links","text":"<p>Of course, prior to reporting a bug, you have read our documentation and could not find a working solution. Please share links to all sections of our documentation that might be relevant to the bug, as it helps us gradually improve it.</p> <p>Additionally, since you have searched our issue tracker and discussion board before reporting an issue, and have possibly found several issues or discussions, include those as well. Every link to an issue or discussion creates a backlink, guiding us maintainers and other users in the future.</p> <p> Stretch goal \u2013 if you also include the search terms you used when searching for a solution to your problem, you make it easier for us maintainers to improve the documentation.</p> <p>Why we need this: related links help us better understand what you were trying to achieve and whether sections of our documentation need to be adjusted, extended, or overhauled.</p>"},{"location":"v10/contributing/reporting-a-bug/#reproduction","title":"Reproduction","text":"<p>A minimal reproduction is at the heart of every well-written bug report, as it allows us maintainers to quickly recreate the necessary conditions to inspect the bug and quickly find its root cause. It's a proven fact that issues with concise and small reproductions can be fixed much faster.</p> <p>\u00a0 Create a reproduction</p> <p>After you have created the reproduction, you should have a .zip file, ideally not larger than 1 MB. Just drag and drop the .zip file into this field, which will automatically upload it to GitHub.</p> <p>Why we need this: if an issue contains no minimal reproduction or just a link to a repository with thousands of files, the maintainers would need to invest a lot of time into trying to recreate the right conditions to even inspect the bug, let alone fix it.</p> <p>Don't share links to repositories</p> <p>While we know that it is a good practice among developers to include a link to a repository with the bug report, we currently don't support those in our process. The reason is that the reproduction which is automatically produced by the built-in info plugin contains all of the necessary environment information that is often forgotten to be included.</p> <p>Additionally, there are many non-technical users of Material for MkDocs that have trouble creating repositories.</p>"},{"location":"v10/contributing/reporting-a-bug/#steps-to-reproduce","title":"Steps to reproduce","text":"<p>At this point, you provided us with enough information to understand the bug, and you gave us a reproduction that we could run and inspect. However, when we run your reproduction, it might not be immediately apparent how we can see the bug in action.</p> <p>Next, please list the specific steps we should follow when running your reproduction to observe the bug. Keep the steps short and concise, and make sure not to leave anything out. Use simple language as you would explain it to a five-year-old, and focus on continuity.</p> <p>Why we need this: we must know how to navigate your reproduction in order to observe the bug, as some bugs only occur at certain viewports or in specific conditions.</p>"},{"location":"v10/contributing/reporting-a-bug/#browser","title":"Browser optional","text":"<p>If you're reporting a bug that only happens in one or more specific browsers, we need to know which browsers are affected. This field is optional, as it is only relevant when the bug you are reporting does not involve a crash when previewing or building your site.</p> <p>Why we need this: some bugs only occur in specific browsers or versions. Since now, almost all browsers are evergreen, we usually don't need to know the version in which it occurs, but we might ask for it later. When in doubt, add the browser version as the first step in the field above.</p>"},{"location":"v10/contributing/reporting-a-bug/#checklist","title":"Checklist","text":"<p>Thanks for following the guide and creating a high-quality and complete bug report \u2013 you are almost done. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with everything we  need to know to help you.</p> <p>We'll take it from here.</p>"},{"location":"v10/contributing/reporting-a-bug/#incomplete-issues","title":"Incomplete issues","text":"<p>Please understand that we reserve the right to close incomplete issues which do not contain minimal reproductions or do not adhere to the quality standards and requirements mentioned in this document. Issues can be reopened when the missing information has been provided.</p> <ol> <li> <p>When adding lines to <code>mkdocs.yml</code>, make sure you are preserving the indentation as mentioned in the documentation since YAML is a whitespace-sensitive language. Many reported issues turn out to be configuration errors.\u00a0\u21a9</p> </li> <li> <p>We might be using terminology in our documentation different from yours, but mean the same. When you include the search terms and related links in your bug report, you help us to adjust and improve the documentation.\u00a0\u21a9</p> </li> <li> <p>Sometimes, users report bugs on our issue tracker that are caused by one of our upstream dependencies, including MkDocs, Python Markdown, Python Markdown Extensions or third-party plugins. A good rule of thumb is to change the <code>theme.name</code> to <code>mkdocs</code> or <code>readthedocs</code> and check if the problem persists. If it does, the problem is likely not related to Material for MkDocs and should be reported upstream. When in doubt, use our discussion board to ask for help.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/contributing/reporting-a-docs-issue/","title":"Reporting a docs issue","text":"<p>In the past seven years, our documentation has grown to more than 60 pages. With a site being this large, inconsistencies can occur. If you find an inconsistency or see room for clarification or improvement, please submit an issue to our public issue tracker by following this guide.</p>"},{"location":"v10/contributing/reporting-a-docs-issue/#issue-template","title":"Issue template","text":"<p>Reporting a documentation issue is usually less involved than reporting a bug, as we don't need a reproduction. Please thoroughly read the following guide before creating a new documentation issue, and provide the following information as part of the issue:</p> <ul> <li>Title</li> <li>Description</li> <li>Related links</li> <li>Proposed change optional</li> <li>Checklist</li> </ul>"},{"location":"v10/contributing/reporting-a-docs-issue/#title","title":"Title","text":"<p>A good title should be a short, one-sentence description of the issue, contain all relevant information and, in particular, keywords to simplify the search in the issue tracker.</p> Example Clear Clarify social cards setup on Windows Unclear Missing information in the docs Generic Please help"},{"location":"v10/contributing/reporting-a-docs-issue/#description","title":"Description","text":"<p>Provide a clear and concise summary of the inconsistency or issue you  encountered in the documentation or the documentation section that needs  improvement. Explain why you think the documentation should be adjusted and  describe the severity of the issue:</p> <ul> <li> <p>Keep it short and concise \u2013 if the inconsistency or issue can be      precisely explained in one or two sentences, perfect. Maintainers and     future users will be grateful for having to read less.</p> </li> <li> <p>One issue at a time \u2013 if you encounter several unrelated inconsistencies,     please create separate issues for them. Don't report them in the same issue \u2013 it makes attribution difficult.</p> </li> </ul> <p>Why we need this: in order for us to understand the problem, we need a clear description of it and quantify its impact, which is essential for triage and prioritization.</p>"},{"location":"v10/contributing/reporting-a-docs-issue/#related-links","title":"Related links","text":"<p>After you described the documentation section that needs to be adjusted above,  we now ask you to share the link to this specific documentation section and other possibly related sections. Make sure to use anchor links (permanent links)  where possible, as it simplifies discovery.</p> <p>Why we need this: providing the links to the documentation help us  understand which sections of our documentation need to be adjusted, extended,  or overhauled.</p>"},{"location":"v10/contributing/reporting-a-docs-issue/#proposed-change","title":"Proposed change optional","text":"<p>Now that you have provided us with the description and links to the documentation sections, you can help us, maintainers, and the community by proposing an improvement. You can sketch out rough ideas or write a concrete proposal. This field is optional but very helpful.</p> <p>Why we need this: improvement proposal can be beneficial for other users  who encounter the same issue, as they offer solutions before we maintainers can update the documentation.</p>"},{"location":"v10/contributing/reporting-a-docs-issue/#checklist","title":"Checklist","text":"<p>Thanks for following the guide and creating a high-quality and complete issue  report \u2013 you are almost done. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with every piece of information we need to improve our documentation.</p> <p>We'll take it from here.</p>"},{"location":"v10/contributing/requesting-a-change/","title":"Requesting a change","text":"<p>Material for MkDocs is a powerful tool for creating beautiful and functional project documentation. With more than 20,000 users, we understand that our project serves a wide range of use cases, which is why we have created the following guide.</p> <p>Put yourself in our shoes \u2013 with a project of this size, it can be challenging to maintain existing functionality while constantly adding new features at the same time. We highly value every idea or contribution from our community, and we kindly ask you to take the time to read the following guidelines before  submitting your change request in our public issue tracker. This will help us  better understand the proposed change and how it will benefit the community.</p> <p>This guide is our best effort to explain the criteria and reasoning behind our decisions when evaluating change requests and considering them for implementation. </p>"},{"location":"v10/contributing/requesting-a-change/#before-creating-an-issue","title":"Before creating an issue","text":"<p>Before you invest your time to fill out and submit a change request, we kindly ask you to do some preliminary work by answering some questions to determine if your idea is a good fit for Material for MkDocs and matches the project's philosophy and tone.</p> <p>Please find answers to the following questions before creating an issue.</p>"},{"location":"v10/contributing/requesting-a-change/#its-not-a-bug-its-a-feature","title":"It's not a bug, it's a feature","text":"<p>Change requests are intended to suggest minor adjustments, ideas for new features, or to influence the project's direction and vision. It is important to note that change requests are not intended for reporting bugs, as they're missing essential information for debugging.</p> <p>If you want to report a bug, please refer to our bug reporting guide instead.</p>"},{"location":"v10/contributing/requesting-a-change/#source-of-inspiration","title":"Source of inspiration","text":"<p>If you have seen your idea implemented in another static site generator or theme, make sure to collect enough information on its implementation before submitting, as this allows us to evaluate potential fit more quickly. Explain what you like and dislike about the implementation.</p>"},{"location":"v10/contributing/requesting-a-change/#benefit-for-the-community","title":"Benefit for the community","text":"<p>Our discussion board is the best place to connect with our community. When  evaluating new ideas, it's essential to seek input from other users and consider  alternative viewpoints. This approach helps to implement new features in a way that benefits a large number of users.</p> <p>\u00a0 Start a discussion</p>"},{"location":"v10/contributing/requesting-a-change/#issue-template","title":"Issue template","text":"<p>Now that you have taken the time to do the necessary preliminary work and ensure  that your idea meets our requirements, you are invited to create a change request. The following guide will walk you through all the necessary steps to  help you submit a comprehensive and useful issue:</p> <ul> <li>Title</li> <li>Context optional</li> <li>Description</li> <li>Related links</li> <li>Use cases</li> <li>Visuals optional</li> <li>Checklist</li> </ul>"},{"location":"v10/contributing/requesting-a-change/#title","title":"Title","text":"<p>A good title is short and descriptive. It should be a one-sentence executive summary of the idea, so the potential impact and benefit for the community can  be inferred from the title.</p> Example Clear Index custom front matter in search Wordy Add a feature where authors can define custom front matter to be indexed in search Unclear Improve search Generic Please help"},{"location":"v10/contributing/requesting-a-change/#context","title":"Context optional","text":"<p>Before describing your idea, you can provide additional context for us to understand what you are trying to achieve. Explain the circumstances in which you're using Material for MkDocs, and what you think might be relevant. Don't write about the change request here.</p> <p>Why this might be helpful: some ideas might only benefit specific settings, environments, or edge cases, for example, when your documentation contains thousands of documents. With a little context, change requests can be prioritized more accurately.</p>"},{"location":"v10/contributing/requesting-a-change/#description","title":"Description","text":"<p>Next, provide a detailed and clear description of your idea. Explain why your  idea is relevant to Material for MkDocs and must be implemented here, and not in one of its dependencies:1</p> <ul> <li> <p>Explain the what, not the why \u2013 don't explain     the benefits of your idea here, we're getting there.     Focus on describing the proposed change request as precisely as possible.</p> </li> <li> <p>Keep it short and concise \u2013 be brief and to the point when describing      your idea, there is no need to over-describe it. Maintainers and future     users will be grateful for having to read less.</p> </li> <li> <p>One idea at a time \u2013 if you have multiple ideas that don't belong  together, please open separate change requests for each of those ideas.</p> </li> </ul> <p> Stretch goal \u2013 if you have a customization or another way to add the proposed change, you can help other users by sharing it here before we maintainers can add it to our code base.</p> <p>Why we need this: To understand and evaluate your proposed change, we need to have a clear understanding of your idea. By providing a detailed and  precise description, you can help save you and us time spent discussing further clarification of your idea in the comments.</p>"},{"location":"v10/contributing/requesting-a-change/#related-links","title":"Related links","text":"<p>Please provide any relevant links to issues, discussions, or documentation  sections related to your change request. If you (or someone else) already discussed this idea with the community on our discussion board, please include  the link to the discussion as well.</p> <p>Why we need this: Related links help us gain a comprehensive understanding of your change request by providing additional context. Additionally, linking to previous issues and discussions allows us to quickly evaluate the feedback and input already provided by the community.</p>"},{"location":"v10/contributing/requesting-a-change/#use-cases","title":"Use cases","text":"<p>Explain how your change request would work from an author's and user's perspective \u2013 what's the expected impact, and why does it benefit not only you but other users? How many of them? Furthermore, would it potentially break existing functionality?</p> <p>Why we need this: Understanding the use cases and benefits of an idea is  crucial in evaluating its potential impact and usefulness for the project and  its users. This information helps us to understand the expected value of the  idea and how it aligns with the goals of the project.</p>"},{"location":"v10/contributing/requesting-a-change/#visuals","title":"Visuals optional","text":"<p>We now have a clear and detailed description of your idea, including information  on its potential use cases and relevant links for context. If you have any  visuals, such as sketches, screenshots, mockups, or external assets, you may  present them in this section.</p> <p>You can drag and drop the files here or include links to external assets.</p> <p>Additionally, if you have seen this change, feature, or improvement used in  other static site generators or themes, please provide an example by showcasing  it and describing how it was implemented and incorporated.</p> <p>Why we need this: Illustrations and visuals can help us maintainers  better understand and envision your idea. Screenshots, sketches, or mockups  can create an additional level of detail and clarity that text alone may not  be able to convey. Also, seeing how your idea has been implemented in other  projects can help us understand its potential impact and feasibility in  Material for MkDocs, which helps us maintainers evaluate and triage  change requests.</p>"},{"location":"v10/contributing/requesting-a-change/#checklist","title":"Checklist","text":"<p>Thanks for following the change request guide and creating a high-quality  change request. This section ensures that you have read this guide and have worked to the best of your knowledge to provide us with every piece of  information to review your idea for Material for MkDocs.</p> <p>We'll take it from here.</p> <ol> <li> <p>Sometimes, users suggest ideas on our issue tracker that concern one of our upstream dependencies, including MkDocs, Python Markdown, Python Markdown Extensions or third-party plugins. It's a good idea to think about whether your idea is beneficial to other themes, upstreaming change requests for a bigger impact.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/faq/sponsoring/","title":"Sponsoring FAQs","text":"<p>Do you have questions about Material for MkDocs Insiders? We do our best to answer all of your questions on this page. If you can't find your question  below, ask it on our discussion board!</p>"},{"location":"v10/faq/sponsoring/#general","title":"General","text":"<p>Why is the Insiders edition offered as a subscription model?</p> <p>Material for MkDocs always was and will be Open Source, available for free to individuals and organizations. As the project grew over time, we found that maintaining and managing the overhead that comes with growth became more challenging and time-consuming.</p> <p>In order to sustain the project and add new and useful features more frequently, we decided to create the Insiders edition, with early access to the latest and greatest features of Material for MkDocs. The subscription-based model of the Insiders edition allows us to dedicate more time and resources to the project, which benefits all  users of Material for MkDocs. Once our funding goals based on monthly  subscriptions are hit, the Insiders features of those^ funding goals are released  to the community edition, letting everyone benefit from them. </p> <p>Maintaining both the community and Insiders editions is an ongoing process, and  we rely on our sponsors to support us on a monthly basis, which makes this whole  project possible.</p> <p>What features are included in the Insiders edition?</p> <p>The Insiders edition includes more than 20 additional features. You can find an  overview of these features on our Insiders page, which is updated when new features are added and released.</p> <p>How often is the Insiders edition updated?</p> <p>We try to keep our open issue count low, fixing known bugs quickly. Both our repositories, the community and Insiders edition, are constantly updated with bug fixes and new features.</p>"},{"location":"v10/faq/sponsoring/#sponsorship","title":"Sponsorship","text":"<p>Can I sponsor the project without a GitHub account?</p> <p>Yes. You can support Material for MkDocs by sponsoring us on Ko-fi, regardless of whether you have a GitHub account or not. However, please note that Insiders is provided as a private repository on GitHub. If after sponsoring, you'd like to gain access to the repository, you'll need to have a GitHub individual or bot account that can be added as a collaborator. If your organization doesn't use GitHub or/and host its repositories on other platforms, you can mirror the Insiders repository in your environment once you have access.</p> <p>Which sponsoring tier should I choose?</p> <p>The sponsoring tiers are divided into non-commercial and commercial tiers. If  you are an individual or organization using Material for MkDocs for private or non-commercial Open Source projects, you have two tiers to choose from,  depending on the number of sites you want to build. For companies using  Material for MkDocs, we offer three different commercial tiers, from which  you can choose depending on your requirements.</p> <p>Also, please read what is considered commercial use.</p> <p>Why are one-time sponsorships not granted access to Insiders?</p> <p>Primarily due to technical reasons, that we're working on lifting in the future. We use GitHub webhooks to determine our current active sponsors. When you create or cancel your monthly subscription, GitHub sends events that we use to automatically add and remove collaborators.</p> <p>Note that $15 is the minimum amount to be granted access to Insiders.</p> <p>How is my sponsorship contribution used to support the project?</p> <p>Your sponsorship contribution directly supports the development and  maintenance of the project, by buying us maintainers time. It allows us to dedicate more time and resources to enhance the project's features and functionality. The additional funding helps us prioritize improvements and updates, benefiting Insiders users and the wider community. We also actively contribute to other upstream projects, fostering collaboration and giving back to the Open Source ecosystem.</p> <p>Are there any limitations on the number of sponsors for a particular tier?</p> <p>No, there are no limitations on the number of sponsors for any tier. You can sponsor the project at any tier regardless of how many other sponsors are already there.</p>"},{"location":"v10/faq/sponsoring/#payment-billing","title":"Payment &amp; billing","text":"<p>Is there a trial period for the Insiders edition?</p> <p>No, we do not offer a trial period for the Insiders edition. However, if you're a company and are considering sponsoring on the commercial tier, but want to first give the Insiders edition a try, you can sponsor on the $15 tier with a personal account for non-commercial evaluation purposes.</p> <p>Additionally, our subscription model allows you to cancel your sponsorship anytime. If you decide to cancel, your sponsorship will remain active until  the end of your billing cycle.</p> <p>What payment options do you accept?</p> <p>We manage all our transactions and sponsorships through GitHub Sponsors and  Ko-fi. To become a sponsor of Material for MkDocs on GitHub, visit  our sponsors' page. On there, you can choose from five different sponsorship  tiers and pay by credit card. Please note that as of the beginning of 2023,  GitHub no longer supports PayPal payments. If you wish to pay with PayPal,  ou can find a selection of our sponsorship tiers on Ko-fi. Both platforms provide you with a payment receipt once your purchase is successful.</p> <p>If you're a company and need assistance choosing the right payment method, please don't hesitate to reach out to sponsors@squidfunk.com.</p> <p>Are discounts available for the Insiders edition, such as student discounts?</p> <p>Unfortunately, we are not able to offer any discounts for the Material for  MkDocs Insiders program. To ensure that everyone can afford the Insiders program  and keep the barrier as low as possible, we have set prices as low as $15 a month for non-commercial use.</p> <p>Do you offer free access to Insiders for Open Source projects?</p> <p>No, we do not offer free access to our Material for MkDocs Insiders edition.  We understand that non-profit organizations may have limited budgets and may  need to prioritize their spending on other projects or organizations. However, it's important to note that Material for MkDocs is maintained by a small team,  investing a lot of time and resources into constantly improving this project.  Material for MkDocs and its core features are free to the community through our  Open Source model. Therefore, Material for MkDocs itself is already free.</p> <p>However, we do offer an affordable sponsorship tier starting at $15 a month,  which is meant for individuals and non-profit organizations using Material for  MkDocs to build 1-2 sites for non-commercial purposes. This tier provides access  to all new features, benefiting you from our ongoing development efforts.</p> <p>Is Insiders free for those who contribute to this project?</p> <p>Great question! We can not offer free access to \"drive-by\" contributors that  only fix minor issues like typos or add new languages. These contributions are  always welcome, but as we need to review them, they result in a higher time  investment from our side and don't compensate for this work. However, as this  project keeps growing, we always seek for individuals to support us. In return,  we offer financial compensation or/and Insiders access. If you are interested  and have experience in the technologies and paradigms listed below, please get in touch with us at sponsors@squidfunk.com:</p> <ul> <li>Deep knowledge of CSS, HTML, TypeScript</li> <li>Experience with progressive enhancement and responsive design</li> <li>Experience with reactive programming with RxJS</li> <li>Solid understanding of Python, MkDocs + ecosystem</li> <li>Solid technical writing skills</li> </ul> <p>Additionally, we're working on a contributor program that will reward contributors that engage in the community by answering questions and helping users with access to Insiders.</p> <p>How can I set my billing to monthly or yearly?</p> <p>You can sponsor Material for MkDocs on a monthly or yearly basis. Depending on  your billing cycle you automatically become a monthly or yearly sponsor. Your  billing cycle is an account-level setting that you can easily change in your  account. If, for some reason, you cannot make this change, you can create a  dedicated bot account with a yearly billing cycle on GitHub, which you only use  for sponsoring (some sponsors already do that). If you have any problems or  further questions, please contact us at sponsors@squidfunk.com.</p> <p>Can I get an invoice for my sponsorship payment?</p> <p>Right now, we can't provide you with an invoice for your sponsoring transaction, as GitHub Sponsors handles all transactions for us. However, both payment platforms, GitHub and Ko-Fi, automatically send you a payment receipt  via mail once the sponsorship is active.</p> <p>Furthermore, we are working on a solution to optimize access management and more features. If you are interested in this, please get in touch with us via mail at sponsors@squidfunk.com or turn on all notifications for MkDocs, and we will reach out as soon as we are live.</p> <p>Can I switch between different sponsoring tiers?</p> <p>Yes, you can switch between different sponsoring tiers at any time. Simply go  to the GitHub Sponsors page and change your sponsoring tier. Once you make  that change, you will immediately change to the new tier.</p> <p>If you change to a higher tier, the amount will be prorated according to your billing cycle.</p> <p>Can I sponsor the project for a specific feature or development goal?</p> <p>While sponsoring specific goals directly is not possible, our sponsoring goals are connected to specific features or development goals aligned with the  project's roadmap. You can find an overview of these sponsoring goals and their  associated features on our website. Insider users have early access to all  already developed features, including those associated with higher funding goals  that will be reached at a later stage. If you're interested in accessing these  features, becoming a sponsor is the way to go. If you have a feature in mind  that you would like to see on the list, we encourage you to  initiate a new discussion to evaluate it with others.</p> <p>What happens if I reach my sponsoring limit for my current tier?</p> <p>If you extend the number of sites that are in your current sponsoring limit,  please upgrade your sponsorship to a higher tier to continue using the  Insiders version and build more sites. The change will be effective immediately.</p> <p>Do you offer refunds for sponsoring payments?</p> <p>Unfortunately, we cannot offer any refund for sponsorship payments.  GitHub Sponsors and Ko-Fi manage all sponsoring transactions. Because of  that, we do not have any insights into the details of the funds and cannot access  them. If you have any payment issues, please get in touch with the GitHub  or Ko-Fi support team, as they can help you.</p>"},{"location":"v10/faq/sponsoring/#access-management","title":"Access management","text":"<p>How do I gain access to the private Insiders repository?</p> <p>If you sponsored with your individual account, you should have received an  email invitation to the private Material for MkDocs Insiders repository right  after you initiated your sponsorship. Simply accept the invitation within seven  days to gain access.</p> <p>If you sponsored using an organization account, please note we need  an individual account that we can list as a collaborator of the private Insiders  repository. After you initiate your sponsorship, please email us at  sponsors@squidfunk.com with the name of the individual or bot account. Once you  provide us with this information, we will add the account as a collaborator, and  after you accept the invitation, you will gain access to the repository.</p> <p>If you have yet to receive the email or the invitation link has expired, please  contact us, the maintainers, at sponsors@squidfunk.com. We're working on a solution that will allow you to manage collaborator status yourself.</p> <p>Why can't our whole organization get access to Insiders?</p> <p>Currently, it is not possible to grant access to an organizational account, as  GitHub only allows for adding individual user accounts. We are working on a  solution ourselves to simplify access for organizations. For now, to ensure that  access is not tied to a particular individual, we recommend creating a bot  account, i.e., a GitHub account that does not belong to a specific individual  but is listed as the owner of the organizational account and using this account  for sponsorship.</p> <p>Do I need to fork the repository to use it?</p> <p>It depends. If you are using the Insiders edition as an individual, you can work directly with the private repository, as you do not need to share the Insiders features with others. If you are working with a team, it is best to create a private fork using the individual account you listed as a collaborator of Material for MkDocs to grant access to all members of your organization to your fork.</p> <p>Can I share my Insiders access with others?</p> <p>At the moment, it is not possible to directly share your collaborator status  for the private Insiders repository with other accounts. However, if you are  working with a team and would like them to access Insiders, you can share the  Insiders repository by utilizing options such as cloning, forking, or  mirroring. By doing so, you can start collaborating with your team members on  the new repository you have shared. This way, you can collectively benefit  from the Insiders features and work together on the project.</p>"},{"location":"v10/faq/sponsoring/#runtime-cancellation","title":"Runtime &amp; cancellation","text":"<p>How long is my sponsorship valid?</p> <p>Your sponsorship is valid for as long as your monthly or yearly subscription is valid. If you choose to cancel your sponsorship, you will lose access to  the Insiders edition once your cancelation is active and will be automatically  removed by GitHub as a collaborator from the private repository. </p> <p>How do I cancel my sponsorship?</p> <p>To cancel your sponsorship, follow the step-by-step guide provided by GitHub.  If you sponsored using an organizational account, please ensure that you cancel  your sponsorship using the same organizational account rather than your  individual account.</p> <p>What happens when I cancel my sponsorship?</p> <p>If you choose to cancel your subscription to Insiders, you will be  automatically removed by GitHub as a collaborator on the day your cancellation is  effective. From that day on, you will no longer receive future updates. However,  you are welcome to continue using the latest version that was available to  you at the time of your cancellation for as long as you like.</p> <p>Please note that GitHub deletes private forks, so you may want to take steps to ensure that you have a backup of the software if necessary and use the locally installed version.</p>"},{"location":"v10/faq/sponsoring/#licensing","title":"Licensing","text":"<p>What constitutes commercial use of the Insiders version?</p> <p>Commercial use refers to any use of the software for a business or for-profit  purpose. This includes any use by a corporation or other organization, whether  or not they generate revenue directly from the software. We offer different  pricing tiers for commercial use, each tailored to the needs of different  businesses. It's important to note that internal use of the software within your  organization is also considered commercial use, as with all commercial software.</p> <p>What constitutes non-commercial use of the Insiders version?</p> <p>Non-commercial use of our Material for MkDocs refers to private use. This includes individuals using the Insiders edition for private or purely non-commercial Open Source projects. We offer two different tiers for non-commercial use, depending on the number of sites you want to build.  </p> <p>What is your fair use policy?</p> <p>Our fair use policy includes the following guidelines:</p> <ul> <li> <p>Please refrain from distributing the source code of Insiders. While you  may use the software for public, private, or commercial projects and may  privately fork or mirror it, we ask that you keep the source code private. This  is important to our sponsorware strategy, which helps us fund ongoing  development and support of the software. If this guidelines is violated, everybody loses, as it will reduce the time of us maintainers we can set aside to push this project forward.</p> </li> <li> <p>As our sponsoring tiers are based on the number of sites you want to build,  please make sure to upgrade your sponsorship once your current sponsoring tier  limit has been reached. </p> </li> </ul> <p>Does the Insiders version have a different license?</p> <p>No. Whether you're an individual or a company, you may use Material for  MkDocs Insiders precisely under the same terms as Material for MkDocs, which are  given by the MIT license.</p> <p>Can outside collaborators build and run the documentation locally without access to Insiders?</p> <p>Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, changing the general  appearance of your site should be optional. Most Insiders features enhance the  overall experience, e.g., by adding icons to pages or providing a feedback  widget. While these features add value for your site's users, they should be  optional for previewing when making changes to content. Currently, the only  content-related features in Insiders that non-Insiders users can't properly  preview are Annotations and Card grids.</p> <p>This means that outside collaborators can build the documentation locally with  Material for MkDocs, and when they push their changes, your CI pipeline will  build it with Insiders. When using built-in plugins exclusive to Insiders, it's  recommended to split configuration into a base <code>mkdocs.yml</code> and one with plugin  overrides via configuration inheritance.</p> <p>See the getting started guide for more information.</p>"},{"location":"v10/faq/sponsoring/#support","title":"Support","text":"<p>How can I contact support if I have questions about becoming a sponsor? </p> <p>If you have any questions and would like to contact us before starting your  sponsorship, we are happy to answer all your non-technical questions about the  Insiders program via email at sponsors@squidfunk.com.</p> <p>All technical questions should be asked openly on our discussion board.</p> <p>Is additional support available for Material for MkDocs Insiders users?</p> <p>Yes, we provide non-technical support related to sponsoring at sponsors@squidfunk.com. For technical questions, please submit an issue openly  on our issue tracker or start a discussion on our discussion board. Issues  and discussions from our organizational sponsors, sponsoring on  The Organization tier or higher will be prioritized.1</p> <p>How can I display my logo on the list of premium sponsors?</p> <p>If your sponsorship tier includes logo placement, and you would like us to display your logo in the list of premium sponsors and have it linked to your site, please contact us via mail. Simply send us a horizontal SVG or PNG version of your logo making sure it displays the name of your company and the logo to sponsors@squidfunk.com. </p> <p>Is logo placement optional?</p> <p>Yes, all of our commercial benefits, such as logo placement and backlinks, are  optional and can be opted in or out at any time. You can keep your sponsorship completely private.</p> <p>How can I report a bug in the Insiders version?</p> <p>If you encounter a bug in the Insiders edition, we kindly request that you  report it on our issue tracker in the public community repository. When  submitting the bug report, please ensure that you do not include any private  Insiders' source code, as we want to uphold our fair use policy. </p>"},{"location":"v10/faq/sponsoring/#privacy","title":"Privacy","text":"<p>Will you sign an NDA for sponsorships?</p> <p>Unfortunately, we cannot sign any NDA or vendor agreement form. As a small team working on Material for MkDocs, we have limited resources and cannot review  and sign agreements.</p> <p>Can I sponsor privately?</p> <p>Yes, you can. GitHub gives you the option to set your sponsorship to private  when you set up your sponsorship. Additionally, we have a recommended workflow  for you: We suggest you create a new GitHub bot account. This bot account should  not be tied to a particular individual and should be privately listed as an  owner of your GitHub organization. This account can then be used to sponsor  Material for MkDocs privately. As a bot account, it will automatically be listed  as a collaborator of the private Insiders repository. You can clone, fork, or  mirror using this account. All information will be kept confidential; only the  bot account and us maintainers will have insights into his sponsorship. </p> <p>Are there any geographical restrictions on becoming a sponsor?</p> <p>No, there are no geographical restrictions for becoming a sponsor. We welcome  sponsorships from individuals and organizations worldwide. As long as your  credit card is valid and accepted by GitHub or Ko-Fi, you are eligible to become  a sponsor and support the project, regardless of your location. </p> <ol> <li> <p>Priority support means we will prioritize your issue, meaning we will look  into it and do our best to solve your issue asap. However, the prioritized bug  support does not mean that we can solve your issue before any others since  some issues might take more time to solve.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/guides/creating-a-reproduction/","title":"Creating a reproduction","text":"<p>A reproduction is a simplified version of a bug that demonstrates the specific  scenario in which the bug occurred. It includes all necessary minimal settings  and instructions and should be as simple as possible while still demonstrating  the issue.</p>"},{"location":"v10/guides/creating-a-reproduction/#guide","title":"Guide","text":""},{"location":"v10/guides/creating-a-reproduction/#environment","title":"Environment optional","text":"<p>We recommend using a virtual environment, which is an isolated Python runtime. If you are in a virtual environment, any packages that you install or upgrade will be local to the environment. If you run into problems, you can just delete and recreate the environment. It's trivial to set up:</p> <ul> <li> <p>Create a new virtual environment with:</p> <pre><code>python3 -m venv venv\n</code></pre> </li> <li> <p>Activate the environment with:</p>  macOS Windows Linux <pre><code>. venv/bin/activate\n</code></pre> <pre><code>. venv/Scripts/activate\n</code></pre> <pre><code>. venv/bin/activate\n</code></pre> <p>Your terminal should now print <code>(venv)</code> before the prompt, which is how you know that you are inside the virtual environment that you just created.</p> </li> <li> <p>Exit the environment with:</p> <pre><code>deactivate\n</code></pre> </li> </ul>"},{"location":"v10/guides/creating-a-reproduction/#minimal-reproduction","title":"Minimal reproduction","text":"<p>Following the instructions below, you will set up a skeleton project to create a reproduction. As mentioned above, we recommend using a virtual environment, so create a new folder in your working directory and a a new virtual environment inside it. Next:</p> <ol> <li> <p>As mentioned in our bug reporting guide, ensure that you're running the     latest version of Material for MkDocs, which might already include a fix for     the bug:</p> <pre><code>pip install --upgrade --force-reinstall mkdocs-material\n</code></pre> </li> <li> <p>Bootstrap a new documentation project using the <code>mkdocs</code> executable,     which you use as a basis for the reproduction. It's essential to create a     new, empty project for this:</p> <pre><code>mkdocs new .\n</code></pre> <p>Start by adding the minimal configuration in <code>mkdocs.yml</code>:</p> <pre><code>theme:\nname: material\n</code></pre> </li> <li> <p>Now, only add the necessary settings to <code>mkdocs.yml</code> to keep the     reproduction minimal. If you are creating a reproduction for a rendering     bug, create only the necessary amount of Markdown documents. Repeat this     step until the bug you want to report can be observed.</p> </li> <li> <p>As a last step, before packing everything into a .zip file, double-check     all settings and documents if they are essential to the reproduction, which     means that the bug does not occur when they are omitted. Remove all     non-essential lines and files.</p> </li> </ol>"},{"location":"v10/guides/creating-a-reproduction/#creating-a-zip-file","title":"Creating a .zip file","text":"<p>Material for MkDocs 9.0.0 includes a new plugin solely intended to create reproductions for bug reports. When the built-in info plugin is enabled, MkDocs will add all relevant files to a .zip, print a summary to the terminal and exit. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- info\n</code></pre> <p>Now, when running <code>mkdocs build</code>, a file called <code>example.zip</code> is automatically created, containing the minimal reproduction you can directly attach to your bug report.</p> <pre><code>INFO     -  Started archive creation for bug report\nINFO     -  Archive successfully created:\n\n  example/.dependencies.json 859.0 B\n  example/.versions.log 83.0 B\n  example/docs/index.md 282.0 B\n  example/mkdocs.yml 56.0 B\n\n  example.zip 1.8 kB\n</code></pre>"},{"location":"v10/insiders/","title":"Insiders","text":"<p>Material for MkDocs follows the sponsorware release strategy, which means that new features are first exclusively released to sponsors as part of Insiders. Read on to learn what sponsorships achieve, how to become a sponsor to get access to Insiders, and what's in it for you!</p>"},{"location":"v10/insiders/#what-is-insiders","title":"What is Insiders?","text":"<p>Material for MkDocs Insiders is a private fork of Material for MkDocs, hosted as a private GitHub repository. Almost1 all new features are developed as part of this fork, which means that they are immediately available to all eligible sponsors, as they are made collaborators of this repository.</p> <p>Every feature is tied to a funding goal in monthly subscriptions. When a funding goal is hit, the features that are tied to it are merged back into Material for MkDocs and released for general availability, making them available to all users. Bugfixes are always released in tandem.</p> <p>Sponsorships start as low as $15 a month.2</p>"},{"location":"v10/insiders/#what-sponsorships-achieve","title":"What sponsorships achieve","text":"<p>Sponsorships make this project sustainable, as they buy the maintainers of this project time \u2013 a very scarce resource \u2013 which is spent on the development of new features, bug fixing, stability improvement, issue triage and general support. The biggest bottleneck in Open Source is time.3</p> <p>If you're unsure if you should sponsor this project, check out the list of completed funding goals to learn whether you're already using features that were developed with the help of sponsorships. You're most likely using at least a handful of them, thanks to our awesome sponsors!</p>"},{"location":"v10/insiders/#whats-in-it-for-me","title":"What's in it for me?","text":"<p>The moment you become a sponsor, you'll get immediate access to 23 additional features that you can start using now, and which are currently exclusively available to sponsors:</p> <ul> <li> Projects plugin </li> <li> Instant prefetching </li> <li> Social plugin: custom layouts </li> <li> Social plugin: background images </li> <li> Code range selection</li> <li> Code annotations: custom selectors</li> <li> Privacy plugin: optimization support</li> <li> Optimize plugin</li> <li> Navigation path (Breadcrumbs)</li> <li> Typeset plugin</li> <li> Privacy plugin: external links</li> <li> Navigation subtitles</li> <li> Tags plugin: allow list + custom sorting</li> <li> Blog plugin: custom index pages</li> <li> Blog plugin: related links</li> <li> Meta plugin</li> <li> Tags plugin: additional indexes</li> <li> Document contributors</li> <li> Automatic light / dark mode</li> <li> Content tabs: anchor links</li> <li> Tooltips</li> <li> Card grids</li> <li> Privacy plugin</li> </ul> <p>New features are added every other week. Be sure to come back.</p>"},{"location":"v10/insiders/#how-to-become-a-sponsor","title":"How to become a sponsor","text":"<p>Thanks for your interest in sponsoring! In order to become an eligible sponsor with your GitHub account, visit squidfunk's sponsor profile, and complete a sponsorship of $15 a month or more. You can use your individual or organization GitHub account for sponsoring.</p> <p>Important: If you're sponsoring @squidfunk through a GitHub organization, please send a short email to sponsors@squidfunk.com with the name of your organization and the GitHub account of the individual that should be added as a  collaborator.4</p> <p>You can cancel your sponsorship anytime.5</p> <p> \u00a0 Join our  awesome sponsors</p> <p>Silver sponsors:</p> <p></p> <p>Bronze sponsors:</p> <p> </p>      If you sponsor publicly, you're automatically added here with a link to     your profile and avatar to show your support for Material for MkDocs.     Alternatively, if you wish to keep your sponsorship private, you'll be a     silent +1. You can select visibility during checkout and change it     afterwards."},{"location":"v10/insiders/#funding","title":"Funding","text":""},{"location":"v10/insiders/#goals","title":"Goals","text":"<p>The following section lists all funding goals. Each goal contains a list of features prefixed with a checkmark symbol, denoting whether a feature is  already available or   planned, but not yet implemented. When the funding goal is hit, the features are released for general availability.</p>"},{"location":"v10/insiders/#14000-goats-horn","title":"$ 14,000 \u2013 Goat's Horn","text":"<ul> <li> Privacy plugin</li> <li> Card grids</li> <li> Tooltips</li> <li> Content tabs: anchor links</li> <li> Automatic light / dark mode</li> <li> Document contributors</li> </ul>"},{"location":"v10/insiders/#16000-chipotle","title":"$ 16,000 \u2013 Chipotle","text":"<ul> <li> Meta plugin</li> <li> Blog plugin: related links</li> <li> Blog plugin: custom index pages</li> <li> Tags plugin: additional indexes</li> <li> Tags plugin: allow list + custom sorting</li> <li> Navigation subtitles</li> </ul>"},{"location":"v10/insiders/#20000-jalapeno","title":"$ 20,000 \u2013 Jalape\u00f1o","text":"<ul> <li> Optimize plugin</li> <li> Typeset plugin</li> <li> Navigation path (Breadcrumbs)</li> <li> Privacy plugin: optimization support</li> <li> Privacy plugin: external links</li> <li> Instant prefetching</li> </ul>"},{"location":"v10/insiders/#24000-blockpaprika","title":"$ 24,000 \u2013 Blockpaprika","text":"<ul> <li> Projects plugin</li> <li> Social plugin: custom layouts</li> <li> Social plugin: background images</li> <li> Code range selection</li> <li> Code annotations: custom selectors</li> <li> Code line wrap button</li> </ul>"},{"location":"v10/insiders/#goals-completed","title":"Goals completed","text":"<p>This section lists all funding goals that were previously completed, which means that those features were part of Insiders, but are now generally available and can be used by all users.</p>"},{"location":"v10/insiders/#12000-piri-piri","title":"$ 12,000 \u2013 Piri Piri","text":"<ul> <li> Blog plugin</li> <li> Chinese search support</li> <li> Annotations</li> <li> Navigation icons</li> <li> Navigation pruning</li> <li> Navigation status</li> </ul>"},{"location":"v10/insiders/#10000-carolina-reaper","title":"$ 10,000 \u2013 Carolina Reaper","text":"<ul> <li> Brand new search plugin</li> <li> Rich search previews</li> <li> Tokenizer with lookahead</li> <li> Advanced search highlighting</li> <li> Excluding content from search</li> <li> Offline plugin</li> </ul>"},{"location":"v10/insiders/#8000-scotch-bonnet","title":"$ 8,000 \u2013 Scotch Bonnet","text":"<ul> <li> Social cards</li> <li> Code annotations: anchor links</li> <li> Code annotations: strip comments</li> <li> Tag icons</li> <li> Table of contents anchor following</li> <li> Sidebars automatically scroll to active item</li> </ul>"},{"location":"v10/insiders/#7000-royal-gold","title":"$ 7,000 \u2013 Royal Gold","text":"<ul> <li> Cookie consent</li> <li> Was this page helpful?</li> <li> Dismissable announcement bar</li> </ul>"},{"location":"v10/insiders/#6000-trinidad-scorpion","title":"$ 6,000 \u2013 Trinidad Scorpion","text":"<ul> <li> Boosting pages in search</li> <li> Custom admonition icons</li> <li> Linking content tabs</li> </ul>"},{"location":"v10/insiders/#5000-aji-panca","title":"$ 5,000 \u2013 Aji Panca","text":"<ul> <li> Mermaid.js integration</li> <li> Stay on page when switching versions</li> <li> Tags with search integration</li> </ul>"},{"location":"v10/insiders/#4000-ghost-pepper","title":"$ 4,000 \u2013 Ghost Pepper","text":"<ul> <li> Anchor tracking</li> <li> Code annotations</li> <li> Version warning</li> </ul>"},{"location":"v10/insiders/#3000-caribbean-red","title":"$ 3,000 \u2013 Caribbean Red","text":"<ul> <li> Sticky navigation tabs</li> <li> Section index pages</li> <li> Remove generator notice</li> </ul>"},{"location":"v10/insiders/#2500-biquinho-vermelho","title":"$ 2,500 \u2013 Biquinho Vermelho","text":"<ul> <li> Search suggestions</li> <li> Search highlighting</li> <li> Search sharing</li> </ul>"},{"location":"v10/insiders/#2000-black-pearl","title":"$ 2,000 \u2013 Black Pearl","text":"<ul> <li> Latest release tag</li> <li> Color palette toggle</li> <li> Back-to-top button</li> </ul>"},{"location":"v10/insiders/#1500-bhut-jolokia","title":"$ 1,500 \u2013 Bhut Jolokia","text":"<ul> <li> Admonition inline blocks</li> <li> Site language selection</li> <li> Versioning</li> </ul>"},{"location":"v10/insiders/#1000-prairie-fire","title":"$ 1,000 \u2013 Prairie Fire","text":"<ul> <li> Navigation sections</li> <li> Navigation expansion</li> <li> Hiding the sidebars</li> <li> Table of contents in navigation</li> <li> Header hides on scroll</li> </ul>"},{"location":"v10/insiders/#500-madame-jeanette","title":"$ 500 \u2013 Madame Jeanette","text":"<ul> <li> Improved search result grouping</li> <li> Improved search result relevance and scoring</li> <li> Missing query terms in search results</li> </ul>"},{"location":"v10/insiders/#frequently-asked-questions","title":"Frequently asked questions","text":""},{"location":"v10/insiders/#compatibility","title":"Compatibility","text":"<p>We're building an open source project and want to allow outside collaborators to run and build our documentation locally without having access to Insiders. Is this still possible?</p> <p>Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, it should be rarely necessary to change the general appearance of your site. Most Insiders features enhance the overall experience, e.g. by adding icons to pages or providing a feedback widget. While this features add value for the user of your site, they shouldn't be necessary for previewing when making changes to content. Currently, the only content-related features in Insiders that can't be properly previewed by non-Insiders users are:</p> <ul> <li>Annotations</li> <li>Card grids</li> </ul> <p>This means that outside collaborators are able to build the documentation locally with Material for MkDocs and when they push their changes, your CI pipeline will build it with Insiders. When using built-in plugins that are exclusive to Insiders, it's recommended to split configuration into a base <code>mkdocs.yml</code> and one with plugin overrides via configuration inheritance.</p> <p>See the getting started guide for more information.</p>"},{"location":"v10/insiders/#payment","title":"Payment","text":"<p>We don't want to pay for sponsorship every month. Are there any other options?</p> <p>Yes. You can sponsor on a yearly basis by switching your GitHub account to a yearly billing cycle. If for some reason you cannot do that, you could also create a dedicated GitHub account with a yearly billing cycle, which you only use for sponsoring (some sponsors already do that).</p> <p>If you have any problems or further questions, please reach out to sponsors@squidfunk.com.</p>"},{"location":"v10/insiders/#terms","title":"Terms","text":"<p>Are we allowed to use Insiders under the same terms and conditions as Material for MkDocs?</p> <p>Yes. Whether you're an individual or a company, you may use Material for MkDocs Insiders precisely under the same terms as Material for MkDocs, which are given by the MIT license. However, we kindly ask you to respect our fair use policy:</p> <ul> <li> <p>Please don't distribute the source code of Insiders. You may freely use   it for public, private or commercial projects, privately fork or mirror it,   but please don't make the source code public, as it would counteract the    sponsorware strategy.</p> </li> <li> <p>If you cancel your subscription, you're automatically removed as a   collaborator and will miss out on all future updates of Insiders. However, you   may use the latest version that's available to you as long as you like.   Just remember that GitHub deletes private forks.</p> </li> </ul> <ol> <li> <p>In general, every new feature is first exclusively released to sponsors, but sometimes upstream dependencies like Python Markdown Extensions enhance existing features that must be supported by Material for MkDocs.\u00a0\u21a9</p> </li> <li> <p>Note that $15 a month is the minimum amount to become eligible for Insiders. While GitHub Sponsors also allows to sponsor lower amounts or one-time amounts, those can't be granted access to Insiders due to technical reasons.\u00a0\u21a9</p> </li> <li> <p>Making an Open Source project sustainable is exceptionally hard: maintainers burn out, projects are abandoned. That's not great and very unpredictable. The sponsorware model ensures that if you decide to use Material for MkDocs, you can be sure that bugs are fixed quickly and new features are added regularly.\u00a0\u21a9</p> </li> <li> <p>It's currently not possible to grant access to each member of an organization, as GitHub only allows for adding users. Thus, after sponsoring, please send an email to sponsors@squidfunk.com, stating which account should become a collaborator of the Insiders repository. We're working on a solution which will make access to organizations much simpler. To ensure that access is not tied to a particular individual GitHub account, create a bot account (i.e. a GitHub account that is not tied to a specific individual), and use this account for the sponsoring. After being added to the list of collaborators, the bot account can create a private fork of the private Insiders GitHub repository, and grant access to all members of the organizations.\u00a0\u21a9</p> </li> <li> <p>If you cancel your sponsorship, GitHub schedules a cancellation request which will become effective at the end of the billing cycle. This means that even though you cancel your sponsorship, you will keep your access to Insiders as long as your cancellation isn't effective. All charges are processed by GitHub through Stripe. As we don't receive any information regarding your payment, and GitHub doesn't offer refunds, sponsorships are non-refundable.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/insiders/changelog/","title":"Changelog","text":""},{"location":"v10/insiders/changelog/#material-for-mkdocs-insiders","title":"Material for MkDocs Insiders","text":""},{"location":"v10/insiders/changelog/#4.38.1","title":"4.38.1 August 1, 2023","text":"<ul> <li>Improved nested serve mode for projects plugin</li> <li>Improved compat in privacy plugin with third-party plugins</li> <li>Fixed #5790: Typeset plugin ignores data-toc-label attribute</li> <li>Fixed #5778: Interplay of privacy plugin with git-revision-date-localized</li> <li>Fixed #5773: Info plugin erroring when community edition is in beta</li> </ul>"},{"location":"v10/insiders/changelog/#4.38.0","title":"4.38.0 July 29, 2023","text":"<ul> <li>Added projects plugin for building nested projects</li> <li>Updated privacy plugin to new MkDocs API</li> </ul>"},{"location":"v10/insiders/changelog/#4.37.1","title":"4.37.1 July 28, 2023","text":"<ul> <li>Updated MkDocs to 1.5.1</li> <li>Fixed deprecation warning in social plugin due to MkDocs upgrade</li> <li>Fixed #5772: Privacy plugin fails due to API change in MkDocs</li> </ul>"},{"location":"v10/insiders/changelog/#4.37.0","title":"4.37.0 July 7, 2023","text":"<ul> <li>Added support for overriding social cards settings per page</li> <li>Added new social card <code>default/only/image</code> layout</li> <li>Improved resilience of optimize and social plugin</li> <li>Fixed rendering bugs for pruned navigation items</li> <li>Fixed jumping of content tabs anchor links when instant loading is enabled</li> <li>Fixed #5676: Optimize plugin doesn't check for <code>pngquant</code></li> </ul>"},{"location":"v10/insiders/changelog/#4.36.1","title":"4.36.1 June 23, 2023","text":"<ul> <li>Fixed #5618: Date comparison breaking for drafts in blog plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.36.0","title":"4.36.0 June 15, 2023","text":"<ul> <li>Added support for instant prefetching to speed up slow connections</li> <li>Improved stability of anchor link removal in built-in typeset plugin</li> <li>Improved performance of regular expressions in typeset plugin</li> <li>Removed unnecessary import test for <code>cairosvg</code> in optimize plugin</li> <li>Fixed #5590: Regular expression for anchor link removal too greedy</li> </ul>"},{"location":"v10/insiders/changelog/#4.35.3","title":"4.35.3 June 1, 2023","text":"<ul> <li>Fixed #5579: Abbreviations in headlines filtered by typeset plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.35.2","title":"4.35.2 May 29, 2023","text":"<ul> <li>Fixed #5555: Blog plugin crashes when computing readtime for emojis</li> </ul>"},{"location":"v10/insiders/changelog/#4.35.1","title":"4.35.1 May 20, 2023","text":"<ul> <li>Fixed internal handling of errors in social plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.35.0","title":"4.35.0 May 20, 2023","text":"<ul> <li>Improve editing experience and stability of social plugin</li> <li>Added support for custom layout syntax validation in social plugin</li> <li>Added support for layer origin for easier placement in social plugin</li> <li>Added support for in- and exclusion patterns in social plugin</li> <li>Catch and print syntax errors in custom layouts</li> </ul>"},{"location":"v10/insiders/changelog/#4.34.1","title":"4.34.1 May 16, 2023","text":"<ul> <li>Disable social plugin debug mode by default on mkdocs build</li> <li>Added warning in social plugin debug mode when font style couldn't be found</li> <li>Set default concurrency of built-in multi-threaded plugins to CPUs - 1</li> <li>Fixed #5521: Social plugin triggers race condition when downloading fonts</li> <li>Fixed #5515: Social plugin crashes when concurrency is set to 1</li> </ul>"},{"location":"v10/insiders/changelog/#4.34.0","title":"4.34.0 May 14, 2023","text":"<ul> <li>Added support for new overflow mode to auto-fit text in social plugin</li> <li>Reduced subtle rendering bugs in (code) annotations due to subpixel rounding</li> <li>Improved print styles for (code) annotation lists</li> <li>Improved performance of social plugin, now 3x as fast</li> <li>Improved interop of typeset plugin with MkDocstrings</li> <li>Fixed logo location for variants of default template in social plugin</li> <li>Fixed #5446: Built-in typeset plugin picks up headings in code blocks</li> </ul>"},{"location":"v10/insiders/changelog/#4.33.2","title":"4.33.2 May 12, 2023","text":"<ul> <li>Fixed #5508: Social plugin crashes trying to copy cards on Docker/Windows</li> <li>Fixed #5507: Social plugin crashes on serve when layouts folder doesn't exist</li> <li>Fixed #5505: Social plugin trying to resolve logo in wrong location</li> <li>Fixed #5496: Annotations with nested lists incorrectly mounted</li> <li>Fixed #5493: Social plugin crashes on Python 3.8</li> </ul>"},{"location":"v10/insiders/changelog/#4.33.1","title":"4.33.1 May 9, 2023","text":"<ul> <li>Added support for SVG background images in social plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.33.0","title":"4.33.0 May 8, 2023","text":"<ul> <li>Added support for custom layouts for social plugin</li> <li>Added support for background images for social cards</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.6","title":"4.32.6 April 22, 2023","text":"<ul> <li>Fixed #5336: Interplay of blog plugin with git-revision-date-localized</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.5","title":"4.32.5 April 7, 2023","text":"<ul> <li>Fixed #5322: Navigation tabs hoist nested page icons</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.4","title":"4.32.4 March 24, 2023","text":"<ul> <li>Fixed #5241: Built-in typeset plugin jams navigation for anchors in headings</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.3","title":"4.32.3 March 9, 2023","text":"<ul> <li>Fixed Docker image release workflow (9.1.0 regression)</li> <li>Fixed #5159: Missing underline for abbreviations (9.1.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.2","title":"4.32.2 February 23, 2023","text":"<ul> <li>Fixed #5127: Privacy plugin not handling large number of occurrences</li> <li>Fixed #5126: Privacy plugin breaks when replacing specific emojis</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.1","title":"4.32.1 February 23, 2023","text":"<ul> <li>Fixed code block spans interfering with copying</li> <li>Fixed #5077: Privacy plugin breaks image <code>alt</code> text encoding</li> <li>Fixed #5079: Privacy plugin removing <code>rel=me</code> on external links</li> </ul>"},{"location":"v10/insiders/changelog/#4.32.0","title":"4.32.0 February 19, 2023","text":"<ul> <li>Added support for custom selectors for code annotations</li> <li>Added support for code line range selection for better sharing</li> </ul>"},{"location":"v10/insiders/changelog/#4.31.0","title":"4.31.0 February 18, 2023","text":"<ul> <li>Added support for table of contents on blog index and archive pages</li> <li>Fixed #4512: Allow custom search field boosts (experimental)</li> </ul>"},{"location":"v10/insiders/changelog/#4.30.2","title":"4.30.2 February 13, 2023","text":"<ul> <li>Fixed privacy plugin excludes not working (4.30.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.30.1","title":"4.30.1 February 12, 2023","text":"<ul> <li>Fixed privacy plugin not handling static templates (e.g. <code>404.html</code>)</li> </ul>"},{"location":"v10/insiders/changelog/#4.30.0","title":"4.30.0 February 6, 2023","text":"<ul> <li>Rewrite of privacy plugin for concurrency, now twice as fast</li> <li>Added support for explicit inclusion for privacy plugin</li> <li>Added optimization support for privacy plugin (+ optimize plugin)</li> </ul>"},{"location":"v10/insiders/changelog/#4.29.0","title":"4.29.0 January 21, 2023","text":"<ul> <li>Added built-in optimize plugin for automatically compressing images</li> <li>Switched reporting in built-in privacy plugin to <code>info</code> level</li> </ul>"},{"location":"v10/insiders/changelog/#4.28.1","title":"4.28.1 January 17, 2023","text":"<ul> <li>Fixed built-in info plugin erroring for Insiders on version check</li> <li>Fixed #4865: Navigation paths render bug when there's no top-level section</li> <li>Fixed #4875: Added support for hiding navigation paths</li> <li>Improved navigation path to not render for a single item</li> </ul>"},{"location":"v10/insiders/changelog/#4.28.0","title":"4.28.0 January 14, 2023","text":"<ul> <li>Added support for navigation path (breadcrumbs)</li> </ul>"},{"location":"v10/insiders/changelog/#4.27.1","title":"4.27.1 December 20, 2022","text":"<ul> <li>Fixed rendering of succeeding navigation items in typeset plugin</li> <li>Fixed #4795: Built-in typeset plugin changes MkDocs' title precedence</li> <li>Fixed #4724: Blog plugin not rendering integrate table of contents</li> </ul>"},{"location":"v10/insiders/changelog/#4.27.0","title":"4.27.0 December 20, 2022","text":"<ul> <li>Added built-in typeset plugin to preserve formatting in sidebars</li> <li>Added URL and table of contents support for blog categories</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.6","title":"4.26.6 November 28, 2022","text":"<ul> <li>Fixed #4683: Tags plugin crashes when a tag is empty</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.5","title":"4.26.5 November 27, 2022","text":"<ul> <li>Fixed #4632: Post excerpt title link doesn't point to top of the page</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.4","title":"4.26.4 November 27, 2022","text":"<ul> <li>Fixed redundant file extension when using privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.3","title":"4.26.3 November 15, 2022","text":"<ul> <li>Fixed #4637: Attachments w/o titles in related links error in blog plugin</li> <li>Fixed #4631: Remote favicons not downloaded and inlined by privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.2","title":"4.26.2 November 3, 2022","text":"<ul> <li>Updated MkDocs to 1.4.2</li> <li>Added support for tag compare functions when sorting on index pages</li> <li>Fixed footnotes being rendered in post excerpts without separators</li> <li>Fixed error in blog plugin when <code>toc</code> extension is not enabled</li> <li>Fixed issues with invalid asset paths and linked post titles</li> <li>Fixed #4572: Privacy plugin fails when symlinks cannot be created</li> <li>Fixed #4545: Blog plugin doesn't automatically link headline to post</li> <li>Fixed #4542: Blog plugin doesn't allow for multiple instances</li> <li>Fixed #4532: Blog plugin doesn't allow for mixed use of date and datetime</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.1","title":"4.26.1 October 22, 2022","text":"<ul> <li>Improved reporting of configuration errors in tags plugin</li> <li>Fixed #4515: Privacy plugin fails when site URL is not defined</li> <li>Fixed #4514: Privacy plugin doesn't fetch Google fonts (4.26.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.26.0","title":"4.26.0 October 18, 2022","text":"<ul> <li>Refactored privacy plugin to prepare for new features</li> <li>Added support for <code>rel=noopener</code> links in privacy plugin</li> <li>Resolve encoding issues with blog and privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.5","title":"4.25.5 October 16, 2022","text":"<ul> <li>Updated MkDocs to 1.4.1</li> <li>Added namespace prefix to built-in plugins</li> <li>Updated <code>content</code> and <code>header</code> partial</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.4","title":"4.25.4 October 9, 2022","text":"<ul> <li>Fixed other path issues for standalone blogs (4.24.2 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.3","title":"4.25.3 October 9, 2022","text":"<ul> <li>Fixed #4457: Posts not collected for standalone blog (4.24.2 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.2","title":"4.25.2 October 4, 2022","text":"<ul> <li>Fixed #4452: Blog and tags plugin crash when specifying slugify function</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.1","title":"4.25.1 October 3, 2022","text":"<ul> <li>Updated <code>mkdocs-rss-plugin</code> in <code>Dockerfile</code> to fix MkDocs compat errors</li> </ul>"},{"location":"v10/insiders/changelog/#4.25.0","title":"4.25.0 October 2, 2022","text":"<ul> <li>Added support for navigation subtitles</li> <li>Added support for defining an allow list for built-in tags plugin</li> <li>Added support for custom slugify functions for built-in tags plugin</li> <li>Improved stability of search plugin when using <code>--dirtyreload</code></li> </ul>"},{"location":"v10/insiders/changelog/#4.24.2","title":"4.24.2 October 1, 2022","text":"<ul> <li>Updated MkDocs to 1.4</li> <li>Fixed compatibility issues with MkDocs 1.4</li> <li>Fixed incorrectly generated paths in privacy plugin</li> <li>Fixed blog index page not showing navigation when using meta plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.24.1","title":"4.24.1 September 30, 2022","text":"<ul> <li>Fixed #4430: build error when enabling consent without repository URL</li> </ul>"},{"location":"v10/insiders/changelog/#4.24.0","title":"4.24.0 September 27, 2022","text":"<ul> <li>Added support for custom content on index pages (blog)</li> <li>Added support for keeping content on paginated index pages (blog)</li> <li>Added support for limiting categories in post excerpts (blog)</li> <li>Added support for simple override of templates via front matter (blog)</li> <li>Added icon in navigation for pages with encrypted content</li> <li>Fixed #4396: Front matter of index pages not inherited by pagination (blog)</li> <li>Improved performance by building post excerpts once (blog)</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.6","title":"4.23.6 September 22, 2022","text":"<ul> <li>Fixed #4389: Blog posts in first week of year in wrong archive</li> <li>Fixed (= switched) footer previous and next links for blog posts</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.5","title":"4.23.5 September 18, 2022","text":"<ul> <li>Fixed #4367: Improved blog plugin date handling for MultiMarkdown syntax</li> <li>Fixed #4374: Fixed invalid URLs of related links to other blog posts</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.4","title":"4.23.4 September 14, 2022","text":"<ul> <li>Fixed #4365: Recursion error in blog plugin due to <code>deepcopy</code></li> <li>Fixed path errors for blog plugin on Windows</li> <li>Fixed publishing workflow in forked repositories</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.3","title":"4.23.3 September 13, 2022","text":"<ul> <li>Fixed previous and next page links for drafts of blog posts</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.2","title":"4.23.2 September 13, 2022","text":"<ul> <li>Fixed #4348: Blog plugin crashes on custom <code>nav</code> title</li> <li>Fixed blog plugin crashing when category contained only drafts</li> <li>Fixed rendering of content from blog index file</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.1","title":"4.23.1 September 12, 2022","text":"<ul> <li>Fixed #4345: Blog plugin errors with default settings</li> </ul>"},{"location":"v10/insiders/changelog/#4.23.0","title":"4.23.0 September 12, 2022","text":"<ul> <li>Added blogging support via built-in blog plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.22.1","title":"4.22.1 September 7, 2022","text":"<ul> <li>Fixed #4217: Tooltips in data tables render in wrong position</li> </ul>"},{"location":"v10/insiders/changelog/#4.22.0","title":"4.22.0 August 21, 2022","text":"<ul> <li>Added support for navigation status</li> </ul>"},{"location":"v10/insiders/changelog/#4.21.1","title":"4.21.1 August 13, 2022","text":"<ul> <li>Fixed #4176: Broken image when avatar is served by Gravatar</li> <li>Fixed #4212: Deferred search initialization for file:// locations</li> </ul>"},{"location":"v10/insiders/changelog/#4.21.0","title":"4.21.0 July 17, 2022","text":"<ul> <li>Added meta plugin: set front matter for all pages in a folder</li> <li>Fixed #4114: Tags plugin fails if only <code>tags_extra_files</code> is set</li> </ul>"},{"location":"v10/insiders/changelog/#4.20.1","title":"4.20.1 July 11, 2022","text":"<ul> <li>Fixed #4105: Tags plugin fails if <code>tags_file</code> is not set (4.20.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.20.0","title":"4.20.0 July 7, 2022","text":"<ul> <li>Added support for additional tags indexes</li> <li>Fixed #4100: Tag icons not shown in tags index</li> </ul>"},{"location":"v10/insiders/changelog/#4.19.2","title":"4.19.2 July 4, 2022","text":"<ul> <li>Fixed #4051: Privacy plugin fails if symlinking isn't allowed on Windows</li> </ul>"},{"location":"v10/insiders/changelog/#4.19.1","title":"4.19.1 June 25, 2022","text":"<ul> <li>Added <code>mkdocs-git-committers-plugin</code> to Dockerfile</li> <li>Added <code>mkdocs-git-revision-date-localized-plugin</code> to Dockerfile</li> </ul>"},{"location":"v10/insiders/changelog/#4.19.0","title":"4.19.0 June 24, 2022","text":"<ul> <li>Added support for document contributors</li> <li>Updated French translations for cookie consent</li> </ul>"},{"location":"v10/insiders/changelog/#4.18.2","title":"4.18.2 June 16, 2022","text":"<ul> <li>Fixed #4026: Fixed tooltips not mounted for nested navigation links</li> </ul>"},{"location":"v10/insiders/changelog/#4.18.1","title":"4.18.1 June 14, 2022","text":"<ul> <li>Fixed #3990: Chinese search highlighting not working on non-boundaries</li> </ul>"},{"location":"v10/insiders/changelog/#4.18.0","title":"4.18.0 June 11, 2022","text":"<ul> <li>Added support for automatic dark/light mode</li> <li>Fixed #4009: Privacy plugin uses invalid paths for file cache on Windows</li> </ul>"},{"location":"v10/insiders/changelog/#4.17.2","title":"4.17.2 June 5, 2022","text":"<ul> <li>Added support for custom jieba dictionaries (Chinese search)</li> </ul>"},{"location":"v10/insiders/changelog/#4.17.1","title":"4.17.1 June 5, 2022","text":"<ul> <li>Added support for cookie consent reject button</li> <li>Added support for cookie consent custom button ordering</li> <li>Fixed #3988: Content tab not focused after alternating anchor links</li> </ul>"},{"location":"v10/insiders/changelog/#4.17.0","title":"4.17.0 June 4, 2022","text":"<ul> <li>Added support for content tabs anchor links (deep linking)</li> <li>Fixed #3975: Detect composition events in search interface (Chinese)</li> <li>Fixed #3980: Search plugin doesn't use title set via front matter</li> </ul>"},{"location":"v10/insiders/changelog/#4.16.2","title":"4.16.2 May 29, 2022","text":"<ul> <li>Fixed #3961: Nested sections triggered build error for navigation tabs</li> </ul>"},{"location":"v10/insiders/changelog/#4.16.1","title":"4.16.1 May 28, 2022","text":"<ul> <li>Switched feedback widget rating titles to tooltips</li> <li>Improved contrast of link colors for light/dark color schemes</li> <li>Fixed #3950: Sticky navigation tabs rendering broken (4.15.2 regression)</li> <li>Fixed #3958: Links invisible when using <code>white</code> primary color</li> </ul>"},{"location":"v10/insiders/changelog/#4.16.0","title":"4.16.0 May 25, 2022","text":"<ul> <li>Added support for navigation pruning</li> <li>Fixed search results for non-segmented characters (4.15.2 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.15.2","title":"4.15.2 May 22, 2022","text":"<ul> <li>Removed workaround for <code>abbr</code> on touch devices (superseded by tooltips)</li> <li>Fixed #3915: Improved Chinese search query segmentation</li> <li>Fixed #3938: Fixed tooltips position for navigation titles with ellipsis</li> </ul>"},{"location":"v10/insiders/changelog/#4.15.1","title":"4.15.1 May 14, 2022","text":"<ul> <li>Improved performance of element focus observables</li> <li>Fixed #3531: Added prev/next buttons to content tabs</li> <li>Fixed tooltip positioning when host element is hidden</li> </ul>"},{"location":"v10/insiders/changelog/#4.15.0","title":"4.15.0 May 8, 2022","text":"<ul> <li>Added support for improved tooltips</li> <li>Fixed #3785: Show tooltip on hover for overflowing navigation link</li> </ul>"},{"location":"v10/insiders/changelog/#4.14.0","title":"4.14.0 May 5, 2022","text":"<ul> <li>Added Chinese language support to built-in search plugin</li> <li>Fixed all-numeric page titles raising error in social plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.13.2","title":"4.13.2 April 30, 2022","text":"<ul> <li>Improved caching of downloaded resources in privacy plugin</li> <li>Fixed #3851: External images not downloaded by privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.13.1","title":"4.13.1 April 25, 2022","text":"<ul> <li>Fixed #3839: Tags plugin breaks without icons (4.13.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#4.13.0","title":"4.13.0 April 24, 2022","text":"<ul> <li>Added support for tag icons</li> </ul>"},{"location":"v10/insiders/changelog/#4.12.0","title":"4.12.0 March 27, 2022","text":"<ul> <li>Added support for card grids and grid layouts</li> <li>Fixed #3685: Annotations sometimes broken when using instant loading </li> <li>Fixed #3742: Automatically add Mermaid.js when building for offline usage</li> </ul>"},{"location":"v10/insiders/changelog/#4.11.0","title":"4.11.0 March 6, 2022","text":"<ul> <li>Added support for excluding external assets from privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.10.1","title":"4.10.1 March 2, 2022","text":"<ul> <li>Added missing build dependencies to Dockerfile</li> <li>Fixed encoding issues in privacy plugin, now forcing UTF-8 encoding</li> <li>Fixed #3624: Scroll to active navigation item unreliable in Firefox</li> <li>Fixed #3642: Privacy plugin errors when font setting was omitted</li> </ul>"},{"location":"v10/insiders/changelog/#4.10.0","title":"4.10.0 February 27, 2022","text":"<ul> <li>Added support for offline plugin (supersedes offline search support)</li> <li>Improved built-in privacy plugin to download nested JavaScript assets</li> <li>Refactored configuration of built-in privacy plugin</li> </ul>"},{"location":"v10/insiders/changelog/#4.9.1","title":"4.9.1 February 21, 2022","text":"<ul> <li>Fixed #3610: missing <code>lxml</code> dependency for privacy plugin</li> <li>Fixed error when charset is missing in <code>content-type</code> header</li> </ul>"},{"location":"v10/insiders/changelog/#4.9.0","title":"4.9.0 February 20, 2022","text":"<ul> <li>Added privacy plugin: automatic downloading of external assets</li> </ul>"},{"location":"v10/insiders/changelog/#4.8.3","title":"4.8.3 February 13, 2022","text":"<ul> <li>Fixed #3560: Mermaid diagrams don't render for <code>file://</code> locations</li> </ul>"},{"location":"v10/insiders/changelog/#4.8.2","title":"4.8.2 February 10, 2022","text":"<ul> <li>Fixed #3559: Mermaid diagrams don't render inside closed <code>details</code></li> </ul>"},{"location":"v10/insiders/changelog/#4.8.1","title":"4.8.1 February 6, 2022","text":"<ul> <li>Fixed jump back to top on mobile when using anchor following</li> </ul>"},{"location":"v10/insiders/changelog/#4.8.0","title":"4.8.0 February 6, 2022","text":"<ul> <li>Added support for anchor following table of contents (= auto scroll)</li> </ul>"},{"location":"v10/insiders/changelog/#4.7.2","title":"4.7.2 February 2, 2022","text":"<ul> <li>Fixed #3526: Transparent sidebar title due to Safari bug</li> <li>Fixed #3528: Firefox sometimes clips text in flow chart diagrams</li> </ul>"},{"location":"v10/insiders/changelog/#4.7.1","title":"4.7.1 January 30, 2022","text":"<ul> <li>Fixed #3506: Tags index not respecting title set via front matter</li> </ul>"},{"location":"v10/insiders/changelog/#4.7.0","title":"4.7.0 January 25, 2022","text":"<ul> <li>Added native support for offline search</li> </ul>"},{"location":"v10/insiders/changelog/#4.6.1","title":"4.6.1 January 16, 2022","text":"<ul> <li>Fixed #3459: Section index pages picking up wrong title</li> </ul>"},{"location":"v10/insiders/changelog/#4.6.0","title":"4.6.0 January 11, 2022","text":"<ul> <li>Added support for annotations (outside of code blocks)</li> </ul>"},{"location":"v10/insiders/changelog/#4.5.2","title":"4.5.2 January 8, 2022","text":"<ul> <li>Fixed #3440: Content tab indicator not moving when using linking</li> <li>Fixed #3445: Content tab switch flickers/jitters when using linking</li> </ul>"},{"location":"v10/insiders/changelog/#4.5.1","title":"4.5.1 January 2, 2022","text":"<ul> <li>Added support for setting initial state of cookie consent</li> <li>Fixed #3396: Disappearing link in navigation due to Safari bug</li> </ul>"},{"location":"v10/insiders/changelog/#4.5.0","title":"4.5.0 December 16, 2021","text":"<ul> <li>Added support for navigation icons</li> </ul>"},{"location":"v10/insiders/changelog/#4.4.0","title":"4.4.0 December 10, 2021","text":"<ul> <li>Added support for code annotation anchor links (deep linking)</li> <li>Added new code annotation syntax modifier to strip comment</li> <li>Updated German translations for cookie consent</li> </ul>"},{"location":"v10/insiders/changelog/#4.3.0","title":"4.3.0 December 5, 2021","text":"<ul> <li>Added support for custom fonts in social cards</li> <li>Fixed #3300: Announcement bar reappearing when using instant loading</li> </ul>"},{"location":"v10/insiders/changelog/#4.2.0","title":"4.2.0 December 2, 2021","text":"<ul> <li>Added support for dismissible announcement bar</li> <li>Added support for named placeholders in feedback widget</li> </ul>"},{"location":"v10/insiders/changelog/#4.1.0","title":"4.1.0 November 30, 2021","text":"<ul> <li>Added support for passing page title to feedback forms</li> </ul>"},{"location":"v10/insiders/changelog/#4.0.0","title":"4.0.0 November 28, 2021","text":"<ul> <li>Removed deprecated content tabs legacy implementation</li> <li>Removed deprecated <code>seealso</code> admonition type</li> <li>Removed deprecated <code>site_keywords</code> setting (unsupported by MkDocs)</li> <li>Removed deprecated prebuilt search index support</li> <li>Removed deprecated web app manifest \u2013 use customization</li> <li>Removed <code>extracopyright</code> variable \u2013 use new <code>copyright</code> partial</li> <li>Removed Disqus integration \u2013 use customization</li> <li>Switched to <code>:is()</code> selectors for simple selector lists</li> <li>Switched autoprefixer from <code>last 4 years</code> to <code>last 2 years</code></li> <li>Improved CSS overall to match modern standards</li> <li>Improved CSS variable semantics for fonts</li> <li>Improved extensibility by restructuring partials</li> <li>Improved handling of <code>details</code> when printing</li> <li>Improved keyboard navigation for footnotes</li> <li>Fixed #3214: Search highlighting breaks site when empty</li> </ul>"},{"location":"v10/insiders/changelog/#3.2.3","title":"3.2.3 November 20, 2021","text":"<ul> <li>Updated Swedish and French translations</li> <li>Removed support for <code>.mermaid-experimental</code> class (now <code>.mermaid</code>)</li> <li>Fixed #3202: Cookie consent not dismissable on <code>file://</code> locations</li> <li>Fixed #3216: Cookie consent not dismissed when invoked via anchor</li> <li>Fixed #3232: Mermaid.js sometimes runs twice (race condition)</li> </ul>"},{"location":"v10/insiders/changelog/#3.2.2","title":"3.2.2 November 6, 2021","text":"<ul> <li>Fixed always last feedback rating being sent</li> <li>Fixed #3145: Code annotations eat whole comment lines</li> <li>Fixed #3170: Feedback widget doesn't send data to GA4</li> </ul>"},{"location":"v10/insiders/changelog/#3.2.1","title":"3.2.1 November 4, 2021","text":"<ul> <li>Added support for custom Mermaid.js version via additional JavaScript</li> <li>Fixed some configuration edge cases for tags plugin (3.1.5 regression)</li> <li>Fixed feedback widget title not being centered in Firefox</li> <li>Fixed #3179: Safari doesn't send request for feedback widget</li> </ul>"},{"location":"v10/insiders/changelog/#3.2.0","title":"3.2.0 October 31, 2021","text":"<ul> <li>Added support for feedback widget (Was this page helpful?)</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.5","title":"3.1.5 October 28, 2021","text":"<ul> <li>Fixed #3144: Rogue link when using tags with auto-populated navigation</li> <li>Fixed #3147: Code block line numbers appear in search results</li> <li>Fixed #3158: Social cards do not strip HTML tags from title</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.4","title":"3.1.4 October 17, 2021","text":"<ul> <li>Fixed #2974: Text cropped with other fonts than <code>Roboto</code> in social plugin</li> <li>Fixed #3099: Encoding problems with non-latin character in social plugin</li> <li>Fixed #3112: Japanese segmenter not executed as part of new tokenizer</li> <li>Fixed tags (front matter) appearing in search with disabled tags plugin</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.3","title":"3.1.3 October 12, 2021","text":"<ul> <li>Added warnings to search plugin for unsupported options and syntax</li> <li>Fixed #3503: Search sometimes returns entire page</li> <li>Fixed #3089: Single-line code annotations disappear when printing</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.2","title":"3.1.2 October 6, 2021","text":"<ul> <li>Fixed incorrect path separators for social cards on Windows</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.1","title":"3.1.1 September 26, 2021","text":"<ul> <li>Fixed ordering bug in search exclusion logic</li> </ul>"},{"location":"v10/insiders/changelog/#3.1.0","title":"3.1.0 September 26, 2021","text":"<ul> <li>Added support for excluding pages, sections, and elements from search</li> <li>Fixed #2803: Code block annotations not visible when printing</li> </ul>"},{"location":"v10/insiders/changelog/#3.0.1","title":"3.0.1 September 19, 2021","text":"<ul> <li>Added support for using literal <code>h1-6</code> tags for search plugin</li> <li>Fixed search plugin breaking on void elements without slashes</li> <li>Fixed search plugin filtering link contents from headlines</li> <li>Fixed search plugin handling of multiple <code>h1</code> headlines</li> <li>Fixed search plugin handling of missing <code>h1</code> headlines</li> </ul>"},{"location":"v10/insiders/changelog/#3.0.0","title":"3.0.0 September 13, 2021","text":"<ul> <li>Rewrite of MkDocs' search plugin</li> <li>Added support for rich search previews</li> <li>Added support for tokenizer with lookahead</li> <li>Improved search indexing performance (twice as fast)</li> <li>Improved search highlighting</li> </ul>"},{"location":"v10/insiders/changelog/#2.13.3","title":"2.13.3 September 1, 2021","text":"<ul> <li>Added support for disabling social card generation</li> </ul>"},{"location":"v10/insiders/changelog/#2.13.2","title":"2.13.2 August 25, 2021","text":"<ul> <li>Fixed #2965: Social plugin error when primary color is not defined</li> </ul>"},{"location":"v10/insiders/changelog/#2.13.1","title":"2.13.1 August 21, 2021","text":"<ul> <li>Fixed #2948: Social cards are not cached</li> <li>Fixed #2953: Mermaid.js diagrams can't be centered anymore</li> </ul>"},{"location":"v10/insiders/changelog/#2.13.0","title":"2.13.0 August 7, 2021","text":"<ul> <li>Added support for custom colors in social cards</li> </ul>"},{"location":"v10/insiders/changelog/#2.12.2","title":"2.12.2 August 4, 2021","text":"<ul> <li>Fixed #2891: Division by zero error in social plugin</li> </ul>"},{"location":"v10/insiders/changelog/#2.12.1","title":"2.12.1 July 26, 2021","text":"<ul> <li>Fixed error in social plugin when <code>site_description</code> was not set</li> <li>Fixed error in social plugin for non-ASCII characters</li> </ul>"},{"location":"v10/insiders/changelog/#2.12.0","title":"2.12.0 July 25, 2021","text":"<ul> <li>Added support for social cards</li> </ul>"},{"location":"v10/insiders/changelog/#2.11.1","title":"2.11.1 July 20, 2021","text":"<ul> <li>Fixed order of tags index, now sorted alphabetically</li> </ul>"},{"location":"v10/insiders/changelog/#2.11.0","title":"2.11.0 July 18, 2021","text":"<ul> <li>Improved Mermaid.js integration, now stable</li> <li>Added support for sequence diagrams</li> <li>Added support for entity relationship diagrams</li> <li>Added support for cookie consent configuration</li> <li>Added feature flag to always enable annotations</li> </ul>"},{"location":"v10/insiders/changelog/#2.10.0","title":"2.10.0 July 10, 2021","text":"<ul> <li>Added support for cookie consent</li> <li>Fixed #2807: Back-to-top button not hidden when using sticky tabs</li> </ul>"},{"location":"v10/insiders/changelog/#2.9.2","title":"2.9.2 May 30, 2021","text":"<ul> <li>Moved tags to partial for easier customization</li> <li>Added support for hiding tags on any page</li> </ul>"},{"location":"v10/insiders/changelog/#2.9.1","title":"2.9.1 May 24, 2021","text":"<ul> <li>Added missing guard for linking of content tabs</li> </ul>"},{"location":"v10/insiders/changelog/#2.9.0","title":"2.9.0 May 23, 2021","text":"<ul> <li>Added support for linking of content tabs</li> </ul>"},{"location":"v10/insiders/changelog/#2.8.0","title":"2.8.0 May 12, 2021","text":"<ul> <li>Added support for boosting pages in search</li> </ul>"},{"location":"v10/insiders/changelog/#2.7.2","title":"2.7.2 May 8, 2021","text":"<ul> <li>Fixed #2638: Warnings shown when using <code>tags</code> plugin without directory URLs</li> </ul>"},{"location":"v10/insiders/changelog/#2.7.1","title":"2.7.1 May 3, 2021","text":"<ul> <li>Fixed <code>git-revision-date-localized</code> plugin integration (2.7.0 regression)</li> </ul>"},{"location":"v10/insiders/changelog/#2.7.0","title":"2.7.0 May 1, 2021","text":"<ul> <li>Added support for tags (with search integration)</li> </ul>"},{"location":"v10/insiders/changelog/#2.6.0","title":"2.6.0 April 11, 2021","text":"<ul> <li>Stay on page when switching versions</li> </ul>"},{"location":"v10/insiders/changelog/#2.5.0","title":"2.5.0 March 28, 2021","text":"<ul> <li>Added support for version warning</li> </ul>"},{"location":"v10/insiders/changelog/#2.4.0","title":"2.4.0 March 20, 2021","text":"<ul> <li>Added support for custom admonition icons</li> <li>Fixed #2444: Code block annotations with extra comments have wrong index</li> </ul>"},{"location":"v10/insiders/changelog/#2.3.1","title":"2.3.1 March 14, 2021","text":"<ul> <li>Fixed anchor offset for permalinks when using sticky navigation tabs</li> </ul>"},{"location":"v10/insiders/changelog/#2.3.0","title":"2.3.0 March 13, 2021","text":"<ul> <li>Added support for back-to-top button</li> </ul>"},{"location":"v10/insiders/changelog/#2.2.1","title":"2.2.1 March 4, 2021","text":"<ul> <li>Fixed #2382: Repository stats failing when no release tag is present</li> </ul>"},{"location":"v10/insiders/changelog/#2.2.0","title":"2.2.0 February 28, 2021","text":"<ul> <li>Added support for code block annotations</li> </ul>"},{"location":"v10/insiders/changelog/#2.1.0","title":"2.1.0 February 26, 2021","text":"<ul> <li>Added support for anchor tracking</li> </ul>"},{"location":"v10/insiders/changelog/#2.0.0","title":"2.0.0 February 24, 2021","text":"<ul> <li>Migrated Insiders to the new architecture</li> <li>Swapped color palette toggle configuration</li> </ul>"},{"location":"v10/insiders/changelog/#1.17.0","title":"1.17.0 January 31, 2021","text":"<ul> <li>Added support for section index pages</li> </ul>"},{"location":"v10/insiders/changelog/#1.16.1","title":"1.16.1 January 26, 2021","text":"<ul> <li>Fixed #2249: Instant loading + sticky tabs result in invalid links</li> <li>Fixed #2248: Search highlighting URL parameter always added</li> <li>Fixed #2235: Version selector doesn't select current version for aliases</li> </ul>"},{"location":"v10/insiders/changelog/#1.16.0","title":"1.16.0 January 7, 2021","text":"<ul> <li>Added latest release to repository info (GitHub)</li> <li>Slight facelift of repository info (lighter fonts, spacing and icons)</li> </ul>"},{"location":"v10/insiders/changelog/#1.15.0","title":"1.15.0 January 2, 2021","text":"<ul> <li>Added support for native Mermaid.js integration</li> </ul>"},{"location":"v10/insiders/changelog/#1.14.0","title":"1.14.0 December 30, 2020","text":"<ul> <li>Added support for sharing searches</li> </ul>"},{"location":"v10/insiders/changelog/#1.13.2","title":"1.13.2 December 22, 2020","text":"<ul> <li>Fixed version selector + sticky tabs navigation rendering issues</li> <li>Fixed version selector wrapping</li> </ul>"},{"location":"v10/insiders/changelog/#1.13.1","title":"1.13.1 December 20, 2020","text":"<ul> <li>Removed horizontal scrollbars on language and version selector</li> <li>Fixed type conversion in JavaScript config</li> </ul>"},{"location":"v10/insiders/changelog/#1.13.0","title":"1.13.0 December 13, 2020","text":"<ul> <li>Refactored navigation tabs to simplify grouping behavior</li> <li>Added support for sticky navigation tabs</li> <li>Added support for arbitrary links in navigation tabs</li> <li>Fixed #2098: Subsequent active subsection not highlighted correctly</li> </ul>"},{"location":"v10/insiders/changelog/#1.12.1","title":"1.12.1 December 8, 2020","text":"<ul> <li>Fixed empty language selector being shown</li> </ul>"},{"location":"v10/insiders/changelog/#1.12.0","title":"1.12.0 December 6, 2020","text":"<ul> <li>Added support for adding a language selector</li> </ul>"},{"location":"v10/insiders/changelog/#1.11.2","title":"1.11.2 November 29, 2020","text":"<ul> <li>Fixed #2068: Search highlight interprets code blocks as JavaScript</li> </ul>"},{"location":"v10/insiders/changelog/#1.11.1","title":"1.11.1 November 29, 2020","text":"<ul> <li>Refactored styling to be more stable and easier to adjust</li> <li>Fixed some styling regressions from latest features</li> </ul>"},{"location":"v10/insiders/changelog/#1.11.0","title":"1.11.0 November 22, 2020","text":"<ul> <li>Added support for rendering admonitions as inline blocks</li> </ul>"},{"location":"v10/insiders/changelog/#1.10.0","title":"1.10.0 November 15, 2020","text":"<ul> <li>Added support for integrating table of contents into navigation</li> </ul>"},{"location":"v10/insiders/changelog/#1.9.0","title":"1.9.0 November 7, 2020","text":"<ul> <li>Added support for hiding navigation and table of contents on any page</li> <li>Removed autohiding table of contents when empty</li> </ul>"},{"location":"v10/insiders/changelog/#1.8.0","title":"1.8.0 November 1, 2020","text":"<ul> <li>Added support for navigation sections</li> <li>Fixed appearance of inactive search suggestions</li> </ul>"},{"location":"v10/insiders/changelog/#1.7.0","title":"1.7.0 October 25, 2020","text":"<ul> <li>Added support for deploying multiple versions</li> <li>Fixed alignment of sidebar when content area is too small</li> </ul>"},{"location":"v10/insiders/changelog/#1.6.0","title":"1.6.0 October 11, 2020","text":"<ul> <li>Added support for search suggestions to save keystrokes</li> <li>Added support for removing Made with Material for MkDocs from footer</li> <li>Fixed #1915: search should go to first result by pressing Enter</li> </ul>"},{"location":"v10/insiders/changelog/#1.5.1","title":"1.5.1 September 21, 2020","text":"<ul> <li>Fixed content area stretching to whole width for long code blocks</li> </ul>"},{"location":"v10/insiders/changelog/#1.5.0","title":"1.5.0 September 19, 2020","text":"<ul> <li>Added support for autohiding table of contents when empty</li> </ul>"},{"location":"v10/insiders/changelog/#1.4.1","title":"1.4.1 September 6, 2020","text":"<ul> <li>Improved typeahead and search result relevance and scoring</li> </ul>"},{"location":"v10/insiders/changelog/#1.4.0","title":"1.4.0 August 30, 2020","text":"<ul> <li>Added support for autohiding header on scroll</li> </ul>"},{"location":"v10/insiders/changelog/#1.3.0","title":"1.3.0 August 26, 2020","text":"<ul> <li>Added support for user-selectable color palettes</li> </ul>"},{"location":"v10/insiders/changelog/#1.2.0","title":"1.2.0 August 11, 2020","text":"<ul> <li>Added feature to expand navigation by default</li> </ul>"},{"location":"v10/insiders/changelog/#1.1.0","title":"1.1.0 August 3, 2020","text":"<ul> <li>Added highlighting of search results</li> </ul>"},{"location":"v10/insiders/changelog/#1.0.0","title":"1.0.0 July 14, 2020","text":"<ul> <li>Added grouping of search results</li> <li>Added missing query terms to search result</li> <li>Improved search result relevance and scoring</li> </ul>"},{"location":"v10/insiders/getting-started/","title":"Getting started with Insiders","text":"<p>Material for MkDocs Insiders is a compatible drop-in replacement for Material for MkDocs, and can be installed similarly using <code>pip</code>, <code>docker</code> or <code>git</code>. Note that in order to access the Insiders  repository, you need to become an eligible sponsor of @squidfunk on GitHub.</p>"},{"location":"v10/insiders/getting-started/#requirements","title":"Requirements","text":"<p>After you've been added to the list of collaborators and accepted the repository invitation, the next step is to create a personal access token for your GitHub account in order to access the Insiders repository programmatically  (from the command line or GitHub Actions workflows):</p> <ol> <li>Go to https://github.com/settings/tokens</li> <li>Click on Generate a new token</li> <li>Enter a name and select the <code>repo</code> scope</li> <li>Generate the token and store it in a safe place</li> </ol>"},{"location":"v10/insiders/getting-started/#installation","title":"Installation","text":""},{"location":"v10/insiders/getting-started/#with-pip","title":"with pip","text":"<p>Material for MkDocs Insiders can be installed with <code>pip</code>:</p> <pre><code>pip install git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n</code></pre> <p>The <code>GH_TOKEN</code> environment variable must be set to the value of the personal access token you generated in the previous step. Note that the personal access token must be kept secret at all times, as it allows the owner to access your private repositories.</p>"},{"location":"v10/insiders/getting-started/#with-docker","title":"with docker","text":"<p>In case you want to use Material for MkDocs Insiders from within Docker, some additional steps are necessary. While we cannot provide a hosted Docker image for Insiders1, GitHub Container Registry allows for simple and comfortable self-hosting:</p> <ol> <li>Fork the Insiders repository</li> <li>Enable GitHub Actions on your fork2</li> <li>Create a new personal access token3<ol> <li>Go to https://github.com/settings/tokens</li> <li>Click on Generate a new token</li> <li>Enter a name and select the <code>write:packages</code> scope</li> <li>Generate the token and store it in a safe place</li> </ol> </li> <li>Add a GitHub Actions secret on your fork<ol> <li>Set the name to <code>GHCR_TOKEN</code></li> <li>Set the value to the personal access token created in the previous step</li> </ol> </li> <li>Create a new release to build and publish the Docker image</li> <li>Install Pull App on your fork to stay in-sync with upstream</li> </ol> <p>The <code>publish</code> workflow4 is automatically run when a new tag (release) is created. When a new Insiders version is released on the upstream  repository, the Pull App will create a pull request with the changes and pull in the new tag, which is picked up by the <code>publish</code> workflow that builds and publishes the Docker image automatically to your private registry.</p> <p>Now, you should be able to pull the Docker image from your private registry:</p> <pre><code>docker login -u ${GH_USERNAME} -p ${GHCR_TOKEN} ghcr.io\ndocker pull ghcr.io/${GH_USERNAME}/mkdocs-material-insiders\n</code></pre> <p>Should you wish to add additional plugins to the insiders container image, follow the steps outlined in the Getting Started guide.</p>"},{"location":"v10/insiders/getting-started/#with-git","title":"with git","text":"<p>Of course, you can use Material for MkDocs Insiders directly from <code>git</code>:</p> <pre><code>git clone git@github.com:squidfunk/mkdocs-material-insiders.git mkdocs-material\n</code></pre> <p>The theme will reside in the folder <code>mkdocs-material/material</code>. When cloning from <code>git</code>, the theme must be installed, so MkDocs can find the built-in plugins:</p> <pre><code>pip install -e mkdocs-material\n</code></pre>"},{"location":"v10/insiders/getting-started/#upgrading","title":"Upgrading","text":"<p>When upgrading Insiders, you should always check the version of Material for MkDocs which makes up the first part of the version qualifier, e.g.Insiders <code>4.x.x</code> is currently based on <code>8.x.x</code>:</p> <pre><code>8.x.x-insiders-4.x.x\n</code></pre> <p>If the major version increased, it's a good idea to consult the upgrade guide and go through the steps to ensure your configuration is up to date and all necessary changes have been made. If you installed Insiders via <code>pip</code>, you can upgrade your installation with the following command:</p> <pre><code>pip install --upgrade git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git\n</code></pre>"},{"location":"v10/insiders/getting-started/#caveats","title":"Caveats","text":"<p>This section describes some aspects to consider when using Insiders together with Material for MkDocs to ensure that users without access to Insiders can still build your documentation.</p>"},{"location":"v10/insiders/getting-started/#built-in-plugins","title":"Built-in plugins","text":"<p>When using built-in plugins that are solely available via Insiders, it might be  necessary to split the <code>mkdocs.yml</code> configuration into a base configuration, and one with plugin overrides. Note that this is a limitation of MkDocs, which can be mitigated by using configuration inheritance:</p> <code>mkdocs.insiders.yml</code> <code>mkdocs.yml</code> <pre><code>INHERIT: mkdocs.yml\nplugins:\n- search\n- social\n- tags\n</code></pre> <pre><code># Configuration with everything except Insiders plugins\n</code></pre> <p>Now, when you're in an environment with access to Insiders (e.g. in your CI pipeline), you can build your documentation project with the following lines:</p> <pre><code>mkdocs build --config-file mkdocs.insiders.yml\n</code></pre> <p>Sharing plugin and extension configuration</p> <p>If you want to share <code>plugins</code> or <code>markdown_extensions</code> between both configuration files <code>mkdocs.insiders.yml</code> and <code>mkdocs.yml</code>, you can use the alternative key-value syntax in both files. The above example would then look like:</p> <code>mkdocs.insiders.yml</code> <code>mkdocs.yml</code> <pre><code>INHERIT: mkdocs.yml\nplugins:\nsocial: {}\n</code></pre> <pre><code># Additional configuration above\nplugins:\nsearch: {}\ntags: {}\n</code></pre> <ol> <li> <p>Earlier, Insiders provided a dedicated Docker image which was available to all sponsors. On March 21, 2021, the image was deprecated for the reasons outlined and discussed in #2442. It was removed on June 1, 2021.\u00a0\u21a9</p> </li> <li> <p>When forking a repository, GitHub will disables all workflows. While this is a reasonable default setting, you need to enable GitHub Actions to be able to automatically build and publish a Docker image on GitHub Container Registry.\u00a0\u21a9</p> </li> <li> <p>While you could just add the <code>write:packages</code> scope to the personal access token created to access the Insiders repository, it's safer to create a dedicated token which you'll only use for publishing the Docker image.\u00a0\u21a9</p> </li> <li> <p>The Insiders repository contains two GitHub Actions workflows:</p> <ul> <li><code>build.yml</code> \u2013 Build and lint the project (disabled on forks)</li> <li><code>publish.yml</code> \u2013 Build and publish the Docker image</li> </ul> <p>\u21a9</p> </li> </ol>"},{"location":"v10/reference/","title":"Reference","text":"<p>Material for MkDocs is packed with many great features that make technical writing a joyful activity. This section of the documentation explains how to set up a page, and showcases all available specimen that can be used directly from within Markdown files.</p>"},{"location":"v10/reference/#configuration","title":"Configuration","text":""},{"location":"v10/reference/#built-in-typeset-plugin","title":"Built-in typeset plugin","text":"<p> Sponsors only \u00b7  insiders-4.27.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in typeset plugin preserves HTML formatting in the navigation and table of contents. This means that now, code blocks, icons, emojis and other inline formatting will be preserved, which allows for a richer editing experience. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- typeset\n</code></pre> <p>For a demo, just take a look at the table of contents of this page  \u2013 code blocks and icons are preserved from the section headlines; even highlighting inline code blocks is supported </p>"},{"location":"v10/reference/#built-in-meta-plugin","title":"Built-in meta plugin","text":"<p> Sponsors only \u00b7  insiders-4.21.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in meta plugin allows to set front matter per folder, which is especially handy to ensure that all pages in a folder use specific templates or  tags. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- meta\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>meta_file</code> <p> Default: <code>**/.meta.yml</code> \u2013 This option specifies the name of the meta files that the plugin should look for. The default setting assumes that meta files are called <code>.meta.yml</code>:</p> <pre><code>plugins:\n- meta:\nmeta_file: '**/.meta.yml' # (1)!\n</code></pre> <ol> <li>Note that it's strongly recommended to prefix meta files with a <code>.</code>,     since otherwise they would be included in the build output.</li> </ol>"},{"location":"v10/reference/#usage","title":"Usage","text":""},{"location":"v10/reference/#setting-the-page-title","title":"Setting the page <code>title</code>","text":"<p>Each page has a designated title, which is used in the navigation sidebar, for  social cards and in other places. While MkDocs attempts to automatically  determine the title of a page in a four step process, the title can also be  explicitly set with the front matter <code>title</code> property:</p> <pre><code>---\ntitle: Lorem ipsum dolor sit amet # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li>This line sets the <code>title</code> inside the HTML document's     <code>head</code> for the generated page to the given value. Note that the     site title, which is set via <code>site_name</code>, is appended with a     dash.</li> </ol>"},{"location":"v10/reference/#setting-the-page-description","title":"Setting the page <code>description</code>","text":"<p>A Markdown file can include a description that is added to the <code>meta</code> tags of a page, and is also used for social cards. It's a good idea to set a  <code>site_description</code> in <code>mkdocs.yml</code> as a fallback value if the author does not explicitly define a description for a Markdown file:</p> <pre><code>---\ndescription: Nullam urna elit, malesuada eget finibus ut, ac tortor. # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li>This line sets the <code>meta</code> tag containing the description inside the     document <code>head</code> for the current page to the provided value.</li> </ol>"},{"location":"v10/reference/#setting-the-page-icon","title":"Setting the page <code>icon</code>","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>An icon can be assigned to each page, which is then rendered as part of the navigation sidebar, as well as navigation tabs, if enabled. Use the front matter <code>icon</code> property to reference an icon, adding the following lines at the top of a Markdown file:</p> <pre><code>---\nicon: material/emoticon-happy # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol>"},{"location":"v10/reference/#setting-the-page-status","title":"Setting the page <code>status</code>","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>A status can be assigned to each page, which is then displayed as part of the navigation sidebar. First, associate a status identifier with a description by  adding the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nstatus:\n&lt;identifier&gt;: &lt;description&gt; # (1)!\n</code></pre> <ol> <li> <p>The identifier can only include alphanumeric characters, as well as dashes     and underscores. For example, if you have a status <code>Recently added</code>, you can     set <code>new</code> as an identifier:</p> <pre><code>extra:\nstatus:\nnew: Recently added\n</code></pre> </li> </ol> <p>The page status can now be set with the front matter <code>status</code> property. For example, you can mark a page as <code>new</code> with the following lines at the top of a  Markdown file:</p> <pre><code>---\nstatus: new\n---\n# Document title\n...\n</code></pre> <p>The following status identifiers are currently supported:</p> <ul> <li> \u2013 <code>new</code></li> <li> \u2013 <code>deprecated</code></li> </ul>"},{"location":"v10/reference/#setting-the-page-subtitle","title":"Setting the page <code>subtitle</code>","text":"<p> Sponsors only \u00b7  insiders-4.25.0 \u00b7  Experimental</p> <p>Each page can define a subtitle, which is then rendered below the title as part of the navigation sidebar by using the front matter <code>subtitle</code> property, and adding the following lines:</p> <pre><code>---\nsubtitle: Nullam urna elit, malesuada eget finibus ut, ac tortor\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/reference/#setting-the-page-template","title":"Setting the page <code>template</code>","text":"<p>If you're using theme extension and created a new page template in the <code>overrides</code> directory, you can enable it for a specific page. Add the following  lines at the top of a Markdown file:</p> <pre><code>---\ntemplate: custom.html\n---\n# Document title\n...\n</code></pre> How to set a page template for an entire folder? <p>With the help of the built-in meta plugin, you can set a custom template for an entire section and all nested pages, by creating a <code>.meta.yml</code> file in the corresponding folder with the following content:</p> <pre><code>template: custom.html\n</code></pre>"},{"location":"v10/reference/#customization","title":"Customization","text":""},{"location":"v10/reference/#using-metadata-in-templates","title":"Using metadata in templates","text":""},{"location":"v10/reference/#on-all-pages","title":"on all pages","text":"<p>In order to add custom <code>meta</code> tags to your document, you can extend the theme  and override the <code>extrahead</code> block, e.g. to add indexing policies for search engines via the <code>robots</code> property:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block extrahead %}\n  &lt;meta name=\"robots\" content=\"noindex, nofollow\" /&gt;\n{% endblock %}\n</code></pre>"},{"location":"v10/reference/#on-a-single-page","title":"on a single page","text":"<p>If you want to set a <code>meta</code> tag on a single page, or want to set different values for different pages, you can use the <code>page.meta</code> object inside your template override, e.g.:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block extrahead %}\n  {% if page and page.meta and page.meta.robots %}\n    &lt;meta name=\"robots\" content=\"{{ page.meta.robots }}\" /&gt;\n  {% else %}\n    &lt;meta name=\"robots\" content=\"index, follow\" /&gt;\n  {% endif %}\n{% endblock %}\n</code></pre> <p>You can now use <code>robots</code> exactly like <code>title</code> and <code>description</code> to set values. Note that in this case, the template defines an <code>else</code> branch, which would set a default if none was given.</p>"},{"location":"v10/reference/admonitions/","title":"Admonitions","text":"<p>Admonitions, also known as call-outs, are an excellent choice for including side content without significantly interrupting the document flow. Material for MkDocs provides several different types of admonitions and allows for the inclusion and nesting of arbitrary content.</p>"},{"location":"v10/reference/admonitions/#configuration","title":"Configuration","text":"<p>This configuration enables admonitions, allows to make them collapsible and to nest arbitrary content inside admonitions. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- admonition\n- pymdownx.details\n- pymdownx.superfences\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Admonition</li> <li>Details</li> <li>SuperFences</li> </ul>"},{"location":"v10/reference/admonitions/#admonition-icons","title":"Admonition icons","text":"<p> 8.3.0</p> <p>Each of the supported admonition types has a distinct icon, which can be changed to any icon bundled with the theme, or even a custom icon. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nicon:\nadmonition:\n&lt;type&gt;: &lt;icon&gt; # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> Expand to show alternate icon sets  Octicons FontAwesome <pre><code>theme:\nicon:\nadmonition:\nnote: octicons/tag-16\nabstract: octicons/checklist-16\ninfo: octicons/info-16\ntip: octicons/squirrel-16\nsuccess: octicons/check-16\nquestion: octicons/question-16\nwarning: octicons/alert-16\nfailure: octicons/x-circle-16\ndanger: octicons/zap-16\nbug: octicons/bug-16\nexample: octicons/beaker-16\nquote: octicons/quote-16\n</code></pre> <pre><code>theme:\nicon:\nadmonition:\nnote: fontawesome/solid/note-sticky\nabstract: fontawesome/solid/book\ninfo: fontawesome/solid/circle-info\ntip: fontawesome/solid/bullhorn\nsuccess: fontawesome/solid/check\nquestion: fontawesome/solid/circle-question\nwarning: fontawesome/solid/triangle-exclamation\nfailure: fontawesome/solid/bomb\ndanger: fontawesome/solid/skull\nbug: fontawesome/solid/robot\nexample: fontawesome/solid/flask\nquote: fontawesome/solid/quote-left\n</code></pre>"},{"location":"v10/reference/admonitions/#usage","title":"Usage","text":"<p>Admonitions follow a simple syntax: a block starts with <code>!!!</code>, followed by a single keyword used as a type qualifier. The content of the block follows on the next line, indented by four spaces:</p> Admonition<pre><code>!!! note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"v10/reference/admonitions/#changing-the-title","title":"Changing the title","text":"<p>By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier:</p> Admonition with custom title<pre><code>!!! note \"Phasellus posuere in sem ut cursus\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"v10/reference/admonitions/#removing-the-title","title":"Removing the title","text":"<p>Similar to changing the title, the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks:</p> Admonition without title<pre><code>!!! note \"\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"v10/reference/admonitions/#collapsible-blocks","title":"Collapsible blocks","text":"<p>When Details is enabled and an admonition block is started with <code>???</code> instead of <code>!!!</code>, the admonition is rendered as a collapsible block with a small toggle on the right side:</p> Admonition, collapsible<pre><code>??? note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Adding a <code>+</code> after the <code>???</code> token renders the block expanded:</p> Admonition, collapsible and initially expanded<pre><code>???+ note\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"v10/reference/admonitions/#inline-blocks","title":"Inline blocks","text":"<p>Admonitions can also be rendered as inline blocks (e.g., for sidebars), placing them to the right using the <code>inline</code> + <code>end</code> modifiers, or to the left using only the <code>inline</code> modifier:</p>  inline end inline <p>Lorem ipsum</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>!!! info inline end \"Lorem ipsum\"\n\n    Lorem ipsum dolor sit amet, consectetur\n    adipiscing elit. Nulla et euismod nulla.\n    Curabitur feugiat, tortor non consequat\n    finibus, justo purus auctor massa, nec\n    semper lorem quam in massa.\n</code></pre> <p>Use <code>inline end</code> to align to the right (left for rtl languages).</p> <p>Lorem ipsum</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>!!! info inline \"Lorem ipsum\"\n\n    Lorem ipsum dolor sit amet, consectetur\n    adipiscing elit. Nulla et euismod nulla.\n    Curabitur feugiat, tortor non consequat\n    finibus, justo purus auctor massa, nec\n    semper lorem quam in massa.\n</code></pre> <p>Use <code>inline</code> to align to the left (right for rtl languages).</p> <p>Important: admonitions that use the <code>inline</code> modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the admonition next to the block, the admonition will stretch to the full width of the viewport, e.g., on mobile viewports.</p>"},{"location":"v10/reference/admonitions/#supported-types","title":"Supported types","text":"<p>Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is <code>note</code>1:</p> <code>note</code> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>abstract</code> <p>Abstract</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>info</code> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>tip</code> <p>Tip</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>success</code> <p>Success</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>question</code> <p>Question</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>warning</code> <p>Warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>failure</code> <p>Failure</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>danger</code> <p>Danger</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>bug</code> <p>Bug</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>example</code> <p>Example</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <code>quote</code> <p>Quote</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"v10/reference/admonitions/#customization","title":"Customization","text":""},{"location":"v10/reference/admonitions/#classic-admonitions","title":"Classic admonitions","text":"<p>Prior to version  8.5.6, admonitions had a slightly different appearance:</p> <p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>If you want to restore this appearance, add the following CSS to an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-typeset .admonition,\n.md-typeset details {\nborder-width: 0;\nborder-left-width: 4px;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"v10/reference/admonitions/#custom-admonitions","title":"Custom admonitions","text":"<p>If you want to add a custom admonition type, all you need is a color and an <code>*.svg</code> icon. Copy the icon's code from the <code>.icons</code> folder and add the following CSS to an additional style sheet:</p>    :root {     --md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"&gt;&lt;path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/&gt;&lt;/svg&gt;')   }   .md-typeset .admonition.pied-piper,   .md-typeset details.pied-piper {     border-color: rgb(43, 155, 70);   }   .md-typeset .pied-piper &gt; .admonition-title,   .md-typeset .pied-piper &gt; summary {     background-color: rgba(43, 155, 70, 0.1);   }   .md-typeset .pied-piper &gt; .admonition-title::before,   .md-typeset .pied-piper &gt; summary::before {     background-color: rgb(43, 155, 70);     -webkit-mask-image: var(--md-admonition-icon--pied-piper);             mask-image: var(--md-admonition-icon--pied-piper);   }  <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,&lt;svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"&gt;&lt;path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/&gt;&lt;/svg&gt;')\n}\n.md-typeset .admonition.pied-piper,\n.md-typeset details.pied-piper {\nborder-color: rgb(43, 155, 70);\n}\n.md-typeset .pied-piper &gt; .admonition-title,\n.md-typeset .pied-piper &gt; summary {\nbackground-color: rgba(43, 155, 70, 0.1);\n}\n.md-typeset .pied-piper &gt; .admonition-title::before,\n.md-typeset .pied-piper &gt; summary::before {\nbackground-color: rgb(43, 155, 70);\n-webkit-mask-image: var(--md-admonition-icon--pied-piper);\nmask-image: var(--md-admonition-icon--pied-piper);\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, you can use the custom admonition type:</p> Admonition with custom type<pre><code>!!! pied-piper \"Pied Piper\"\n\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et\n    euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\n    purus auctor massa, nec semper lorem quam in massa.\n</code></pre> <p>Pied Piper</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> <p>Previously, some of the supported types defined more than one qualifier. For example, authors could use <code>summary</code> or <code>tldr</code> as alternative qualifiers to render an <code>abstract</code> admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/reference/annotations/","title":"Annotations","text":"<p>One of the flagship features of Material for MkDocs is the ability to inject annotations \u2013 little markers that can be added almost anywhere in a document and expand a tooltip containing arbitrary Markdown on click or keyboard focus.</p>"},{"location":"v10/reference/annotations/#configuration","title":"Configuration","text":"<p>This configuration allows to add annotations to all inline- and block-level elements, as well as code blocks, and nest annotations inside each other. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- md_in_html\n- pymdownx.superfences\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> <li>SuperFences</li> </ul>"},{"location":"v10/reference/annotations/#usage","title":"Usage","text":""},{"location":"v10/reference/annotations/#using-annotations","title":"Using annotations","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>Annotations consist of two parts: a marker, which can be placed anywhere in a block marked with the <code>annotate</code> class, and content located in a list below the block containing the marker:</p> Text with annotations<pre><code>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! I can contain `code`, __formatted\n    text__, images, ... basically anything that can be expressed in Markdown.\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol> <p>Note that the <code>annotate</code> class must only be added to the outermost block. All nested elements can use the same list to define annotations, except when annotations are nested themselves.</p>"},{"location":"v10/reference/annotations/#in-annotations","title":"in annotations","text":"<p>When SuperFences is enabled, annotations can be nested inside annotations by adding the <code>annotate</code> class to the list item hosting the annotation content, repeating the process:</p> Text with nested annotations<pre><code>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! (1)\n    { .annotate }\n\n1.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> <p> I'm an annotation! (1)</p> <ol> <li> I'm an annotation as well!</li> </ol> </li> </ol>"},{"location":"v10/reference/annotations/#in-admonitions","title":"in admonitions","text":"<p>The titles and bodies of admonitions can also host annotations by adding the <code>annotate</code> modifier after the type qualifier, which is similar to how inline blocks work:</p> Admonition with annotations<pre><code>!!! note annotate \"Phasellus posuere in sem ut cursus (1)\"\n\n    Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et\n    euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo\n    purus auctor massa, nec semper lorem quam in massa.\n\n1.  :man_raising_hand: I'm an annotation!\n2.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> <p>Phasellus posuere in sem ut cursus (1)</p> <p>Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <ol> <li> I'm an annotation!</li> <li> I'm an annotation as well!</li> </ol>"},{"location":"v10/reference/annotations/#in-content-tabs","title":"in content tabs","text":"<p>Content tabs can host annotations by adding the <code>annotate</code> class to the block of a dedicated content tab (and not to the container, which is not supported):</p> Content tabs with annotations<pre><code>=== \"Tab 1\"\n\n    Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n    { .annotate }\n\n1.  :man_raising_hand: I'm an annotation!\n\n=== \"Tab 2\"\n\n    Phasellus posuere in sem ut cursus (1)\n    { .annotate }\n\n1.  :woman_raising_hand: I'm an annotation as well!\n</code></pre> Tab 1Tab 2 <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation!</li> </ol> <p>Phasellus posuere in sem ut cursus (1)</p> <ol> <li> I'm an annotation as well!</li> </ol>"},{"location":"v10/reference/annotations/#in-everything-else","title":"in everything else","text":"<p>The Attribute Lists extension is the key ingredient for adding annotations to  most elements, but it has some limitations. However, it's always possible to leverage the Markdown in HTML extension to wrap arbitrary elements with a <code>div</code> with the <code>annotate</code> class:</p> HTML with annotations<pre><code>&lt;div class=\"annotate\" markdown&gt;\n&gt; Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.\n\n&lt;/div&gt;\n1.  :man_raising_hand: I'm an annotation!\n</code></pre> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation!</li> </ol> <p>With this trick, annotations can also be added to blockquotes, lists, and many other elements that are not supported by the Attribute Lists extension. Furthermore, note that code blocks follow different semantics.</p> <p>Known limitations</p> <p>Please note that annotations currently don't work in data tables as reported in #3453, as data tables are scrollable elements and positioning is very tricky to get right. This might be fixed in the future.</p>"},{"location":"v10/reference/buttons/","title":"Buttons","text":"<p>Material for MkDocs provides dedicated styles for primary and secondary buttons that can be added to any link, <code>label</code> or <code>button</code> element. This is especially useful for documents or landing pages with dedicated call-to-actions.</p>"},{"location":"v10/reference/buttons/#configuration","title":"Configuration","text":"<p>This configuration allows to add attributes to all inline- and block-level elements with a simple syntax, turning any link into a button. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> </ul>"},{"location":"v10/reference/buttons/#usage","title":"Usage","text":""},{"location":"v10/reference/buttons/#adding-buttons","title":"Adding buttons","text":"<p>In order to render a link as a button, suffix it with curly braces and add the <code>.md-button</code> class selector to it. The button will receive the selected primary color and accent color if active.</p> Button<pre><code>[Subscribe to our newsletter](#){ .md-button }\n</code></pre> <p>Subscribe to our newsletter</p>"},{"location":"v10/reference/buttons/#adding-primary-buttons","title":"Adding primary buttons","text":"<p>If you want to display a filled, primary button (like on the landing page of Material for MkDocs), add both, the <code>.md-button</code> and <code>.md-button--primary</code> CSS class selectors.</p> Button, primary<pre><code>[Subscribe to our newsletter](#){ .md-button .md-button--primary }\n</code></pre> <p>Subscribe to our newsletter</p>"},{"location":"v10/reference/buttons/#adding-icon-buttons","title":"Adding icon buttons","text":"<p>Of course, icons can be added to all types of buttons by using the icon syntax together with any valid icon shortcode, which can be easily found with a few keystrokes through our icon search.</p> Button with icon<pre><code>[Send :fontawesome-solid-paper-plane:](#){ .md-button }\n</code></pre> <p>Send </p>"},{"location":"v10/reference/code-blocks/","title":"Code blocks","text":"<p>Code blocks and examples are an essential part of technical project documentation. Material for MkDocs provides different ways to set up syntax highlighting for code blocks, either during build time using Pygments or during runtime using a JavaScript syntax highlighter.</p>"},{"location":"v10/reference/code-blocks/#configuration","title":"Configuration","text":"<p>This configuration enables syntax highlighting on code blocks and inline code  blocks, and allows to include source code directly from other files. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\nline_spans: __span\npygments_lang_class: true\n- pymdownx.inlinehilite\n- pymdownx.snippets\n- pymdownx.superfences\n</code></pre> <p>The following sections discuss how to use different syntax highlighting features with Pygments, the recommended highlighter, so they don't apply when using a JavaScript syntax highlighter.</p> <p>See additional configuration options:</p> <ul> <li>Highlight</li> <li>InlineHilite</li> <li>SuperFences</li> <li>Snippets</li> </ul>"},{"location":"v10/reference/code-blocks/#code-copy-button","title":"Code copy button","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>Code blocks can automatically render a button on the right side to allow the user to copy a code block's contents to the clipboard. Add the following to <code>mkdocs.yml</code> to enable them globally:</p> <pre><code>theme:\nfeatures:\n- content.code.copy\n</code></pre> Enabling or disabling code copy buttons for a specific code block <p>If you don't want to enable code copy buttons globally, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension:</p> <pre><code>``` { .yaml .copy }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>. Similarly, the copy button can also be disabled for a specific code block:</p> <pre><code>``` { .yaml .no-copy }\n# Code block content\n```\n</code></pre>"},{"location":"v10/reference/code-blocks/#code-selection-button","title":"Code selection button","text":"<p> Sponsors only \u00b7  insiders-4.32.0 \u00b7  Experimental</p> <p>Code blocks can include a button to allow for the selection of line ranges by the user, which is perfect for linking to a specific subsection of a code block. This allows the user to apply line highlighting dynamically. Add the following to <code>mkdocs.yml</code> to enable it globally:</p> <pre><code>theme:\nfeatures:\n- content.code.select\n</code></pre> Enabling or disabling code selection buttons for a specific code block <p>If you don't want to enable code selection buttons globally, you can enable  them for a specific code block by using a slightly different syntax based on  the Attribute Lists extension:</p> <pre><code>``` { .yaml .select }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>. Similarly, the selection button can also be disabled for a specific code block:</p> <pre><code>``` { .yaml .no-select }\n# Code block content\n```\n</code></pre>"},{"location":"v10/reference/code-blocks/#code-annotations","title":"Code annotations","text":"<p> 8.0.0 \u00b7  Feature flag</p> <p>Code annotations offer a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Add the following to <code>mkdocs.yml</code> to enable them globally:</p> <pre><code>theme:\nfeatures:\n- content.code.annotate # (1)!\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol> Enabling code annotations for a specific code block <p>If you don't want to enable code annotations globally, because you don't like the automatic inlining behavior, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension:</p> <pre><code>``` { .yaml .annotate }\n# Code block content\n```\n</code></pre> <p>Note that the language shortcode which has to come first must now also be  prefixed by a <code>.</code>.</p>"},{"location":"v10/reference/code-blocks/#custom-selectors","title":"Custom selectors","text":"<p> Sponsors only \u00b7  insiders-4.32.0 \u00b7  Experimental</p> <p>Normally, code annotations can only be placed in comments, as comments can be considered safe for placement. However, sometimes it might be necessary to place annotations in parts of the code block where comments are not allowed, e.g. in  strings.</p> <p>Additional selectors can be set per-language:</p> <pre><code>extra:\nannotate:\njson: [.s2] # (1)!\n</code></pre> <ol> <li> <p><code>.s2</code> is the name of the lexeme that Pygments generates for double-quoted     strings. If you want to use a code annotation in another lexeme than a     comment, inspect the code block and determine which lexeme needs to be added     to the list of additional selectors.</p> <p>Important: Code annotations cannot be split between lexemes.</p> </li> </ol> <p>Now, code annotations can be used from within strings in JSON:</p> <pre><code>{\n\"key\": \"value (1)\"\n}\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol>"},{"location":"v10/reference/code-blocks/#usage","title":"Usage","text":"<p>Code blocks must be enclosed with two separate lines containing three backticks. To add syntax highlighting to those blocks, add the language shortcode directly after the opening block. See the list of available lexers to find the shortcode for a given language:</p> Code block<pre><code>``` py\nimport tensorflow as tf\n```\n</code></pre> <pre><code>import tensorflow as tf\n</code></pre>"},{"location":"v10/reference/code-blocks/#adding-a-title","title":"Adding a title","text":"<p>In order to provide additional context, a custom title can be added to a code block by using the <code>title=\"&lt;custom title&gt;\"</code> option directly after the shortcode, e.g. to display the name of a file:</p> Code block with title<pre><code>``` py title=\"bubble_sort.py\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> bubble_sort.py<pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"v10/reference/code-blocks/#adding-annotations","title":"Adding annotations","text":"<p>Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in <code>// ...</code> and <code>/* ... */</code>, for YAML in <code># ...</code>, etc.1:</p> Code block with annotation<pre><code>``` yaml\ntheme:\n  features:\n    - content.code.annotate # (1)\n```\n\n1.  :man_raising_hand: I'm a code annotation! I can contain `code`, __formatted\n    text__, images, ... basically anything that can be written in Markdown.\n</code></pre> <pre><code>theme:\nfeatures:\n- content.code.annotate # (1)\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol>"},{"location":"v10/reference/code-blocks/#stripping-comments","title":"Stripping comments","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>If you wish to strip the comment characters surrounding a code annotation, simply add an <code>!</code> after the closing parenthesis of the code annotation:</p> Code block with annotation, stripped<pre><code>``` yaml\n# (1)!\n```\n\n1.  Look ma, less line noise!\n</code></pre> <pre><code># (1)!\n</code></pre> <ol> <li>Look ma, less line noise!</li> </ol> <p>Note that this only allows for a single code annotation to be rendered per comment. If you want to add multiple code annotations, comments cannot be stripped for technical reasons.</p>"},{"location":"v10/reference/code-blocks/#adding-line-numbers","title":"Adding line numbers","text":"<p>Line numbers can be added to a code block by using the <code>linenums=\"&lt;start&gt;\"</code> option directly after the shortcode, whereas <code>&lt;start&gt;</code> represents the starting line number. A code block can start from a line number other than <code>1</code>, which allows to split large code blocks for readability:</p> Code block with line numbers<pre><code>``` py linenums=\"1\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"v10/reference/code-blocks/#highlighting-specific-lines","title":"Highlighting specific lines","text":"<p>Specific lines can be highlighted by passing the line numbers to the <code>hl_lines</code> argument placed right after the language shortcode. Note that line counts start at <code>1</code>, regardless of the starting line number specified as part of <code>linenums</code>:</p> LinesLine ranges Code block with highlighted lines<pre><code>``` py hl_lines=\"2 3\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> Code block with highlighted line range<pre><code>``` py hl_lines=\"3-5\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"v10/reference/code-blocks/#highlighting-inline-code-blocks","title":"Highlighting inline code blocks","text":"<p>When InlineHilite is enabled, syntax highlighting can be applied to inline code blocks by prefixing them with a shebang, i.e. <code>#!</code>, directly followed by the corresponding language shortcode.</p> Inline code block<pre><code>The `#!python range()` function is used to generate a sequence of numbers.\n</code></pre> <p>The <code>range()</code> function is used to generate a sequence of numbers.</p>"},{"location":"v10/reference/code-blocks/#embedding-external-files","title":"Embedding external files","text":"<p>When Snippets is enabled, content from other files (including source files) can be embedded by using the <code>--8&lt;--</code> notation directly from within a code block:</p> Code block with external content<pre><code>``` title=\".browserslistrc\"\n--8&lt;-- \".browserslistrc\"\n```\n</code></pre> .browserslistrc<pre><code>last 4 years\n</code></pre>"},{"location":"v10/reference/code-blocks/#customization","title":"Customization","text":""},{"location":"v10/reference/code-blocks/#custom-syntax-theme","title":"Custom syntax theme","text":"<p>If Pygments is used, Material for MkDocs provides the styles for code blocks, which are built with a custom and well-balanced palette that works equally well for both color schemes:</p> <ul> <li> <code>--md-code-hl-number-color</code></li> <li> <code>--md-code-hl-special-color</code></li> <li> <code>--md-code-hl-function-color</code></li> <li> <code>--md-code-hl-constant-color</code></li> <li> <code>--md-code-hl-keyword-color</code></li> <li> <code>--md-code-hl-string-color</code></li> <li> <code>--md-code-hl-name-color</code></li> <li> <code>--md-code-hl-operator-color</code></li> <li> <code>--md-code-hl-punctuation-color</code></li> <li> <code>--md-code-hl-comment-color</code></li> <li> <code>--md-code-hl-generic-color</code></li> <li> <code>--md-code-hl-variable-color</code></li> </ul> <p>Code block foreground, background and line highlight colors are defined via:</p> <ul> <li> <code>--md-code-fg-color</code></li> <li> <code>--md-code-bg-color</code></li> <li> <code>--md-code-hl-color</code></li> </ul> <p>Let's say you want to change the color of <code>\"strings\"</code>. While there are several types of string tokens, they use the same color. You can assign a new color by using an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root &gt; * {\n--md-code-hl-string-color: #0FF1CE;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>If you want to tweak a specific type of string, e.g. <code>`backticks`</code>, you can lookup the specific CSS class name in the syntax theme definition, and override it as part of your additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.highlight .sb {\ncolor: #0FF1CE;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre>"},{"location":"v10/reference/code-blocks/#annotation-tooltip-width","title":"Annotation tooltip width","text":"<p>If you have a lot of content hosted inside your code annotations, it can be a good idea to increase the width of the tooltip by adding the following as part of an additional style sheet:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-tooltip-width: 600px;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>This will render annotations with a larger width:</p> <pre><code># (1)!\n</code></pre> <ol> <li>Muuuuuuuuuuuuuuuch more space for content</li> </ol>"},{"location":"v10/reference/code-blocks/#annotations-with-numbers","title":"Annotations with numbers","text":"<p>Prior to  8.1.0, code annotations were rendered with markers showing the original number as used by the author. However, for technical reasons code annotation numbers restart each code block, which might lead to confusion. For this reason, code annotations now render as <code>+</code> signs which are rotated if they're open to denote that clicking them again will close them.</p> <p>If you wish to revert to the prior behavior and display code annotation numbers, you can add an additional style sheet and copy and paste the following CSS:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-typeset .md-annotation__index &gt; ::before {\ncontent: attr(data-md-annotation-id);\n}\n.md-typeset :focus-within &gt; .md-annotation__index &gt; ::before {\ntransform: none;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <ol> <li> <p>Code annotations require syntax highlighting with Pygments \u2013 they're currently not compatible with JavaScript syntax highlighters, or languages that do not have comments in their grammar. However, we're actively working on supporting alternate ways of defining code annotations, allowing to always place code annotations at the end of lines.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/reference/content-tabs/","title":"Content tabs","text":"<p>Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Material for MkDocs allows for beautiful and functional tabs, grouping code blocks and other content.</p>"},{"location":"v10/reference/content-tabs/#configuration","title":"Configuration","text":"<p>This configuration enables content tabs, and allows to nest arbitrary content inside content tabs, including code blocks and ... more content tabs! Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences\n- pymdownx.tabbed:\nalternate_style: true </code></pre> <p>See additional configuration options:</p> <ul> <li>SuperFences</li> <li>Tabbed</li> </ul>"},{"location":"v10/reference/content-tabs/#anchor-links","title":"Anchor links","text":"<p> Sponsors only \u00b7  insiders-4.17.0 \u00b7  Experimental</p> <p>In order to link to content tabs and share them more easily, Insiders adds an anchor link to each content tab automatically, which you can copy via right click or open in a new tab:</p> Open me in a new tab ...... or me ...... or even me <p>You can copy the link of the tab and create a link on the same or any other page. For example, you can jump to the third tab above this paragraph or to the publishing guide for Insiders.</p> <p>Readable anchor links</p> <p>Python Markdown Extensions 9.6 adds support for slugification of content tabs, which produces nicer looking and more readable anchor links. Enable the slugify function with the following lines:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <p>Fore more information, please see the extension guide.</p>"},{"location":"v10/reference/content-tabs/#linked-content-tabs","title":"Linked content tabs","text":"<p> 8.3.0 \u00b7  Feature flag</p> <p>When enabled, all content tabs across the whole documentation site will be linked and switch to the same label when the user clicks on a tab. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.tabs.link\n</code></pre> <p>Content tabs are linked based on their label, not offset. This means that all tabs with the same label will be activated when a user clicks a content tab regardless of order inside a container. Furthermore, this feature is fully integrated with instant loading and persisted across page loads.</p> Feature enabledFeature disabled <p></p> <p></p>"},{"location":"v10/reference/content-tabs/#usage","title":"Usage","text":""},{"location":"v10/reference/content-tabs/#grouping-code-blocks","title":"Grouping code blocks","text":"<p>Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing:</p> Content tabs with code blocks<pre><code>=== \"C\"\n\n    ``` c\n    #include &lt;stdio.h&gt;\n\n    int main(void) {\n      printf(\"Hello world!\\n\");\n      return 0;\n    }\n    ```\n\n=== \"C++\"\n\n    ``` c++\n    #include &lt;iostream&gt;\n\n    int main(void) {\n      std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n      return 0;\n    }\n    ```\n</code></pre> CC++ <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\nprintf(\"Hello world!\\n\");\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre>"},{"location":"v10/reference/content-tabs/#grouping-other-content","title":"Grouping other content","text":"<p>When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks:</p> Content tabs<pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol>"},{"location":"v10/reference/content-tabs/#embedded-content","title":"Embedded content","text":"<p>When SuperFences is enabled, content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like admonitions or blockquotes:</p> Content tabs in admonition<pre><code>!!! example\n\n    === \"Unordered List\"\n\n        ``` markdown\n        * Sed sagittis eleifend rutrum\n        * Donec vitae suscipit est\n        * Nulla tempor lobortis orci\n        ```\n\n    === \"Ordered List\"\n\n        ``` markdown\n        1. Sed sagittis eleifend rutrum\n        2. Donec vitae suscipit est\n        3. Nulla tempor lobortis orci\n        ```\n</code></pre> <p>Example</p> Unordered ListOrdered List <pre><code>* Sed sagittis eleifend rutrum\n* Donec vitae suscipit est\n* Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"v10/reference/data-tables/","title":"Data tables","text":"<p>Material for MkDocs defines default styles for data tables \u2013 an excellent way of rendering tabular data in project documentation. Furthermore, customizations like sortable tables can be achieved with a third-party library and some additional JavaScript.</p>"},{"location":"v10/reference/data-tables/#configuration","title":"Configuration","text":"<p>This configuration enables Markdown table support, which should normally be enabled by default, but to be sure, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- tables\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Tables</li> </ul>"},{"location":"v10/reference/data-tables/#usage","title":"Usage","text":"<p>Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis:</p> Data table<pre><code>| Method      | Description                          |\n| ----------- | ------------------------------------ |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"v10/reference/data-tables/#column-alignment","title":"Column alignment","text":"<p>If you want to align a specific column to the <code>left</code>, <code>center</code> or <code>right</code>, you can use the regular Markdown syntax placing <code>:</code> characters at the beginning and/or end of the divider.</p> LeftCenterRight Data table, columns aligned to left<pre><code>| Method      | Description                          |\n| :---------- | :----------------------------------- |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns centered<pre><code>| Method      | Description                          |\n| :---------: | :----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource Data table, columns aligned to right<pre><code>| Method      | Description                          |\n| ----------: | -----------------------------------: |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"v10/reference/data-tables/#customization","title":"Customization","text":""},{"location":"v10/reference/data-tables/#sortable-tables","title":"Sortable tables","text":"<p>If you want to make data tables sortable, you can add tablesort, which is natively integrated with Material for MkDocs and will also work with instant loading via additional JavaScript:</p> <code>docs/javascripts/tablesort.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(function() {\nvar tables = document.querySelectorAll(\"article table:not([class])\")\ntables.forEach(function(table) {\nnew Tablesort(table)\n})\n})\n</code></pre> <pre><code>extra_javascript:\n- https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js\n- javascripts/tablesort.js\n</code></pre> <p>After applying the customization, data tables can be sorted by clicking on a column:</p> Data table, columns sortable<pre><code>| Method      | Description                          |\n| ----------- | ------------------------------------ |\n| `GET`       | :material-check:     Fetch resource  |\n| `PUT`       | :material-check-all: Update resource |\n| `DELETE`    | :material-close:     Delete resource |\n</code></pre> Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource <p>Note that tablesort provides alternative comparison implementations like numbers, filesizes, dates and month names. See the tablesort documentation for more information.</p>    var tables = document.querySelectorAll(\"article table\")   new Tablesort(tables.item(tables.length - 1));"},{"location":"v10/reference/data-tables/#import-table-from-file","title":"Import table from file","text":"<p> Plugin</p> <p>You can also import data from a CSV or Excel file using the plugin <code>mkdocs-table-reader-plugin</code>.</p> <p>First, you will need to install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-table-reader-plugin\n</code></pre> <p>Then extend the <code>mkdocs.yml</code> file like this:</p> <pre><code>plugins:\n- table-reader\n</code></pre> <p>Then, it is a simple process to import the data in to the Markdown files.</p> Import data from  CSV fileImport data from  Excel fileImport data from other file types <p>Let's use a  CSV in the local directory. The file may look like this:</p> ./data.csv<pre><code>col1,col2,col3\nr1c1,r1c2,r1c3\nr2c1,r2c2,r2c3\nr3c1,r3c2,r3c3\n</code></pre> <p>You can then add it to your  Markdown page like this:</p> ./markdown.md<pre><code>...\n\n{{ read_csv('./data.csv') }}\n\n...\n</code></pre> <p>...</p> col1 col2 col3 r1c1 r1c2 r1c3 r2c1 r2c2 r2c3 r3c1 r3c2 r3c3 <p>...</p> <p>Let's use an  Excel file in the local directory. The file may look like this:</p> <p></p> <p>And you can add it to your  Markdown page like this:</p> ./markdown.md<pre><code>...\n\n{{ read_excel('./Book1.xlsx', engine='openpyxl') }}\n\n...\n</code></pre> <p>It will then return a result like this:</p> col1 col2 col3 r1c1 r1c2 r1c3 r2c1 r2c2 r2c3 r3c1 r3c2 r3c3 <p>Warning</p> <p>You may receive an error if you use <code>engine='openpyxl'</code>.</p> <p>If this happens, you can resolve it by installing it using <code>pip</code>:</p> <pre><code>pip install openpyxl\n</code></pre> <p>Read more here: pandas.read_excel</p> <p>Pro Tip: Multiple Sheets</p> <p>If your Excel file contains multiple sheets, you may want to extend the function by adding the <code>sheet_name</code> parameter.</p> <p>It would look like this:</p> ./markdown.md<pre><code>...\n\n{{ read_excel('./Book1.xlsx', engine='openpyxl', sheet_name=\"Sheet1\") }}\n\n...\n</code></pre> <p>By default, Pandas will grab the first sheet in the workbook.</p> <p>Read more here: pandas.read_excel</p> <p>The plugin <code>mkdocs-table-reader-plugin</code> also provides readers for other formats:</p> <ul> <li><code>read_csv</code></li> <li><code>read_fwf</code></li> <li><code>read_yaml</code></li> <li><code>read_table</code></li> <li><code>read_json</code></li> <li><code>read_excel</code></li> <li><code>read_raw</code></li> </ul> <p>You can read more on their Docs website: mkdocs-table-reader-plugin</p>"},{"location":"v10/reference/diagrams/","title":"Diagrams","text":"<p>Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js, a very popular and flexible solution for drawing diagrams.</p>"},{"location":"v10/reference/diagrams/#configuration","title":"Configuration","text":"<p> 8.2.0</p> <p>This configuration enables native support for Mermaid.js diagrams. Material for MkDocs will automatically initialize the JavaScript runtime when a page  includes a <code>mermaid</code> code block:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <p>No further configuration is necessary. Advantages over a custom integration:</p> <ul> <li> Works with instant loading without any additional effort</li> <li> Diagrams automatically use fonts and colors defined in <code>mkdocs.yml</code>1</li> <li> Fonts and colors can be customized with additional style sheets</li> <li> Support for both, light and dark color schemes \u2013 try it on this page!</li> </ul>"},{"location":"v10/reference/diagrams/#usage","title":"Usage","text":""},{"location":"v10/reference/diagrams/#using-flowcharts","title":"Using flowcharts","text":"<p>Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps:</p> Flow chart<pre><code>``` mermaid\ngraph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];\n```\n</code></pre> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"v10/reference/diagrams/#using-sequence-diagrams","title":"Using sequence diagrams","text":"<p>Sequence diagrams describe a specific scenario as sequential interactions  between multiple objects or actors, including the messages that are exchanged between those actors:</p> Sequence diagram<pre><code>``` mermaid\nsequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!\n```\n</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre>"},{"location":"v10/reference/diagrams/#using-state-diagrams","title":"Using state diagrams","text":"<p>State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states:</p> State diagram<pre><code>``` mermaid\nstateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]\n```\n</code></pre> <pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre>"},{"location":"v10/reference/diagrams/#using-class-diagrams","title":"Using class diagrams","text":"<p>Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them:</p> Class diagram<pre><code>``` mermaid\nclassDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n  }\n```\n</code></pre> <pre><code>classDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n  }</code></pre>"},{"location":"v10/reference/diagrams/#using-entity-relationship-diagrams","title":"Using entity-relationship diagrams","text":"<p>An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge:</p> Entity-relationship diagram<pre><code>``` mermaid\nerDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    string name\n    int pricePerUnit\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n```\n</code></pre> <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    string name\n    int pricePerUnit\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>"},{"location":"v10/reference/diagrams/#other-diagram-types","title":"Other diagram types","text":"<p>Besides the diagram types listed above, Mermaid.js provides support for pie charts, gantt charts, user journeys, git graphs and requirement diagrams, all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js, but we don't consider them a good choice, mostly as they don't work well on mobile.</p> <ol> <li> <p>While all Mermaid.js features should work out-of-the-box, Material for MkDocs will currently only adjust the fonts and colors for flowcharts, sequence diagrams, class diagrams, state diagrams and entity relationship  diagrams. See the section on other diagrams for more information why this is currently not implemented for all diagrams.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/reference/footnotes/","title":"Footnotes","text":"<p>Footnotes are a great way to add supplemental or additional information to a specific word, phrase or sentence without interrupting the flow of a document. Material for MkDocs provides the ability to define, reference and render footnotes.</p>"},{"location":"v10/reference/footnotes/#configuration","title":"Configuration","text":"<p>This configuration adds the ability to define inline footnotes, which are then rendered below all Markdown content of a document. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- footnotes\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Footnotes</li> </ul>"},{"location":"v10/reference/footnotes/#usage","title":"Usage","text":""},{"location":"v10/reference/footnotes/#adding-footnote-references","title":"Adding footnote references","text":"<p>A footnote reference must be enclosed in square brackets and must start with a caret <code>^</code>, directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax.</p> Text with footnote references<pre><code>Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2]\n</code></pre> <p>Lorem ipsum1 dolor sit amet, consectetur adipiscing elit.2</p>"},{"location":"v10/reference/footnotes/#adding-footnote-content","title":"Adding footnote content","text":"<p>The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added.</p>"},{"location":"v10/reference/footnotes/#on-a-single-line","title":"on a single line","text":"<p>Short footnotes can be written on the same line:</p> Footnote<pre><code>[^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n</code></pre> <p> Jump to footnote</p>"},{"location":"v10/reference/footnotes/#on-multiple-lines","title":"on multiple lines","text":"<p>Paragraphs can be written on the next line and must be indented by four spaces:</p> Footnote<pre><code>[^2]:\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n</code></pre> <p> Jump to footnote</p> <ol> <li> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit.\u00a0\u21a9</p> </li> <li> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/reference/formatting/","title":"Formatting","text":"<p>Material for MkDocs provides support for several HTML elements that can be used  to highlight sections of a document or apply specific formatting. Additionally,  Critic Markup is supported, adding the ability to display suggested changes for a document.</p>"},{"location":"v10/reference/formatting/#configuration","title":"Configuration","text":"<p>This configuration enables support for keyboard keys, tracking changes in documents, defining sub- and superscript and highlighting text. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.critic\n- pymdownx.caret\n- pymdownx.keys\n- pymdownx.mark\n- pymdownx.tilde\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Critic</li> <li>Caret, Mark &amp; Tilde</li> <li>Keys</li> </ul>"},{"location":"v10/reference/formatting/#usage","title":"Usage","text":""},{"location":"v10/reference/formatting/#highlighting-changes","title":"Highlighting changes","text":"<p>When Critic is enabled, Critic Markup can be used, which adds the ability to  highlight suggested changes, as well as add inline comments to a document:</p> Text with suggested changes<pre><code>Text can be {--deleted--} and replacement text {++added++}. This can also be\ncombined into {~~one~&gt;a single~~} operation. {==Highlighting==} is also\npossible {&gt;&gt;and comments can be added inline&lt;&lt;}.\n\n{==\n\nFormatting can also be applied to blocks by putting the opening and closing\ntags on separate lines and adding new lines between the tags and the content.\n\n==}\n</code></pre> <p>Text can be deleted and replacement text added. This can also be combined into onea single operation. Highlighting is also possible and comments can be added inline.</p> <p>       Formatting can also be applied to blocks by putting the opening and       closing tags on separate lines and adding new lines between the tags and       the content.     </p>"},{"location":"v10/reference/formatting/#highlighting-text","title":"Highlighting text","text":"<p>When Caret, Mark &amp; Tilde are enabled, text can be highlighted with a simple  syntax, which is more convenient that directly using the corresponding <code>mark</code>, <code>ins</code> and <code>del</code> HTML tags:</p> Text with highlighting<pre><code>- ==This was marked==\n- ^^This was inserted^^\n- ~~This was deleted~~\n</code></pre> <ul> <li>This was marked</li> <li>This was inserted</li> <li>This was deleted</li> </ul>"},{"location":"v10/reference/formatting/#sub-and-superscripts","title":"Sub- and superscripts","text":"<p>When Caret &amp; Tilde are enabled, text can be sub- and  superscripted with a simple syntax, which is more convenient than directly using the corresponding <code>sub</code> and <code>sup</code> HTML tags:</p> Text with sub- and superscripts<pre><code>- H~2~O\n- A^T^A\n</code></pre> <ul> <li>H2O</li> <li>ATA</li> </ul>"},{"location":"v10/reference/formatting/#adding-keyboard-keys","title":"Adding keyboard keys","text":"<p>When Keys is enabled, keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available shortcodes:</p> Keyboard keys<pre><code>++ctrl+alt+del++\n</code></pre> <p>Ctrl+Alt+Del</p>"},{"location":"v10/reference/grids/","title":"Grids","text":"<p>Material for MkDocs makes it easy to arrange sections into grids, grouping blocks that convey similar meaning or are of equal importance. Grids are just perfect for building index pages that show a brief overview of a large section of your documentation.</p>"},{"location":"v10/reference/grids/#configuration","title":"Configuration","text":"<p>This configuration enables the use of grids, allowing to bring blocks of identical or different types into a rectangular shape. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions: # (1)!\n- attr_list\n- md_in_html\n</code></pre> <ol> <li>Note that some of the examples listed below use icons and emojis, which     have to be configured separately.</li> </ol> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> </ul>"},{"location":"v10/reference/grids/#usage","title":"Usage","text":"<p>Grids come in two flavors: card grids, which wrap each element in a card that levitates on hover, and generic grids, which allow to arrange arbitrary block elements in a rectangular shape.</p>"},{"location":"v10/reference/grids/#using-card-grids","title":"Using card grids","text":"<p> Sponsors only \u00b7  insiders-4.12.0 \u00b7  Experimental</p> <p>Card grids wrap each grid item with a beautiful hover card that levitates on hover. They come in two slightly different syntaxes: list and block syntax, adding support for distinct use cases.</p>"},{"location":"v10/reference/grids/#list-syntax","title":"List syntax","text":"<p>The list syntax is essentially a shortcut for card grids, and consists of an unordered (or ordered) list wrapped by a <code>div</code> with both, the <code>grid</code> and <code>cards</code> classes:</p> Card grid<pre><code>&lt;div class=\"grid cards\" markdown&gt;\n- :fontawesome-brands-html5: __HTML__ for content and structure\n- :fontawesome-brands-js: __JavaScript__ for interactivity\n- :fontawesome-brands-css3: __CSS__ for text running out of boxes\n- :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh?\n\n&lt;/div&gt;\n</code></pre> <ul> <li> HTML for content and structure</li> <li> JavaScript for interactivity</li> <li> CSS for text running out of boxes</li> <li> Internet Explorer ... huh?</li> </ul> <p>List elements can contain arbitrary Markdown, as long as the surrounding <code>div</code> defines the <code>markdown</code> attribute. Following is a more complex example, which includes icons and links:</p> Card grid, complex example<pre><code>&lt;div class=\"grid cards\" markdown&gt;\n-   :material-clock-fast:{ .lg .middle } __Set up in 5 minutes__\n\n    ---\n\n    Install [`mkdocs-material`](#) with [`pip`](#) and get up\n    and running in minutes\n\n    [:octicons-arrow-right-24: Getting started](#)\n\n-   :fontawesome-brands-markdown:{ .lg .middle } __It's just Markdown__\n\n    ---\n\n    Focus on your content and generate a responsive and searchable static site\n\n    [:octicons-arrow-right-24: Reference](#)\n\n-   :material-format-font:{ .lg .middle } __Made to measure__\n\n    ---\n\n    Change the colors, fonts, language, icons, logo and more with a few lines\n\n    [:octicons-arrow-right-24: Customization](#)\n\n-   :material-scale-balance:{ .lg .middle } __Open Source, MIT__\n\n    ---\n\n    Material for MkDocs is licensed under MIT and available on [GitHub]\n\n    [:octicons-arrow-right-24: License](#)\n\n&lt;/div&gt;\n</code></pre> <ul> <li> <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> </li> <li> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> </li> <li> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> </li> <li> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on GitHub</p> <p> License</p> </li> </ul> <p>If there's insufficient space to render grid items next to each other, the items will stretch to the full width of the viewport, e.g. on mobile viewports. If there's more space available, grids will render in items of 3 and more, e.g. when hiding both sidebars.</p>"},{"location":"v10/reference/grids/#block-syntax","title":"Block syntax","text":"<p>The block syntax allows for arranging cards in grids together with other elements, as explained in the section on generic grids. Just add the <code>card</code> class to any block element inside a <code>grid</code>:</p> Card grid, blocks<pre><code>&lt;div class=\"grid\" markdown&gt;\n:fontawesome-brands-html5: __HTML__ for content and structure\n{ .card }\n\n:fontawesome-brands-js: __JavaScript__ for interactivity\n{ .card }\n\n:fontawesome-brands-css3: __CSS__ for text running out of boxes\n{ .card }\n\n&gt; :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh?\n\n&lt;/div&gt;\n</code></pre> <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer ... huh?</p> <p>While this syntax may seem unnecessarily verbose at first, the previous example shows how card grids can now be mixed with other elements that will also stretch to the grid.</p>"},{"location":"v10/reference/grids/#using-generic-grids","title":"Using generic grids","text":"<p> Sponsors only \u00b7  insiders-4.12.0 \u00b7  Experimental</p> <p>Generic grids allow for arranging arbitrary block elements in a grid, including admonitions, code blocks, content tabs and more. Just wrap a set of blocks by using a <code>div</code> with the <code>grid</code> class:</p> Generic grid<pre><code>&lt;div class=\"grid\" markdown&gt;\n=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n\n``` title=\"Content tabs\"\n=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n```\n\n&lt;/div&gt;\n</code></pre> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol> Content tabs<pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"v10/reference/icons-emojis/","title":"Icons, Emojis","text":"<p>One of the best features of Material for MkDocs is the possibility to use more than 10,000 icons and thousands of emojis in your project  documentation with practically zero additional effort. Moreover, custom icons  can be added and used in <code>mkdocs.yml</code>, documents and templates.</p>"},{"location":"v10/reference/icons-emojis/#search","title":"Search","text":"<p> Tip: Enter some keywords to find icons and emojis and click on the   shortcode to copy it to your clipboard. </p>"},{"location":"v10/reference/icons-emojis/#configuration","title":"Configuration","text":"<p>This configuration enables the use of icons and emojis by using simple shortcodes which can be discovered through the icon search. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <p>The following icon sets are bundled with Material for MkDocs:</p> <ul> <li> \u2013 Material Design</li> <li> \u2013 FontAwesome</li> <li> \u2013 Octicons</li> <li> \u2013 Simple Icons</li> </ul> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Emoji</li> <li>Emoji with custom icons</li> </ul>"},{"location":"v10/reference/icons-emojis/#usage","title":"Usage","text":""},{"location":"v10/reference/icons-emojis/#using-emojis","title":"Using emojis","text":"<p>Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. If you're using Twemoji (recommended), you can look up the shortcodes at Emojipedia:</p> Emoji<pre><code>:smile: \n</code></pre> <p></p>"},{"location":"v10/reference/icons-emojis/#using-icons","title":"Using icons","text":"<p>When Emoji is enabled, icons can be used similar to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the <code>.icons</code> directory, and replacing <code>/</code> with <code>-</code>:</p> Icon<pre><code>:fontawesome-regular-face-laugh-wink:\n</code></pre> <p></p>"},{"location":"v10/reference/icons-emojis/#with-colors","title":"with colors","text":"<p>When Attribute Lists is enabled, custom CSS classes can be added to icons by suffixing the icon with a special syntax. While HTML allows to use inline styles, it's always recommended to add an additional style sheet and move declarations into dedicated CSS classes:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.twitter {\ncolor: #1DA1F2;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, add the CSS class to the icon shortcode:</p> Icon with color<pre><code>:fontawesome-brands-twitter:{ .twitter }\n</code></pre> <p></p>"},{"location":"v10/reference/icons-emojis/#with-animations","title":"with animations","text":"<p>Similar to adding colors, it's just as easy to add animations to icons by using an additional style sheet, defining a <code>@keyframes</code> rule and adding a dedicated CSS class to the icon:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>@keyframes heart {\n0%, 40%, 80%, 100% {\ntransform: scale(1);\n}\n20%, 60% {\ntransform: scale(1.15);\n}\n}\n.heart {\nanimation: heart 1000ms infinite;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>After applying the customization, add the CSS class to the icon shortcode:</p> Icon with animation<pre><code>:octicons-heart-fill-24:{ .heart }\n</code></pre> <p></p>"},{"location":"v10/reference/icons-emojis/#icons-emojis-in-sidebars","title":"Icons, emojis in sidebars","text":"<p>With the help of the built-in typeset plugin, you can use icons and emojis in headings, which will then be rendered in the sidebars. The plugin preserves Markdown and HTML formatting.</p>"},{"location":"v10/reference/icons-emojis/#customization","title":"Customization","text":""},{"location":"v10/reference/icons-emojis/#using-icons-in-templates","title":"Using icons in templates","text":"<p>When you're extending the theme with partials or blocks, you can simply reference any icon that's bundled with the theme with Jinja's <code>include</code> function and wrap it with the <code>.twemoji</code> CSS class:</p> <pre><code>&lt;span class=\"twemoji\"&gt;\n  {% include \".icons/fontawesome/brands/twitter.svg\" %} &lt;!-- (1)! --&gt;\n&lt;/span&gt;\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>This is exactly what Material for MkDocs does in its templates.</p>"},{"location":"v10/reference/images/","title":"Images","text":"<p>While images are first-class citizens of Markdown and part of the core syntax,  it can be difficult to work with them. Material for MkDocs makes working with  images more comfortable, providing styles for image alignment and image captions.</p>"},{"location":"v10/reference/images/#configuration","title":"Configuration","text":"<p>This configuration adds the ability to align images, add captions to images (rendering them as figures), and mark large images for lazy-loading. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n- md_in_html\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Attribute Lists</li> <li>Markdown in HTML</li> </ul>"},{"location":"v10/reference/images/#lightbox","title":"Lightbox","text":"<p> 0.1.0 \u00b7  Plugin</p> <p>If you want to add image zoom functionality to your documentation, the  glightbox plugin is an excellent choice, as it integrates perfectly with Material for MkDocs. Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-glightbox\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- glightbox\n</code></pre> <p>We recommend checking out the available configuration options.</p>"},{"location":"v10/reference/images/#usage","title":"Usage","text":""},{"location":"v10/reference/images/#image-alignment","title":"Image alignment","text":"<p>When Attribute Lists is enabled, images can be aligned by adding the respective alignment directions via the <code>align</code> attribute, i.e. <code>align=left</code> or <code>align=right</code>:</p> LeftRight Image, aligned to left<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=left }\n</code></pre> <p></p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> Image, aligned to right<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=right }\n</code></pre> <p></p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports.</p> Why is there no centered alignment? <p>The <code>align</code> attribute doesn't allow for centered alignment, which is why this option is not supported by Material for MkDocs.1 Instead, the image captions syntax can be used, as captions are optional.</p>"},{"location":"v10/reference/images/#image-captions","title":"Image captions","text":"<p>Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to use the Markdown in HTML extension with literal <code>figure</code> and <code>figcaption</code> tags:</p> Image with caption<pre><code>&lt;figure markdown&gt;\n  ![Image title](https://dummyimage.com/600x400/){ width=\"300\" }\n  &lt;figcaption&gt;Image caption&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre> Image caption"},{"location":"v10/reference/images/#image-lazy-loading","title":"Image lazy-loading","text":"<p>Modern browsers provide native support for lazy-loading images through the <code>loading=lazy</code> directive, which degrades to eager-loading in browsers without support:</p> Image, lazy-loaded<pre><code>![Image title](https://dummyimage.com/600x400/){ loading=lazy }\n</code></pre> <p></p>"},{"location":"v10/reference/images/#light-and-dark-mode","title":"Light and dark mode","text":"<p> 8.1.1</p> <p>If you added a color palette toggle and want to show different images for light and dark color schemes, you can append a <code>#only-light</code> or <code>#only-dark</code> hash fragment to the image URL:</p> Image, different for light and dark mode<pre><code>![Image title](https://dummyimage.com/600x400/f5f5f5/aaaaaa#only-light)\n![Image title](https://dummyimage.com/600x400/21222c/d5d7e2#only-dark)\n</code></pre> <p> </p> <p>Requirements when using custom color schemes</p> <p>The built-in color schemes define the aforementioned hash fragments, but if you're using custom color schemes, you'll also have to add the following selectors to your scheme, depending on whether it's a light or dark scheme:</p> Custom light schemeCustom dark scheme <pre><code>[data-md-color-scheme=\"custom-light\"] img[src$=\"#only-dark\"],\n[data-md-color-scheme=\"custom-light\"] img[src$=\"#gh-dark-mode-only\"] {\ndisplay: none; /* Hide dark images in light mode */\n}\n</code></pre> <pre><code>[data-md-color-scheme=\"custom-dark\"] img[src$=\"#only-light\"],\n[data-md-color-scheme=\"custom-dark\"] img[src$=\"#gh-light-mode-only\"] {\ndisplay: none; /* Hide light images in dark mode */\n}\n</code></pre> <p>Remember to change <code>\"custom-light\"</code> and <code>\"custom-dark\"</code> to the name of your scheme.</p> <ol> <li> <p>You might also realize that the <code>align</code> attribute has been deprecated as of HTML5, so why use it anyways? The main reason is portability \u2013 it's still supported by all browsers and clients, and is very unlikely to be completely removed, as many older websites still use it. This ensures a consistent appearance when a Markdown file with these attributes is viewed outside of a website generated by Material for MkDocs.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/reference/lists/","title":"Lists","text":"<p>Material for MkDocs supports several flavors of lists that cater to different use cases, including unordered lists and ordered lists, which are supported through standard Markdown, as well as definition lists and task lists, which are supported through extensions.</p>"},{"location":"v10/reference/lists/#configuration","title":"Configuration","text":"<p>This configuration enables the use of definition lists and tasks lists, which are both not part of the standard Markdown syntax. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- def_list\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Definition Lists</li> <li>Tasklist</li> </ul>"},{"location":"v10/reference/lists/#usage","title":"Usage","text":""},{"location":"v10/reference/lists/#using-unordered-lists","title":"Using unordered lists","text":"<p>Unordered lists can be written by prefixing a line with a <code>-</code>, <code>*</code> or <code>+</code> list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other:</p> List, unordered<pre><code>- Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur\n  accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh\n  lacinia sed. Aenean in finibus diam.\n\n* Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\n    * Nam vulputate tincidunt fringilla.\n    * Nullam dignissim ultrices urna non auctor.\n</code></pre> <ul> <li> <p>Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur   accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh   lacinia sed. Aenean in finibus diam.</p> <ul> <li>Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.</li> <li>Nam vulputate tincidunt fringilla.</li> <li>Nullam dignissim ultrices urna non auctor.</li> </ul> </li> </ul>"},{"location":"v10/reference/lists/#using-ordered-lists","title":"Using ordered lists","text":"<p>Ordered lists must start with a number immediately followed by a dot. The  numbers do not need to be consecutive and can be all set to <code>1.</code>, as they will be re-numbered when rendered:</p> List, ordered<pre><code>1.  Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis\n    sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis\n    nulla. Vivamus a pharetra leo.\n\n1.  Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet\n        quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a\n        ultricies libero efficitur sed.\n\n2.  Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet\n        rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a.\n\n1.  Mauris dictum mi lacus\n        2.  Ut sit amet placerat ante\n        3.  Suspendisse ac eros arcu\n</code></pre> <ol> <li> <p>Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis     sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis     nulla. Vivamus a pharetra leo.</p> <ol> <li> <p>Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet     quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a     ultricies libero efficitur sed.</p> </li> <li> <p>Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet     rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a.</p> <ol> <li>Mauris dictum mi lacus</li> <li>Ut sit amet placerat ante</li> <li>Suspendisse ac eros arcu</li> </ol> </li> </ol> </li> </ol>"},{"location":"v10/reference/lists/#using-definition-lists","title":"Using definition lists","text":"<p>When Definition Lists is enabled, lists of arbitrary key-value pairs, e.g. the parameters of functions or modules, can be enumerated with a simple syntax:</p> Definition list<pre><code>`Lorem ipsum dolor sit amet`\n:   Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus\n    tellus non sem sollicitudin, quis rutrum leo facilisis.\n\n`Cras arcu libero`\n:   Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin\n    ut eros sed sapien ullamcorper consequat. Nunc ligula ante.\n\n    Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\n    Nam vulputate tincidunt fringilla.\n    Nullam dignissim ultrices urna non auctor.\n</code></pre> <code>Lorem ipsum dolor sit amet</code> <p>Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.</p> <code>Cras arcu libero</code> <p>Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante.</p> <p>Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.</p>"},{"location":"v10/reference/lists/#using-task-lists","title":"Using task lists","text":"<p>When Tasklist is enabled, unordered list items can be prefixed with <code>[ ]</code> to render an unchecked checkbox or <code>[x]</code> to render a checked checkbox, allowing for the definition of task lists:</p> Task list<pre><code>- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n- [ ] Vestibulum convallis sit amet nisi a tincidunt\n    * [x] In hac habitasse platea dictumst\n    * [x] In scelerisque nibh non dolor mollis congue sed et metus\n    * [ ] Praesent sed risus massa\n- [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul>"},{"location":"v10/reference/math/","title":"Math","text":"<p>MathJax and KaTeX are two popular libraries for displaying  mathematical content in browsers. Although both libraries offer similar  functionality, they use different syntaxes and have different configuration  options. This documentation site provides information on how to integrate them  with Material for MkDocs easily.</p>"},{"location":"v10/reference/math/#configuration","title":"Configuration","text":"<p>The following configuration enables support for rendering block and  inline block equations using MathJax and KaTeX.</p>"},{"location":"v10/reference/math/#mathjax","title":"MathJax","text":"<p>MathJax is a powerful and flexible library that supports multiple input formats,  such as LaTeX, MathML, AsciiMath, as well as various output formats like  HTML, SVG, MathML. To use MathJax within your project, add the following lines  to your <code>mkdocs.yml</code>.</p> <code>docs/javascripts/mathjax.js</code> <code>mkdocs.yml</code> <pre><code>window.MathJax = {\ntex: {\ninlineMath: [[\"\\\\(\", \"\\\\)\"]],\ndisplayMath: [[\"\\\\[\", \"\\\\]\"]],\nprocessEscapes: true,\nprocessEnvironments: true\n},\noptions: {\nignoreHtmlClass: \".*|\",\nprocessHtmlClass: \"arithmatex\"\n}\n};\ndocument$.subscribe(() =&gt; { // (1)!\nMathJax.typesetPromise()\n})\n</code></pre> <ol> <li>This integrates MathJax with instant loading.</li> </ol> <pre><code>markdown_extensions:\n- pymdownx.arithmatex:\ngeneric: true\nextra_javascript:\n- javascripts/mathjax.js\n- https://polyfill.io/v3/polyfill.min.js?features=es6\n- https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Arithmatex</li> </ul>"},{"location":"v10/reference/math/#katex","title":"KaTeX","text":"<p>KaTeX is a lightweight library that focuses on speed and simplicity. It  supports a subset of LaTeX syntax and can render math to HTML and SVG. To use  KaTeX within your project, add the following lines to your <code>mkdocs.yml</code>.</p> <code>docs/javascripts/katex.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(({ body }) =&gt; { // (1)!\nrenderMathInElement(body, {\ndelimiters: [\n{ left: \"$$\",  right: \"$$\",  display: true },\n{ left: \"$\",   right: \"$\",   display: false },\n{ left: \"\\\\(\", right: \"\\\\)\", display: false },\n{ left: \"\\\\[\", right: \"\\\\]\", display: true }\n],\n})\n})\n</code></pre> <ol> <li>This integrates KaTeX with instant loading.</li> </ol> <pre><code>extra_javascript:\n- javascripts/katex.js - https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js  # (1)!\n- https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js\nextra_css:\n- https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css\n</code></pre> <ol> <li>Alternatively, you can add these JavaScript and CSS files via <code>script</code> tags by overriding HTML files.</li> </ol>    window.MathJax = {     tex: {       inlineMath: [[\"\\\\(\", \"\\\\)\"]],       displayMath: [[\"\\\\[\", \"\\\\]\"]],       processEscapes: true,       processEnvironments: true     },     options: {       ignoreHtmlClass: \".*|\",       processHtmlClass: \"arithmatex\"     }   };"},{"location":"v10/reference/math/#usage","title":"Usage","text":""},{"location":"v10/reference/math/#using-block-syntax","title":"Using block syntax","text":"<p>Blocks must be enclosed in <code>$$...$$</code> or <code>\\[...\\]</code> on separate lines:</p> block syntax<pre><code>$$\n\\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}}\n$$\n</code></pre> \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]"},{"location":"v10/reference/math/#using-inline-block-syntax","title":"Using inline block syntax","text":"<p>Inline blocks must be enclosed in <code>$...$</code> or <code>\\(...\\)</code>:</p> inline syntax<pre><code>The homomorphism $f$ is injective if and only if its kernel is only the \nsingleton set $e_G$, because otherwise $\\exists a,b\\in G$ with $a\\neq b$ such \nthat $f(a)=f(b)$.\n</code></pre> <p>The homomorphism \\(f\\) is injective if and only if its kernel is only the  singleton set \\(e_G\\), because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such  that \\(f(a)=f(b)\\).</p>"},{"location":"v10/reference/math/#comparing-mathjax-and-katex","title":"Comparing MathJax and KaTeX","text":"<p>When deciding between MathJax and KaTeX, there are several key factors to  consider:</p> <ul> <li> <p>Speed: KaTeX is generally faster than MathJax. If your site requires rendering large  quantities of complex equations quickly, KaTeX may be the better choice.</p> </li> <li> <p>Syntax Support: MathJax supports a wider array of LaTeX commands and can  process a variety of mathematical markup languages (like AsciiMath and MathML).  If you need advanced LaTeX features, MathJax may be more suitable.</p> </li> <li> <p>Output Format: Both libraries support HTML and SVG outputs. However,  MathJax also offers MathML output, which can be essential for accessibility, as  it is readable by screen readers.</p> </li> <li> <p>Configurability: MathJax provides a range of configuration options,  allowing for more precise control over its behavior. If you have specific  rendering requirements, MathJax might be a more flexible choice.</p> </li> <li> <p>Browser Support: While both libraries work well in modern browsers,  MathJax has broader compatibility with older browsers. If your audience uses a  variety of browsers, including older ones, MathJax might be a safer option.</p> </li> </ul> <p>In summary, KaTeX shines with its speed and simplicity, whereas MathJax offers  more features and better compatibility at the expense of speed. The choice  between the two will largely depend on your specific needs and constraints.</p>"},{"location":"v10/reference/tooltips/","title":"Tooltips","text":"<p>Technical documentation often incurs the usage of many acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries.</p>"},{"location":"v10/reference/tooltips/#configuration","title":"Configuration","text":"<p>This configuration enables abbreviations and allows to build a simple project-wide glossary, sourcing definitions from a central location. Add the following line to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- abbr\n- attr_list\n- pymdownx.snippets\n</code></pre> <p>See additional configuration options:</p> <ul> <li>Abbreviations</li> <li>Attribute Lists</li> <li>Snippets</li> </ul>"},{"location":"v10/reference/tooltips/#improved-tooltips","title":"Improved tooltips","text":"<p> Sponsors only \u00b7  insiders-4.15.0 \u00b7  Experimental</p> <p>When improved tooltips are enabled, Material for MkDocs replaces the browser's rendering logic for <code>title</code> attribute with beautiful little tooltips. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- content.tooltips\n</code></pre> <p>Now, tooltips will be rendered for the following elements:</p> <ul> <li>Content \u2013 elements with a <code>title</code>, permalinks and code copy button</li> <li>Header \u2013 home button, header title, color palette switch and repository link</li> <li>Navigation \u2013 links that are shortened with ellipsis, i.e. <code>...</code></li> </ul>"},{"location":"v10/reference/tooltips/#usage","title":"Usage","text":""},{"location":"v10/reference/tooltips/#adding-tooltips","title":"Adding tooltips","text":"<p>The Markdown syntax allows to specify a <code>title</code> for each link, which will render as a beautiful tooltip when improved tooltips are enabled. Add a  tooltip to a link with the following lines:</p> Link with tooltip, inline syntax<pre><code>[Hover me](https://example.com \"I'm a tooltip!\")\n</code></pre> <p>Hover me</p> <p>Tooltips can also be added to link references:</p> Link with tooltip, reference syntax<pre><code>[Hover me][example]\n\n  [example]: https://example.com \"I'm a tooltip!\"\n</code></pre> <p>Hover me</p> <p>For all other elements, a <code>title</code> can be added by using the Attribute Lists extension:</p> Icon with tooltip<pre><code>:material-information-outline:{ title=\"Important information\" }\n</code></pre> <p></p>"},{"location":"v10/reference/tooltips/#adding-abbreviations","title":"Adding abbreviations","text":"<p>Abbreviations can be defined by using a special syntax similar to URLs and  footnotes, starting with a <code>*</code> and immediately followed by the term or acronym to be associated in square brackets:</p> Text with abbreviations<pre><code>The HTML specification is maintained by the W3C.\n\n*[HTML]: Hyper Text Markup Language\n*[W3C]: World Wide Web Consortium\n</code></pre> <p>The HTML specification is maintained by the W3C.</p>"},{"location":"v10/reference/tooltips/#adding-a-glossary","title":"Adding a glossary","text":"<p>The Snippets extension can be used to implement a simple glossary by moving all abbreviations in a dedicated file1, and auto-append this file to all pages with the following configuration:</p> <code>includes/abbreviations.md</code> <code>mkdocs.yml</code> <pre><code>*[HTML]: Hyper Text Markup Language\n*[W3C]: World Wide Web Consortium\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.snippets:\nauto_append:\n- includes/abbreviations.md\n</code></pre> <ol> <li> <p>It's highly recommended to put the Markdown file containing the abbreviations outside of the <code>docs</code> folder (here, a folder with the name  <code>includes</code> is used), as MkDocs might otherwise complain about an unreferenced file.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/","title":"Setup","text":"<p>Material for MkDocs offers a wide range of options for customizing your documentation. In this section, we will explain how you can create a meaningful structure for your site, change the look and feel, add a blog and comment system, and build a highly optimized site.</p>"},{"location":"v10/setup/#site-structure","title":"Site structure","text":"<p>V10.0.0. Set up and customize the structure of your documentation by configuring the header and footer to your taste, choosing among many modes of navigation, setting up site search, and more.</p> <ul> <li> Language \u2013 Choose out of the 60+ supported languages or add a new one</li> <li> Navigation \u2013 Create a clear, concise, and comprehensive navigation structure</li> <li> Header \u2013 Customize the behavior of the header, add an announcement bar</li> <li> Footer \u2013 Add links to your social media profiles or websites in the footer </li> <li> Search \u2013 Set up and configure search, running entirely in the user's browser</li> <li> Tags \u2013 Categorize your pages with tags and group related pages</li> </ul>"},{"location":"v10/setup/#appearance","title":"Appearance","text":"<p>Match your brand's colors, fonts, icons, logo, and more with a few lines of configuration \u2013 Material for MkDocs makes it easy to extend the basic configuration or alter the appearance.</p> <ul> <li> Colors Change colors with an existing color palette or customize with CSS</li> <li> Fonts \u2013 Choose among 1,000 Google Fonts or load self-hosted fonts</li> <li> Logo &amp; Icons \u2013 Change the logo, use any of the 8,000+ icons, or add new ones</li> <li> Social Cards \u2013 Automatically create social media previews when sharing links</li> </ul>"},{"location":"v10/setup/#content","title":"Content","text":"<p>Create a blog, integrate a comment system, connect a git repository, and set up versioned documentation that matches your project's versioning methodology.</p> <ul> <li> Blog \u2013 Set up a standalone blog or host it alongside your documentation</li> <li> Comment System \u2013 Add a third-party comment system on any page or footer</li> <li> Versioning \u2013 Deploy multiple versions by integrating with external utilities</li> <li> Repository \u2013 Connect your documentation to your git repository</li> </ul>"},{"location":"v10/setup/#optimization","title":"Optimization","text":"<p>Add site analytics and build an optimized site by adding automatic image compression, complying with GDPR data privacy regulations, and making it offline-capable.</p> <ul> <li> Site analytics \u2013 Learn how your users experience your documentation</li> <li> Optimized site \u2013 Create optimized sites that rank great on search engines</li> <li> Data Privacy \u2013 Ensure compliance with data privacy regulations</li> <li> Offline usage \u2013 Build an online and offline-capable documentation</li> </ul>"},{"location":"v10/setup/adding-a-comment-system/","title":"Adding a comment system","text":"<p>Material for MkDocs allows to easily add the third-party comment system of your choice to the footer of any page by using theme extension. As an example, we'll be integrating Giscus, which is Open Source, free, and uses GitHub discussions as a backend.</p>"},{"location":"v10/setup/adding-a-comment-system/#customization","title":"Customization","text":""},{"location":"v10/setup/adding-a-comment-system/#giscus-integration","title":"Giscus integration","text":"<p>Before you can use Giscus, you need to complete the following steps:</p> <ol> <li>Install the Giscus GitHub App and grant access to the repository     that should host comments as GitHub discussions. Note that this can be a     repository different from your documentation.</li> <li> <p>Visit Giscus and generate the snippet through their configuration tool     to load the comment system. Copy the snippet for the next step. The     resulting snippet should look similar to this:</p> <pre><code>&lt;script\nsrc=\"https://giscus.app/client.js\"\ndata-repo=\"&lt;username&gt;/&lt;repository&gt;\"\ndata-repo-id=\"...\"\ndata-category=\"...\"\ndata-category-id=\"...\"\ndata-mapping=\"pathname\"\ndata-reactions-enabled=\"1\"\ndata-emit-metadata=\"1\"\ndata-theme=\"light\"\ndata-lang=\"en\"\ncrossorigin=\"anonymous\"\nasync\n&gt;\n&lt;/script&gt;\n</code></pre> </li> </ol> <p>The <code>comments.html</code> partial (empty by default) is the best place to add the snippet generated by Giscus. Follow the guide on theme extension and override the <code>comments.html</code> partial with:</p> <pre><code>{% if page.meta.comments %}\n  &lt;h2 id=\"__comments\"&gt;{{ lang.t(\"meta.comments\") }}&lt;/h2&gt;\n&lt;!-- Insert generated snippet here --&gt;\n&lt;!-- Synchronize Giscus theme with palette --&gt;\n&lt;script&gt;\nvar giscus = document.querySelector(\"script[src*=giscus]\")\n/* Set palette on initial load */\nvar palette = __md_get(\"__palette\")\nif (palette &amp;&amp; typeof palette.color === \"object\") {\nvar theme = palette.color.scheme === \"slate\" ? \"dark\" : \"light\"\ngiscus.setAttribute(\"data-theme\", theme) // (1)!\n}\n/* Register event handlers after documented loaded */\ndocument.addEventListener(\"DOMContentLoaded\", function() {\nvar ref = document.querySelector(\"[data-md-component=palette]\")\nref.addEventListener(\"change\", function() {\nvar palette = __md_get(\"__palette\")\nif (palette &amp;&amp; typeof palette.color === \"object\") {\nvar theme = palette.color.scheme === \"slate\" ? \"dark\" : \"light\"\n/* Instruct Giscus to change theme */\nvar frame = document.querySelector(\".giscus-frame\")\nframe.contentWindow.postMessage(\n{ giscus: { setConfig: { theme } } },\n\"https://giscus.app\"\n)\n}\n})\n})\n&lt;/script&gt;\n{% endif %}\n</code></pre> <ol> <li>This code block ensures that Giscus renders with a dark theme when the     palette is set to <code>slate</code>. Note that multiple dark themes are available,     so you can change it to your liking.</li> </ol> <p>Replace the highlighted line with the snippet you generated with the Giscus configuration tool in the previous step. If you copied the snippet from above, you can enable comments on a page by setting the <code>comments</code> front matter property to <code>true</code>:</p> <pre><code>---\ncomments: true\n---\n# Document title\n...\n</code></pre> <p>If you wish to enable comments for an entire folder, you can use the built-in meta plugin.</p>"},{"location":"v10/setup/adding-a-git-repository/","title":"Adding a git repository","text":"<p>If your documentation is related to source code, Material for MkDocs provides the ability to display information to the project's repository as part of the static site, including stars and forks. Furthermore, the date of last update and creation, as well as contributors can be shown.</p>"},{"location":"v10/setup/adding-a-git-repository/#configuration","title":"Configuration","text":""},{"location":"v10/setup/adding-a-git-repository/#repository","title":"Repository","text":"<p> 0.1.0 \u00b7  Default: none</p> <p>In order to display a link to the repository of your project as part of your documentation, set <code>repo_url</code> in <code>mkdocs.yml</code> to the public URL of your repository, e.g.:</p> <pre><code>repo_url: https://github.com/squidfunk/mkdocs-material\n</code></pre> <p>The link to the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Additionally, for public repositories hosted on GitHub or GitLab, the number of stars and forks is automatically requested and rendered.</p> <p>GitHub repositories also include the tag of the latest release.1</p>"},{"location":"v10/setup/adding-a-git-repository/#repository-name","title":"Repository name","text":"<p> 0.1.0 \u00b7  Default: automatically set to <code>GitHub</code>, <code>GitLab</code> or <code>Bitbucket</code></p> <p>MkDocs will infer the source provider by examining the URL and try to set the repository name automatically. If you wish to customize the name, set <code>repo_name</code> in <code>mkdocs.yml</code>:</p> <pre><code>repo_name: squidfunk/mkdocs-material\n</code></pre>"},{"location":"v10/setup/adding-a-git-repository/#repository-icon","title":"Repository icon","text":"<p> 5.0.0 \u00b7  Default:  \u2013 <code>fontawesome/brands/git-alt</code></p> <p>While the default repository icon is a generic git icon, it can be set to any icon bundled with the theme by referencing a valid icon path in <code>mkdocs.yml</code>:</p> <pre><code>theme:\nicon:\nrepo: fontawesome/brands/git-alt # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>Some popular choices:</p> <ul> <li> \u2013 <code>fontawesome/brands/git</code></li> <li> \u2013 <code>fontawesome/brands/git-alt</code></li> <li> \u2013 <code>fontawesome/brands/github</code></li> <li> \u2013 <code>fontawesome/brands/github-alt</code></li> <li> \u2013 <code>fontawesome/brands/gitlab</code></li> <li> \u2013 <code>fontawesome/brands/gitkraken</code></li> <li> \u2013 <code>fontawesome/brands/bitbucket</code></li> <li> \u2013 <code>fontawesome/solid/trash</code></li> </ul>"},{"location":"v10/setup/adding-a-git-repository/#code-actions","title":"Code actions","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>If the repository URL points to a valid GitHub, GitLab or Bitbucket repository, MkDocs provides a setting called <code>edit_uri</code>, which resolves to the subfolder where your documentation is hosted.</p> <p>If your default branch is called <code>main</code>, change the setting to:</p> <pre><code>edit_uri: edit/main/docs/\n</code></pre> <p>After making sure that <code>edit_uri</code> is correctly configured, buttons for code actions can be added. Two types of code actions are supported: <code>edit</code> and <code>view</code> (GitHub only):</p>  Edit this page View source of this page <pre><code>theme:\nfeatures:\n- content.action.edit\n</code></pre> <pre><code>theme:\nfeatures:\n- content.action.view\n</code></pre> <p>The icon of the edit and view buttons can be changed with the following lines:</p> <pre><code>theme:\nicon:\nedit: material/pencil # (1)!\nview: material/eye\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol>"},{"location":"v10/setup/adding-a-git-repository/#revisioning","title":"Revisioning","text":"<p>The following plugins are fully integrated with Material for MkDocs, allowing for showing the date of last update and creation of a document, as well as links to all contributors or authors involved.</p>"},{"location":"v10/setup/adding-a-git-repository/#document-dates","title":"Document dates","text":"<p> 4.6.0 \u00b7  Plugin</p> <p>The git-revision-date-localized plugin adds support for adding the date of last update and creation of a document at the bottom of each page. Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-revision-date-localized-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenable_creation_date: true\n</code></pre> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenabled: !ENV [CI, false]\n</code></pre> <code>type</code> <p> Default: <code>date</code> \u2013 The format of the date to be displayed. Valid values are <code>date</code>, <code>datetime</code>, <code>iso_date</code>, <code>iso_datetime</code> and <code>timeago</code>:</p> <pre><code>plugins:\n- git-revision-date-localized:\ntype: date\n</code></pre> <code>enable_creation_date</code> <p> Default: <code>false</code> \u2013 Enables the display of the creation date of the file associated with the page next to the last updated date at the bottom of the page:</p> <pre><code>plugins:\n- git-revision-date-localized:\nenable_creation_date: true\n</code></pre> <code>fallback_to_build_date</code> <p> Default: <code>false</code> \u2013 Enables falling back to the time when <code>mkdocs build</code> was executed. Can be used as a fallback when the build is performed outside of a git repository:</p> <pre><code>plugins:\n- git-revision-date-localized:\nfallback_to_build_date: true\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"v10/setup/adding-a-git-repository/#document-contributors","title":"Document contributors","text":"<p> Sponsors only \u00b7  insiders-4.19.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The git-committers2 plugin renders the GitHub avatars of all contributors, linking to their GitHub profiles at the bottom of each page. As always, it can be installed with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-committers-plugin-2\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-committers:\nrepository: squidfunk/mkdocs-material\nbranch: main\n</code></pre> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- git-committers:\nenabled: !ENV [CI, false]\n</code></pre> <code>repository</code> <p> Default: none \u00b7  Required \u2013 This property must be set to the slug of the repository that contains your documentation. The slug must follow the pattern <code>&lt;username&gt;/&lt;repository&gt;</code>:</p> <pre><code>plugins:\n- git-committers:\nrepository: squidfunk/mkdocs-material\n</code></pre> <code>branch</code> <p> Default: <code>master</code> \u2013 This property should be set to the branch of the repository from which to retrieve the contributors. To use the <code>main</code> branch:</p> <pre><code>plugins:\n- git-committers:\nbranch: main\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"v10/setup/adding-a-git-repository/#document-authors","title":"Document authors","text":"<p> Sponsors only \u00b7  insiders-4.19.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The git-authors plugin is a lightweight alternative to the git-committers plugin and extracts the authors of a document from git to display them at the bottom of each page.</p> <p>Insiders offers deep integration for git-authors. This means the customized overrides are not necessary, and additional styling (such as nice icons) are added. Simply install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-git-authors-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- git-authors\n</code></pre> <ol> <li> <p>Unfortunately, GitHub only provides an API endpoint to obtain the latest release - not the latest tag. Thus, make sure to create a release (not  pre-release) for the latest tag you want to display next to the number of stars and forks.\u00a0\u21a9</p> </li> <li> <p>We currently recommend using a fork of the git-committers plugin, as it contains many improvements that have not yet been merged back into the original plugin. See byrnereese/mkdocs-git-committers-plugin#12 for more information.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/building-an-optimized-site/","title":"Building an optimized site","text":"<p>Material for MkDocs, by default, allows to build optimized sites that rank great on search engines, load fast (even on slow networks), and work perfectly without JavaScript. Additionally, the built-in optimize plugin adds support for further useful automatic optimization techniques.</p>"},{"location":"v10/setup/building-an-optimized-site/#configuration","title":"Configuration","text":""},{"location":"v10/setup/building-an-optimized-site/#built-in-projects-plugin","title":"Built-in projects plugin","text":"<p> Sponsors only \u00b7  insiders-4.38.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in projects plugin allows to split your documentation into multiple distinct MkDocs projects, build them concurrently and serve them together. Add the following to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- projects\n</code></pre> <p>Next, create a folder called <code>projects</code> in your root directory which will contain all projects. For example, if we want to build a project with two additional languages, we can use:</p> <pre><code>.\n\u251c\u2500 projects/\n\u2502  \u251c\u2500 de/\n\u2502  \u2502  \u251c\u2500 docs/\n\u2502  \u2502  \u2514\u2500 mkdocs.yml\n\u2502  \u2514\u2500 fr/\n\u2502     \u251c\u2500 docs/\n\u2502     \u2514\u2500 mkdocs.yml\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>If you now invoke <code>mkdocs serve</code> and change a file in one of the projects, the projects plugin makes sure that MkDocs will also reload those files. Note that the projects are currently entirely separate, which means they will have separate search indexes and sitemaps. We're happy to receive feedback on this plugin and learn about your requirements to make it better, as we plan to add support for merging and hoisting files. Create a discussion to share your thoughts!</p> Use cases for the projects plugin <p>Ideal use cases for the projects plugin are:</p> <ul> <li>Building a multi-language site</li> <li>Building a blog alongside your documentation</li> <li>Splitting large code bases for better performance</li> </ul> <p>Note that the plugin is currently experimental. We're releasing it early, so that we can improve it together with our users and make it even more powerful as we discover new use cases.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- projects:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when building projects. With more CPUs, the plugin can do more work in the same time, thus complete optimization faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- projects:\nconcurrency: 1\n</code></pre>"},{"location":"v10/setup/building-an-optimized-site/#projects","title":"Projects","text":"<p>The following configuration options are available for projects:</p> <code>projects</code> <p> Default: <code>true</code> \u2013 This option specifies whether to build nested projects. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable:</p> <pre><code>plugins:\n- projects:\nprojects: !ENV [CI, false]\n</code></pre> <code>projects_dir</code> <p> Default: <code>projects</code> \u2013 This option specifies the name of the folder the plugin expects your projects to be stored. While it's usually not necessary to change this option, change it with:</p> <pre><code>plugins:\n- projects:\nprojects_dir: path/to/folder\n</code></pre>"},{"location":"v10/setup/building-an-optimized-site/#built-in-optimize-plugin","title":"Built-in optimize plugin","text":"<p> Sponsors only \u00b7  insiders-4.29.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in optimize plugin automatically identifies and optimizes all media files as part of the build using compression and conversion techniques. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- optimize # (1)!\n</code></pre> <ol> <li>Please ensure that all dependencies for image processing are installed,     or the plugin will not work properly.</li> </ol> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- optimize:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when optimizing media files. With more CPUs, the plugin can do more work in the same time, thus complete optimization faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- optimize:\nconcurrency: 1\n</code></pre>"},{"location":"v10/setup/building-an-optimized-site/#optimization","title":"Optimization","text":"<p>Technical documentation often includes screenshots or diagrams, both of which are prime candidates for compression. The built-in optimize plugin allows to automatically compress images using pngquant (for PNGs), and Pillow (for JPGs).</p> <p>The following configuration options are available for optimization:</p> <code>optimize_png</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should optimize PNG files using pngquant, which must be installed on the system. PNG optimization can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_png: false\n</code></pre> <code>optimize_png_speed</code> <p> Default: <code>4</code> of <code>[1,10]</code> \u2013 This option specifies the speed/quality tradeoff that pngquant applies when compressing. The lower the number, the more time will be spent optimizing:</p> Slower smallFaster rough <pre><code>plugins:\n- optimize:\noptimize_png_speed: 1\n</code></pre> <pre><code>plugins:\n- optimize:\noptimize_png_speed: 10\n</code></pre> <p>A factor of <code>10</code> has 5% lower quality, but is 8x faster than the default <code>4</code>.</p> <code>optimize_png_strip</code> <p> Default: <code>true</code> \u2013 This option specifies whether pngquant should remove all non-optional metadata that is not necessary for rendering images in a browser:</p> <pre><code>plugins:\n- optimize:\noptimize_png_strip: false\n</code></pre> <code>optimize_jpg</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should optimize JPG files using Pillow, a Python image processing library. JPG optimization can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg: false\n</code></pre> <code>optimize_jpg_quality</code> <p> Default: <code>60</code> of <code>[0,100]</code> \u2013 This option specifies the image quality that Pillow uses when compressing. If the images look blurry, it's a good idea to tune and change this setting:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg_quality: 75\n</code></pre> <code>optimize_jpg_progressive</code> <p> Default: <code>true</code> \u2013 This option specifies whether Pillow should use progressive encoding (faster rendering) when compressing JPGs. Progressive encoding can be disabled with:</p> <pre><code>plugins:\n- optimize:\noptimize_jpg_progressive: false\n</code></pre>"},{"location":"v10/setup/building-an-optimized-site/#caching","title":"Caching","text":"<p>The built-in optimize plugin implements an intelligent caching mechanism, ensuring that media files are only pushed through the optimization pipeline when their contents change. If you swap out or update an image, the plugin will detect it and update the optimized version.</p> <p>The following configuration options are available for caching:</p> <code>cache</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin queries its cache for an existing artifact before starting an optimization job. It's normally not necessary to change this setting, except for when debugging the plugin itself. Caching can be disabled with:</p> <pre><code>plugins:\n- optimize:\ncache: false\n</code></pre> <code>cache_dir</code> <p> Default: <code>.cache/plugins/optimize</code> \u2013 This option specifies the file system location of the plugin's cache. It's normally not necessary to change this setting, except for when debugging the plugin itself. The cache directory can be changed with:</p> <pre><code>plugins:\n- optimize:\ncache_dir: .cache/plugins/optimize\n</code></pre> <p>By default, all built-in plugins that implement caching will create a <code>.cache</code> directory in the same folder your <code>mkdocs.yml</code> resides, and create subfolders to not interfere with each other. If you use multiple instances of this plugin, it could be necessary to change this setting.</p>"},{"location":"v10/setup/building-for-offline-usage/","title":"Building for offline usage","text":"<p>If you want to ship your documentation together with your product, MkDocs has you covered \u2013 with support from themes, MkDocs allows for building offline-capable documentation. Notably, Material for MkDocs offers offline support for many of its features.</p>"},{"location":"v10/setup/building-for-offline-usage/#configuration","title":"Configuration","text":""},{"location":"v10/setup/building-for-offline-usage/#built-in-offline-plugin","title":"Built-in offline plugin","text":"<p> 9.0.0 \u00b7  Plugin</p> <p>The built-in offline plugin makes sure that the site search works when you distribute the contents of your site directory as a download. Simply add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- offline\n</code></pre> <p>The plugin will automatically disable the <code>use_directory_urls</code> setting, ensuring that users can open your documentation directly from the local file system.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable:</p> <pre><code>plugins:\n- offline:\nenabled: !ENV [OFFLINE, false]\n</code></pre> <p>Now, after invoking <code>mkdocs build</code>, you can open <code>site/index.html</code> directly in your browser and the site search will work as if the documentation was hosted on a regular server.</p> <p>Automatically bundle all external assets</p> <p>The built-in privacy plugin makes it easy to use external assets while building documentation for offline usage, as it will automatically download all external assets to distribute them with your documentation.</p>"},{"location":"v10/setup/building-for-offline-usage/#limitations","title":"Limitations","text":"<p>Material for MkDocs offers many interactive features, some of which will not work from the file system due to the restrictions of modern browsers: all features that use the <code>fetch</code> API will error.</p> <p>Thus, when building for offline usage, make sure to disable the following configuration settings: instant loading, site analytics, git repository, versioning and comment systems.</p>"},{"location":"v10/setup/changing-the-colors/","title":"Changing the colors","text":"<p>As any proper Material Design implementation, Material for MkDocs supports Google's original color palette, which can be easily configured through  <code>mkdocs.yml</code>. Furthermore, colors can be customized with a few lines of CSS to fit your brand's identity by using CSS variables.</p>"},{"location":"v10/setup/changing-the-colors/#configuration","title":"Configuration","text":""},{"location":"v10/setup/changing-the-colors/#color-palette","title":"Color palette","text":""},{"location":"v10/setup/changing-the-colors/#color-scheme","title":"Color scheme","text":"<p> 5.2.0 \u00b7  Default: <code>default</code></p> <p>Material for MkDocs supports two color schemes: a light mode, which is just called <code>default</code>, and a dark mode, which is called <code>slate</code>. The color scheme can be set via <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\nscheme: default\n</code></pre> <p>Click on a tile to change the color scheme:</p> <code>default</code> <code>slate</code>"},{"location":"v10/setup/changing-the-colors/#primary-color","title":"Primary color","text":"<p> 0.2.0 \u00b7  Default: <code>indigo</code></p> <p>The primary color is used for the header, the sidebar, text links and several other components. In order to change the primary color, set the following value in <code>mkdocs.yml</code> to a valid color name:</p> <pre><code>theme:\npalette:\nprimary: indigo\n</code></pre> <p>Click on a tile to change the primary color:</p> <code>red</code> <code>pink</code> <code>purple</code> <code>deep purple</code> <code>indigo</code> <code>blue</code> <code>light blue</code> <code>cyan</code> <code>teal</code> <code>green</code> <code>light green</code> <code>lime</code> <code>yellow</code> <code>amber</code> <code>orange</code> <code>deep orange</code> <code>brown</code> <code>grey</code> <code>blue grey</code> <code>black</code> <code>white</code>    var buttons = document.querySelectorAll(\"button[data-md-color-primary]\")   buttons.forEach(function(button) {     button.addEventListener(\"click\", function() {       var attr = this.getAttribute(\"data-md-color-primary\")       document.body.setAttribute(\"data-md-color-primary\", attr)       var name = document.querySelector(\"#__code_1 code span.l\")       name.textContent = attr.replace(\"-\", \" \")     })   })  <p>See our guide below to learn how to set custom colors.</p>"},{"location":"v10/setup/changing-the-colors/#accent-color","title":"Accent color","text":"<p> 0.2.0 \u00b7  Default: <code>indigo</code></p> <p>The accent color is used to denote elements that can be interacted with, e.g. hovered links, buttons and scrollbars. It can be changed in <code>mkdocs.yml</code> by choosing a valid color name:</p> <pre><code>theme:\npalette:\naccent: indigo\n</code></pre> <p>Click on a tile to change the accent color:</p> <code>red</code> <code>pink</code> <code>purple</code> <code>deep purple</code> <code>indigo</code> <code>blue</code> <code>light blue</code> <code>cyan</code> <code>teal</code> <code>green</code> <code>light green</code> <code>lime</code> <code>yellow</code> <code>amber</code> <code>orange</code> <code>deep orange</code>    var buttons = document.querySelectorAll(\"button[data-md-color-accent]\")   buttons.forEach(function(button) {     button.addEventListener(\"click\", function() {       var attr = this.getAttribute(\"data-md-color-accent\")       document.body.setAttribute(\"data-md-color-accent\", attr)       var name = document.querySelector(\"#__code_2 code span.l\")       name.textContent = attr.replace(\"-\", \" \")     })   })  <p>See our guide below to learn how to set custom colors.</p>"},{"location":"v10/setup/changing-the-colors/#color-palette-toggle","title":"Color palette toggle","text":"<p> 7.1.0 \u00b7  Default: none</p> <p>Offering a light and dark color palette makes your documentation pleasant to read at different times of the day, so the user can choose accordingly. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette: # (1)!\n# Palette toggle for light mode\n- scheme: default\ntoggle:\nicon: material/brightness-7 # (2)!\nname: Switch to dark mode\n# Palette toggle for dark mode\n- scheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to light mode\n</code></pre> <ol> <li> <p>Note that the <code>theme.palette</code> setting is now defined as a list.</p> </li> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>This configuration will render a color palette toggle next to the search bar. Note that you can also define separate settings for <code>primary</code> and <code>accent</code> per color palette.</p> <p>The following properties must be set for each toggle:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations:</p> <ul> <li> +  \u2013 <code>material/brightness-7</code> + <code>material/brightness-4</code></li> <li> +  \u2013 <code>material/toggle-switch</code> + <code>material/toggle-switch-off-outline</code></li> <li> +  \u2013 <code>material/weather-night</code> + <code>material/weather-sunny</code></li> <li> +  \u2013 <code>material/eye</code> + <code>material/eye-outline</code></li> <li> +  \u2013 <code>material/lightbulb</code> + <code>material/lightbulb-outline</code></li> </ul> <code>name</code> <p> Default: none \u00b7  Required \u2013 This property is used as the toggle's <code>title</code> attribute and should be set to a discernable name to improve accessibility. It's rendered as a tooltip.</p>"},{"location":"v10/setup/changing-the-colors/#system-preference","title":"System preference","text":"<p> 7.1.0 \u00b7  Default: none</p> <p>Each color palette can be linked to the user's system preference for light and dark appearance by using a media query. Simply add a <code>media</code> property next to the <code>scheme</code> definition in <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\n# Palette toggle for light mode\n- media: \"(prefers-color-scheme: light)\"\nscheme: default\ntoggle:\nicon: material/brightness-7\nname: Switch to dark mode\n# Palette toggle for dark mode\n- media: \"(prefers-color-scheme: dark)\"\nscheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to light mode\n</code></pre> <p>When the user first visits your site, the media queries are evaluated in the order of their definition. The first media query that matches selects the default color palette.</p>"},{"location":"v10/setup/changing-the-colors/#automatic-light-dark-mode","title":"Automatic light / dark mode","text":"<p> Sponsors only \u00b7  insiders-4.18.0 \u00b7  Experimental</p> <p>Newer operating system allow to automatically switch between light and dark appearance during day and night times. Insiders adds support for automatic light / dark mode, delegating color palette selection to the user's operating system. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\npalette:\n# Palette toggle for automatic mode\n- media: \"(prefers-color-scheme)\"\ntoggle:\nicon: material/brightness-auto\nname: Switch to light mode\n# Palette toggle for light mode\n- media: \"(prefers-color-scheme: light)\"\nscheme: default # (1)!\ntoggle:\nicon: material/brightness-7\nname: Switch to dark mode\n# Palette toggle for dark mode\n- media: \"(prefers-color-scheme: dark)\"\nscheme: slate\ntoggle:\nicon: material/brightness-4\nname: Switch to system preference\n</code></pre> <ol> <li>You can also define separate settings for <code>primary</code> and     <code>accent</code> per color palette, i.e. different colors for     light and dark mode.</li> </ol> <p>Material for MkDocs will now change the color palette each time the operating system switches between light and dark appearance, even when the user doesn't reload the site.</p>"},{"location":"v10/setup/changing-the-colors/#customization","title":"Customization","text":""},{"location":"v10/setup/changing-the-colors/#custom-colors","title":"Custom colors","text":"<p>Material for MkDocs implements colors using CSS variables (custom properties). If you want to customize the colors beyond the palette (e.g. to use your brand-specific colors), you can add an additional style sheet and tweak the values of the CSS variables.</p> <p>First, set the <code>primary</code> or <code>accent</code> values in <code>mkdocs.yml</code> to <code>custom</code>, to signal to the theme that you want to define custom colors, e.g., when you want to override the <code>primary</code> color:</p> <pre><code>theme:\npalette:\nprimary: custom\n</code></pre> <p>Let's say you're  YouTube, and want to set the primary color to your brand's palette. Just add:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>:root {\n--md-primary-fg-color:        #EE0F0F;\n--md-primary-fg-color--light: #ECB7B7;\n--md-primary-fg-color--dark:  #90030C;\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>See the file containing the color definitions for a list of all CSS variables.</p>"},{"location":"v10/setup/changing-the-colors/#custom-color-schemes","title":"Custom color schemes","text":"<p>Besides overriding specific colors, you can create your own, named color scheme by wrapping the definitions in a <code>[data-md-color-scheme=\"...\"]</code> attribute selector, which you can then set via <code>mkdocs.yml</code> as described in the color schemes section:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>[data-md-color-scheme=\"youtube\"] {\n--md-primary-fg-color:        #EE0F0F;\n--md-primary-fg-color--light: #ECB7B7;\n--md-primary-fg-color--dark:  #90030C;\n}\n</code></pre> <pre><code>theme:\npalette:\nscheme: youtube\nextra_css:\n- stylesheets/extra.css\n</code></pre> <p>Additionally, the <code>slate</code> color scheme defines all of it's colors via <code>hsla</code> color functions and deduces its colors from the <code>--md-hue</code> CSS variable. You can tune the <code>slate</code> theme with:</p> <pre><code>[data-md-color-scheme=\"slate\"] {\n--md-hue: 210; /* (1)! */\n}\n</code></pre> <ol> <li>The <code>hue</code> value must be in the range of <code>[0, 360]</code></li> </ol>"},{"location":"v10/setup/changing-the-fonts/","title":"Changing the fonts","text":"<p>Material for MkDocs makes it easy to change the typeface of your project documentation, as it directly integrates with Google Fonts. Alternatively, fonts can be custom-loaded if self-hosting is preferred for data privacy reasons or another destination should be used.</p>"},{"location":"v10/setup/changing-the-fonts/#configuration","title":"Configuration","text":""},{"location":"v10/setup/changing-the-fonts/#regular-font","title":"Regular font","text":"<p> 0.1.2 \u00b7  Default: <code>Roboto</code></p> <p>The regular font is used for all body copy, headlines, and essentially everything that does not need to be monospaced. It can be set to any valid Google Font via <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont:\ntext: Roboto\n</code></pre> <p>The typeface will be loaded in 300, 400, 400i and 700.</p>"},{"location":"v10/setup/changing-the-fonts/#monospaced-font","title":"Monospaced font","text":"<p> 0.1.2 \u00b7  Default: <code>Roboto Mono</code></p> <p>The monospaced font is used for code blocks and can be configured separately. Just like the regular font, it can be set to any valid Google Font via <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont:\ncode: Roboto Mono\n</code></pre> <p>The typeface will be loaded in 400.</p>"},{"location":"v10/setup/changing-the-fonts/#autoloading","title":"Autoloading","text":"<p> 1.0.0 \u00b7  Default: none</p> <p>If you want to prevent typefaces from being loaded from Google Fonts, e.g. to adhere to data privacy regulations, and fall back to system fonts, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfont: false\n</code></pre> <p>Automatically bundle Google Fonts</p> <p>The built-in privacy plugin makes it easy to use Google Fonts while complying with the General Data Protection Regulation (GDPR), by automatically downloading and self-hosting the web font files.</p>"},{"location":"v10/setup/changing-the-fonts/#customization","title":"Customization","text":""},{"location":"v10/setup/changing-the-fonts/#additional-fonts","title":"Additional fonts","text":"<p>If you want to load an (additional) font from another destination or override the system font, you can use an additional style sheet to add the corresponding <code>@font-face</code> definition:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>@font-face {\nfont-family: \"&lt;font&gt;\";\nsrc: \"...\";\n}\n</code></pre> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <p>The font can then be applied to specific elements, e.g. only headlines, or  globally to be used as the site-wide regular or monospaced font:</p> Regular fontMonospaced font <pre><code>:root {\n--md-text-font: \"&lt;font&gt;\"; /* (1)! */\n}\n</code></pre> <ol> <li>Always define fonts through CSS variables and not <code>font-family</code>, as     this would disable the system font fallback.</li> </ol> <pre><code>:root {\n--md-code-font: \"&lt;font&gt;\";\n}\n</code></pre>"},{"location":"v10/setup/changing-the-language/","title":"Changing the language","text":"<p>Material for MkDocs supports internationalization (i18n) and provides translations for template variables and labels in 60+ languages. Additionally, the site search can be configured to use a language-specific stemmer, if available.</p>"},{"location":"v10/setup/changing-the-language/#configuration","title":"Configuration","text":""},{"location":"v10/setup/changing-the-language/#site-language","title":"Site language","text":"<p> 1.12.0 \u00b7  Default: <code>en</code></p> <p>You can set the site language in <code>mkdocs.yml</code> with:</p> <pre><code>theme:\nlanguage: en # (1)!\n</code></pre> <ol> <li> <p>HTML5 only allows to set a single language per document, which is why     Material for MkDocs only supports setting a canonical language for the     entire project, i.e. one per <code>mkdocs.yml</code>.</p> <p>The easiest way to build a multi-language documentation is to create one project in a subfolder per language, and then use the language selector to interlink those projects.</p> </li> </ol> <p>The following languages are supported:</p> <p>Note that some languages will produce unreadable anchor links due to the way the default slug function works. Consider using a Unicode-aware slug function.</p> <p>Translations missing? Help us out, it takes only 5 minutes</p> <p>Material for MkDocs relies on outside contributions for adding and updating translations for the almost 60 languages it supports. If your language shows that some translations are missing, click on the link to add them. If your language is not in the list, click here to add a new language.</p>"},{"location":"v10/setup/changing-the-language/#site-language-selector","title":"Site language selector","text":"<p> 7.0.0 \u00b7  Default: none</p> <p>If your documentation is available in multiple languages, a language selector pointing to those languages can be added to the header. Alternate languages can be defined via <code>mkdocs.yml</code>.</p> <pre><code>extra:\nalternate:\n- name: English\nlink: /en/ # (1)!\nlang: en\n- name: Deutsch\nlink: /de/\nlang: de\n</code></pre> <ol> <li>Note that this must be an absolute link. If it includes a domain part, it's     used as defined. Otherwise the domain part of the <code>site_url</code> as     set in <code>mkdocs.yml</code> is prepended to the link.</li> </ol> <p>The following properties are available for each alternate language:</p> <code>name</code> <p> Default: none \u00b7  Required \u2013 This value of this property is used inside the language selector as the name of the language and must be set to a non-empty string.</p> <code>link</code> <p> Default: none \u00b7  Required \u2013 This property must be set to an absolute link, which might also point to another domain or subdomain not necessarily generated with MkDocs.</p> <code>lang</code> <p> Default: none \u00b7  Required \u2013 This property must contain an ISO 639-1 language code and is used for the <code>hreflang</code> attribute of the link, improving discoverability via search engines.</p> <p></p>"},{"location":"v10/setup/changing-the-language/#directionality","title":"Directionality","text":"<p> 2.5.0 \u00b7  Default: automatically set</p> <p>While many languages are read <code>ltr</code> (left-to-right), Material for MkDocs also supports <code>rtl</code> (right-to-left) directionality which is deduced from the selected language, but can also be set with:</p> <pre><code>theme:\ndirection: ltr\n</code></pre> <p>Click on a tile to change the directionality:</p> <code>ltr</code> <code>rtl</code>"},{"location":"v10/setup/changing-the-language/#customization","title":"Customization","text":""},{"location":"v10/setup/changing-the-language/#custom-translations","title":"Custom translations","text":"<p>If you want to customize some of the translations for a language, just follow the guide on theme extension and create a new partial in the <code>overrides</code> folder. Then, import the translations of the language as a fallback and only adjust the ones you want to override:</p> <code>overrides/partials/languages/custom.html</code> <code>mkdocs.yml</code> <pre><code>&lt;!-- Import translations for language and fallback --&gt;\n{% import \"partials/languages/de.html\" as language %}\n{% import \"partials/languages/en.html\" as fallback %} &lt;!-- (1)! --&gt;\n&lt;!-- Define custom translations --&gt;\n{% macro override(key) %}{{ {\n  \"source.file.date.created\": \"Erstellt am\", &lt;!-- (2)! --&gt;\n  \"source.file.date.updated\": \"Aktualisiert am\"\n}[key] }}{% endmacro %}\n\n&lt;!-- Re-export translations --&gt;\n{% macro t(key) %}{{\n  override(key) or language.t(key) or fallback.t(key)\n}}{% endmacro %}\n</code></pre> <ol> <li> <p>Note that <code>en</code> must always be used as a fallback language, as it's the     default theme language.</p> </li> <li> <p>Check the list of available languages, pick the translation you want     to override for your language and add them here.</p> </li> </ol> <pre><code>theme:\nlanguage: custom\n</code></pre>"},{"location":"v10/setup/changing-the-logo-and-icons/","title":"Changing the logo and icons","text":"<p>When installing Material for MkDocs, you immediately get access to over 8,000  icons ready to be used for customization of specific parts of the theme and/or  when writing your documentation in Markdown. Not enough? You can also add additional icons with minimal effort.</p>"},{"location":"v10/setup/changing-the-logo-and-icons/#configuration","title":"Configuration","text":""},{"location":"v10/setup/changing-the-logo-and-icons/#logo","title":"Logo","text":"<p> 0.1.0 \u00b7  Default:  \u2013 <code>material/library</code></p> <p>The logo can be changed to a user-provided image (any type, incl. <code>*.png</code> and <code>*.svg</code>) located in the <code>docs</code> folder, or to any icon bundled with the theme. Add the following lines to <code>mkdocs.yml</code>:</p>  Image Icon, bundled <pre><code>theme:\nlogo: assets/logo.png\n</code></pre> <pre><code>theme:\nicon:\nlogo: material/library # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>Normally, the logo in the header and sidebar links to the homepage of the documentation, which is the same as <code>site_url</code>. This behavior can be changed with the following configuration:</p> <pre><code>extra:\nhomepage: https://example.com\n</code></pre>"},{"location":"v10/setup/changing-the-logo-and-icons/#favicon","title":"Favicon","text":"<p> 0.1.0 \u00b7  Default: <code>assets/images/favicon.png</code></p> <p>The favicon can be changed to a path pointing to a user-provided image, which  must be located in the <code>docs</code> folder. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfavicon: images/favicon.png\n</code></pre>"},{"location":"v10/setup/changing-the-logo-and-icons/#customization","title":"Customization","text":""},{"location":"v10/setup/changing-the-logo-and-icons/#additional-icons","title":"Additional icons","text":"<p>In order to use custom icons, extend the theme and create a new folder named <code>.icons</code> in the <code>custom_dir</code> you want to use for overrides. Next, add your <code>*.svg</code> icons into a subfolder of the <code>.icons</code> folder. Let's say you downloaded and unpacked the Bootstrap icon set, and want to add it to your project documentation. The structure of your project should look like this:</p> <pre><code>.\n\u251c\u2500 overrides/\n\u2502  \u2514\u2500 .icons/\n\u2502     \u2514\u2500 bootstrap/\n\u2502        \u2514\u2500 *.svg\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\noptions:\ncustom_icons:\n- overrides/.icons\n</code></pre> <p>You can now use all  Bootstrap icons anywhere in Markdown files, as well as everywhere icons can be used in <code>mkdocs.yml</code>. However, note that the syntaxes are slightly different:</p> <ul> <li> <p>Using icons in configuration: take the path of the <code>*.svg</code> icon file   starting at the <code>.icons</code> folder and drop the file extension, e.g. for   <code>.icons/bootstrap/envelope-paper.svg</code>, use:</p> <pre><code>theme:\nicon:\nlogo: bootstrap/envelope-paper\n</code></pre> </li> <li> <p>Using icons in Markdown files: additionally to taking the path from the   <code>.icons</code> folder as noted above, replace all <code>/</code> with <code>-</code> and enclose the icon   shortcode in two colons:</p> <pre><code>:bootstrap-envelope-paper:\n</code></pre> </li> </ul> <p>For further notes on icon usage, please consult the icon reference.</p>"},{"location":"v10/setup/ensuring-data-privacy/","title":"Ensuring data privacy","text":"<p>Material for MkDocs makes compliance with data privacy regulations very easy,  as it offers a native cookie consent solution to seek explicit consent from users before setting up analytics. Additionally, external assets can be automatically downloaded for self-hosting.</p>"},{"location":"v10/setup/ensuring-data-privacy/#configuration","title":"Configuration","text":""},{"location":"v10/setup/ensuring-data-privacy/#cookie-consent","title":"Cookie consent","text":"<p> 8.4.0 \u00b7  Default: none \u00b7  Experimental</p> <p>Material for MkDocs ships a native and extensible cookie consent form which asks the user for consent prior to sending requests to third parties. Add the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nconsent:\ntitle: Cookie consent\ndescription: &gt;- # (1)!\nWe use cookies to recognize your repeated visits and preferences, as well\nas to measure the effectiveness of our documentation and whether users\nfind what they're searching for. With your consent, you're helping us to\nmake our documentation better.\n</code></pre> <ol> <li>You can add arbitrary HTML tags in the <code>description</code>, e.g. to link to your     terms of service or other parts of the site.</li> </ol> <p>The following properties are available:</p> <code>title</code> <p> Default: none \u00b7  Required \u2013 This property sets the title of the cookie consent, which is rendered at the  top of the form and must be set to a non-empty string.</p> <code>description</code> <p> Default: none \u00b7  Required \u2013 This property sets the description of the cookie consent, is rendered below the title, and may include raw HTML (e.g. a links to the terms of service).</p> <code>cookies</code> <p> Default: none \u2013 This property allows to add custom  cookies or change the initial <code>checked</code> state and name of built-in cookies. Currently, the following cookies are built-in:</p> <ul> <li>Google Analytics \u2013 <code>analytics</code> (enabled by default)</li> <li>GitHub \u2013 <code>github</code> (enabled by default)</li> </ul> <p>Each cookie must receive a unique identifier which is used as a key in the <code>cookies</code> map, and can be either set to a string, or to a map defining <code>name</code> and <code>checked</code> state:</p> Custom cookie nameCustom initial stateCustom cookie <pre><code>extra:\nconsent:\ncookies:\nanalytics: Custom name\n</code></pre> <pre><code>extra:\nconsent:\ncookies:\nanalytics:\nname: Google Analytics\nchecked: false\n</code></pre> <pre><code>extra:\nconsent:\ncookies:\nanalytics: Google Analytics # (1)!\ncustom: Custom cookie\n</code></pre> <ol> <li>If you define a custom cookie as part of the <code>cookies</code> property,     the <code>analytics</code> cookie must be added back explicitly, or analytics     won't be triggered.</li> </ol> <p>If Google Analytics was configured via <code>mkdocs.yml</code>, the cookie consent will automatically include a setting for the user to disable it. Custom cookies can be used from JavaScript.</p> <code>actions</code> <p> Default: <code>[accept, manage]</code> \u2013 This property defines which buttons are shown and in which order, e.g. to allow the user to accept  cookies and manage settings:</p> <pre><code>extra:\nconsent:\nactions:\n- accept\n- manage # (1)!\n</code></pre> <ol> <li>If the <code>manage</code> settings button is omitted from the <code>actions</code> property,     the settings are always shown.</li> </ol> <p>The cookie consent form includes three types of buttons:</p> <ul> <li><code>accept</code> \u2013 Button to accept selected cookies</li> <li><code>reject</code> \u2013 Button to reject all cookies</li> <li><code>manage</code> \u2013 Button to manage settings</li> </ul> <p>When a user first visits your site, a cookie consent form is rendered:</p> <p></p>"},{"location":"v10/setup/ensuring-data-privacy/#change-cookie-settings","title":"Change cookie settings","text":"<p>In order to comply with GDPR, users must be able to change their cookie settings at any time. This can be done by adding a simple link to your copyright notice  in <code>mkdocs.yml</code>:</p> <pre><code>copyright: &gt;\nCopyright &amp;copy; 2016 - 2023 Martin Donath \u2013\n&lt;a href=\"#__consent\"&gt;Change cookie settings&lt;/a&gt;\n</code></pre>"},{"location":"v10/setup/ensuring-data-privacy/#built-in-privacy-plugin","title":"Built-in privacy plugin","text":"<p> Sponsors only \u00b7  insiders-4.9.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in privacy plugin automatically identifies external assets as part of the build process and downloads all assets for very simple self-hosting. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- privacy\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- privacy:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> Default: number of CPUs \u2013 This option specifies how many CPUs the plugin is allowed to use when downloading external assets. With more CPUs, the plugin can do more work in the same time, thus complete its work faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- privacy:\nconcurrency: 1\n</code></pre>"},{"location":"v10/setup/ensuring-data-privacy/#external-assets","title":"External assets","text":"<p>The following configuration options are available for external assets:</p> <code>assets</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should scan the HTML output to detect and process external assets:</p> <pre><code>plugins:\n- privacy:\nassets: true\n</code></pre> <p>If you've removed all external assets from your project via customization, it's still a good idea to enable the plugin, as the plugin will make sure that there are no hidden external links in any Markdown files that were  unintentionally added.</p> <p>Using <code>assets</code> in strict mode will make the build fail when external assets are detected.</p> <code>assets_fetch</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should download external assets it encountered and bundle them with your documentation:</p> <pre><code>plugins:\n- privacy:\nassets_fetch: true\n</code></pre> <code>assets_fetch_dir</code> <p> Default: <code>assets/external</code> \u2013 This option specifies where the downloaded external assets will be stored. It's normally not necessary to change this option:</p> <pre><code>plugins:\n- privacy:\nassets_fetch_dir: assets/external\n</code></pre> <p>The path must be defined relative to <code>docs_dir</code>.</p> <code>assets_include</code> <p> Default: none \u2013 This option allows to only include certain external assets for processing by the privacy plugin, so they will be downloaded and bundled during the build:</p> <pre><code>plugins:\n- privacy:\nassets_include:\n- unsplash.com/*\n</code></pre> <p>Hosting images externally and optimizing them automatically</p> <p>This option makes the built-in privacy plugin an excellent choice for when you want to host assets like images outside of your git repository in another location to keep them fresh and your repository lean.</p> <p>Additionally, as of  insiders-4.30.0, the built-in privacy plugin was entirely rewritten and now works perfectly with the built-in optimize plugin, which means that external assets can be passed through the same optimization pipeline as the rest of your documentation. This means you can store and edit unoptimized files outside of your repository, and let both plugins built a highly optimized site for you.</p> <p>If you want to implement separate pipelines, i.e., optimize some images differently from others or exclude some images from downloading, you can use multiple instances of the built-in privacy plugin.</p> <code>assets_exclude</code> <p> Default: none \u2013 This option allows to exclude certain external assets from processing by the privacy plugin, so they will not be downloaded and bundled during the build:</p> <pre><code>plugins:\n- privacy:\nassets_exclude: # (1)!\n- cdn.jsdelivr.net/npm/mathjax@3/* - giscus.app/*\n</code></pre> <ol> <li> <p>MathJax loads web fonts for typesetting of mathematical content     through relative URLs, and thus cannot be automatically bundled by the     privacy plugin. MathJax can be self-hosted.</p> <p>Giscus, which we recommend to use as a comment system, uses a technique called code-splitting to load only the code that is necessary, which is implemented via relative URLs. Giscus can be self-hosted as well.</p> </li> </ol> <p>Excluding specific external assets can be necessary if they contain dynamically created or relative URLs, which can't be resolved by the privacy plugin due to technical limitations.</p> <p>Why can't Material for MkDocs bundle all assets by design?</p> <p>The primary reason why Material for MkDocs can't just bundle all of its own assets is the integration with Google Fonts, which offers over a thousand different fonts that can be used to render your documentation. Most of the fonts include several weights and are split up into different character sets  to keep the download size small, so the browser only downloads what is really needed. For Roboto, our default regular font, this results in 42 <code>*.woff2</code> files in total.</p> <p>If Material for MkDocs would bundle all font files, the download size would be in the hundreds of megabytes, slowing down automated builds. Furthermore,  authors might add external assets like third-party scripts or style sheets  that would need to be remembered to be defined as further local assets.</p> <p>This is the very reason the built-in privacy plugin exists \u2014 it automates the process of downloading all external assets manually to ensure compliance with GDPR with some some technical limitations.</p>"},{"location":"v10/setup/ensuring-data-privacy/#external-links","title":"External links","text":"<p> Sponsors only \u00b7  insiders-4.26.0 \u00b7  Experimental</p> <p>The following configuration options are available for external links:</p> <code>links</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should parse and process external links. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- privacy:\nlinks: !ENV [CI, false]\n</code></pre> <code>links_attr_map</code> <p> Default: None \u2013 This option specifies custom attributes that should be added to external links, like for example <code>target=\"_blank\"</code> so all external links open in a new window:</p> <pre><code>plugins:\n- privacy:\nlinks_attr_map:\ntarget: _blank\n</code></pre> <code>links_noopener</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin should automatically add <code>rel=\"noopener\"</code> to all links with <code>target=\"_blank\"</code> for security reasons:</p> <pre><code>plugins:\n- privacy:\nlinks_noopener: true\n</code></pre>"},{"location":"v10/setup/ensuring-data-privacy/#how-it-works","title":"How it works","text":"<p>The built-in privacy plugin scans the resulting HTML for links to external resources, including external scripts, style sheets, images and web fonts, and downloads them to bundle them with your documentation site. Every URL referring to an external resource, no matter if part of a template or Markdown file, is then replaced with the URL to the local copy. An example:</p> <pre><code>&lt;script src=\"https://example.com/script.js\"&gt;&lt;/script&gt;\n</code></pre> <p>The external script is downloaded, and the link is replaced with:</p> <pre><code>&lt;script src=\"assets/external/example.com/script.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Style sheets are scanned for external <code>url(...)</code> references, e.g. images and web fonts, which are then also downloaded and bundled with your documentation site. This means that Google Fonts can be configured in <code>mkdocs.yml</code> as usual, as the built-in privacy plugin automatically downloads and bundles all dependent resources.</p> <p>As a third measure, <code>preconnect</code> hints used for DNS pre-fetching which might also leak the visitors IP address to a third party are automatically removed during the build process.</p> Expand to inspect example <p>For the official documentation, the built-in privacy plugin downloads the following resources:</p> <pre><code>.\n\u2514\u2500 assets/external/\n   \u251c\u2500 unpkg.com/tablesort@5.3.0/dist/tablesort.min.js\n   \u251c\u2500 fonts.googleapis.com/css\n   \u251c\u2500 fonts.gstatic.com/s/\n   \u2502  \u251c\u2500 roboto/v29/\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc-CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc0CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc1CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc2CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc3CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc5CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc6CsQ.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic-CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic0CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic1CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic2CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic3CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic5CsTKlA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic6CsQ.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xEIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xFIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xGIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xHIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xIIzI.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xLIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOkCnqEu92Fr1Mu51xMIzIFKw.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fABc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBBc4.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCRc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfABc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBBc4.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCBc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCRc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfChc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCxc4EsA.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu4WxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu4mxK.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu5mxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu72xKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu7GxKOzY.woff2\n   \u2502  \u2502  \u251c\u2500 KFOmCnqEu92Fr1Mu7WxKOzY.woff2\n   \u2502  \u2502  \u2514\u2500 KFOmCnqEu92Fr1Mu7mxKOzY.woff2\n   \u2502  \u2514\u2500 robotomono/v13/\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSV0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSZ0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSd0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSh0mQ.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSt0mf0h.woff2\n   \u2502     \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSx0mf0h.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtElOUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEleUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEluUlYIw.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEm-Ul.woff2\n   \u2502     \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEmOUlYIw.woff2\n   \u2502     \u2514\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEn-UlYIw.woff2\n   \u2514\u2500 polyfill.io/v3/polyfill.min.js\n</code></pre>"},{"location":"v10/setup/ensuring-data-privacy/#caching","title":"Caching recommended","text":"<p>All downloaded files are written to the <code>.cache</code> directory, significantly  reducing the duration of subsequent builds as only replacements need to be  carried out. You might want to:</p> <ol> <li>Ignore the <code>.cache</code> directory in your project, by adding it to <code>.gitignore</code>.</li> <li> <p>When building your site for publishing, use a build cache to save the     <code>.cache</code> directory in between builds. Taking the example from the     publishing guide, add the following lines:</p> <pre><code>name: ci\non:\npush:\nbranches:\n- master\n- main\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV\n- uses: actions/cache@v3\nwith:\nkey: mkdocs-material-${{ env.cache_id }}\npath: .cache\nrestore-keys: |\nmkdocs-material-\n- run: pip install mkdocs-material\n- run: mkdocs gh-deploy --force\n</code></pre> </li> </ol>"},{"location":"v10/setup/ensuring-data-privacy/#limitations","title":"Limitations","text":"<p>Note that dynamically created URLs as part of scripts are not detected, and thus cannot be automatically downloaded. The built-in privacy plugin does not execute scripts \u2013 it can only detect fully qualified URLs to download and replace.</p> <p>In short, don't do this:</p> <pre><code>const cdn = \"https://polyfill.io\"\nconst url = `${cdn}/v3/polyfill.min.js`\n</code></pre> <p>Instead, always use fully qualified URLs:</p> <pre><code>const url =\"https://polyfill.io/v3/polyfill.min.js\"\n</code></pre>"},{"location":"v10/setup/ensuring-data-privacy/#customization","title":"Customization","text":""},{"location":"v10/setup/ensuring-data-privacy/#custom-cookies","title":"Custom cookies","text":"<p>If you've customized the cookie consent and added a <code>custom</code> cookie, the user will be prompted to accept or reject your custom cookie. Once the user accepts or rejects the cookie consent, or changes the settings, the page reloads1. Use additional JavaScript to query the result:</p> <code>docs/javascripts/consent.js</code> <code>mkdocs.yml</code> <pre><code>var consent = __md_get(\"__consent\")\nif (consent &amp;&amp; consent.custom) {\n/* The user accepted the cookie */\n} else {\n/* The user rejected the cookie */\n}\n</code></pre> <pre><code>extra_javascript:\n- javascripts/consent.js\n</code></pre> <ol> <li> <p>We reload the page to make interop with custom cookies simpler. If Material for MkDocs would implement a callback-based approach, the author would need to make sure to correctly update all scripts that use cookies. Additionally, the cookie consent is only answered initially, which is why we consider this to be a good trade-off of DX and UX.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/setting-up-a-blog/","title":"Setting up a blog","text":"<p>Material for MkDocs makes it very easy to build a blog, either as a sidecar to your documentation or standalone. Focus on your content while the engine does all the heavy lifting, automatically generating archive and category indexes, post slugs, configurable pagination and more.</p> <p>Check out our blog, which is created with the new built-in blog plugin!</p>"},{"location":"v10/setup/setting-up-a-blog/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-a-blog/#built-in-blog-plugin","title":"Built-in blog plugin","text":"<p> 9.2.0b0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in blog plugin adds support for building a blog from a folder of posts, which are annotated with dates and other structured data. First, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- blog\n</code></pre> <p>If you need to be able to build your documentation with and without Insiders, please refer to the built-in plugins section to learn how shared configurations help to achieve this.</p> <p>By default, the built-in blog plugin assumes that your blog is hosted inside the <code>blog</code> subfolder of your documentation (this is configurable). Next, you need to create the following structure:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <p>Since the built-in blog plugin auto-generates archive and category indexes, it must know where to add those to the navigation. Thus, make sure to add a <code>blog/index.md</code> file in <code>mkdocs.yml</code>:</p> <pre><code>nav:\n- Blog:\n- blog/index.md # (1)!\n</code></pre> <ol> <li> <p>Within this file, you can specify the title of your blog, which is then     picked up and used by the built-in blog plugin:</p> <pre><code># Blog\n</code></pre> </li> </ol> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- blog:\nenabled: !ENV [CI, false]\n</code></pre> <code>blog_dir</code> <p> Default: <code>blog</code> \u2013 This option specifies the folder where your posts and metadata live. The name of the folder will also be included in the generated URLs as a prefix to all blog-related pages. If you want to build a standalone blog, change it to <code>.</code>:</p> SubdirectoryStandalone <pre><code>plugins:\n- blog:\nblog_dir: blog\n</code></pre> <pre><code>plugins:\n- blog:\nblog_dir: .\n</code></pre> <p>The path must be defined relative to <code>docs_dir</code>.</p> <code>blog_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether indexes include a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\nblog_toc: true\n</code></pre> <p>Note that this setting is also used as the default value for <code>archive_toc</code> and <code>categories_toc</code>, unless those settings are explicitly defined.</p> <p>The built-in blog plugin has dozens of options that allow for advanced configuration. It's a good idea to start writing your first post, and come back here later for fine-tuning the output.</p>"},{"location":"v10/setup/setting-up-a-blog/#posts","title":"Posts","text":"<p>The following configuration options are available for posts:</p> <code>post_date_format</code> <p> Default: <code>long</code> \u2013 This option specifies the date format that is used when posts are rendered. Under the hood, the built-in blog plugin leverages Babel to render dates locale-aware using the configured site language. The following formats are supported:</p> Monday, January 31, 2022January 31, 2022Jan 31, 20221/31/22 <pre><code>plugins:\n- blog:\npost_date_format: full\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: long\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: medium\n</code></pre> <pre><code>plugins:\n- blog:\npost_date_format: short\n</code></pre> <p>Note that depending on the site language, formats might look different for other languages. Additionally, Babel supports a pattern syntax which allows for custom formats.</p> <code>post_url_date_format</code> <p> Default: <code>yyyy/MM/dd</code> \u2013 This option specifies the date format that is used in the URL of the post. The format string must adhere to Babel's pattern syntax. Some examples:</p>  blog/2022/01/31// blog/2022/01// blog/2022// <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy/MM/dd\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy/MM\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_date_format: yyyy\n</code></pre> <p>If you want to exclude the date altogether, e.g. when your blog features mostly evergreen content, you can remove the <code>date</code> placeholder from the format string (see below).</p> <code>post_url_format</code> <p> Default: <code>{date}/{slug}</code> \u2013 This option specifies the format string that is used for the URL of the post. The following placeholders are currently supported:</p> <ul> <li> <p><code>categories</code> \u2013 Replaced with the post's slugified categories.</p> </li> <li> <p><code>date</code> \u2013 Replaced with the post's date, as configured in   <code>post_url_date_format</code>.</p> </li> <li> <p><code>slug</code> \u2013 Replaced with a slug generated from the post's title.</p> </li> <li> <p><code>file</code> \u2013 Replaced with the post's file name.</p> </li> </ul>  blog/2022// blog// <pre><code>plugins:\n- blog:\npost_url_format: \"{date}/{slug}\"\n</code></pre> <pre><code>plugins:\n- blog:\npost_url_format: \"{slug}\"\n</code></pre> <p>If you remove the <code>date</code> placeholder, make sure that post URLs don't collide with other the URLs of other pages added to the blog section, as this leads to undefined behavior.</p> <code>post_url_max_categories</code> <p> Default: <code>1</code> \u2013 This option specifies the number of categories that are included in the URL if the <code>categories</code> placeholder is part of <code>post_url_format</code>. If a post is assigned to multiple categories, they are joined with <code>/</code>:</p> <pre><code>plugins:\n- blog:\npost_url_format: \"{categories}/{slug}\"\npost_url_max_categories: 2\n</code></pre> <code>post_slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for generating URL-compatible slugs from post titles.  Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- blog:\npost_slugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- blog:\npost_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>post_slugify_separator</code> <p> Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string:</p> <pre><code>plugins:\n- blog:\npost_slugify_separator: \"-\"\n</code></pre> <code>post_excerpt</code> <p> Default: <code>optional</code> \u2013 This option specifies whether post excerpts should be considered being optional or required by the built-in blog plugin when generating indexes. If excerpts are required, the plugin terminates with an error if a post doesn't define an excerpt:</p> OptionalRequired <pre><code>plugins:\n- blog:\npost_excerpt: optional\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt: required\n</code></pre> <code>post_excerpt_max_authors</code> <p> Default: <code>1</code> \u2013 This option specifies the number of authors rendered in post excerpts. While each post may be written by multiple authors, this setting allows to limit the display to just a few or even a single author, or disable authors in excerpts altogether:</p> Render up to 2 authors in excerptsDisable authors in excerpts <pre><code>plugins:\n- blog:\npost_excerpt_max_authors: 2\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt_max_authors: 0\n</code></pre> <code>post_excerpt_max_categories</code> <p> Default: <code>5</code> \u2013 This option specifies the number of categories rendered in post excerpts. While each post may be assigned to multiple categories, the built-in blog plugin can be instructed to only show the first <code>n</code> categories to keep it short and concise:</p> Render up to 2 categories in excerptsDisable categories in excerpts <pre><code>plugins:\n- blog:\npost_excerpt_max_categories: 2\n</code></pre> <pre><code>plugins:\n- blog:\npost_excerpt_max_categories: 0\n</code></pre> <code>post_excerpt_separator</code> <p> Default: <code>&lt;!-- more --&gt;</code> \u2013 This option specifies the separator the built-in blog plugin will look for in a post's content when generating post excerpts. All content after the separator is not considered to be part of the excerpt.</p> <code>post_readtime</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should compute the reading time of a post automatically, which is then rendered in post excerpts, as well as in the posts themselves. If you want to disable reading time computation, add:</p> <pre><code>plugins:\n- blog:\npost_readtime: false\n</code></pre> <code>post_readtime_words_per_minute</code> <p> Default: <code>265</code> \u2013 This option specifies the number of words that a reader is expected to read per minute when computing the reading time of a post. If you feel that estimation is not quite right, you can fine-tune reading time computation with the following setting:</p> <pre><code>plugins:\n- blog:\npost_readtime_words_per_minute: 265\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#archive","title":"Archive","text":"<p>The following configuration options are available for archive index generation:</p> <code>archive</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate archive indexes. An archive indexes shows all posts for a specific interval (e.g. year, month, etc.) in reverse chronological order. If you want to disable archive index generation, add:</p> <pre><code>plugins:\n- blog:\narchive: false\n</code></pre> <code>archive_name</code> <p> Default: automatically set \u2013 This option specifies the title of the archive section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with:</p> <pre><code>plugins:\n- blog:\narchive_name: Archive\n</code></pre> <code>archive_date_format</code> <p> Default: <code>yyyy</code> \u2013 This option specifies the date format that is used when archive indexes are rendered. The format string must adhere to Babel's pattern syntax. Popular settings are:</p> 2022January 2022 <pre><code>plugins:\n- blog:\narchive_date_format: yyyy\n</code></pre> <pre><code>plugins:\n- blog:\narchive_date_format: MMMM yyyy\n</code></pre> <code>archive_url_date_format</code> <p> Default: <code>yyyy</code> \u2013 This option specifies the date format that is used in the archive index URL. The format string must adhere to Babel's pattern syntax. Some examples:</p>  blog/archive/2022/ blog/archive/2022/01/ <pre><code>plugins:\n- blog:\narchive_url_date_format: yyyy\n</code></pre> <pre><code>plugins:\n- blog:\narchive_url_date_format: yyyy/MM\n</code></pre> <code>archive_url_format</code> <p> Default: <code>archive/{date}</code> \u2013 This option specifies the format string that is used for the URL of the archive index, and can be used to localize the URL:</p>  blog/archive/2022/ blog/2022/ <pre><code>plugins:\n- blog:\narchive_url_format: \"archive/{date}\"\n</code></pre> <pre><code>plugins:\n- blog:\narchive_url_format: \"{date}\"\n</code></pre> <code>archive_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether an archive index includes a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\narchive_toc: true\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#categories","title":"Categories","text":"<p>The following configuration options are available for category index generation:</p> <code>categories</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate category indexes. A category index shows all posts for a specific category in reverse chronological order. If you want to disable category index generation, add:</p> <pre><code>plugins:\n- blog:\ncategories: false\n</code></pre> <code>categories_name</code> <p> Default: automatically set \u2013 This option specifies the title of the category section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with:</p> <pre><code>plugins:\n- blog:\ncategories_name: Categories\n</code></pre> <code>categories_url_format</code> <p> Default: <code>category/{slug}</code> \u2013 This option specifies the format string that is used for the URL of a category index, and can be used to localize the URL:</p>  blog/category// blog// <pre><code>plugins:\n- blog:\ncategories_url_format: \"category/{slug}\"\n</code></pre> <pre><code>plugins:\n- blog:\ncategories_url_format: \"{slug}\"\n</code></pre> <code>categories_slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for generating URL-compatible slugs from categories.  Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- blog:\ncategories_slugify: !!python/object/apply:pymdownx.slugs.slugify kwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- blog:\ncategories_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>categories_slugify_separator</code> <p> Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string:</p> <pre><code>plugins:\n- blog:\ncategories_slugify_separator: \"-\"\n</code></pre> <code>categories_allowed</code> <p> Default: none \u2013 This option specifies the categories that are allowed to be used in posts. If this setting is omitted, the built-in blog plugin will not check category names. Use this option to define a list of categories in order to catch typos:</p> <pre><code>plugins:\n- blog:\ncategories_allowed:\n- General\n- Search\n- Performance\n</code></pre> <code>categories_toc</code> <p> Default: <code>false</code> \u2013 This option specifies whether a category index includes a table of contents with all post titles on the right side as an overview:</p> <pre><code>plugins:\n- blog:\ncategories_toc: true\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#pagination","title":"Pagination","text":"<p>The following configuration options are available for index pagination:</p> <code>pagination</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should paginate the index. The index shows all posts in reverse chronological order, which can be many. If you want to disable index pagination, add:</p> <pre><code>plugins:\n- blog:\npagination: false\n</code></pre> <code>pagination_per_page</code> <p> Default: <code>10</code> \u2013 This option specifies the number of posts rendered on a single index page. If more posts are found, they are assigned to a 2nd page, and so on. If you have large post excerpts, it might be a good idea to reduce the number of posts per page:</p> <pre><code>plugins:\n- blog:\npagination_per_page: 5\n</code></pre> <code>pagination_url_format</code> <p> Default: <code>page/{page}</code> \u2013 This option specifies the format string that is used for the URL of the paginated index, and can be used to localize the URL:</p>  blog/page/n/ blog/n/ <pre><code>plugins:\n- blog:\npagination_url_format: \"page/{page}\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_url_format: \"{page}\"\n</code></pre> <code>pagination_template</code> <p> Default: <code>~2~</code> \u2013 This option specifies the format string that is provided to the paginate module, which allows to customize how pagination is constructed. Popular choices:</p> 1 2 3 .. n1 2 3 .. n  1  <pre><code>plugins:\n- blog:\npagination_template: \"~2~\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_template: \"$link_first $link_previous ~2~ $link_next $link_last\"\n</code></pre> <pre><code>plugins:\n- blog:\npagination_template: \"$link_previous $page $link_next\"\n</code></pre> <p>The paginate module exposes the following placeholders:</p> <ul> <li><code>$first_page</code> \u2013 number of first reachable page</li> <li><code>$last_page</code> \u2013 number of last reachable page</li> <li><code>$page</code> \u2013 number of currently selected page</li> <li><code>$page_count</code> \u2013 number of reachable pages</li> <li><code>$items_per_page</code> \u2013 maximal number of items per page</li> <li><code>$first_item</code> \u2013 index of first item on the current page</li> <li><code>$last_item</code> \u2013 index of last item on the current page</li> <li><code>$item_count</code> \u2013 total number of items</li> <li><code>$link_first</code> \u2013 link to first page (unless this is first page)</li> <li><code>$link_last</code> \u2013 link to last page (unless this is last page)</li> <li><code>$link_previous</code> \u2013 link to previous page (unless this is first page)</li> <li><code>$link_next</code> \u2013 link to next page (unless this is last page)</li> </ul> <code>pagination_keep_content</code> <p> Default: <code>false</code> \u2013 This option specifies whether paginated index pages should inherit the custom content from the index page, i.e. the content of <code>blog/index.md</code>:</p> <pre><code>plugins:\n- blog:\npagination_keep_content: true\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#authors","title":"Authors","text":"<p>The following configuration options are available for author info:</p> <code>authors</code> <p> Default: <code>true</code> \u2013 This option specifies whether the built-in blog plugin should generate author info. If it is enabled, the plugin will look up authors in a file called <code>.authors.yml</code> and include authors in indexes and in posts. If you want to disable this behavior, add:</p> <pre><code>plugins:\n- blog:\nauthors: false\n</code></pre> <code>authors_file</code> <p> Default: <code>.authors.yml</code> \u2013 This option specifies the name of the file where the authors for your posts resides. The default settings assumes that the file is called <code>.authors.yml</code> (mind the <code>.</code> at the beginning):</p> <pre><code>plugins:\n- blog:\nauthors_file: .authors.yml\n</code></pre> <p>The path must be defined relative to <code>blog_dir</code>. Also see the section on adding authors.</p>"},{"location":"v10/setup/setting-up-a-blog/#drafts","title":"Drafts","text":"<p>The following configuration options are available for drafts:</p> <code>draft</code> <p> Default: <code>false</code> \u2013 This option specifies whether the built-in blog plugin should also include posts marked as drafts when the site is being built. Including draft posts might be desired in deploy previews, which is why it exists in the first place:</p> Render draftsDon't render drafts <pre><code>plugins:\n- blog:\ndraft: true\n</code></pre> <pre><code>plugins:\n- blog:\ndraft: false\n</code></pre> <code>draft_on_serve</code> <p> Default: <code>true</code> \u2013 This option specifies whether posts marked as drafts should be included when previewing your site with <code>mkdocs serve</code>. By default, drafts are rendered when previewing, but skipped when the site is being built:</p> <pre><code>plugins:\n- blog:\ndraft_on_serve: true\n</code></pre> <code>draft_if_future_date</code> <p> Default: <code>false</code> \u2013 This option specifies whether the built-in blog plugin should mark posts with a future date as drafts. When the date passed today, the post is automatically unmarked and included when the site is being built:</p> <pre><code>plugins:\n- blog:\ndraft_if_future_date: true\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#rss","title":"RSS","text":"<p> Sponsors only \u00b7  insiders-4.23.0 \u00b7  Plugin</p> <p>The built-in blog plugin integrates seamlessly with the RSS plugin, which provides a simple way to add an RSS feed to your blog (or to your whole  documentation). Install it with <code>pip</code>:</p> <pre><code>pip install mkdocs-rss-plugin\n</code></pre> <p>Then, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- rss:\nmatch_path: blog/posts/.* # (1)!\ndate_from_meta:\nas_creation: date\ncategories:\n- categories\n- tags # (2)!\n</code></pre> <ol> <li> <p>The RSS plugin allows to filter for URLs to be included in the feed. In     this example, only blog posts will be part of the feed.</p> </li> <li> <p>If you want to include a post's categories as well as its tags in the feed,     add both <code>categories</code> and <code>tags</code> here.</p> </li> </ol> <p>The following configuration options are supported:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- rss:\nenabled: !ENV [CI, false]\n</code></pre> <code>match_path</code> <p> Default: <code>.*</code> \u2013 This option specifies which pages should be included in the feed. For example, to only include blog posts in the feed, use the following regular expression:</p> <pre><code>plugins:\n- rss:\nmatch_path: blog/posts/.*\n</code></pre> <code>date_from_meta</code> <p> Default: none \u2013 This option specifies which front matter property should be used as a creation date of a page in the  feed. It's recommended to use the <code>date</code> property:</p> <pre><code>plugins:\n- rss:\ndate_from_meta:\nas_creation: date\n</code></pre> <code>categories</code> <p> Default: none \u2013 This option specifies which front matter properties are used as categories as part of the feed. If you use categories and tags, add both with the following lines:</p> <pre><code>plugins:\n- rss:\ncategories:\n- categories\n- tags\n</code></pre> <code>comments_path</code> <p> Default: none \u2013 This option specifies the anchor at which comments for a post or page can be found. If you've integrated a comment system, add the following lines:</p> <pre><code>plugins:\n- rss:\ncomments_path: \"#__comments\"\n</code></pre> <p>Material for MkDocs will automatically add the necessary metadata to your site which will make the RSS feed discoverable by browsers and feed readers. Note that the RSS plugin comes with several other configuration options. For further information, see the documentation.</p>"},{"location":"v10/setup/setting-up-a-blog/#usage","title":"Usage","text":""},{"location":"v10/setup/setting-up-a-blog/#writing-your-first-post","title":"Writing your first post","text":"<p>After you've successfully set up the built-in blog plugin, it's time to write your first post. The plugin doesn't assume any specific directory structure, so you're completely free in how you organize your posts, as long as they are all located inside the <code>posts</code> directory:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u2502  \u2514\u2500 hello-world.md # (1)!\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li>If you'd like to arrange posts differently, you're free to do so. The URLs     are built from the format specified in <code>post_url_format</code> and     the titles and dates of posts, no matter how they are organized     inside the <code>posts</code> directory.</li> </ol> <p>Create a new file called <code>hello-world.md</code> and add the following lines:</p> <pre><code>---\ndraft: true # (1)!\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\n...\n</code></pre> <ol> <li>If you mark a post as a draft, a red marker appears next to the post date      on index pages. When the site is built, drafts are not included in the      output. This behavior can be changed, e.g. for rendering drafts when      building deploy previews.</li> </ol> <p>When you spin up the live preview server, you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you.</p>"},{"location":"v10/setup/setting-up-a-blog/#adding-an-excerpt","title":"Adding an excerpt","text":"<p>The blog index, as well as archive and category indexes can either list the entire content of each post, or excerpts of posts. An excerpt can be created by adding a <code>&lt;!-- more --&gt;</code> separator after the first few paragraphs of a post:</p> <pre><code># Hello world!\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n&lt;!-- more --&gt;\n...\n</code></pre> <p>When the built-in blog plugin generates all indexes, the content before the excerpt separator is automatically extracted, allowing the user to start reading a post before deciding to jump in.</p>"},{"location":"v10/setup/setting-up-a-blog/#adding-authors","title":"Adding authors","text":"<p>In order to add a little more personality to your posts, you can associate each post with one or multiple authors. First, create the <code>.authors.yml</code> file in your blog directory, and add an author:</p> <pre><code>squidfunk:\nname: Martin Donath\ndescription: Creator\navatar: https://github.com/squidfunk.png\n</code></pre> <p>The <code>.authors.yml</code> file associates each author with an identifier (in this example <code>squidfunk</code>), which can then be used in posts. The following properties are available for each author:</p> <code>name</code> <p> Default: none \u00b7  Required \u2013 This property must define a name for the author. The name is displayed in the left sidebar of each post as part of the author info.</p> <code>description</code> <p> Default: none \u00b7  Required \u2013 This property can be used to add a short description for the author, e.g. the role or profession of the author, or any other title.</p> <code>avatar</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid image URL, internal or external, and is used as part of posts and excerpts as the author's avatar.</p> <p>Now, you can assign one or more authors to a post by referencing their identifiers in the front matter of the Markdown file under the <code>authors</code> property. For each author, a small profile is rendered in the left sidebar of each post, as well as in post excerpts on index pages:</p> <pre><code>---\ndate: 2022-01-31\nauthors:\n- squidfunk\n...\n---\n# Hello world!\n...\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#adding-categories","title":"Adding categories","text":"<p>Categories are an excellent way for grouping your posts thematically on dedicated index pages. This way, a user interested in a specific topic can explore all of your posts on this topic. Make sure categories are enabled and add them to the front matter <code>categories</code> property:</p> <pre><code>---\ndate: 2022-01-31\ncategories:\n- Hello\n- World\n---\n# Hello world!\n...\n</code></pre> <p>If you want to save yourself from typos when typing out categories, you can define your desired categories in <code>mkdocs.yml</code> as part of the <code>categories_allowed</code> configuration option. The built-in blog plugin will stop the build if a category is not found within the list.</p>"},{"location":"v10/setup/setting-up-a-blog/#adding-tags","title":"Adding tags","text":"<p>Besides categories, the built-in blog plugin also integrates with the built-in tags plugin. If you add tags in the front matter <code>tags</code> property as part of a post, the post is linked from the tags index:</p> <pre><code>---\ndate: 2022-01-31\ntags:\n- Foo\n- Bar\n---\n# Hello world!\n...\n</code></pre> <p>As usual, the tags are rendered above the main headline and posts are linked  on the tags index page, if configured. Note that posts are, as pages, only linked with their titles.</p>"},{"location":"v10/setup/setting-up-a-blog/#adding-related-links","title":"Adding related links","text":"<p> Sponsors only \u00b7  insiders-4.23.0 \u00b7  Experimental</p> <p>Related links offer the perfect way to prominently add a further reading  section to your post that is included in the left sidebar, guiding the user to  other destinations of your documentation. Use the front matter <code>links</code> property  to add related links to a post:</p> <pre><code>---\ndate: 2022-01-31\nlinks:\n- setup/setting-up-site-search.md#built-in-search-plugin\n- insiders/index.md#how-to-become-a-sponsor\n---\n# Hello world!\n...\n</code></pre> <p>You can use the exact same syntax as for the <code>nav</code> section in <code>mkdocs.yml</code>, which means you can set explicit titles for links, add external links and even use nesting:</p> <pre><code>---\ndate: 2022-01-31\nlinks:\n- setup/setting-up-site-search.md#built-in-search-plugin\n- insiders/index.md#how-to-become-a-sponsor\n- Nested section:\n- External link: https://example.com\n- setup/setting-up-site-search.md\n---\n# Hello world!\n...\n</code></pre> <p>If you look closely, you'll realize that you can even use an anchor to link to a specific section of a document, extending the possibilities of the <code>nav</code>  syntax in <code>mkdocs.yml</code>. The built-in blog plugin resolves the anchor and sets  the title of the anchor as a subtitle of the related link.</p> <p>Note that all links must be relative to <code>docs_dir</code>, as is also the case for the <code>nav</code> setting.</p>"},{"location":"v10/setup/setting-up-a-blog/#linking-from-and-to-posts","title":"Linking from and to posts","text":"<p>While post URLs are dynamically computed, the built-in blog  plugin ensures that all links from and to posts and a post's assets are  correct. If you want to link to a post, just use the path to the Markdown file  as a link reference (links must be relative):</p> <pre><code>[Hello World!](blog/posts/hello-world.md)\n</code></pre> <p>Linking from a post to a page, e.g. the index, follows the same method:</p> <pre><code>[Blog](../index.md)\n</code></pre> <p>All assets inside the <code>posts</code> directory are copied to the <code>blog/assets</code> folder  when the site is being built. Of course, you can also reference assets from posts outside of the <code>posts</code> directory. The built-in blog plugin ensures that all links are correct.</p>"},{"location":"v10/setup/setting-up-a-blog/#setting-the-reading-time","title":"Setting the reading time","text":"<p>When enabled, the readtime package is used to compute the expected reading time of each post, which is rendered as part of the post and post excerpt. Nowadays, many blogs show reading times, which is why the built-in blog plugin  offers this capability as well.</p> <p>Sometimes, however, the computed reading time might not feel accurate, or result in odd and unpleasant numbers. For this reason, reading time can be  overridden and explicitly set with the front matter <code>readtime</code> property for a post:</p> <pre><code>---\ndate: 2022-01-31\nreadtime: 15\n---\n# Hello world!\n...\n</code></pre> <p>This will disable automatic reading time computation.</p>"},{"location":"v10/setup/setting-up-a-blog/#setting-defaults","title":"Setting defaults","text":"<p>If you have a lot of posts, it might feel redundant to define all of the above for each post. Luckily, the built-in meta plugin allows to set default front matter properties per folder. You can group your posts by categories, or authors, and add a <code>.meta.yml</code> file to set common properties:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 posts/\n\u2502     \u251c\u2500 .meta.yml # (1)!\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li> <p>As already noted, you can also place a <code>.meta.yml</code> file in nested folders     of the <code>posts</code> directory. This file then can define all front matter     properties that are valid in posts, e.g.:</p> <pre><code>authors:\n- squidfunk\ncategories:\n- Hello\n- World\n</code></pre> </li> </ol> <p>Note that order matters \u2013 the built-in meta plugin must be defined before the blog plugin in <code>mkdocs.yml</code>, so that all set defaults are correctly picked up by the built-in blog plugin:</p> <pre><code>plugins:\n- meta\n- blog\n</code></pre> <p>Lists and dictionaries in <code>.meta.yml</code> files are merged and deduplicated with the values defined for a post, which means you can define common properties in <code>.meta.yml</code> and then add specific properties or overrides for each post.</p>"},{"location":"v10/setup/setting-up-a-blog/#adding-pages","title":"Adding pages","text":"<p>Besides posts, it's also possible to add static pages to your blog by listing the pages in the <code>nav</code> section of <code>mkdocs.yml</code>. All generated indexes are included after the last specified page. For example, to add a page on the  authors of the blog, add the following to <code>mkdocs.yml</code>:</p> <pre><code>nav:\n- Blog:\n- blog/index.md\n- blog/authors.md\n...\n</code></pre>"},{"location":"v10/setup/setting-up-a-blog/#customization","title":"Customization","text":""},{"location":"v10/setup/setting-up-a-blog/#custom-index-pages","title":"Custom index pages","text":"<p> Sponsors only \u00b7  insiders-4.24.0 \u00b7  Experimental</p> <p>If you want to add custom content to automatically generated archive and  category indexes, e.g. to add a category description prior to the list of posts, you can manually create the category page in the same location where the built-in blog plugin would create it:</p> <pre><code>.\n\u251c\u2500 docs/\n\u2502  \u2514\u2500 blog/\n\u2502     \u251c\u2500 category/\n\u2502     \u2502  \u2514\u2500 hello.md # (1)!\n\u2502     \u251c\u2500 posts/\n\u2502     \u2514\u2500 index.md\n\u2514\u2500 mkdocs.yml\n</code></pre> <ol> <li> <p>The easiest way is to first add the category to the blog post, then take     the URL generated by the built-in blog plugin and create the file at the     corresponding location in the <code>blog_dir</code> folder.</p> <p>Note that the shown directory listing is based on the default configuration. If you specify different values for the following options, be sure to adjust the path accordingly:</p> <ul> <li><code>blog_dir</code></li> <li><code>categories_url_format</code></li> <li><code>categories_slugify</code></li> </ul> </li> </ol> <p>You can now add arbitrary content to the newly created file, or set specific front matter properties for this page, e.g. to change the page description:</p> <pre><code>---\ndescription: Nullam urna elit, malesuada eget finibus ut, ac tortor.\n---\n# Hello\n...\n</code></pre> <p>All post excerpts belonging to the category are automatically appended.</p>"},{"location":"v10/setup/setting-up-a-blog/#overriding-templates","title":"Overriding templates","text":"<p>The built-in blog plugin is built on the same basis as Material for MkDocs, which means you can override all templates used for the blog by using theme extension as usual.</p> <p>The following templates are added by the built-in blog plugin:</p> <ul> <li><code>blog.html</code> \u2013 Template for blog index</li> <li><code>blog-post.html</code> \u2013 Template for blog post</li> <li><code>blog-archive.html</code> \u2013 Template for blog archive index</li> <li><code>blog-category.html</code> \u2013 Template for blog category index</li> </ul>"},{"location":"v10/setup/setting-up-navigation/","title":"Setting up navigation","text":"<p>A clear and concise navigation structure is an important aspect of good project  documentation. Material for MkDocs provides a multitude of options to configure the behavior of navigational elements, including tabs and sections, and one of its flagship features: instant loading.</p>"},{"location":"v10/setup/setting-up-navigation/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-navigation/#instant-loading","title":"Instant loading","text":"<p> 5.0.0 \u00b7  Feature flag</p> <p>When instant loading is enabled, clicks on all internal links will be intercepted and dispatched via XHR without fully reloading the page. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.instant\n</code></pre> <p>The resulting page is parsed and injected and all event handlers and components are rebound automatically, i.e., Material for MkDocs now behaves like a Single Page Application. Now, the search index survives navigation, which is especially useful for large documentation sites.</p>"},{"location":"v10/setup/setting-up-navigation/#instant-prefetching","title":"Instant prefetching","text":"<p> Sponsors only \u00b7  insiders-4.36.0 \u00b7  Experimental</p> <p>Instant prefetching is a new experimental feature that will start to fetch a page once the user hovers over a link. This will reduce the perceived loading time for the user, especially on slow connections, as the page will be available immediately upon navigation. Enable it with:</p> <pre><code>theme:\nfeatures:\n- navigation.instant\n- navigation.instant.prefetch\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#anchor-tracking","title":"Anchor tracking","text":"<p> 8.0.0 \u00b7  Feature flag</p> <p>When anchor tracking is enabled, the URL in the address bar is automatically updated with the active anchor as highlighted in the table of contents. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tracking\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#navigation-tabs","title":"Navigation tabs","text":"<p> 1.1.0 \u00b7  Feature flag</p> <p>When tabs are enabled, top-level sections are rendered in a menu layer below the header for viewports above <code>1220px</code>, but remain as-is on mobile.1 Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tabs\n</code></pre> With tabsWithout <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#sticky-navigation-tabs","title":"Sticky navigation tabs","text":"<p> 7.3.0 \u00b7  Feature flag</p> <p>When sticky tabs are enabled, navigation tabs will lock below the header and always remain visible when scrolling down. Just add the following two feature flags to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.tabs\n- navigation.tabs.sticky\n</code></pre> With sticky tabsWithout <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#navigation-sections","title":"Navigation sections","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When sections are enabled, top-level sections are rendered as groups in the sidebar for viewports above <code>1220px</code>, but remain as-is on mobile. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.sections\n</code></pre> With sectionsWithout <p></p> <p></p> <p>Both feature flags, <code>navigation.tabs</code> and <code>navigation.sections</code>, can be combined with each other. If both feature flags are enabled, sections are rendered for level 2 navigation items.</p>"},{"location":"v10/setup/setting-up-navigation/#navigation-expansion","title":"Navigation expansion","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When expansion is enabled, the left sidebar will expand all collapsible subsections by default, so the user doesn't have to open subsections manually. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.expand\n</code></pre> With expansionWithout <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#navigation-path","title":"Navigation path Breadcrumbs","text":"<p> Sponsors only \u00b7  insiders-4.28.0 \u00b7  Experimental</p> <p>When navigation paths are activated, a breadcrumb navigation is rendered above the title of each page, which might make orientation easier for users visiting your documentation on devices with smaller screens. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.path\n</code></pre> With navigation pathWithout <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#navigation-pruning","title":"Navigation pruning","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>When pruning is enabled, only the visible navigation items are included in the  rendered HTML, reducing the size of the built site by 33% or more. Add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.prune # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with     <code>navigation.expand</code>, as navigation expansion requires     the complete navigation structure.</li> </ol> <p>This feature flag is especially useful for documentation sites with 100+ or even 1,000+ of pages, as the navigation makes up a significant fraction of the HTML. Navigation pruning will replace all expandable sections with links to the first page in that section (or the section index page).</p>"},{"location":"v10/setup/setting-up-navigation/#section-index-pages","title":"Section index pages","text":"<p> 7.3.0 \u00b7  Feature flag</p> <p>When section index pages are enabled, documents can be directly attached to sections, which is particularly useful for providing overview pages. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.indexes # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with <code>toc.integrate</code>,     as sections cannot host the table of contents due to missing space.</li> </ol> With section index pagesWithout <p></p> <p></p> <p>In order to link a page to a section, create a new document with the name <code>index.md</code> in the respective folder, and add it to the beginning of your navigation section:</p> <pre><code>nav:\n- Section:\n- section/index.md # (1)!\n- Page 1: section/page-1.md\n...\n- Page n: section/page-n.md\n</code></pre> <ol> <li>MkDocs also considers files called <code>README.md</code> as index pages.</li> </ol>"},{"location":"v10/setup/setting-up-navigation/#table-of-contents","title":"Table of contents","text":""},{"location":"v10/setup/setting-up-navigation/#anchor-following","title":"Anchor following","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>When anchor following for the table of contents is enabled, the sidebar is automatically scrolled so that the active anchor is always visible. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- toc.follow\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#navigation-integration","title":"Navigation integration","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When navigation integration for the table of contents is enabled, it is always rendered as part of the navigation sidebar on the left. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- toc.integrate # (1)!\n</code></pre> <ol> <li>This feature flag is not compatible with     <code>navigation.indexes</code>, as sections cannot host the     table of contents due to missing space.</li> </ol> With navigation integrationWithout <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#back-to-top-button","title":"Back-to-top button","text":"<p> 7.1.0 \u00b7  Feature flag</p> <p>A back-to-top button can be shown when the user, after scrolling down, starts to scroll up again. It's rendered centered and just below the header. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.top\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#usage","title":"Usage","text":""},{"location":"v10/setup/setting-up-navigation/#hiding-the-sidebars","title":"Hiding the sidebars","text":"<p>The navigation and/or table of contents sidebars can be hidden for a document with the front matter <code>hide</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nhide:\n- navigation\n- toc\n---\n# Document title\n...\n</code></pre> Hide navigationHide table of contentsHide both <p></p> <p></p> <p></p>"},{"location":"v10/setup/setting-up-navigation/#hiding-the-navigation-path","title":"Hiding the navigation path","text":"<p>While the navigation path is rendered above the main headline, sometimes, it might be desirable to hide it for a specific page, which can be achieved with the front matter <code>hide</code> property:</p> <pre><code>---\nhide:\n- path\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#customization","title":"Customization","text":""},{"location":"v10/setup/setting-up-navigation/#keyboard-shortcuts","title":"Keyboard shortcuts","text":"<p>Material for MkDocs includes several keyboard shortcuts that make it possible to navigate your project documentation via keyboard. There are two modes:</p> <code>search</code> <p>This mode is active when the search is focused. It provides several key bindings to make search accessible and navigable via keyboard:</p> <ul> <li>Down , Up : select next / previous result</li> <li>Esc , Tab : close search dialog</li> <li>Enter : follow selected result</li> </ul> <code>global</code> <p>This mode is active when search is not focussed and when there's no other focussed element that is susceptible to keyboard input. The following keys are bound:</p> <ul> <li>F , S , / : open search dialog</li> <li>P , , : go to previous page</li> <li>N , . : go to next page</li> </ul> <p>Let's say you want to bind some action to the X key. By using additional JavaScript, you can subscribe to the <code>keyboard$</code> observable and attach your custom event listener:</p> <code>docs/javascripts/shortcuts.js</code> <code>mkdocs.yml</code> <pre><code>keyboard$.subscribe(function(key) {\nif (key.mode === \"global\" &amp;&amp; key.type === \"x\") {\n/* Add custom keyboard handler here */\nkey.claim() // (1)!\n}\n})\n</code></pre> <ol> <li>The call to <code>key.claim()</code> will execute <code>preventDefault()</code> on the     underlying event, so the keypress will not propagate further and     touch other event listeners.</li> </ol> <pre><code>extra_javascript:\n- javascripts/shortcuts.js\n</code></pre>"},{"location":"v10/setup/setting-up-navigation/#content-area-width","title":"Content area width","text":"<p>The width of the content area is set so the length of each line doesn't exceed 80-100 characters, depending on the width of the characters. While this is a reasonable default, as longer lines tend to be harder to read, it may be desirable to increase the overall width of the content area, or even make it stretch to the entire available space.</p> <p>This can easily be achieved with an additional style sheet and a few lines of CSS:</p> <code>docs/stylesheets/extra.css</code> <code>mkdocs.yml</code> <pre><code>.md-grid {\nmax-width: 1440px; /* (1)! */\n}\n</code></pre> <ol> <li> <p>If you want the content area to always stretch to the available screen     space, reset <code>max-width</code> with the following CSS:</p> <pre><code>.md-grid {\nmax-width: initial;\n}\n</code></pre> </li> </ol> <pre><code>extra_css:\n- stylesheets/extra.css\n</code></pre> <ol> <li> <p>Prior to  6.2.0, navigation tabs had a slightly different behavior. All top-level pages (i.e. all top-level entries directly referring to a <code>*.md</code> file) defined inside the <code>nav</code> entry of <code>mkdocs.yml</code> were grouped under the first tab which received the title of the first page. This made it impossible to include a top-level page (or external link) as a tab item, as was reported in #1884 and #2072. From  6.2.0 on, navigation tabs include all top-level pages and sections.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/setting-up-site-analytics/","title":"Setting up site analytics","text":"<p>As with any other service offered on the web, understanding how your project documentation is actually used can be an essential success factor. Material for MkDocs natively integrates with Google Analytics and offers a customizable cookie consent and a feedback widget.</p>"},{"location":"v10/setup/setting-up-site-analytics/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-site-analytics/#google-analytics","title":"Google Analytics","text":"<p> 7.1.8 \u00b7  Default: none</p> <p>Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. Depending on the given property prefix, add the following lines to <code>mkdocs.yml</code>:</p>  Google Analytics 4 Universal Analytics <pre><code>extra:\nanalytics:\nprovider: google\nproperty: G-XXXXXXXXXX\n</code></pre> <pre><code>extra:\nanalytics:\nprovider: google\nproperty: UA-XXXXXXXX-X\n</code></pre> How to measure site search usage? <p>Besides page views and events, site search can be tracked to better understand how people use your documentation and what they expect to find. In order to enable site search tracking, the following steps are required:</p>  Google Analytics 4 Universal Analytics <ol> <li>Go to your Google Analytics admin settings</li> <li>Select the property for the respective tracking code</li> <li>Select the data streams tab and click the corresponding URL</li> <li>Click the gear icon within the enhanced measurement section</li> <li>Ensure that site search is enabled</li> </ol> <ol> <li>Go to your Google Analytics admin settings</li> <li>Select the property for the respective tracking code</li> <li>Go to the view settings tab</li> <li>Scroll down and enable site search settings</li> <li>Set the query parameter to <code>q</code></li> </ol>"},{"location":"v10/setup/setting-up-site-analytics/#was-this-page-helpful","title":"Was this page helpful?","text":"<p> 8.4.0 \u00b7  Default: none</p> <p>A simple feedback widget can be included at the bottom of each page, encouraging users to give instant feedback whether a page was helpful or not. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nanalytics: # (1)!\nfeedback:\ntitle: Was this page helpful?\nratings:\n- icon: material/emoticon-happy-outline\nname: This page was helpful\ndata: 1\nnote: &gt;-\nThanks for your feedback!\n- icon: material/emoticon-sad-outline\nname: This page could be improved\ndata: 0\nnote: &gt;- # (2)!\nThanks for your feedback! Help us improve this page by\nusing our &lt;a href=\"...\" target=\"_blank\" rel=\"noopener\"&gt;feedback form&lt;/a&gt;.\n</code></pre> <ol> <li> <p>This feature is natively integrated with Google Analytics,     which is why <code>provider</code> and <code>property</code> are also required. However, it's also     possible to provide a custom feedback integration.</p> </li> <li> <p>You can add arbitrary HTML tags to the note which is shown after the user     submitted the feedback, e.g. to link to a feedback form.</p> </li> </ol> <p>Both properties, <code>title</code> and <code>ratings</code>, are required. Note that it's allowed to define more than two ratings, e.g. to implement a 1-5 star rating. Since the feedback widget sends data to a third-party service, it is, of course, natively  integrated with the cookie consent feature1.</p> How to visualize the collected feedback ratings? <p>To visualize feedback ratings you'll need to create a custom report with Google Analytics that will quickly show you the worst- and best-rated pages of your project documentation.</p>  Google Analytics 4 Universal Analytics <ol> <li> <p>Go to your Google Analytics dashboard</p> </li> <li> <p>Go to the configure page on the left hand menu, then select     custom definitions</p> </li> <li> <p>Click the custom metrics tab and then create custom metrics,      enter the following values:</p> <ul> <li>Metric name: Page helpful</li> <li>Description: Was this page helpful?</li> <li>Event parameter: <code>data</code></li> <li>Unit of measurement: Standard</li> </ul> </li> <li> <p>Go to the explore page on the left hand menu, create a new     blank exploration</p> </li> <li> <p>Configure the report as follows:</p> <ul> <li>Dimensions: Add <code>Event name</code> and <code>Page location</code></li> <li>Metrics: Add <code>Event count</code> and <code>Page helpful</code>   (the custom metric created in step 3)</li> <li>Rows: <code>Page location</code></li> <li>Values: Drag in both <code>Event count</code> and <code>Page helpful</code></li> <li>Filters: Add a new filter for    <code>Event name / exactly matches / feedback</code></li> </ul> </li> </ol> <p>Delay in data availability</p> <p>The report may take 24 hours or longer to begin displaying data</p> <ol> <li>Go to your Google Analytics dashboard</li> <li>Open the customization panel on the left and go to custom reports</li> <li>Create a new custom report and set a custom title and name</li> <li>Add <code>Avg. Value</code> and <code>Total Events</code> to metric group</li> <li>Add <code>Event Label</code> to dimension drilldown</li> <li>Add <code>Event Category</code> to filters and filter for the value feedback</li> </ol> <p>Now, after you've saved the report and collected some feedback ratings, you'll have a list of all pages with the total number of ratings, and an average rating per page. This should help you identify pages that need to be improved:</p> <p></p> <p>The following properties are available for each rating:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations:</p> <ul> <li> +  \u2013 <code>material/emoticon-happy-outline</code> + <code>material/emoticon-sad-outline</code></li> <li> +  \u2013 <code>material/thumb-up-outline</code> + <code>material/thumb-down-outline</code></li> <li> +  \u2013 <code>material/heart</code> + <code>material/heart-broken</code></li> </ul> <code>name</code> <p> Default: none \u00b7  Required \u2013 The value of this property is shown on user interaction (i.e. keyboard focus or mouse hover), explaining the meaning of the rating behind the icon.</p> <code>data</code> <p> Default: none \u00b7  Required \u2013 The value of this property is sent as a data value with the custom event that is transmitted to Google Analytics2 (or any custom integration).</p> <code>note</code> <p> Default: none \u00b7  Required \u2013 The value of this property is shown after the user selected the rating. It may contain arbitrary HTML tags, which is especially useful to ask the user to provide more detailed feedback for the current page through a form. It's also possible to pre-fill forms with the URL and title of the current page by using the following placeholders:</p> <ul> <li><code>{url}</code> \u2013 Page URL</li> <li><code>{title}</code> \u2013 Page title</li> </ul> <pre><code>https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url}\n</code></pre> <p>In this example, when clicking the link, the user is redirected to the \"new  issue\" form of your repository, with a pre-filled title including the path of the current document, e.g.:</p> <pre><code>[Feedback] Setting up site analytics \u2013 /setup/setting-up-site-analytics/\n</code></pre> <p>An alternative to GitHub issues is Google Forms.</p>"},{"location":"v10/setup/setting-up-site-analytics/#usage","title":"Usage","text":""},{"location":"v10/setup/setting-up-site-analytics/#hiding-the-feedback-widget","title":"Hiding the feedback widget","text":"<p>The feedback widget can be hidden for a document with the front matter <code>hide</code> property. Add the following lines at the top of a Markdown file:</p> <pre><code>---\nhide:\n- feedback\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/setup/setting-up-site-analytics/#customization","title":"Customization","text":""},{"location":"v10/setup/setting-up-site-analytics/#custom-site-analytics","title":"Custom site analytics","text":"<p>In order to integrate another analytics service provider offering a  JavaScript-based tracking solution, just follow the guide on theme extension and create a new partial in the <code>overrides</code> folder. The name of the partial is used to configure the custom integration via <code>mkdocs.yml</code>:</p> <code>overrides/partials/integrations/analytics/custom.html</code> <code>mkdocs.yml</code> <pre><code>&lt;script&gt;\n/* Add custom analytics integration here, e.g. */\nvar property = \"{{ config.extra.analytics.property }}\" // (1)!\n/* Wait for page to load and application to mount */\ndocument.addEventListener(\"DOMContentLoaded\", function() {\nlocation$.subscribe(function(url) {\n/* Add custom page event tracking here */ // (2)!\n})\n})\n&lt;/script&gt;\n</code></pre> <ol> <li>As an example, this variable receives the value set in <code>mkdocs.yml</code>,     which is <code>\"foobar\"</code> for <code>property</code>.</li> <li>If you're using instant loading, you can use the <code>location$</code>     observable to listen for navigation events, which always emits the     current <code>URL</code>.</li> </ol> <pre><code>extra:\nanalytics:\nprovider: custom\nproperty: foobar # (1)!\n</code></pre> <ol> <li>You can add arbitrary key-value combinations to configure your     custom integration. This is especially useful if you're sharing the     custom integration across multiple repositories.</li> </ol>"},{"location":"v10/setup/setting-up-site-analytics/#custom-site-feedback","title":"Custom site feedback","text":"<p>A custom feedback widget integration just needs to process the events that are generated by users interacting with the feedback widget with the help of some additional JavaScript:</p> <code>docs/javascripts/feedback.js</code> <code>mkdocs.yml</code> <pre><code>var feedback = document.forms.feedback\nfeedback.addEventListener(\"submit\", function(ev) {\nev.preventDefault()\n/* Retrieve page and feedback value */\nvar page = document.location.pathname\nvar data = ev.submitter.getAttribute(\"data-md-value\")\n/* Send feedback value */\nconsole.log(page, data)\n})\n</code></pre> <pre><code>extra_javascript:\n- javascripts/feedback.js\n</code></pre> <p> </p> <ol> <li> <p>If the user doesn't accept the <code>analytics</code> cookie, the feedback widget is not shown.\u00a0\u21a9</p> </li> <li> <p>Note that for Google Analytics, the data value must be an integer.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/setting-up-site-search/","title":"Setting up site search","text":"<p>Material for MkDocs provides an excellent client-side search implementation, omitting the need for the integration of third-party services, which might not be compliant with privacy regulations. Moreover, search even works offline, allowing users to download your documentation.</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#configuration","title":"Configuration","text":"","boost":1.05},{"location":"v10/setup/setting-up-site-search/#built-in-search-plugin","title":"Built-in search plugin","text":"<p> 0.1.0 \u00b7  Plugin</p> <p>The built-in search plugin integrates seamlessly with Material for MkDocs, adding multilingual client-side search with lunr and lunr-languages. It's  enabled by default, but must be re-added to <code>mkdocs.yml</code> when other plugins are used:</p> <pre><code>plugins:\n- search\n</code></pre> <p>The following configuration options are supported:</p> <code>lang</code> <p> Default: automatically set \u2013 This option allows to include the language-specific stemmers provided by lunr-languages. Note that Material for MkDocs will set this automatically based on the site language, but it may be overridden, e.g. to support multiple languages:</p> A single languageMultiple languages <pre><code>plugins:\n- search:\nlang: en\n</code></pre> <pre><code>plugins:\n- search:\nlang: # (1)!\n- en\n- de\n</code></pre> <ol> <li>Be aware that including support for other languages increases the     general JavaScript payload by around 20kb (before <code>gzip</code>) and by     another 15-30kb per language.</li> </ol> <p>The following languages are supported by lunr-languages:</p> <ul> <li><code>ar</code> \u2013 Arabic</li> <li><code>da</code> \u2013 Danish</li> <li><code>de</code> \u2013 German</li> <li><code>du</code> \u2013 Dutch</li> <li><code>en</code> \u2013 English</li> <li><code>es</code> \u2013 Spanish</li> <li><code>fi</code> \u2013 Finnish</li> <li><code>fr</code> \u2013 French</li> <li><code>hi</code> \u2013 Hindi</li> <li><code>hu</code> \u2013 Hungarian</li> <li><code>hy</code> \u2013 Armenian</li> <li><code>it</code> \u2013 Italian</li> <li><code>ja</code> \u2013 Japanese</li> <li><code>kn</code> - Kannada</li> <li><code>ko</code> \u2013 Korean</li> <li><code>no</code> \u2013 Norwegian</li> <li><code>pt</code> \u2013 Portuguese</li> <li><code>ro</code> \u2013 Romanian</li> <li><code>ru</code> \u2013 Russian</li> <li><code>sa</code> \u2013 Sanskrit</li> <li><code>sv</code> \u2013 Swedish</li> <li><code>ta</code> \u2013 Tamil</li> <li><code>te</code> \u2013 Telugu</li> <li><code>th</code> \u2013 Thai</li> <li><code>tr</code> \u2013 Turkish</li> <li><code>vi</code> \u2013 Vietnamese</li> <li><code>zh</code> \u2013 Chinese</li> </ul> <p>Material for MkDocs goes to great lengths to support languages that are not part of this list by automatically falling back to the stemmer yielding the best result.</p> <code>separator</code> <p> Default: automatically set \u2013 The separator for indexing and query tokenization can be customized, making it possible to index parts of words separated by other characters than whitespace and <code>-</code>, e.g. by including <code>.</code>:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\-\\.]+'\n</code></pre> <p>With  9.0.0, a faster and more flexible tokenizer method is shipped, allowing for tokenizing with lookahead, which yields more influence on the way documents are indexed. As a result, we use the following separator setting for this site's search:</p> <pre><code>plugins:\n- search:\nseparator: '[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&amp;[lg]t;'\n</code></pre> <p>Broken into its parts, the separator induces the following behavior:</p> Special charactersCase changesVersion stringsHTML/XML tags <pre><code>[\\s\\-,:!=\\[\\]()\"/]+\n</code></pre> <p>The first part of the expression inserts token boundaries for each document before and after whitespace, hyphens, commas, brackets and other special characters. If several of those special characters are adjacent, they are treated as one.</p> <pre><code>(?!\\b)(?=[A-Z][a-z])\n</code></pre> <p>Many programming languages have naming conventions like <code>PascalCase</code> or <code>camelCase</code>. By adding this subexpression to the separator, words are split at case changes, tokenizing the word <code>PascalCase</code> into <code>Pascal</code> and <code>Case</code>.</p> <p> Read more on tokenizing case changes</p> <pre><code>\\.(?!\\d)\n</code></pre> <p>When adding <code>.</code> to the separator, version strings like <code>1.2.3</code> are split into <code>1</code>, <code>2</code> and <code>3</code>, which makes them undiscoverable via search. When using this subexpression, a small lookahead is introduced which will preserve version strings and keep them discoverable.</p> <p> Read more on tokenizing version numbers</p> <pre><code>&amp;[lg]t;\n</code></pre> <p>If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the <code>&lt;</code> and <code>&gt;</code> control characters are encoded in code blocks as <code>&amp;lt;</code> and <code>&amp;gt;</code>. Adding this subexpression to the separator allows for just that.</p> <p> Read more on tokenizing HTML/XML tags</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#chinese-language-support","title":"Chinese language support","text":"<p> 9.2.0b0 \u00b7  Experimental</p> <p>In order to add support for Chinese languages to the built-in search plugin, install the text segmentation library jieba via <code>pip</code>, and the plugin will run all text through the segmenter:</p> <pre><code>pip install jieba\n</code></pre> <p>The following configuration options are available:</p> <code>jieba_dict</code> <p> Default: none \u2013 This option allows for specifying a custom dictionary to be used by jieba for segmenting text, replacing the default dictionary:</p> <pre><code>plugins:\n- search:\njieba_dict: dict.txt # (1)!\n</code></pre> <ol> <li> <p>The following alternative dictionaries are provided by jieba:</p> <ul> <li>dict.txt.small \u2013 \u5360\u7528\u5185\u5b58\u8f83\u5c0f\u7684\u8bcd\u5178\u6587\u4ef6</li> <li>dict.txt.big \u2013 \u652f\u6301\u7e41\u4f53\u5206\u8bcd\u66f4\u597d\u7684\u8bcd\u5178\u6587\u4ef6</li> </ul> </li> </ol> <code>jieba_dict_user</code> <p> Default: none \u2013 This option allows for specifying an additional user dictionary to be used by jieba for segmenting text,  augmenting the default dictionary:</p> <pre><code>plugins:\n- search:\njieba_dict_user: user_dict.txt\n</code></pre> <p>User dictionaries can be used for tuning the segmenter to preserve technical terms.</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#search-suggestions","title":"Search suggestions","text":"<p> 7.2.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>When search suggestions are enabled, the search will display the likeliest completion for the last word which can be accepted with the Right key. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.suggest\n</code></pre> <p>Searching for  search su yields search suggestions as a suggestion.</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#search-highlighting","title":"Search highlighting","text":"<p> 7.2.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>When search highlighting is enabled and a user clicks on a search result, Material for MkDocs will highlight all occurrences after following the link. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.highlight\n</code></pre> <p>Searching for  code blocks highlights all occurrences of both terms.</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#search-sharing","title":"Search sharing","text":"<p> 7.2.0 \u00b7  Feature flag</p> <p>When search sharing is activated, a  share button is rendered next to the reset button, which allows to deep link to the current search query and result. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- search.share\n</code></pre> <p>When a user clicks the share button, the URL is automatically copied to the clipboard.</p>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#usage","title":"Usage","text":"","boost":1.05},{"location":"v10/setup/setting-up-site-search/#search-boosting","title":"Search boosting","text":"<p> 8.3.0</p> <p>Pages can be boosted in search with the front matter <code>search.boost</code> property, which will make them rank higher. Add the following lines at the top of a Markdown file:</p>  Rank up Rank down <pre><code>---\nsearch:\nboost: 2 # (1)!\n---\n# Document title\n...\n</code></pre> <ol> <li> When boosting pages, be gentle and start with     low values.</li> </ol> <pre><code>---\nsearch:\nboost: 0.5\n---\n# Document title\n...\n</code></pre>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#search-exclusion","title":"Search exclusion","text":"<p> 9.0.0 \u00b7  Experimental</p> <p>Pages can be excluded from search with the front matter <code>search.exclude</code> property, removing them from the index. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nsearch:\nexclude: true\n---\n# Document title\n...\n</code></pre>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#excluding-sections","title":"Excluding sections","text":"<p>When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the <code>data-search-exclude</code> pragma after a Markdown heading:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\n## Section 1\nThe content of this section is included\n\n## Section 2 { data-search-exclude }\nThe content of this section is excluded\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"\",\n\"title\":\"Document title\"\n},\n{\n\"location\":\"page/#section-1\",\n\"text\":\"&lt;p&gt;The content of this section is included&lt;/p&gt;\",\n\"title\":\"Section 1\"\n}\n]\n}\n</code></pre>","boost":1.05},{"location":"v10/setup/setting-up-site-search/#excluding-blocks","title":"Excluding blocks","text":"<p>When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the <code>data-search-exclude</code> pragma after a Markdown inline- or block-level element:</p> <code>docs/page.md</code> <code>search_index.json</code> <pre><code># Document title\nThe content of this block is included\n\nThe content of this block is excluded\n{ data-search-exclude }\n</code></pre> <pre><code>{\n...\n\"docs\": [\n{\n\"location\":\"page/\",\n\"text\":\"&lt;p&gt;The content of this block is included&lt;/p&gt;\",\n\"title\":\"Document title\"\n}\n]\n}\n</code></pre>","boost":1.05},{"location":"v10/setup/setting-up-social-cards/","title":"Setting up social cards","text":"<p>Material for MkDocs can automatically create beautiful social cards for your  documentation, which appear as link previews on social media platforms. You  can select from several pre-designed layouts or create custom layouts to match your unique style and branding.</p> <p> How to build custom social cards by @james-willett \u2013  24m \u2013 Learn how to create entirely custom social cards perfectly matching your branding for each page automatically!</p> <p></p> <p>Social card of our formatting reference</p>"},{"location":"v10/setup/setting-up-social-cards/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-social-cards/#built-in-social-plugin","title":"Built-in social plugin","text":"<p> 8.5.0 \u00b7  Plugin \u00b7  Experimental</p> <p>The built-in social plugin automatically generate a custom preview image for  each page. Install all dependencies for image processing1 and add the  following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- social\n</code></pre> <p>Note that Insiders contains a ground up rewrite of the social plugin that  generates images much more efficiently in parallel and allows to build  entirely custom layouts.</p> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- social:\nenabled: !ENV [CI, false]\n</code></pre> <code>concurrency</code> <p> insiders-4.33.0 \u00b7   Default: number of CPUs \u2013 How many CPUs the plugin is allowed to use when generating social cards. With more CPUs, the plugin can do more work in the same time, thus complete generation faster. Concurrent processing can be disabled with:</p> <pre><code>plugins:\n- social:\nconcurrency: 1\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#social-cards","title":"Social cards","text":"<p>The following configuration options are available for card generation:</p> <code>cards</code> <p> Default: <code>true</code> \u2013 This option specifies whether to generate social card images. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable:</p> <pre><code>plugins:\n- social:\ncards: !ENV [CI, false]\n</code></pre> <code>cards_dir</code> <p> Default: <code>assets/images/social</code> \u2013 This option specifies where the generated social cards will be stored. While it's usually not necessary to change this option, change it with:</p> <pre><code>plugins:\n- social:\ncards_dir: assets/images/social\n</code></pre> <code>cards_color</code> \u2013  Deprecated, use <code>cards_layout_options</code> <p> Default: <code>theme.palette.primary</code> \u2013  This option specifies the colors for the background <code>fill</code> and foreground <code>text</code> when generating the social card:</p> <pre><code>plugins:\n- social:\ncards_color:\nfill: \"#0FF1CE\"\ntext: \"#FFFFFF\"\n</code></pre> <code>cards_font</code> \u2013  Deprecated, use <code>cards_layout_options</code> <p> Default: <code>theme.font.text</code> \u2013 This option specifies which font to use for rendering the social card, which can be any font hosted on Google Fonts:</p> <pre><code>plugins:\n- social:\ncards_font: Ubuntu\n</code></pre> <code>cards_layout_dir</code> <p> insiders-4.33.0 \u00b7  Default: none \u2013 This option specifies where the social plugin should try to resolve custom layouts from, taking precedence over the included layouts:</p> <pre><code>plugins:\n- social:\ncards_layout_dir: layouts\n</code></pre> <code>cards_layout</code> <p> insiders-4.33.0 \u00b7  Default: <code>default</code> \u2013 Layout specification the social card should use. The plugin includes the following layouts which make use of the color palette and font:</p> <code>default</code><code>default/variant</code><code>default/accent</code><code>default/invert</code><code>default/only/image</code> <pre><code>plugins:\n- social:\ncards_layout: default\n</code></pre> <p>This layout uses the configured primary color as a background:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/variant\n</code></pre> <p>This layout includes the page icon as a watermark, if defined:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/accent\n</code></pre> <p>This layout uses the configured accent color as a background:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/invert\n</code></pre> <p>This layout inverts the background and foreground colors:</p> <p></p> <pre><code>plugins:\n- social:\ncards_layout: default/only/image\ncards_layout_options:\nbackground_image: layouts/background.png\n</code></pre> <p>This layout will only show the given background image and scale to fit:</p> <p></p> <p>All <code>default</code> layouts make use of the following template variables:</p> <ul> <li> \u2013 <code>config.site_name</code></li> <li> \u2013 <code>page.meta.title</code> or <code>page.title</code></li> <li> \u2013 <code>page.meta.description</code> or <code>config.site_description</code></li> <li> \u2013 <code>theme.logo</code> or <code>theme.icon.logo</code></li> </ul> <code>cards_layout_options</code> <p> 9.1.10 \u00b7  Default: none \u2013 This option allows to set parameters as provided by the layout specification. For custom layouts, this key can be used to provide layout-specific options, making layouts entirely configurable.</p> <p>All <code>default</code> layouts expose the following parameters:</p> <code>background_color</code> <p>Set a background color, which can be a CSS color keyword, or a 3, 4, 6 or 8 letter HEX color code. Alpha channels are supported as well:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nbackground_color: \"#0FF1CE\"\n</code></pre> <code>background_image</code> <p> insiders-4.33.0 \u2013 Set a background image.  If a <code>background_color</code> is set, like for the <code>default</code> layouts, the image is tinted (overlayed) with the color. Thus, the background color must be (partially) transparent for the image to become visible:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nbackground_color: \"#00000000\"\nbackground_image: layouts/background.png\n</code></pre> <p>The path of the image must be defined relative to the project root.</p> <code>color</code> <p>Set a foreground color, which can be a CSS color keyword, or a 3, 4, 6 or 8 letter HEX color code. The color is primarily used to tint text and icons:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\ncolor: \"#0FF1CE\"\n</code></pre> <code>font_family</code> <p>Set a font family. This overrides the font that is set as part of the theme configuration. The built-in social plugin will automatically download the font from Google Fonts:</p> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Ubuntu\n</code></pre> <code>cards_include</code> <p> insiders-4.35.0 \u00b7  Default: none \u2013 This option allows to only generate social cards for certain subsections of your documentation, e.g. to generate different cards for different subfolders with multiple instances of the plugin:</p> <pre><code>plugins:\n- social:\ncards_include:\n- blog/*\n</code></pre> <code>cards_exclude</code> <p> Default: none \u2013 This option allows to exclude certain subsections of your documentation from generating social cards:</p> <pre><code>plugins:\n- social:\ncards_exclude:\n- changelog/*.md\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#debugging","title":"Debugging","text":"<p>The following configuration options are available for debugging:</p> <code>debug</code> <p> insiders-4.33.0 \u00b7  Default: <code>false</code> \u2013 This option enables a special debug mode, which renders each layer with an outline and its <code>x</code> and <code>y</code> offset in order to understand how the layout is composed, and optionally renders a grid for easier alignment:</p> <pre><code>plugins:\n- social:\ndebug: true\n</code></pre> With debug modeWithout <p></p> <p></p> <code>debug_on_build</code> <p> insiders-4.34.1 \u00b7  Default: <code>false</code> \u2013 Whether debug mode should be automatically disabled when building your site with <code>mkdocs build</code>. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_on_build: true\n</code></pre> <p>This setting is just intended to be a safety net, so that when building your site social cards definitely won't contain the dot grid or layer outlines by accident.</p> <code>debug_grid</code> <p> insiders-4.33.0 \u00b7  Default: <code>true</code> \u2013 This option enables the rendering of a dot grid when <code>debug</code> is enabled (see screenshot above). The grid can be switched off with:</p> <pre><code>plugins:\n- social:\ndebug_grid: false\n</code></pre> <code>debug_grid_step</code> <p> insiders-4.33.0 \u00b7  Default: <code>32</code> \u2013 This option specifies the step size of the grid in pixels, if enabled, which can be used to align elements. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_grid_step: 64\n</code></pre> <code>debug_color</code> <p> insiders-4.33.0 \u00b7  Default: <code>grey</code> \u2013 This option sets the color of the layer outlines and the grid which are rendered when <code>debug</code> is enabled. It can be changed with:</p> <pre><code>plugins:\n- social:\ndebug_color: yellow\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#caching","title":"Caching","text":"<p>The built-in social plugin implements an intelligent caching mechanism, ensuring that social cards are only re-generated when they're not contained in the cache or their contents change. If any of the variables used in a layout  changes, the plugin will detect it and re-generate the card.</p> <p>The following configuration options are available for caching:</p> <code>cache</code> <p> insiders-4.33.0 \u00b7  Default: <code>true</code> \u2013 Whether the plugin queries its cache for an existing artifact before starting a generation job. It's normally not necessary to change this setting, except for when debugging the plugin itself. Caching can be disabled with:</p> <pre><code>plugins:\n- social:\ncache: false\n</code></pre> <code>cache_dir</code> <p> Default: <code>.cache/plugins/social</code> \u2013 This option specifies the file system location of the plugin's cache. It's normally not necessary to change this setting, except for when debugging the plugin itself. The cache directory can be changed with:</p> <pre><code>plugins:\n- social:\ncache_dir: .cache/plugins/social\n</code></pre> <p>By default, all built-in plugins that implement caching will create a <code>.cache</code> directory in the same folder your <code>mkdocs.yml</code> resides, and create subfolders to not interfere with each other. If you use multiple instances of this plugin, it could be necessary to change this setting.</p>"},{"location":"v10/setup/setting-up-social-cards/#usage","title":"Usage","text":"<p>If you want to adjust the title or set a custom description for the social card, you can set the front matter <code>title</code> and <code>description</code> properties, which take  precedence over the default values.</p> <ul> <li>Changing the title</li> <li>Changing the description</li> </ul>"},{"location":"v10/setup/setting-up-social-cards/#choosing-a-font","title":"Choosing a font","text":"<p>Some fonts do not contain CJK characters, like for example the default font, <code>Roboto</code>. In case your <code>site_name</code>, <code>site_description</code>, or page title contain CJK characters, choose another font from Google Fonts which comes with CJK characters, e.g. one from the <code>Noto Sans</code> font family:</p> Chinese (Simplified)Chinese (Traditional)JapaneseKorean <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans SC\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans TC\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans JP\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_options:\nfont_family: Noto Sans KR\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#changing-the-layout","title":"Changing the layout","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>If you want to use a different layout for a single page (e.g. your landing page), you can use the <code>social</code> front matter property together with the <code>cards_layout</code> key, exactly as in <code>mkdocs.yml</code>:</p> <pre><code>---\nsocial:\ncards_layout: custom\n---\n# Headline\n...\n</code></pre> <p>You can apply those changes for entire subtrees of your documentation, e.g., to generate different social cards for your blog and API reference, by using the built-in meta plugin.</p>"},{"location":"v10/setup/setting-up-social-cards/#parametrizing-the-layout","title":"Parametrizing the layout","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>Besides changing the entire layout, you can override all options that a layout exposes. This means you can parametrize social cards with custom front matter properties, such as <code>tags</code>, <code>date</code>, <code>author</code> or anything you can think of. Simply define <code>cards_layout_options</code>:</p> <pre><code>---\nsocial:\ncards_layout_options:\nbackground_color: blue # Change background color\nbackground_image: null # Remove background image\n---\n# Headline\n...\n</code></pre> <p>You can apply those changes for entire subtrees of your documentation, e.g., to generate different social cards for your blog and API reference, by using the built-in meta plugin.</p>"},{"location":"v10/setup/setting-up-social-cards/#disabling-social-cards","title":"Disabling social cards","text":"<p> insiders-4.37.0 \u00b7  Experimental</p> <p>If you wish to disable social cards for a page, simply add the following to the front matter of the Markdown document:</p> <pre><code>---\nsocial:\ncards: false\n---\n# Headline\n...\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#customization","title":"Customization","text":"<p> Sponsors only \u00b7  insiders-4.33.0 \u00b7  Experimental</p> <p>Insiders ships a ground up rewrite of the built-in social plugin and introduces a brand new layout system based on a combination of YAML and Jinja templates \u2013 the same engine Material for MkDocs uses for HTML templating \u2013 allowing for the creation of complex custom layouts:</p> Layer 0 Layer 1 Layer 2 Layer 3 Layer 4 Layer 5 <p>Social cards are composed of layers, analogous to how they are represented in graphic design software such as Adobe Photoshop. As many layers are common across the cards generated for each page (e.g., backgrounds or logos), the built-in social plugin can automatically deduplicate layers and render them just once, substantially accelerating card generation. The generated cards are cached to ensure they are only regenerated when their contents change.</p> <p>Layouts are written in YAML syntax. Before starting to create a custom layout, it is a good idea to study the pre-designed layouts (link to Insiders repository), in order to get a better understanding of how they work. Then, create a new layout and reference it in <code>mkdocs.yml</code>:</p> <code>layouts/custom.yml</code> <code>mkdocs.yml</code> <pre><code>size: { width: 1200, height: 630 }\nlayers: []\n</code></pre> <pre><code>plugins:\n- social:\ncards_layout_dir: layouts\ncards_layout: custom\ndebug: true\n</code></pre> <p>Note that the <code>.yml</code> file extension should be omitted. Next, run <code>mkdocs serve</code>, and see how the <code>.cache</code> directory is populated with the generated cards. Open any card in your editor, so you can see your changes immediately. Since we haven't defined any layers, the cards are transparent.</p> <p>The following sections explain how to create custom layouts.</p>"},{"location":"v10/setup/setting-up-social-cards/#size-and-offset","title":"Size and offset","text":"<p>Each layer has an associated size and offset, which is defined in pixels. The <code>size</code> is defined by a <code>width</code> and <code>height</code> property, and the <code>offset</code> by <code>x</code> and <code>y</code> properties:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 1200, height: 630 }\noffset: { x: 0, y: 0 }\n</code></pre> <p>If the <code>size</code> is omitted, it defaults to the size of the layout. If the <code>offset</code> is omitted, it defaults to the top left corner, which is the defaut <code>origin</code>. Saving the layout and reloading renders:</p> <p></p> <p>The layer outline and grid are visible because we enabled <code>debug</code> mode in <code>mkdocs.yml</code>. The top left shows the layer index and offset, which is useful for alignment and composition.</p>"},{"location":"v10/setup/setting-up-social-cards/#origin","title":"Origin","text":"<p> insiders-4.35.0 \u00b7  Experimental</p> <p>The <code>origin</code> for the <code>x</code> and <code>y</code> values can be changed, so that the layer is aligned to one of the edges or corners of the layout, e.g., to the bottom right corner of the layout:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 1200, height: 630 }\noffset: { x: 0, y: 0 }\norigin: end bottom\n</code></pre> <p>The following table shows the supported values:</p> Origin <code>start top</code> <code>center top</code> <code>end top</code> <code>start center</code> <code>center</code> <code>end center</code> <code>start bottom</code> <code>center bottom</code> <code>end bottom</code>      Supported values for origin"},{"location":"v10/setup/setting-up-social-cards/#backgrounds","title":"Backgrounds","text":"<p>Each layer can be assigned a background color and image. If both are given, the color is rendered on top of the image, allowing for semi-transparent, tinted backgrounds:</p> Background colorBackground imageBackground image, tinted <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n</code></pre> <p></p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\nimage: layouts/background.png\n</code></pre> <p></p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\nimage: layouts/background.png\ncolor: \"#4051b5ee\" # (1)!\n</code></pre> <ol> <li>The color value can be set to a CSS color keyword, or a 3, 4, 6 or 8     letter HEX color code, allowing for semi-transparent layers.</li> </ol> <p></p> <p>Background images are automatically scaled to fit the layer while preserving aspect-ratio. Notice how we omitted <code>size</code> and <code>offset</code>, because we want to fill the entire area of the social card.</p>"},{"location":"v10/setup/setting-up-social-cards/#typography","title":"Typography","text":"<p>Now, we can add dynamic typography that is sourced from Markdown files - this is the actual raison d'\u00eatre of the built-in social plugin. Jinja templates are used to render a text string that is then added to the image:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 832, height: 310 }\noffset: { x: 62, y: 160 }\ntypography:\ncontent: \"{{ page.title }}\" # (1)!\nalign: start\ncolor: white\nline:\namount: 3\nheight: 1.25\nfont:\nfamily: Roboto\nstyle: Bold\n</code></pre> <ol> <li> <p>The following variables can be used in Jinja templates:</p> <ul> <li><code>config.*</code></li> <li><code>page.*</code></li> <li><code>layout.*</code></li> </ul> <p>The author is free in defining <code>layout.*</code> options, which can be used to pass arbitrary data to the layout from <code>mkdocs.yml</code>.</p> </li> </ol> <p>This renders a text layer with the title of the page with a line height of 1.25, and a maximum number of 3 lines. The plugin automatically computes the font size from the line height, the number of lines, and font metrics like ascender and descender.2 This renders:</p> <p></p>"},{"location":"v10/setup/setting-up-social-cards/#overflow","title":"Overflow","text":"<p>If the text overflows the layer, there are two possible behaviors: either the text is automatically truncated and shortened with an ellipsis, or the text is automatically scaled down to fit the layer:</p> <pre><code># If we use a very long headline, we can see how the text will be truncated\n</code></pre>  Ellipsis Shrink <p></p> <p></p> <p>While truncating with an ellipsis is the default, auto-shrinking can be enabled  by setting <code>overflow</code> to <code>shrink</code>:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- size: { width: 832, height: 310 }\noffset: { x: 62, y: 160 }\ntypography:\ncontent: \"{{ page.title }}\"\noverflow: shrink\nalign: start\ncolor: white\nline:\namount: 3\nheight: 1.25\nfont:\nfamily: Roboto\nstyle: Bold\n</code></pre>"},{"location":"v10/setup/setting-up-social-cards/#alignment","title":"Alignment","text":"<p>Text can be aligned to all corners and edges of the layer. For example, if we want to align the text to the middle of the layer, we can set <code>align</code> to  <code>start center</code>, which will render as:</p> <p></p> <p>The following table shows the supported values:</p> Alignment <code>start top</code> <code>center top</code> <code>end top</code> <code>start center</code> <code>center</code> <code>end center</code> <code>start bottom</code> <code>center bottom</code> <code>end bottom</code>      Supported values for text alignment"},{"location":"v10/setup/setting-up-social-cards/#font","title":"Font","text":"<p>The built-in social plugin integrates with Google Fonts and will automatically download the font files for you. The <code>font</code> property accepts a <code>family</code> and <code>style</code> property, where the <code>family</code> must be set to the name of the font, and the <code>style</code> to one of the supported font styles. For example, setting <code>family</code> to <code>Roboto</code> will automatically download the following files:</p> <pre><code>.cache/plugins/social/fonts\n\u2514\u2500 Roboto/\n    \u251c\u2500 Black.ttf\n    \u251c\u2500 Black Italic.ttf\n    \u251c\u2500 Bold.ttf\n    \u251c\u2500 Bold Italic.ttf\n    \u251c\u2500 Italic.ttf\n    \u251c\u2500 Light.ttf\n    \u251c\u2500 Light Italic.ttf\n    \u251c\u2500 Medium.ttf\n    \u251c\u2500 Medium Italic.ttf\n    \u251c\u2500 Regular.ttf\n    \u251c\u2500 Thin.ttf\n    \u2514\u2500 Thin Italic.ttf\n</code></pre> <p>In that case, the author can use <code>Bold</code> or <code>Medium Italic</code> as the <code>style</code>. If the font style specified in the layer is not part of the font family, the font always falls back to <code>Regular</code> and prints a warning in <code>debug</code> mode, as <code>Regular</code> is included with all font families.</p>"},{"location":"v10/setup/setting-up-social-cards/#icons","title":"Icons","text":"<p>Authors can leverage the full range of icons that are shipped with Material for MkDocs, or even provide custom icons by using theme extension and going through the process described in the guide on additional icons. Icons can even be tinted by using the <code>color</code> property:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n- size: { width: 144, height: 144 }\noffset: { x: 992, y: 64 }\nicon:\nvalue: material/cat\ncolor: white\n</code></pre> <p>This will render the icon in the top right corner of the social card:</p> <p></p> <p>The possibilities are endless. For example, icons can be used to draw shapes like circles:</p> <pre><code>size: { width: 1200, height: 630 }\nlayers:\n- background:\ncolor: \"#4051b5\"\n- size: { width: 2400, height: 2400 }\noffset: { x: -1024, y: 64 }\nicon:\nvalue: material/circle\ncolor: \"#5c6bc0\"\n- size: { width: 1800, height: 1800 }\noffset: { x: 512, y: -1024 }\nicon:\nvalue: material/circle\ncolor: \"#3949ab\"\n</code></pre> <p>This will add two circles to the background:</p> <p></p>"},{"location":"v10/setup/setting-up-social-cards/#tags","title":"Tags","text":"<p>The new built-in social plugin gives full flexibility of the meta tags that are added to your site, which are necessary to instruct services like Twitter or Discord how to display your social card. All default layouts use the following set of tags, which you can copy to your layout and adapt:</p> <pre><code>definitions:\n- &amp;page_title_with_site_name &gt;-\n{%- if not page.is_homepage -%}\n{{ page.meta.get(\"title\", page.title) }} - {{ config.site_name }}\n{%- else -%}\n{{ page.meta.get(\"title\", page.title) }}\n{%- endif -%}\n- &amp;page_description &gt;-\n{{ page.meta.get(\"description\", config.site_description) or \"\" }}\ntags:\nog:type: website\nog:title: *page_title_with_site_name\nog:description: *page_description\nog:image: \"{{ image.url }}\"\nog:image:type: \"{{ image.type }}\"\nog:image:width: \"{{ image.width }}\"\nog:image:height: \"{{ image.height }}\"\nog:url: \"{{ page.canonical_url }}\"\ntwitter:card: summary_large_image\ntwitter.title: *page_title_with_site_name\ntwitter:description: *page_description\ntwitter:image: \"{{ image.url }}\"\n</code></pre> <p>Note that this examples makes use of YAML anchors to minify repetition. The  <code>definitions</code> property is solely intended for the definition on aliases that  can then be referenced with anchors.</p> <p>Are you missing something? Please open a discussion and let us know!</p> <ol> <li> <p>The awesome thing about social cards is that they are generated during  build time and directly distributed with your documentation, no external  services involved. While it would technically be simpler to generate  social cards using a web browser and an automation framework like  Puppeteer, it would add further liabilities to the toolchain, with the  potential to make build pipelines more complex and resource intense.</p> <p>For this reason, Material for MkDocs again follows its core principle of  making it as simple and powerful as possible, providing an easy-to-use  framework for building custom layouts using Python image processing  libraries.\u00a0\u21a9</p> </li> <li> <p>If the plugin would require the author to specify the font size and line height manually, it would be impossible to guarantee that the text fits into the layer. For this reason we implemented a declarative approach, where the author specifies the desired line height and number of lines, and the plugin computes the font size automatically.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/setting-up-tags/","title":"Setting up tags","text":"<p>Material for MkDocs adds first-class support for categorizing pages with tags, which adds the possibility to group related pages and make them discoverable via search and a dedicated tags index. If your documentation is large, tags can help to discover relevant information faster.</p>"},{"location":"v10/setup/setting-up-tags/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-tags/#built-in-tags-plugin","title":"Built-in tags plugin","text":"<p> 8.2.0 \u00b7  Plugin</p> <p>The built-in tags plugin adds the ability to categorize any page with tags as part of the front matter of the page. In order to add support for tags, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n- tags\n</code></pre> <p>The following configuration options are available:</p> <code>enabled</code> <p> Default: <code>true</code> \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable:</p> <pre><code>plugins:\n- tags:\nenabled: !ENV [CI, false]\n</code></pre> <code>tags_file</code> <p> Default: none \u2013 This option specifies which page should be used to render the tags index. See the section on adding a tags  index for more information. If this option is specified, tags become clickable, pointing to the corresponding section in the tags index:</p> <pre><code>plugins:\n- tags:\ntags_file: tags.md\n</code></pre> <p>The page holding the tags index can be linked anywhere in the <code>nav</code> section of <code>mkdocs.yml</code>. Note, however, that this options is not required \u2013 only use it if you want a tags index page.</p> <code>tags_extra_files</code> <p> insiders-4.20.0 \u00b7   Default: none \u2013 This option specifies additional pages, i.e. to render subsets of the tags index, in order to provide scoped tags indexes for  specific sections:</p> <pre><code>plugins:\n- tags:\ntags_extra_files:\ncompatibility.md:\n- compat # (1)!\nweb.md:\n- html\n- js\n- css\n</code></pre> <ol> <li> <p>Each page can be assigned a list of tag identifiers, which must be     defined as part of <code>extra.tags</code> in <code>mkdocs.yml</code>:</p> <pre><code>extra:\ntags:\nCompatibility: compat\nHTML5: html\nJavaScript: js\nCSS: css\n</code></pre> <p>In this example, all pages with the tag <code>Compatibility</code> will be included  in the additional tags index on <code>compatibility.md</code>, all pages defining at least one of the tags <code>HTML5</code>, <code>JavaScript</code> or <code>CSS</code> will be included in the additional tags index on <code>web.md</code>.</p> </li> </ol> <p>Note that the values listed under each tags extra file must be alphanumeric tag identifiers, not tags themselves. See #3864 for more information.</p> <code>tags_slugify</code> <p> insiders-4.25.0 \u00b7   Default: <code>headerid.slugify</code> \u2013 This option specifies which function to use for  generating URL-compatible slugs from tags. Python Markdown Extensions  includes several Unicode-aware slug functions which are a good choice for  non-ASCII languages:</p> UnicodeUnicode, case-sensitive <pre><code>plugins:\n- tags:\ntags_slugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>plugins:\n- tags:\ntags_slugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>tags_slugify_separator</code> <p> insiders-4.25.0 \u00b7   Default: <code>-</code> \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string:</p> <pre><code>plugins:\n- tags:\ntags_slugify_separator: \"-\"\n</code></pre> <code>tags_compare</code> <p> insiders-4.26.2 \u00b7  Default: <code>None</code> \u2013 This option specifies which function to use when comparing tag values for sorting. If you wish to compare tags irregardless of casing, use:</p> <pre><code>plugins:\n- tags:\ntags_compare: !!python/name:material.plugins.tags.casefold\n</code></pre> <p>You can also define your own comparison function which must return a tag value (as a string) that is used for sorting, and reference it accordingly.</p> <code>tags_compare_reverse</code> <p> insiders-4.26.2 \u00b7  Default: <code>false</code> \u2013 This option specifies whether tags are sorted in reverse order. It is mainly provided for completeness. To change direction, use:</p> <pre><code>plugins:\n- tags:\ntags_compare_reverse: true\n</code></pre> <code>tags_allowed</code> <p> insiders-4.25.0 \u00b7   Default: none \u2013 This option allows the author to define explicitly which tags are allowed to be used on pages. If this setting is omitted, the built-in tags plugin won't check tag names. Use this option to define a list of tags in order to catch typos:</p> <pre><code>plugins:\n- tags:\ntags_allowed:\n- HTML5\n- JavaScript\n- CSS\n</code></pre>"},{"location":"v10/setup/setting-up-tags/#tag-icons-and-identifiers","title":"Tag icons and identifiers","text":"<p> 8.5.0 \u00b7  Experimental</p> <p>Each tag can be associated with an icon, which is then rendered inside the tag. Before assigning icons to tags, associate each tag with a unique identifier, by adding the following to <code>mkdocs.yml</code>:</p> <pre><code>extra:\ntags:\n&lt;tag&gt;: &lt;identifier&gt; # (1)!\n</code></pre> <ol> <li> <p>The identifier can only include alphanumeric characters, as well as dashes     and underscores. For example, if you have a tag <code>Compatibility</code>, you can     set <code>compat</code> as an identifier:</p> <pre><code>extra:\ntags:\nCompatibility: compat\n</code></pre> <p>Identifiers can be reused between tags. Tags which are not explicitly associated will use the default tag icon which is </p> </li> </ol> <p>Next, each identifier can be associated with an icon, even a custom icon, by adding the following lines to <code>mkdocs.yml</code> under the <code>theme.icon</code> configuration  setting:</p> Tag iconTag default icon <pre><code>theme:\nicon:\ntag:\n&lt;identifier&gt;: &lt;icon&gt; # (1)!\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <pre><code>theme:\nicon:\ntag:\ndefault: &lt;icon&gt;\n</code></pre> Expand to inspect example <pre><code>theme:\nicon:\ntag:\nhtml: fontawesome/brands/html5\njs: fontawesome/brands/js\ncss:  fontawesome/brands/css3\nextra:\ntags:\nHTML5: html\nJavaScript: js\nCSS: css\n</code></pre>"},{"location":"v10/setup/setting-up-tags/#usage","title":"Usage","text":""},{"location":"v10/setup/setting-up-tags/#adding-tags","title":"Adding tags","text":"<p>When the built-in tags plugin is enabled, tags can be added for a document with the front matter <code>tags</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\ntags:\n  - HTML5\n  - JavaScript\n  - CSS\n---\n\n...\n</code></pre> <p>The page will now render with those tags above the main headline and within the search preview, which now allows to find pages by tags.</p> How to set tags for an entire folder? <p>With the help of the built-in meta plugin, you can ensure that tags are set for an entire section and all nested pages, by creating a <code>.meta.yml</code> file in the corresponding folder with the following content:</p> <pre><code>tags:\n- HTML5\n- JavaScript\n- CSS\n</code></pre> <p>The tags set in <code>.meta.yml</code> are merged and deduplicated with the tags defined for a page, which means you can define common tags in <code>.meta.yml</code> and then add specific tags for each page. The tags in <code>.meta.yml</code> are appended.</p>"},{"location":"v10/setup/setting-up-tags/#adding-a-tags-index","title":"Adding a tags index","text":"<p>The built-in tags plugin allows to define a file to render a tags index, which can be any page that is part of the <code>nav</code> section. To add a tags index, create a page, e.g. <code>tags.md</code>:</p> <pre><code># Tags\nFollowing is a list of relevant tags:\n\n[TAGS]\n</code></pre> <p>The <code>[TAGS]</code> marker specifies the position of the tags index, i.e. it is replaced with the actual tags index when the page is rendered. You can include arbitrary content before and after the marker:</p> <p></p>"},{"location":"v10/setup/setting-up-tags/#hiding-tags-on-a-page","title":"Hiding tags on a page","text":"<p>While the tags are rendered above the main headline, sometimes, it might be desirable to hide them for a specific page, which can be achieved with the front matter <code>hide</code> property:</p> <pre><code>---\nhide:\n- tags\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/setup/setting-up-the-footer/","title":"Setting up the footer","text":"<p>The footer of your project documentation is a great place to add links to websites or platforms you or your company are using as additional marketing  channels, e.g.  or , which you can easily configure via <code>mkdocs.yml</code>.</p>"},{"location":"v10/setup/setting-up-the-footer/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-the-footer/#navigation","title":"Navigation","text":"<p> 9.0.0 \u00b7  Feature flag</p> <p>The footer can include links to the previous and next page of the current page. If you wish to enable this behavior, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- navigation.footer\n</code></pre>"},{"location":"v10/setup/setting-up-the-footer/#social-links","title":"Social links","text":"<p> 1.0.0 \u00b7  Default: none</p> <p>Social links are rendered next to the copyright notice as part of the  footer of your project documentation. Add a list of social links in <code>mkdocs.yml</code>  with:</p> <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon # (1)!\nlink: https://fosstodon.org/@squidfunk\n</code></pre> <ol> <li> <p>Enter a few keywords to find the perfect icon using our icon search and     click on the shortcode to copy it to your clipboard:</p> <p> <ol></ol> </p> </li> </ol> <p>The following properties are available for each link:</p> <code>icon</code> <p> Default: none \u00b7  Required \u2013 This property must contain a valid path to any icon bundled with the theme, or the build will not succeed. Some popular choices:</p> <ul> <li> \u2013 <code>fontawesome/brands/mastodon</code> automatically adds <code>rel=me</code></li> <li> \u2013 <code>fontawesome/brands/twitter</code></li> <li> \u2013 <code>fontawesome/brands/github</code></li> <li> \u2013 <code>fontawesome/brands/docker</code></li> <li> \u2013 <code>fontawesome/brands/facebook</code></li> <li> \u2013 <code>fontawesome/brands/medium</code></li> <li> \u2013 <code>fontawesome/brands/instagram</code></li> <li> \u2013 <code>fontawesome/brands/linkedin</code></li> <li> \u2013 <code>fontawesome/brands/pied-piper-alt</code></li> <li> \u2013 <code>fontawesome/brands/slack</code></li> <li> \u2013 <code>fontawesome/brands/discord</code></li> </ul> <code>link</code> <p> Default: none \u00b7  Required \u2013 This property must be set to a relative or absolute URL including the URI  scheme. All URI schemes are supported, including <code>mailto</code> and <code>bitcoin</code>:</p>  Mastodon Email <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon\nlink: https://fosstodon.org/@squidfunk\n</code></pre> <pre><code>extra:\nsocial:\n- icon: fontawesome/solid/paper-plane\nlink: mailto:&lt;email-address&gt;\n</code></pre> <code>name</code> <p> Default: domain name from <code>link</code>, if available \u2013 This property is used as the link's <code>title</code> attribute and can be set to a  discernable name to improve accessibility:</p> <pre><code>extra:\nsocial:\n- icon: fontawesome/brands/mastodon\nlink: https://fosstodon.org/@squidfunk\nname: squidfunk on Fosstodon\n</code></pre>"},{"location":"v10/setup/setting-up-the-footer/#copyright-notice","title":"Copyright notice","text":"<p> 0.1.0 \u00b7  Default: none</p> <p>A custom copyright banner can be rendered as part of the footer, which is displayed next to the social links. It can be defined as part of <code>mkdocs.yml</code>:</p> <pre><code>copyright: Copyright &amp;copy; 2016 - 2020 Martin Donath\n</code></pre>"},{"location":"v10/setup/setting-up-the-footer/#generator-notice","title":"Generator notice","text":"<p> 7.3.0 \u00b7  Default: <code>true</code></p> <p>The footer displays a Made with Material for MkDocs notice to denote how the site was generated. The notice can be removed with the following option via <code>mkdocs.yml</code>:</p> <pre><code>extra:\ngenerator: false\n</code></pre> <p>Please read this before removing the generator notice</p> <p>The subtle Made with Material for MkDocs hint in the footer is one of the reasons why this project is so popular, as it tells the user how the site is generated, helping new users to discover this project. Before removing please consider that you're enjoying the benefits of @squidfunk's work for free, as this project is Open Source and has a permissive license. Thousands of hours went into this project, most of them without any financial return.</p> <p>Thus, if you remove this notice, please consider sponsoring the project. Thank you </p>"},{"location":"v10/setup/setting-up-the-footer/#usage","title":"Usage","text":""},{"location":"v10/setup/setting-up-the-footer/#hiding-prevnext-links","title":"Hiding prev/next links","text":"<p>The footer navigation showing links to the previous and next page can be hidden with the front matter <code>hide</code> property. Add the following lines at the top of a  Markdown file:</p> <pre><code>---\nhide:\n- footer\n---\n# Document title\n...\n</code></pre>"},{"location":"v10/setup/setting-up-the-footer/#customization","title":"Customization","text":""},{"location":"v10/setup/setting-up-the-footer/#custom-copyright","title":"Custom copyright","text":"<p> 8.0.0 \u00b7  Customization</p> <p>In order to customize and override the copyright notice, extend the theme and override the <code>copyright.html</code> partial, which normally includes the <code>copyright</code> property set in <code>mkdocs.yml</code>.</p>"},{"location":"v10/setup/setting-up-the-header/","title":"Setting up the header","text":"<p>Material for MkDocs' header can be customized to show an announcement bar that  disappears upon scrolling, and provides some options for further configuration. It also includes the search bar and a place to display your project's git repository, as explained in those dedicated guides.</p>"},{"location":"v10/setup/setting-up-the-header/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-the-header/#automatic-hiding","title":"Automatic hiding","text":"<p> 6.2.0 \u00b7  Feature flag</p> <p>When autohiding is enabled, the header is automatically hidden when the user scrolls past a certain threshold, leaving more space for content. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- header.autohide\n</code></pre>"},{"location":"v10/setup/setting-up-the-header/#announcement-bar","title":"Announcement bar","text":"<p> 5.0.0 \u00b7  Customization</p> <p>Material for MkDocs includes an announcement bar, which is the perfect place to display project news or other important information to the user. When the user scrolls past the header, the bar will automatically disappear. In order to add an announcement bar, extend the theme and override the <code>announce</code> block, which is empty by default:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block announce %}\n  &lt;!-- Add announcement here, including arbitrary HTML --&gt;\n{% endblock %}\n</code></pre>"},{"location":"v10/setup/setting-up-the-header/#mark-as-read","title":"Mark as read","text":"<p> 8.4.0 \u00b7  Feature flag \u00b7  Experimental</p> <p>In order to render temporary announcements that can be marked as read by the user, a button to dismiss the current announcement can be included. Add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>theme:\nfeatures:\n- announce.dismiss\n</code></pre> <p>When the user clicks the button, the current announcement is dismissed and not displayed again until the content of the announcement changes. This is handled automatically.</p> <p>Scroll to the top of this page to see it in action.</p>"},{"location":"v10/setup/setting-up-versioning/","title":"Setting up versioning","text":"<p>Material for MkDocs makes it easy to deploy multiple versions of your project documentation by integrating with external utilities that add those capabilities to MkDocs, i.e. mike. When deploying a new version, older versions of your documentation remain untouched.</p>"},{"location":"v10/setup/setting-up-versioning/#configuration","title":"Configuration","text":""},{"location":"v10/setup/setting-up-versioning/#versioning","title":"Versioning","text":"<p> 7.0.0 \u00b7  Utility</p> <p>mike makes it easy to deploy multiple versions of your project documentation. It integrates natively with Material for MkDocs and can be enabled via <code>mkdocs.yml</code>:</p> <pre><code>extra:\nversion:\nprovider: mike\n</code></pre> <p>This renders a version selector in the header:</p> <p></p> <p>Check out the versioning example to see it in action \u2013 squidfunk.github.io/mkdocs-material-example-versioning</p> <p>Why use mike?</p> <p>mike is built around the idea that once you've generated your docs for a particular version, you should never need to touch that version again. This means you never have to worry about breaking changes in MkDocs, since your old docs (built with an old version of MkDocs) are already generated and sitting in your <code>gh-pages</code> branch.</p> <p>While mike is flexible, it's optimized around putting your docs in a <code>&lt;major&gt;.&lt;minor&gt;</code> directory, with optional aliases (e.g. <code>latest</code> or <code>dev</code>) to particularly notable versions. This makes it easy to make permalinks to whatever version of the documentation you want to direct people to.</p>"},{"location":"v10/setup/setting-up-versioning/#version-warning","title":"Version warning","text":"<p> 8.0.0 \u00b7  Customization</p> <p>If you're using versioning, you might want to display a warning when the user visits any other version than the latest version. Using theme extension, you can override the <code>outdated</code> block:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block outdated %}\n  You're not viewing the latest version.\n  &lt;a href=\"{{ '../' ~ base_url }}\"&gt; &lt;!-- (1)! --&gt;\n&lt;strong&gt;Click here to go to latest.&lt;/strong&gt;\n&lt;/a&gt;\n{% endblock %}\n</code></pre> <ol> <li>Given this value for the <code>href</code> attribute, the link will always redirect to      the root of your site, which will then redirect to the latest version. This     ensures that older versions of your site do not depend on a specific alias,     e.g. <code>latest</code>, to allow for changing the alias later on without breaking     earlier versions.</li> </ol> <p>This will render a version warning above the header:</p> <p></p> <p>The default version is identified by the <code>latest</code> alias. If you wish to set another alias as the latest version, e.g. <code>stable</code>, add the following lines to <code>mkdocs.yml</code>:</p> <pre><code>extra:\nversion:\ndefault: stable # (1)!\n</code></pre> <ol> <li> <p>You can also define multiple aliases as the default version, e.g. <code>stable</code>     and <code>development</code>.</p> <pre><code>extra:\nversion:\ndefault:\n- stable\n- development\n</code></pre> <p>Now every version that has the <code>stable</code> and <code>development</code> aliases will not display the version warning.</p> </li> </ol> <p>Make sure one alias matches the default version, as this is where users are redirected to.</p>"},{"location":"v10/setup/setting-up-versioning/#usage","title":"Usage","text":"<p>While this section outlines the basic workflow for publishing new versions,  it's best to check out mike's documentation to make yourself familiar with its mechanics.</p>"},{"location":"v10/setup/setting-up-versioning/#publishing-a-new-version","title":"Publishing a new version","text":"<p>If you want to publish a new version of your project documentation, choose a version identifier and update the alias set as the default version with:</p> <pre><code>mike deploy --push --update-aliases 0.1 latest\n</code></pre> <p>Note that every version will be deployed as a subdirectory of your <code>site_url</code>, e.g.:</p> <ul> <li>docs.example.com/0.1/</li> <li>docs.example.com/0.2/</li> <li>...</li> </ul>"},{"location":"v10/setup/setting-up-versioning/#setting-a-default-version","title":"Setting a default version","text":"<p>When starting with mike, a good idea is to set an alias as a default version, e.g. <code>latest</code>, and when publishing a new version, always update the alias to point to the latest version:</p> <pre><code>mike set-default --push latest\n</code></pre> <p>When publishing a new version, mike will create a redirect in the root of your project documentation to the version associated with the alias:</p> <p>docs.example.com docs.example.com/0.1</p>"},{"location":"v10/setup/dependencies/image-processing/","title":"Image processing","text":"<p>Material for MkDocs depends on several libraries to allow for image processing as part of the build pipeline, including social cards and image optimization. For this reason, a few external libraries must be installed on the host system. This section explains how to install them.</p>"},{"location":"v10/setup/dependencies/image-processing/#dependencies","title":"Dependencies","text":"<p>Install the Python dependencies for image processing with:</p> <pre><code>pip install pillow cairosvg\n</code></pre>"},{"location":"v10/setup/dependencies/image-processing/#cairo-graphics","title":"Cairo Graphics","text":"<p>Cairo Graphics is a graphics library and dependency of Pillow, which Material for MkDocs makes use of for generating social cards and performing image optimization. See the following section which explains how to install Cairo Graphics and its dependencies on your system:</p>  macOS Windows Linux <p>Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>As stated in the installation guide, the easiest way to get up and running with the Cairo Graphics library on Windows is by installing GTK+, since it has Cairo as a dependency. You can also download and install a precompiled GTK runtime.</p> <p>There are several package managers for Linux with varying availability per distribution. The installation guide explains how to install the Cairo Graphics library for your distribution:</p>  Ubuntu Fedora openSUSE <pre><code>apt-get install libcairo2-dev libfreetype6-dev libffi-dev libjpeg-dev libpng-dev libz-dev\n</code></pre> <pre><code>yum install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel\n</code></pre> <pre><code>zypper install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel\n</code></pre> <p>The following environments come with a preinstalled version of Cairo Graphics:</p> <ul> <li> No installation needed in Docker image</li> <li> No installation needed in GitHub Actions (Ubuntu)</li> </ul>"},{"location":"v10/setup/dependencies/image-processing/#pngquant","title":"pngquant","text":"<p>pngquant is an excellent library for lossy PNG compression, and a direct dependency of the built-in optimize plugin. See the following section which  explains how to install pngquant system:</p>  macOS Windows Linux <p>Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies:</p> <pre><code>brew install pngquant\n</code></pre> <p>Installing pngquant on Windows is a little more involved. The  pngquant-winbuild repository contains a guide on how to set up an  environment for building pngquant on Windows.</p> <p>All popular Linux distributions, regardless of package manager, should allow to install pngquant with the bundled package manager. For example, on Ubuntu, pngquant can be installed with:</p> <pre><code>apt-get install pngquant\n</code></pre> <p>The same is true for <code>yum</code> and <code>zypper</code>.</p>"},{"location":"v10/setup/extensions/","title":"Extensions","text":"<p>Markdown is a very small language with a kind-of reference implementation called John Gruber's Markdown. Python Markdown and Python Markdown Extensions are two packages that enhance the Markdown writing experience, adding useful syntax extensions for technical writing.</p>"},{"location":"v10/setup/extensions/#supported-extensions","title":"Supported extensions","text":"<p>The following extensions are all supported by Material for MkDocs and therefore  strongly recommended. Click on each extension to learn about its purpose and configuration:</p> <ul> <li>Abbreviations</li> <li>Admonition</li> <li>Arithmatex</li> <li>Attribute Lists</li> <li>BetterEm</li> <li>Caret, Mark &amp; Tilde</li> <li>Critic</li> <li>Definition Lists</li> <li>Details</li> <li>Emoji</li> <li>Footnotes</li> <li>Highlight</li> <li>Keys</li> <li>Markdown in HTML</li> <li>SmartSymbols</li> <li>Snippets</li> <li>SuperFences</li> <li>Tabbed</li> <li>Table of Contents</li> <li>Tables</li> <li>Tasklist</li> </ul>"},{"location":"v10/setup/extensions/#configuration","title":"Configuration","text":"<p>Extensions are configured as part of <code>mkdocs.yml</code> \u2013 the MkDocs configuration file. The following sections contain two example configurations to bootstrap your documentation project.</p>"},{"location":"v10/setup/extensions/#minimal-configuration","title":"Minimal configuration","text":"<p>This configuration is a good starting point for when you're using Material for  MkDocs for the first time. The best idea is to explore the reference, and  gradually add what you want to use:</p> <pre><code>markdown_extensions:\n# Python Markdown\n- toc:\npermalink: true\n# Python Markdown Extensions\n- pymdownx.highlight\n- pymdownx.superfences\n</code></pre>"},{"location":"v10/setup/extensions/#recommended-configuration","title":"Recommended configuration","text":"<p>This configuration enables all Markdown-related features of Material for MkDocs and is great for experienced users bootstrapping a new documentation project:</p> <pre><code>markdown_extensions:\n# Python Markdown\n- abbr\n- admonition\n- attr_list\n- def_list\n- footnotes\n- md_in_html\n- toc:\npermalink: true\n# Python Markdown Extensions\n- pymdownx.arithmatex:\ngeneric: true\n- pymdownx.betterem:\nsmart_enable: all\n- pymdownx.caret\n- pymdownx.details\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\n- pymdownx.highlight\n- pymdownx.inlinehilite\n- pymdownx.keys\n- pymdownx.mark\n- pymdownx.smartsymbols\n- pymdownx.superfences\n- pymdownx.tabbed:\nalternate_style: true\n- pymdownx.tasklist:\ncustom_checkbox: true\n- pymdownx.tilde\n</code></pre>"},{"location":"v10/setup/extensions/python-markdown-extensions/","title":"Python Markdown Extensions","text":"<p>The Python Markdown Extensions package is an excellent collection of additional extensions perfectly suited for advanced technical writing. Material for MkDocs lists this package as an explicit dependency, so it's automatically installed with a supported version.</p>"},{"location":"v10/setup/extensions/python-markdown-extensions/#supported-extensions","title":"Supported extensions","text":"<p>In general, all extensions that are part of Python Markdown Extensions should work with Material for MkDocs. The following list includes all extensions that are natively supported, meaning they work without any further adjustments.</p>"},{"location":"v10/setup/extensions/python-markdown-extensions/#arithmatex","title":"Arithmatex","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Arithmatex extension allows for rendering of block and inline block equations and integrates seamlessly with MathJax1 \u2013 a library for mathematical typesetting. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.arithmatex:\ngeneric: true\n</code></pre> <p>Besides enabling the extension in <code>mkdocs.yml</code>, a MathJax configuration and  the JavaScript runtime need to be included, which can be done with a few lines of additional JavaScript:</p> <code>docs/javascripts/mathjax.js</code> <code>mkdocs.yml</code> <pre><code>window.MathJax = {\ntex: {\ninlineMath: [[\"\\\\(\", \"\\\\)\"]],\ndisplayMath: [[\"\\\\[\", \"\\\\]\"]],\nprocessEscapes: true,\nprocessEnvironments: true\n},\noptions: {\nignoreHtmlClass: \".*|\",\nprocessHtmlClass: \"arithmatex\"\n}\n};\ndocument$.subscribe(() =&gt; {\nMathJax.typesetPromise()\n})\n</code></pre> <pre><code>extra_javascript:\n- javascripts/mathjax.js\n- https://polyfill.io/v3/polyfill.min.js?features=es6\n- https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using block syntax</li> <li>Using inline block syntax</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#betterem","title":"BetterEm","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The BetterEm extension improves the detection of Markup to emphasize text in Markdown using special characters, i.e. for <code>**bold**</code> and <code>_italic_</code> formatting. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.betterem\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the BetterEm  documentation for more information.</p>"},{"location":"v10/setup/extensions/python-markdown-extensions/#caret-mark-tilde","title":"Caret, Mark &amp; Tilde","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Caret, Mark and Tilde extensions add the ability to highlight text and define sub- and superscript using a simple syntax. Enable them together via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.caret\n- pymdownx.mark\n- pymdownx.tilde\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Caret, Mark and Tilde documentation for guidance.</p> <p>See reference for usage:</p> <ul> <li>Highlighting text</li> <li>Sub- and superscripts</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#critic","title":"Critic","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Critic extension allows for the usage of Critic Markup to highlight added, deleted or updated sections in a document, i.e. for tracking changes in Markdown syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.critic\n</code></pre> <p>The following configuration options are supported:</p> <code>mode</code> <p> Default: <code>view</code> \u2013 This option defines how the markup  should be parsed, i.e. whether to just <code>view</code> all suggested changes, or alternatively <code>accept</code> or <code>reject</code> them:</p> View changesAccept changesReject changes <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: view\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: accept\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.critic:\nmode: reject\n</code></pre> <p>See reference for usage:</p> <ul> <li>Highlighting changes</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#details","title":"Details","text":"<p> 1.9.0 \u00b7  Extension</p> <p>The Details extension supercharges the Admonition extension, making the resulting call-outs collapsible, allowing them to be opened and closed by the user. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.details\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Collapsible blocks</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#emoji","title":"Emoji","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Emoji extension automatically inlines bundled and custom icons and emojis in <code>*.svg</code> file format into the resulting HTML page. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji # (1)!\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <ol> <li>Python Markdown Extensions uses the <code>pymdownx</code> namespace, but in order to     support the inlining of icons, the <code>materialx</code> namespace must be used, as it     extends the functionality of <code>pymdownx</code>.</li> </ol> <p>The following configuration options are supported:</p> <code>emoji_index</code> <p> Default: <code>emojione</code> \u2013 This option defines which set of emojis is used for rendering. Note that the use of <code>emojione</code> is not recommended due to restrictions in licensing:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\n</code></pre> <code>emoji_generator</code> <p> Default: <code>to_png</code> \u2013 This option defines how the resolved emoji or icon shortcode is render. Note that icons can only be used together with the <code>to_svg</code> configuration:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre> <code>options.custom_icons</code> <p> Default: none \u2013 This option allows to list folders with additional icon sets to be used in Markdown or <code>mkdocs.yml</code>, which is  explained in more detail in the icon customization guide:</p> <pre><code>markdown_extensions:\n- pymdownx.emoji:\nemoji_index: !!python/name:materialx.emoji.twemoji\nemoji_generator: !!python/name:materialx.emoji.to_svg\noptions:\ncustom_icons:\n- overrides/.icons\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using emojis</li> <li>Using icons</li> <li>Using icons in templates</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#highlight","title":"Highlight","text":"<p> 5.0.0 \u00b7  Extension \u00b7  Supersedes CodeHilite</p> <p>The Highlight extension adds support for syntax highlighting of code blocks (with the help of SuperFences) and inline code blocks (with the help of InlineHilite). Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\n- pymdownx.superfences # (1)!\n</code></pre> <ol> <li>Highlight is used by the SuperFences extension to     perform syntax highlighting on code blocks, not the other way round, which     is why this extension also needs to be enabled.</li> </ol> <p>The following configuration options are supported:</p> <code>use_pygments</code> <p> Default: <code>true</code> \u2013 This option allows to control whether highlighting should be carried out during build time using Pygments or in the browser with a JavaScript syntax highlighter:</p> PygmentsJavaScript <pre><code>markdown_extensions:\n- pymdownx.highlight:\nuse_pygments: true\n- pymdownx.superfences\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nuse_pygments: false\n</code></pre> <p>As an example, Highlight.js, a JavaScript syntax highlighter, can be  integrated with some additional JavaScript and an additional style sheet in <code>mkdocs.yml</code>:</p> <code>docs/javascripts/highlight.js</code> <code>mkdocs.yml</code> <pre><code>document$.subscribe(() =&gt; {\nhljs.highlightAll()\n})\n</code></pre> <pre><code>extra_javascript:\n- https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js\n- javascripts/highlight.js\nextra_css:\n- https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css\n</code></pre> <p>Note that Highlight.js has no affiliation with the Highlight extension.</p> <p>All following configuration options are only compatible with build-time syntax highlighting using Pygments, so they don't apply if <code>use_pygments</code> is set to <code>false</code>.</p> <code>pygments_lang_class</code> <p> Default: <code>false</code> \u2013 This option instructs Pygments to add a CSS class to identify the language of the code block, which is essential for custom annotation markers to function:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\npygments_lang_class: true\n</code></pre> <code>auto_title</code> <p> Default: <code>false</code> \u2013 This option will automatically add a title to all code blocks that shows the name of the language being used, e.g. <code>Python</code> is printed for a <code>py</code> block:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nauto_title: true\n</code></pre> <code>linenums</code> <p> Default: <code>false</code> \u2013 This option will add line numbers to all code blocks. If you wish to add line numbers to some, but not all code blocks, consult the section on adding line numbers in the code block reference, which also contains some tips on working with line numbers:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nlinenums: true\n</code></pre> <code>linenums_style</code> <p> Default: <code>table</code> \u2013 The Highlight extension provides three ways to add line numbers, two of which are supported by Material for MkDocs. While <code>table</code> wraps a code block in a <code>&lt;table&gt;</code> element, <code>pymdownx-inline</code> renders line numbers as part of the line itself:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nlinenums_style: pymdownx-inline\n</code></pre> <p>Note that <code>inline</code> will put line numbers next to the actual code, which means that they will be included when selecting text with the cursor or  copying a code block to the clipboard. Thus, the usage of either <code>table</code> or <code>pymdownx-inline</code> is recommended.</p> <code>anchor_linenums</code> <p> 8.1.0 \u00b7  Default: <code>false</code> \u2013 If a code blocks contains line numbers, enabling this setting will wrap them with anchor links, so they can be hyperlinked and shared more easily:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\n</code></pre> <code>line_spans</code> <p> Default: none \u2013 When this option is set, each line of a code block is wrapped in a <code>span</code>, which is essential for features like line highlighting to work correctly:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight:\nline_spans: __span\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using code blocks</li> <li>Adding a title</li> <li>Adding line numbers</li> <li>Highlighting specific lines</li> <li>Custom syntax theme</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#inlinehilite","title":"InlineHilite","text":"<p> 5.0.0 \u00b7  Extension</p> <p>The InlineHilite extension add support for syntax highlighting of inline code  blocks. It's built on top of the Highlight extension, from which it sources its configuration. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.highlight\n- pymdownx.inlinehilite\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the <code>css_class</code> option, which must not be changed. See the  InlineHilite documentation for guidance.</p> <p>See reference for usage:</p> <ul> <li>Highlighting inline code blocks</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#keys","title":"Keys","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Keys extension adds a simple syntax to allow for the rendering of keyboard  keys and combinations, e.g. Ctrl+Alt+Del. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.keys\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the <code>class</code> option, which must not be changed. See the  Keys documentation for more information.</p> <p>See reference for usage:</p> <ul> <li>Adding keyboard keys</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#smartsymbols","title":"SmartSymbols","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The SmartSymbols extension converts some sequences of characters into their  corresponding symbols, e.h. copyright symbols or fractions. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.smartsymbols\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the SmartSymbols  documentation for guidance.</p>"},{"location":"v10/setup/extensions/python-markdown-extensions/#snippets","title":"Snippets","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Snippets extension adds the ability to embed content from arbitrary files into a document, including other documents or source files, by using a simple syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.snippets\n</code></pre> <p>The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Snippets  documentation for more information.</p> <p>See reference for usage:</p> <ul> <li>Adding a glossary</li> <li>Embedding external files</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#superfences","title":"SuperFences","text":"<p> 0.1.0 \u00b7  Extension \u00b7  Supersedes Fenced Code Blocks</p> <p>The SuperFences extension allows for arbitrary nesting of code and content blocks inside each other, including admonitions, tabs, lists and all other elements. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences\n</code></pre> <p>The following configuration options are supported:</p> <code>custom_fences</code> <p> Default: none \u2013 This option allows to define a handler for custom fences, e.g. to preserve the definitions of Mermaid.js diagrams to be interpreted in the browser:</p> <pre><code>markdown_extensions:\n- pymdownx.superfences:\ncustom_fences:\n- name: mermaid\nclass: mermaid\nformat: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <p>Note that this will primarily prevent syntax highlighting from being applied. See the reference on diagrams to learn how Mermaid.js is integrated with Material for MkDocs.</p> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using code blocks</li> <li>Using content tabs</li> <li>Using flowcharts</li> <li>Using sequence diagrams</li> <li>Using state diagrams</li> <li>Using class diagrams</li> <li>Using entity-relationship diagrams</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#tabbed","title":"Tabbed","text":"<p> 5.0.0 \u00b7  Extension</p> <p>The Tabbed extension allows the usage of content tabs, a simple way to group related content and code blocks under accessible tabs. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true\n</code></pre> <p>The following configuration options are supported:</p> <code>alternate_style</code> <p> 7.3.1 \u00b7  Default: <code>false</code> \u00b7  Required \u2013  This option enables the content tabs alternate style, which has better behavior on mobile viewports, and is the only supported style:</p> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nalternate_style: true\n</code></pre> <code>slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions:</p> UnicodeUnicode, case-sensitive <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>markdown_extensions:\n- pymdownx.tabbed:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Grouping code blocks</li> <li>Grouping other content</li> <li>Embedded content</li> </ul>"},{"location":"v10/setup/extensions/python-markdown-extensions/#tasklist","title":"Tasklist","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Tasklist extension allows for the usage of GitHub Flavored Markdown inspired task lists, following the same syntactical conventions. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <p>The following configuration options are supported:</p> <code>custom_checkbox</code> <p> Default: <code>false</code> \u00b7 This option toggles the rendering style of checkboxes, replacing native checkbox styles with beautiful icons,  and is therefore recommended:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\ncustom_checkbox: true\n</code></pre> <code>clickable_checkbox</code> <p> Default: <code>false</code> \u00b7 This option toggles whether checkboxes are clickable. As the state is not persisted, the use of this  option is rather discouraged from a user experience perspective:</p> <pre><code>markdown_extensions:\n- pymdownx.tasklist:\nclickable_checkbox: true\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p> <p>See reference for usage:</p> <ul> <li>Using task lists</li> </ul> <ol> <li> <p>Other libraries like KaTeX are also supported and can be integrated with some additional effort. See the Arithmatex documentation on KaTeX for further guidance, as this is beyond the scope of Material for MkDocs.\u00a0\u21a9</p> </li> </ol>"},{"location":"v10/setup/extensions/python-markdown/","title":"Python Markdown","text":"<p>Material for MkDocs supports a large number of Python Markdown extensions, which is part of what makes it so attractive for technical writing. Following is a list of all supported extensions, linking to the relevant sections of the reference for which features they need to be enabled.</p>"},{"location":"v10/setup/extensions/python-markdown/#supported-extensions","title":"Supported extensions","text":""},{"location":"v10/setup/extensions/python-markdown/#abbreviations","title":"Abbreviations","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Abbreviations extension adds the ability to add a small tooltip to an element, by wrapping it with an <code>abbr</code> tag. Only plain text (no markup) is supported. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- abbr\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Adding abbreviations</li> <li>Adding a glossary</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#admonition","title":"Admonition","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Admonition extension adds support for admonitions, more commonly known as  call-outs, which can be defined in Markdown by using a simple syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- admonition\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Adding admonitions</li> <li>Changing the title</li> <li>Removing the title</li> <li>Supported types</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#attribute-lists","title":"Attribute Lists","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Attribute Lists extension allows to add HTML attributes and CSS classes to almost every Markdown inline- and block-level element with a special syntax. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- attr_list\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using grids</li> <li>Adding buttons</li> <li>Adding tooltips</li> <li>Using icons with colors</li> <li>Using icons with animations</li> <li>Image alignment</li> <li>Image lazy-loading</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#definition-lists","title":"Definition Lists","text":"<p> 1.1.0 \u00b7  Extension</p> <p>The Definition Lists extension adds the ability to add definition lists (more commonly known as description lists \u2013 <code>dl</code> in HTML) via Markdown to a document. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- def_list\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using definition lists</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#footnotes","title":"Footnotes","text":"<p> 1.0.0 \u00b7  Extension</p> <p>The Footnotes extension allows to define inline footnotes, which are then rendered below all Markdown content of a document. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- footnotes\n</code></pre> <p>No configuration options are supported. See reference for usage:</p> <ul> <li>Adding footnote references</li> <li>Adding footnote content</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#markdown-in-html","title":"Markdown in HTML","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Markdown in HTML extension allows for writing Markdown inside of HTML, which is useful for wrapping Markdown content with custom elements. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- md_in_html\n</code></pre> <p>By default, Markdown ignores any content within a raw HTML block-level element. With the <code>md_in_html</code> extension enabled, the content of a raw HTML block-level element can be parsed as Markdown by including a <code>markdown</code> attribute on the opening tag. The <code>markdown</code> attribute will be stripped from the output, while all other attributes will be preserved.</p> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using annotations</li> <li>Using grids</li> <li>Image captions</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#table-of-contents","title":"Table of Contents","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Table of Contents extension automatically generates a table of contents from a document, which Material for MkDocs will render as part of the resulting  page. Enable it via <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- toc:\npermalink: true\n</code></pre> <p>The following configuration options are supported:</p> <code>title</code> <p> 7.3.5 \u00b7  Default: automatically set \u2013 This option sets the title of the table of contents in the right navigation sidebar, which is normally automatically sourced from the translations for the site language as set in <code>mkdocs.yml</code>:</p> <pre><code>markdown_extensions:\n- toc:\ntitle: On this page\n</code></pre> <code>permalink</code> <p> Default: <code>false</code> \u2013 This option adds an anchor link containing the paragraph symbol <code>\u00b6</code> or another custom symbol at the end of each headline, exactly like on the page you're currently viewing, which Material for MkDocs will make appear on hover:</p> \u00b6\u2693\ufe0e <pre><code>markdown_extensions:\n- toc:\npermalink: true\n</code></pre> <pre><code>markdown_extensions:\n- toc:\npermalink: \u2693\ufe0e\n</code></pre> <code>permalink_title</code> <p> Default: <code>Permanent link</code> \u2013 This option sets the title of the anchor link which is shown on hover and read by screen readers. For accessibility reasons, it might be beneficial to change it to a more  discernable name, stating that the anchor links to the section itself:</p> <pre><code>markdown_extensions:\n- toc:\npermalink_title: Anchor link to this section for reference\n</code></pre> <code>slugify</code> <p> Default: <code>headerid.slugify</code> \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions:</p> UnicodeUnicode, case-sensitive <pre><code>markdown_extensions:\n- toc:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\nkwds:\ncase: lower\n</code></pre> <pre><code>markdown_extensions:\n- toc:\nslugify: !!python/object/apply:pymdownx.slugs.slugify\n</code></pre> <code>toc_depth</code> <p> Default: <code>6</code> \u2013 Define the range of levels to be included in the table of contents. This may be useful for project documentation with deeply structured headings to decrease the length of the table of contents, or to remove the table of contents altogether:</p> Hide levels 4-6Hide table of contents <pre><code>markdown_extensions:\n- toc:\ntoc_depth: 3\n</code></pre> <pre><code>markdown_extensions:\n- toc:\ntoc_depth: 0\n</code></pre> <p>The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.</p>"},{"location":"v10/setup/extensions/python-markdown/#tables","title":"Tables","text":"<p> 0.1.0 \u00b7  Extension</p> <p>The Tables extension adds the ability to create tables in Markdown by using a  simple syntax. Enable it via <code>mkdocs.yml</code> (albeit it should be enabled by default):</p> <pre><code>markdown_extensions:\n- tables\n</code></pre> <p>No configuration options are available. See reference for usage:</p> <ul> <li>Using data tables</li> <li>Column alignment</li> </ul>"},{"location":"v10/setup/extensions/python-markdown/#superseded-extensions","title":"Superseded extensions","text":"<p>The following Python Markdown extensions are not (or might not be) supported  anymore, and are therefore not recommended for use. Instead, the alternatives should be considered.</p>"},{"location":"v10/setup/extensions/python-markdown/#fenced-code-blocks","title":"Fenced Code Blocks","text":"<p> 0.1.0 \u00b7  Extension</p> <p>Superseded by SuperFences. This extension might still work, but the SuperFences extension is superior in many ways, as it allows for arbitrary  nesting, and is therefore recommended.</p>"},{"location":"v10/setup/extensions/python-markdown/#codehilite","title":"CodeHilite","text":"<p> 0.1.0 ... 5.5.14 \u00b7  Extension</p> <p>Superseded by Highlight. Support for CodeHilite was dropped in  6.0.0, as Highlight has a better integration with other  essential extensions like SuperFences and InlineHilite.</p>"},{"location":"whats-new/asr-engine/","title":"Configure Speech Recognition","text":"<p>After you configure the Voice channel, you can personalize the ASR Engine by configuring speech recognition preference and language for speech-to-text conversion. You can also add call control parameters.</p> <p>Steps to configure or modify the ASR Engine settings:</p> <ol> <li>Log in to AgentAssist using your credentials.</li> <li>Click Configuration &gt; Speech Recognition. \\     </li> <li>Click Speech Recognition on the ASR engine page. \\     </li> <li>Select your preference in the Speech Recognition Preference list. \\     </li> <li>Select the language-specific dialect in the Dialect list. \\     </li> <li>Click the Add button against Call Control Parameters to add a new call parameter. This helps you to control the call flow behavior using the added parameter(s) in the VoiceXML file. \\     <ol> <li>Enter a parameter name and value in the Name and Value fields. \\  The names and values are used to include the corresponding property in the VoiceXML definition in the IVR system and Session Parameters in the AudioCodes channel. These values defined for a node or a standard response override the global Call Control Parameters defined in the VA IVR /AudioCodes settings page.</li> <li>Click Confirm.</li> <li>Click Save to complete the process. </li> </ol> </li> </ol> <p>[!NOTE] Highlights information that users should take into account, even when skimming.</p> <p>[!IMPORTANT] Crucial information necessary for users to succeed.</p> <p>[!WARNING] Critical content demanding immediate user attention due to potential risks.</p>"},{"location":"whats-new/generative-ai-llm/","title":"Dynamic Conversations Features Specifications","text":"<p>The following dynamic features enable human-like and organic conversations between your VA by leveraging the NLP capabilities of LLM during run time:</p>"},{"location":"whats-new/generative-ai-llm/#supportability-matrix","title":"Supportability Matrix","text":"<p>The following is the dynamic feature supportability matrix.</p> Model/Feature GenAI Node     Answer From Documents     GenAI Prompt     Rephrase Dialog Responses     Zero-shot ML Model     Repeat Responses     Azure OpenAI \u2013 GPT 3     \u2705     \u2705     \u2705     \u2705     \u2705     \u2705     Azure OpenAI \u2013 GPT 3.5     \u274c     \u2705     \u2705     \u2705     \u274c     \u2705     Azure OpenAI \u2013 GPT 4     \u274c     \u2705     \u274c     \u274c     \u274c     \u274c     Azure OpenAI \u2013 GPT 4 (32 K)     \u274c     \u2705     \u274c     \u274c     \u274c     \u274c     OpenAI \u2013 GPT 3     \u2705     \u2705     \u2705     \u2705     \u2705     \u2705     OpenAI \u2013 GPT 3.5     \u274c     \u2705     \u2705     \u2705     \u274c     \u2705     OpenAI \u2013 GPT 4     \u274c     \u2705     \u274c     \u274c     \u274c     \u274c     Anthropic \u2013 Claude Instant     \u274c     \u274c     \u2705     \u2705     \u274c     \u2705     Anthropic \u2013 Claude     \u274c     \u274c     \u2705     \u2705     \u274c     \u2705"},{"location":"whats-new/generative-ai-llm/#genai-node","title":"GenAI Node","text":"<p>When enabled, this feature lets you add an GenAI Node to Dialog Tasks. This node allows you to collect Entities from end-users in a free-flowing conversation (in the selected English/Non-English Bot Language) using LLM and Generative AI in the background. You can define the entities to be collected as well as rules &amp; scenarios in English and Non-English Bot languages. You can configure node properties just like any other node. You can also use the GenAI Node across Dialog Tasks.</p> <p></p> <p>Usage</p> <p>When creating or editing a Dialog Task that\u2019s created manually or auto-generated, you can find a node called GenAI Node within your nodes list. \\ When this feature is disabled, the node is unavailable within the Dialog Builder. Learn more.</p>"},{"location":"whats-new/generative-ai-llm/#answer-from-documents","title":"Answer From Documents","text":"<p>This feature leverages a Large Language Model (LLM) and Generative AI models from OpenAI to generate answers for FAQs by processing uploaded documents in an unstructured PDF format and user queries.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image2.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Usage</p> <p>After redacting personally identifiable information, the uploaded documents and the end-user queries are shared with OpenAI to curate the answers.</p> <p>Once you meet the prerequisites and enable the feature:</p> <ol> <li>You should upload the PDF document(s) to be shared with the third-party system (OpenAI). You can upload a maximum of 10 documents with a size of not more than 5 MB.</li> <li>The uploaded documents are listed under the Answer from Documents section with the following details:<ul> <li>Upload Name</li> <li>Uploaded by</li> <li>Uploaded on</li> <li>Status (Active/Inactive)</li> <li>Actions (View and Delete File)</li> </ul> </li> <li>A good practice is to test the answer generation by asking the VA a question directly related to the contents of your uploaded documents. Learn more.</li> <li>You can view, delete, and disable the uploaded documents.</li> <li>The VA provides answers only from uploaded documents that are active, whereas disabled documents are ignored.</li> </ol> <p>If the feature is disabled, you won\u2019t be able to send queries to LLMs as a fallback. Learn more.</p>"},{"location":"whats-new/generative-ai-llm/#genai-prompt","title":"GenAI Prompt","text":"<p>This feature lets you define custom user prompts based on the conversation context and the response from the LLMs. You can define the subsequent conversation flow by selecting a specific AI model, tweaking its settings, and previewing the response for the prompt.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image3.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Usage</p> <ol> <li>** When building the Dialog Flow, click the **\u201c+\u201d **button, and select the **GenAI Prompt **node. \\ **</li> </ol> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image4.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <ol> <li>Configuring the Component Properties in the following sections helps set up the node:</li> <li>General Settings: Provide** Name** and Display Name for the node and write your own OpenAI Prompt.</li> <li>**Advanced Settings: **Fine-tune the model\u2019s behavior and tweak its settings as required for the following:<ul> <li>Model</li> <li>System Context</li> <li>Temperature</li> <li>Max Tokens</li> </ul> </li> <li>Advanced Controls: Select the maximum wait time (Timeout) to receive a response from the LLM and the bot\u2019s response (Timeout Error Handling) when a timeout error occurs.</li> <li>When you add custom tags to the current message, user profile, and **session **under **Instance Properties, **you can build custom profiles for the bot conversation. .</li> <li>Configuring node connections on an instance lets you define the connection rules for the conversation using transition conditions. This lets the conversation follow specific paths based on the user\u2019s input.</li> </ol> <p>If this feature is disabled, you cannot configure the ML model to build custom prompts using OpenAI for different use cases. Learn more.</p>"},{"location":"whats-new/generative-ai-llm/#rephrase-dialog-responses","title":"Rephrase Dialog Responses","text":"<p>This feature sends all User Prompts, Error Prompts, and Bot Responses to the Generative AI along with the conversation context, which depends on the configured number of user inputs. Responses are rephrased in English or the selected Non-English Bot Language based on the context and user emotion, providing a more empathetic, natural, and contextual conversation experience to the end-user. You can give instructions (additional instructions) in English or any other bot language you select.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image5.gif). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>Usage</p> <p>When configuring a Message, Entity, or Confirmation node, you can enable the **Rephrase Response **feature (disabled by default). This lets you set the number of user inputs sent to OpenAI/Anthropic Claude-1 based on the selected model as context for rephrasing the response sent through the node. You can choose between 0 and 5, where 0 means that no previous input is considered, while 5 means that the previous. 5 responses are sent as context.</p> <p>When this feature is disabled, the Rephrase Response section is not visible within your node\u2019s Component Properties.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image6.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p>"},{"location":"whats-new/generative-ai-llm/#zero-shot-ml-model","title":"Zero-shot ML Model","text":"<p>This feature uses a pre-trained language and Open AI LLM models to help the ML Engine identify the relevant intents from user utterances based on semantic similarity. By identifying the logical intent during run time, this feature eliminates the need for training data. The Zero-shot ML model requires well-defined intents to work well. This training approach is well-suited for virtual assistants with relatively fewer intents and distinct use cases.</p> <p>&gt;&gt;&gt;&gt;&gt;  gd2md-html alert: inline image link here (to images/image7.png). Store image on your image server and adjust path/filename/extension if necessary. (Back to top)(Next alert)&gt;&gt;&gt;&gt;&gt; </p> <p></p> <p>**Usage **</p> <p>Before performing utterance testing, the user selects the **_Zero-Shot Learning Model with OpenAI _**Network Type. During utterance testing, the user provides a more descriptive input with a subject, object, and nouns. Once the test runs, the system identifies the most logical intent as the definitive match by comparing the following:</p> <ul> <li>User utterance input</li> <li>Intent names</li> </ul> <p>The identified intent is then displayed as the matched intent.</p> <p>If this feature is disabled, the system won\u2019t identify and display the logical and matched intent during utterance testing. Learn more.</p>"},{"location":"whats-new/generative-ai-llm/#repeat-responses","title":"Repeat Responses","text":"<p>This feature uses LLM to reiterate the recent bot responses when the Repeat Response event is triggered. Bot developers can enable the event and customize the trigger conditions. This empowers end-users to ask the bot to repeat its recent responses at any point during the conversation. Currently, this event is supported for IVR, Audiocodes, and Twilio Voice channels. Learn more.</p>"},{"location":"whats-new/generative-ai-llm/#few-shot-ml-model-not-in-ui","title":"Few-shot ML Model (Not in UI)","text":"<p>The Few-shot network type uses Kore Ai\u2019s hosted embeddings instead of commercial LLM models to train virtual assistants based on task names and training utterances. The Few-shot ML Model identifies the intents and task names based on their semantic similarity to the training utterances.</p> <p>**Usage **</p> <p>Before performing utterance testing, the user selects the **Few-Shot Model (Kore.ai Hosted Embeddings) **network type. </p> <p>During utterance testing, the user provides a more descriptive task name with a subject, object, and nouns, and the training utterances. Once the test runs, the system identifies the most logical intent as the definitive match based on the following:</p> <ul> <li>The default configuration settings</li> <li>User utterance input</li> <li>Task name</li> <li>Intent names</li> </ul> <p>If this feature is disabled, the system won\u2019t identify and display the logically matched intent during utterance testing. Learn more.</p>"},{"location":"whats-new/test/","title":"Test","text":"Q&amp;A_1 <p>Q&amp;A_1_content</p> Q&amp;A_1 <p>Q&amp;A_1_content</p> <ul> <li> <p> HTML for content and structure</p> </li> <li> <p> JavaScript for interactivity</p> </li> <li> <p> CSS for text running out of boxes</p> </li> <li> <p> Internet Explorer ... huh?</p> </li> </ul> Tab 1Tab 2 <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer ... huh?</p> <p>Test  <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]</p> <p> License</p> <p>End of tab</p> <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes  Getting started</p> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site  Reference</p> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines  Customization</p> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]  License</p> <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer ... huh?</p> Tab 1Tab 2 <p>one</p> <p> Introduction to Dialog Tasks A core component of the XO Platform, an essential tool for building conversations that are connected to your business logic. Reference Introduction to Dialog Tasks A core component of the XO Platform,an essential tool for building conversations that are connected to your business logic. Reference Introduction to Dialog Tasks A core component of the XO Platform,an essential tool for building conversations that are connected to your business logic. Reference </p>"},{"location":"whats-new/whats-new-in-this-release/","title":"What\u2019s New","text":"<p>Learn about the new features and enhancements included in v10.1 of Kore.ai Experience Optimization Platform which was released on April 16, 2023.</p> <p>The v10.1 of the Kore.ai XO Platform focuses on leveraging the power of Large Language Models and Generative AI to enable enterprises to create intelligent and context-specific conversational experiences. The release offers a copilot for smart assistance, better conversational capabilities, and delivers personalized responses.</p> <p>The key features and enhancements included in this release are listed below for your reference:</p>"},{"location":"whats-new/whats-new-in-this-release/#smart-copilot-for-iva-development","title":"Smart Copilot for IVA Development","text":""},{"location":"whats-new/whats-new-in-this-release/#enhanced-bot-creation-journey-with-use-case-suggestions","title":"Enhanced Bot Creation Journey with Use Case Suggestions","text":"<p>Create Virtual Assistants faster with the new bot creation process that lets you generate use cases automatically. Dialog Tasks are auto-created along with the bot, providing you with the base framework to fasttrack your VA creation journey. [Learn more].</p>"},{"location":"whats-new/whats-new-in-this-release/#automatic-dialog-generation","title":"Automatic Dialog Generation","text":"<p>This feature auto-generates conversations and dialog flows using the VA\u2019s purpose and intent description provided during the creation process. The Platform uses LLM and generative AI to create suitable Dialog Tasks for Conversation Design, Logic Building &amp; Training by including the required nodes in the flow.</p> <p>You can provide an intent description, and the Platform handles the Conversation Generation for the Dialog Flow. You can preview the conversation flow, view the Bot Action taken, improvise the intent description, and regenerate the conversation to make it more human-like. The nodes and the flow for the Business Logic are automatically built for your conversation, and you only need to configure the flow transition. Learn more .</p> <p></p>"},{"location":"whats-new/whats-new-in-this-release/#training-data-suggestions","title":"Training Data Suggestions","text":"<p>Quickly generate high-quality training data using suggested utterances for each intent. Review and add the utterances to create a robust training set for your bot.  Learn more .</p> <p></p>"},{"location":"whats-new/whats-new-in-this-release/#nlp-batch-test-case-suggestions","title":"NLP Batch Test Case Suggestions","text":"<p>Automatically generate NLP test cases for every intent, including the entity checks. Use the generated utterances to quickly create test suites in the builder.  Learn more .</p> <p></p>"},{"location":"whats-new/whats-new-in-this-release/#conversation-test-cases-suggestions","title":"Conversation Test Cases Suggestions","text":"<p>Get simulated user inputs covering end-user scenarios at every test step. Use the suggestions to create test suites instantly. You can view input/utterance suggestions at every conversation step simulating the various input types and scenarios. This feature helps check if the task/intent is robust enough to handle random user utterances. It helps you predict and simulate the end user\u2019s behavior and check if the VA can execute all the defined flows by generating user responses and presenting any digressions from the specified intent.  Learn more .</p> <p></p>"},{"location":"whats-new/whats-new-in-this-release/#dynamic-conversations","title":"Dynamic Conversations","text":""},{"location":"whats-new/whats-new-in-this-release/#dynamic-paraphrasing","title":"Dynamic Paraphrasing","text":"<p>You can now leverage Generative AI to rephrase bot responses based on conversation context and users\u2019 emotions, resulting in more empathetic and natural responses that enhance user experience and engagement. When the OpenAI or Azure-OpenAI integration is enabled, you can see a new setting to rephrase responses at the node level for Message, Entity, and Confirmation Nodes. The messages added as User Prompts, Error Prompts, and Bot Responses are rephrased during runtime using the integration.  Learn more .</p> <p></p>"},{"location":"whats-new/whats-new-in-this-release/#ai-assisted-adaptive-dialog","title":"AI-Assisted Adaptive Dialog","text":"<p>The AI-Assisted Dialog Node lets you leverage the full potential of LLMs and Generative AI models to quickly build conversations that involve complex flows and also provide human-like experiences. You can define the entities you would like to collect and also the business rules that govern the collection of these entities. The XO Platform orchestrates the conversation using contextual intelligence, ensuring that the conversation is always grounded to your enterprise business rules. You can also provide exit rules for handing off the conversation to the virtual assistant or the human agents.  Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#knowledge-graph-powered-by-llm","title":"Knowledge Graph Powered by LLM","text":"<p>The new Few-Shot Knowledge Graph leverages LLMs to understand the FAQs without the need for exhaustive ontology. All you need to do is add all FAQs to the root node/term. This significantly reduces the complexity of building and maintaining an ontology structure. Learn more.</p> <p>With the introduction of Few-shot models in ML and KG engines, rescoring by Ranking &amp; Resolver is no longer required for intent identification. Therefore, we have introduced a new version of Ranking &amp; Resolver (Version 2) for Few-shot models that only ranks intents based on scores from ML and KG engines. The version significantly improves the accuracy of intent identification.</p> <p>Multi-language Support for Zero-shot and Few-shot Models</p> <p>The Zero-shot and the Few-shot ML Models are now supported in all non-English languages.</p>"},{"location":"whats-new/whats-new-in-this-release/#pre-built-integrations","title":"Pre-built Integrations","text":""},{"location":"whats-new/whats-new-in-this-release/#integration-with-unblu-for-agent-transfer","title":"Integration with Unblu for Agent Transfer","text":"<p>Kore.ai\u2019s pre-built Agent Transfer integrations now allow you to seamlessly hand off the conversations to the Unblu agent system without writing any custom code using the BotKit. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#disable-or-delete-pre-built-action-integrations","title":"Disable or Delete Pre-built Action Integrations","text":"<p>You can now disable or delete a configured external Action integration.</p>"},{"location":"whats-new/whats-new-in-this-release/#additional-enhancements","title":"Additional Enhancements","text":""},{"location":"whats-new/whats-new-in-this-release/#external-nlu-for-universal-bots","title":"External NLU for Universal Bots","text":"<p>The Platform provides more flexibility in bot orchestration by allowing you to link some bots using external NLU engines and others using proprietary multi-engine NLP. With external NLU integration, you can continue to have the NLU training on an external system and build the conversation flow on the XO platform. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#analytics-details-in-webhook-v2-response","title":"Analytics Details in Webhook v2 Response","text":"<p>The Webhook v2 response now includes additional conversation flow-related analytics information to help you build custom analytics. You can set the AnalyticsDetails parameter to Include in the request to view meta tags related to all nodes, tasks, sub-task, and session_id details in the response. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#export-conversational-path-analysis-data","title":"Export Conversational Path Analysis Data","text":"<p>You can now export the Conversational Path Analysis data in a .csv file to analyze the flow of drop-off sessions and take the required actions. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#customize-authorization-profiles-for-a-conversion-session","title":"Customize Authorization Profiles for a Conversion Session","text":"<p>The Platform provides a new way to clear authorization profiles collected from the users. The authorization profiles can be auto-cleared as part of the session closure, or you can also use the koreUtil.clearAuthProfiles and koreUtil.clearAllAuthProfiles functions. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#improved-messaging-channel-support","title":"Improved Messaging Channel Support","text":"<p>SmartAssist Gateway is Kore.ai\u2019s native voice interface to deliver seamless and low-latency conversation experiences. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#plan-usage","title":"Plan &amp; Usage","text":"<p>Ecommerce Plans are now supported in the EU region. Also, wire transfer-based payments are now supported for Ecommerce Plans. Learn more.</p>"},{"location":"whats-new/whats-new-in-this-release/#entity-rule-enhancements","title":"Entity Rule Enhancements","text":"<ul> <li>Letters rule for the String Entity: The new Letters rule <code>(letters=a single number OR a range)</code> for the String entity allows you to extract a word of a specific length or a sequence of individual characters that meet the length criteria. Learn more.</li> <li>New Model Number Rule for Composite Entity: The new Model Number rule <code>(\"modelNumber\":true)</code> for Composite Entity allows you to set a specific number of letters and numbers to extract a unique identifier. For example, a social security number, membership ID, or other structured data on a voice channel where the user\u2019s utterance does not follow a strict regex pattern. Learn more.</li> <li>New Precondition Rule for all entity types allows you to define preconditions for entity extraction if one of the conditions is true. If the precondition is invalid then the entity extraction is skipped entirely. For example, a composite entity matches with a set of identification numbers, such as membership ID, provider ID, and RX number. You can set the precondition rule as <code>\"preConditions\" : [\"checkMemberID\"]</code>. Learn more.</li> </ul>"}]}