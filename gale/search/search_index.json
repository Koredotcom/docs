{"config":{"lang":["tr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2016-2023 Martin Donath</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"administration/user-management/invite-a-user-to-your-account/","title":"Invite a User to your Account","text":"<p>As the owner of the account in GALE, you have the authority to invite any user and grant them access to your account for viewing and working in GALE. When you send an invitation to a user, they receive an invitation email through which they can access the product.</p> <p>To invite a user to your account, follow these steps:</p> <ol> <li> <p>Click the Profile icon from the top navigation bar of the product. A pop-up with a list of options is displayed.</p> <p></p> </li> <li> <p>Hover over &lt;Account name&gt;&gt; from the pop-up list and click Invite user to the account option from the list of options displayed as shown in the following image.</p> <p></p> <p>The Invite users to &lt;&gt; dialog is displayed. <li> <p>Enter the Email ID of the user to add to the account and click Invite.</p> <p></p> <p>An Email is sent to the invitee and the user can access the product now.</p> <p>Note</p> <p>Once the user clicks the Open Invite button from the email, the Sign-up page of GALE is displayed. The new user can add a Full name and Password and create a new account.</p> </li>"},{"location":"administration/user-management/overview/","title":"Overview","text":"<p>User management within GALE operates on two distinct levels:</p> <ul> <li>Account level: At the account level, administrators can manage users with a broader scope, encompassing the entire GALE account. This includes responsibilities such as user registration, access control, and permissions applicable across various applications within the GALE platform.</li> <li>Application level: User management becomes more detailed and specific at the application level, concentrating on individual applications within the GALE platform. The owner of each respective application holds the authority to extend invitations to any number of individual users, customizing their capabilities in alignment with the unique requirements of each application. For more information about setting app-level permissions, see Manage user roles and permissions.</li> </ul>"},{"location":"agents/configure-an-agent/","title":"Configure an Agent","text":"<p>You can modify and manage the general details of your agent if required and add or manage environment variables. Environment variables allow you to capture commonly used values that different nodes can use. They can be secured and managed from the Agent Configurations page.</p>"},{"location":"agents/configure-an-agent/#add-an-environment-variable","title":"Add an Environment Variable","text":"<p>To add an environment variable, follow these steps:</p> <ol> <li>Click Agents on the top navigation bar of the application. The Agents page is displayed with the list of agents.</li> <li> <p>Click the required Agent you want to modify the details, click Configurations and then click Manage environment variables.</p> <p></p> </li> <li> <p>The Create environment variable dialog box is displayed. Click Add or Add variable.</p> </li> <li> <p>Specify the following information on the Add variable dialog box:</p> <p></p> <ul> <li>Variable name: Provide a descriptive name for the variable.</li> <li>Secure variable: Use the toggle to enable security for the variable. (If you are enabling the security, read the onscreen information carefully to understand the impact.)</li> <li>Value: Enter the desired value for the variable.</li> <li>Notes (optional): Enter any notes about how the variable should be used or its purpose.</li> <li>Click Save. The created variable is listed on the Create environment variable dialog box.</li> </ul> </li> </ol>"},{"location":"agents/configure-an-agent/#edit-or-delete-an-environment-variable","title":"Edit or Delete an Environment Variable","text":"<p>To manage a variable, follow these steps:</p> <ul> <li> <p>Click the three dots icon corresponding to the Name of the variable to edit the details of the variable or Delete to delete a variable.</p> <p></p> </li> </ul> <p>Note</p> <p>To delete an agent, you must first un-deploy it and then delete it.</p>"},{"location":"agents/create-a-new-agent/","title":"Create an Agent","text":"<p>You can create a new agent to leverage models, build flows, and later deploy it as an endpoint. You can start the agent creation journey from the Agents page. The page also allows you to manage your existing agents and view agents that have been shared with you by others.</p> <p>Steps to create an agent:</p> <ol> <li>On the Agents page, click Create new agent. The New agent dialog box is displayed. </li> <li>Enter a name and a brief description for the agent and click Create. The agent is created, and the Agent Flow option is displayed. You can start creating your agent flow now.</li> </ol>"},{"location":"agents/create-a-new-api-key/","title":"Create a New API Key","text":"<p>You can generate an API for your agents and share it with other trusted users.  It is essential to have a secure API key when trying to connect to these agents in an external environment. </p> <p>To generate a new API key for your agents, follow these steps:</p> <ol> <li> <p>Click the API keys tab in the left panel on the Agents page.</p> <p></p> </li> <li> <p>Click the Create a new API key button. The Create new API key dialog is displayed.</p> <p></p> </li> <li> <p>Enter a Name for the key and click the Generate key button. The API key is displayed in the Create new API key dialog as shown in the following image:</p> <p></p> </li> <li> <p>Click the Copy and close button. You can copy the key and share it with others if required.</p> <p>All the generated API keys are listed in the API keys section.</p> <p></p> </li> </ol>"},{"location":"agents/deploy-an-agent/","title":"Deploy an Agent","text":"<p>After completing and testing your agent flow, you can deploy your agent. After the deployment, you can see the dedicated API endpoint created for the agent.</p> <p>Note</p> <p>Before deploying the agent, you must fix any errors or warnings in the Agent Flow.</p> <p>Steps to deploy an agent and get its endpoint:</p> <ol> <li> <p>Click Agent endpoint in the left navigation. </p> </li> <li> <p>Click Deploy. After the deployment, you can see the dedicated API endpoint created for your agent. The API endpoint is available in the following formats: curl, Python, and Node.js. You can copy the code and use it as needed. </p> </li> </ol>"},{"location":"agents/deploy-an-agent/#redeploy-an-agent-for-the-changes-in-the-flow","title":"Redeploy an Agent for the Changes in the Flow","text":"<p>The Deployed version of your agent's flow is accessible from the Agent Flow page. You can click the View the Flow button to view the flow in read-only mode. </p> <p>You can change the in-development version of the flow. To redeploy the agent with the updated flow, click the Deploy button at the top-right corner of the Agent endpoint page. The redeployment doesn't change the agent's endpoint.  </p>"},{"location":"agents/manage-user-roles-and-permissions/","title":"Manage User Roles and Permissions","text":"<p>Account owners can invite users to collaborate on specific Agents. Invited users can access the Models and Data modules for the invited account but can only see the Agents they are invited to. </p> <p>Note</p> <p>You can only invite those users to an application, who have access to your account.</p> <p>Steps to invite users to your Agent:</p> <ol> <li> <p>Open the Agent - click Agents on the top navigation bar and click the specific Agent to open it.</p> </li> <li> <p>Click Sharing &amp; Permission in the left navigation bar. The page lists the existing collaborators, if any. </p> </li> <li> <p>Click Invite to add users to your agent. The Invite Users dialog box is displayed.  </p> <p>Note</p> <p>Only the account owners can view the Invite button and invite other users.    </p> </li> <li> <p>Enter users\u2019 email addresses to invite them and click Invite to grant them access to collaborate on the Agent. </p> </li> </ol>"},{"location":"agents/overview-copy/","title":"About Agents (OLD)","text":"<p>By leveraging AI technology, agents can automate processes, streamline workflows, and generate valuable insights. Integrating these applications seamlessly into existing systems and workflows is the key to maximizing their benefits. For example, creating an agent for deal summarization can help businesses quickly extract essential information from complex contracts or agreements, saving time and reducing the risk of human error. Similarly, an agent for auto email generation can automate routine communication tasks, freeing up employees to focus on more strategic activities.</p> <p>Agents can be accessed using an API key, enabling their easy integration with other enterprise applications that allow for seamless data exchange and interoperability across different systems, enhancing overall connectivity and functionality.</p>"},{"location":"agents/overview/","title":"About Agents","text":"<p>Agents can automate processes, streamline workflows, generate insights, and create outputs like deal summaries or emails. GALE's agent builder empowers you to create AI-powered workflows and automations using a visual drag-and-drop interface with little to no coding required. You can easily configure settings, combine multiple workflows, and integrate with systems like AWS.</p>"},{"location":"agents/overview/#key-features","title":"Key Features","text":"<ul> <li> <p>Agent Flow: A visual no-code/low-code builder for creating and managing agent flows and versions. It uses nodes and transitions to help you automate end-to-end tasks without writing complex code. Learn more.</p> </li> <li> <p>Sharing &amp; Permissions: Account owners can invite users to collaborate on specific Agents. Invited users can access the Models and Data modules for the invited account and see only the Agents they are invited to. Learn more.</p> </li> <li> <p>Agent Endpoint: After building and testing your agent flow, you can deploy it. Once deployed, you'll receive an API endpoint for your agent, which you can use to integrate it with other systems. Learn more.</p> </li> <li> <p>API Keys: Create API keys for your deployed agents to access them from external systems securely. Share these keys only with trusted users. Learn more.</p> </li> <li> <p>Guardrails: Deploy various guardrail models and use them to scan LLM requests and responses to enforce safety and appropriateness standards. Learn more.</p> </li> <li> <p>Configurations: Manage your agent's general details, define reusable values and configurations using environment variables, and undeploy the agent. Learn more.</p> </li> </ul>"},{"location":"agents/agents-flows/flows-overview/","title":"About Agent Flow","text":"<p>GALE's Agent Flow allows you to quickly build an AI agent using a simple drag-and-drop interface combined with smart code editing. This approach enables developers to quickly create a complex AI agent for various use cases, such as candidate evaluation, banking applications, or content generation, without sacrificing flexibility or control.</p> <p>Every flow consists of an input node, which receives the necessary information or variables, and an output node, which provides the results generated by the flow. These results can be accessed by other systems through an API, as every element in the flow automatically becomes part of a deployable API.</p> <p>After building the flow, you can test it to ensure the application functions as intended. For example, you could create an agent for a retail business that collects data on performance, investments, and gross margins. The model can then evaluate key metrics like ROI and provide recommendations for improvement based on the analysis.</p>"},{"location":"agents/agents-flows/manage-flow-nodes/","title":"Manage Nodes in Agent Flow","text":"<p>A flow consists of a sequence of nodes connected on the flow builder canvas. You can easily add nodes on the canvas, connect them, rename and rearrange them, and delete them as required.</p>"},{"location":"agents/agents-flows/manage-flow-nodes/#add-a-new-node","title":"Add a new node","text":"<p>The Start node is the starting point of any flow and is available by default. You can drag and drop it (as well as any other nodes) anywhere on the canvas.</p> <p>Click the \u201c+\u201d icon and select a node from the pop-up menu, or drag a node from the Assets panel onto the canvas.  </p>"},{"location":"agents/agents-flows/manage-flow-nodes/#rename-a-node","title":"Rename a node","text":"<p>Right-click the node you want to rename and select Rename from the list of options. </p>"},{"location":"agents/agents-flows/manage-flow-nodes/#rearrange-nodes","title":"Rearrange nodes","text":"<p>To rearrange nodes on your canvas, drag and drop them to the desired location, as shown in the demo below. </p> <p>Note</p> <ul> <li> <p>Only the node that you are dragging will change position. Any connecting nodes will remain in place, regardless of the direction of their connection.</p> </li> <li> <p>You can right-click anywhere on the canvas and perform some other actions on the canvas such as Changing the background color of the canvas, Show/Hide UI, and Show/Hide Grid by.</p> </li> </ul>"},{"location":"agents/agents-flows/manage-flow-nodes/#connect-nodes","title":"Connect nodes","text":"<p>Node connections are either made from within each node's configuration or by dragging and dropping the nodes on the canvas. You can also connect nodes from the property panel of the node while defining the settings for success and failure. That will also automatically connect the nodes.</p> <p>Steps to connect the nodes:</p> <ol> <li>Click the grey dot that displays next to the node, drag your cursor over the grey dot displayed on top of the connecting node, and release. A line is drawn between the nodes, with an arrow indicating the direction of the node connection.</li> <li>You can change the destination node by clicking the grey dot on top of the initial destination node and then dragging the connection line to the grey dot on top of the new destination node. </li> </ol>"},{"location":"agents/agents-flows/manage-flow-nodes/#delete-a-nodes-connection","title":"Delete a node\u2019s connection","text":"<p>Click the line connecting two nodes and click the Delete icon to delete the connection. The nodes remain on the canvas but will not be connected anymore. To ensure a working flow, you must create another connection between the nodes.</p>"},{"location":"agents/agents-flows/manage-flow-nodes/#delete-a-node","title":"Delete a node","text":"<p>Right-click the required node and select Delete from the list of options.</p>"},{"location":"agents/agents-flows/perform-other-actions-on-the-flow-builder/create-a-new-version-of-the-flow/","title":"Create a New Version of the Flow","text":"<p>You can save versions of your flows, restore the older versions, and delete a version if required. Once you have deployed a flow it will be shown as the Deployed version.</p> <p>To create a new version, follow these steps:</p> <ol> <li> <p>Click the down arrow corresponding to the agents on the header of the canvas.</p> <p>The Flow versions dialog is displayed.</p> </li> <li> <p>Click the + icon to save a version of the flow.</p> <p></p> <p>The Name the Version dialog is displayed.</p> </li> <li> <p>Enter a Name and Description for the flow and click Save.</p> <p></p> <p>The version you saved will be the current version. Any changes you make in the flow are auto-saved to the current version.</p> <p>Note</p> <p>You can click the 3 dots icon corresponding to the version name to Restore or Delete a version. When you restore a version, the current version goes down to the bottom of the list and the restored version becomes the current version and is moved to the top of the list. If you want to edit a restored version, a new current version is created, and you can save this version with a new name. A deployed version can only be restored but cannot be deleted.</p> </li> </ol>"},{"location":"agents/agents-flows/perform-other-actions-on-the-flow-builder/manage-input-and-output/","title":"Manage Input and Output","text":"<p>You can initiate a fresh agent flow and specify the inputs required to initialize the process. Within the starting node, essential variables necessary for the flow's execution are received from the front end through API requests. Correspondingly, the end node gathers outputs from the preceding nodes and transmits them for utilization by the front end as an API.</p> <p>Once the input and output variables have been defined, they become accessible within the context objects and can be utilized throughout the flow's progression.</p> <p>To manage input variables, follow these steps:</p> <ol> <li> <p>Click the Manage I/O button on the top of the canvas of the Agents page.</p> <p>The Manage Input &amp; Output dialog is displayed.</p> <p></p> </li> <li> <p>Click the + Add input variable button under the Input tab.</p> <p>The Enter input variable dialog is displayed. </p> <p></p> </li> <li> <p>Enter a Name(key) to the input variable. For example, Product_ID.</p> </li> <li>Select a data type from the Type drop-down list. If you want to make the data type mandatory, then move the Mandatory toggle button.</li> <li>You can Enable the Default value toggle button to add a Default value for the input variable. You can set a default value for this input variable. If the value is not provided, then the flow automatically selects this default value. For example, Default Value - 9393JAS</li> <li>Click Save. The Input variable is displayed in the list on the Manage Input &amp; Output dialog.</li> </ol> <p>To manage output variables, follow these steps:</p> <ol> <li> <p>Click the Manage I/O button on the top of the canvas of the Agents page.</p> <p>The Manage Input &amp; Output dialog is displayed.</p> </li> <li> <p>Click the + Add output variable button under the Output tab.</p> <p>The Enter output variable dialog is displayed.</p> <p></p> </li> <li> <p>Enter a Name(key) to the input variable.</p> </li> <li>Select a data type from the Type drop-down list.</li> <li>Click Save. The Output variable is displayed in the list on the Manage Input &amp; Output dialog.</li> </ol> <p>Note</p> <p>You can create multiple output variables based on your use case.</p>"},{"location":"agents/agents-flows/perform-other-actions-on-the-flow-builder/run-the-flow/","title":"Run the Flow","text":"<p>You can run a flow and test it to see how it works. Once you click the Run, a debug log opens and a context object is generated. Every node in the flow has a context temporary storage where you can view what is the context object at each node level.</p> <p>The output shows the start, end, elapsed time taken to run the flow, and if any unresolved issues are displayed.</p> <p>To run the flow, follow these steps:</p> <ol> <li> <p>Click the Run icon on the right side of the top navigation bar of your agents page.</p> <p></p> <p>The debug log is opened and output results are started.</p> </li> <li> <p>Click the Debug icon on the top of the output dialog to open the Debug log as shown in the following image.</p> <p></p> <p>The following are the details you can view:</p> <ul> <li> <p>All the values that you provided in the flow are displayed in this section.</p> </li> <li> <p>The flow level log details are displayed.</p> </li> <li> <p>For each flow initiation, end, and node level details will be displayed.</p> </li> <li> <p>For each node\u2019s success or failure, an info link is displayed. If you click the Info the details are displayed for your reference.</p> </li> <li> <p>If you expand the node, metrics at each node such as Initiated on, Executed on, Total time taken, and Tokens (available only for AI node) are displayed.</p> </li> <li> <p>In case a flow is successful, the copy icon is available to copy the output, and the overall run-time flow is displayed.</p> </li> <li> <p>In case of any errors in the flow, an error message is displayed and the output key in the JSON format displayed is empty as shown in the image.</p> <p></p> </li> </ul> <p>Note</p> <p>You can stop the flow in the middle of a flow and restart the execution by clicking the Run icon again.</p> </li> </ol>"},{"location":"agents/agents-flows/types-of-nodes/api-node/","title":"API Node","text":"<p>The API Node lets you connect to external systems and retrieve data by making SOAP or REST API calls. You can configure the APIs and pass the necessary parameters to fetch the required information.</p>"},{"location":"agents/agents-flows/types-of-nodes/api-node/#add-and-configure-an-api-node","title":"Add and Configure an API Node","text":"<p>Setting up an API node in an Agent Flow involves adding the node at the appropriate location in the flow and configuring various node properties, as explained below.</p> <p>Steps to add and configure the node:</p> <ol> <li> <p>Open the Agent Flow to which you want to add the node: go to Agents &gt; Agent Flow &gt; Go to Flow.</p> </li> <li> <p>The Agent Flow opens in the Flow Builder. Click the \u201c+\u201d icon on any existing node on the canvas and select API from the pop-up menu. (Alternatively, you can drag the API node from the Assets panel onto the canvas.)</p> </li> <li> <p>Click the added node to open its properties dialog box. The General Settings for the node are displayed. </p> </li> <li> <p>Enter or select the following information:</p> <ul> <li>Custom Name: Enter an appropriate name for the node.</li> <li>Type: Select the API type from the drop-down list - REST or SOAP.</li> <li>Request Definition: Define the details of the service request to make the call and fetch the data. Click Define Request and enter or select the following details in the Edit Request dialog box: <ol> <li>Select the request type from the list - GET, PUT, POST, PATCH, or DELETE.</li> <li>Paste your API Endpoint URL or cURL in the text field.</li> <li>In the Headers tab, specify the details of the Key and Value pair. For example,  Key: Content-Type Value: application/json</li> <li>The Body tab is displayed for all request types except GET. Select the body content type from the drop-down list:<ul> <li>application/x-www-form-urlencoded: Allows file uploads through HTTP POST requests. Add key/value pairs encoded by the platform.</li> <li>application/json: Transmits data between servers and web applications using JSON format without processing.</li> <li>application/xml: Sends XML payload for SOAP services via POST methods, with the option to include node values.</li> <li>Custom: Allows sending request payload in non-standard formats, such as for handling blogs or custom variables. </li> </ul> </li> <li>Click the Test button at the top-right corner of the dialog. The API response will appear on the Response tab.</li> <li>Click Save at the top-right corner of the dialog.</li> </ol> </li> </ul> </li> <li> <p>Click the Connections icon in the left navigation and select the Go to Node for both success and failure conditions. </p> <ol> <li> <p>On Success &gt; Go to Node: After the current node is successfully executed, go to a selected node in the flow to execute next. For example, you can process the data from this node into a Function node and then use it further. In this case, select the Function node. </p> </li> <li> <p>On Failure &gt; Go to Node: If the execution of the current node fails, go to an appropriate node having a custom error message configured.</p> </li> </ol> </li> <li> <p>Finally, test the flow and fix any issues found: Click the Run Flow button at the top-right corner of the flow builder.</p> </li> </ol> <p>Note</p> <p>To access an API node using the context variable, use the following format:  <pre><code>{{context.steps.Start.APINodeName}}\n</code></pre></p>"},{"location":"agents/agents-flows/types-of-nodes/api-node/#api-status-codes","title":"API Status Codes","text":"<ul> <li>200: Request successful</li> <li>400: Client error, cannot process request</li> <li>401: Authentication required</li> <li>403: Access denied</li> <li>404: Resource not found</li> <li>500: Unexpected server error</li> <li>504: Gateway timeout, no timely response from the upstream server</li> </ul>"},{"location":"agents/agents-flows/types-of-nodes/condition-node/","title":"Condition Node","text":"<p>Condition Nodes allow you to create branches in a workflow, directing actions based on whether certain conditions are met. This helps control the flow\u2019s execution.</p> <p>The node can handle three types of conditions:</p> <ul> <li>If: Directs the flow to a specific path if certain criteria (Node, Context, or Value) are met.</li> <li>Else: Sets the node connection when no condition is met, allowing you to configure the next node to connect to.</li> <li>Else If: Allows you to configure another set of criteria (Node, Context, or Value) to be met when the initial If condition is not satisfied.</li> </ul>"},{"location":"agents/agents-flows/types-of-nodes/condition-node/#add-and-configure-a-condition-node","title":"Add and Configure a Condition Node","text":"<p>Setting up a Condition node in an Agent Flow involves adding the node at the appropriate location in the flow and configuring various node properties, as explained below.</p> <p>Steps to add and configure the node:</p> <ol> <li> <p>Open the Agent Flow to which you want to add the node: go to Agents &gt; Agent Flow &gt; Go to Flow.</p> </li> <li> <p>The Agent Flow opens in the Flow Builder. Click the \u201c+\u201d icon on any existing node on the canvas and select Condition from the pop-up menu. (Alternatively, you can drag the Condition node from the Assets panel onto the canvas.)</p> </li> <li> <p>Click the added node to open its properties dialog box. The General Settings for the node are displayed. </p> </li> <li> <p>Enter or select the following information:</p> <ul> <li>Custom Name: Enter an appropriate name for the node.</li> <li> <p>If/Else Condition: Define the IF ELSE/ELSE IF conditions using context variables and the AND/OR operator. You can use Node, Context, or Value.</p> <ol> <li> <p>In the IF section, select the context variable you want to use - enter \"{{context.\" and select the node/variable from the list and then close the braces with \"}}\". </p> <p>For example:  <pre><code>{{context.ambiguous_sub_categories}}\n</code></pre></p> </li> <li> <p>Select an appropriate Operator from the drop-down list. For example, Contains.</p> </li> <li> <p>Enter the value for the condition. If you want to use a context variable, start entering \"{{context.\" and then select the node/variable, and then close the braces with \"}}\".</p> <p>For example: <pre><code>{{context.steps.Sub_Category_Detection.output}}   \n</code></pre></p> </li> <li> <p>Additionally, you can use an AND/OR logical operator to add more criteria to the condition.</p> </li> <li> <p>In the Then Go To drop-down list, select the node to connect to if the condition is met.</p> </li> <li> <p>In the ELSE section, select the node you want to trigger if the IF condition fails. </p> </li> </ol> </li> </ul> </li> <li> <p>Finally, test the flow and fix any issues found: Click the Run Flow button at the top-right corner of the flow builder.</p> </li> </ol> <p>Standard Error</p> <p>If a condition is true or false but has no connected node, the following error message is displayed: \"Path not defined. Please check the flow.\"</p>"},{"location":"agents/agents-flows/types-of-nodes/end-node/","title":"End Node","text":"<p>End nodes allow you to show the agent\u2019s/flow's outputs on success or an error message on failure.   </p>"},{"location":"agents/agents-flows/types-of-nodes/end-node/#add-and-configure-an-end-node","title":"Add and Configure an End Node","text":"<p>Setting up an End node in an Agent Flow involves adding the node at the appropriate location in the flow and configuring various node properties, as explained below.</p> <p>Steps to add and configure the node:</p> <ol> <li> <p>Open the Agent Flow to which you want to add the node: go to Agents &gt; Agent Flow &gt; Go to Flow.</p> </li> <li> <p>The Agent Flow opens in the Flow Builder. Click the \u201c+\u201d icon on any existing node on the canvas and select End from the pop-up menu. (Alternatively, you can drag the End node from the Assets panel onto the canvas.)</p> </li> <li> <p>Click the added node to open its properties dialog box. The General Settings for the node are displayed. </p> </li> <li> <p>Enter or select the following information:</p> <ul> <li> <p>Custom Name: Enter an appropriate name for the node.</p> </li> <li> <p>Name (key): Select a key from the drop-down list. All defined keys in the Manage Output section are displayed here. You can select a variable and assign a value to it. (You can also add a new key. For more information, see Manage Input and Output variable.) </p> </li> <li> <p>Value: Select an appropriate variable or node as the value. Enter \u201c{{context.\u201d and select the node/variable from the list and then close the braces with \u201c}}\u201d.</p> <p>For example: <pre><code>{{context.steps.summarization.output}}\n</code></pre> </p> </li> <li> <p>If you want to show multiple outputs/messages, click Add a Key to add the key and value details for the same.</p> </li> </ul> </li> <li> <p>Finally, test the flow and fix any issues found: Click the Run Flow button at the top-right corner of the flow builder.</p> </li> </ol> <p>Standard Error</p> <p>When the value for the output variable is not defined, a list of unresolved outputs is displayed.</p>"},{"location":"agents/agents-flows/types-of-nodes/function-node/","title":"Function Node","text":"<p>Function nodes allow you to write custom scripts using JavaScript or Python to process context variables or other variables used in building the experience flow.</p>"},{"location":"agents/agents-flows/types-of-nodes/function-node/#add-and-configure-a-function-node","title":"Add and Configure a Function Node","text":"<p>Setting up a Function node in an Agent Flow involves adding the node at the appropriate location in the flow and configuring various node properties, as explained below.</p> <p>Steps to add and configure the node:</p> <ol> <li> <p>Open the Agent Flow to which you want to add the node: go to Agents &gt; Agent Flow &gt; Go to Flow.</p> </li> <li> <p>The Agent Flow opens in the Flow Builder. Click the \u201c+\u201d icon on any existing node on the canvas and select Function from the pop-up menu. (Alternatively, you can drag the Function node from the Assets panel onto the canvas.)</p> </li> <li> <p>Click the added node to open its properties dialog box. The General Settings for the node are displayed. </p> </li> <li> <p>Enter or select the following information:</p> <ul> <li> <p>Custom Name: Enter an appropriate name for the node.</p> </li> <li> <p>Define a Script: You can define a script using Javascript or Python to process/parse the given input or the output of the previous node. Click anywhere in the Define a Script field to open the Script Editor dialog box. </p> <ol> <li> <p>In the top-left corner, choose the appropriate scripting language - Javascript or Python. Enter the script in the box. You can use variables or context variables in the Script Editor. For example:</p> <p>To read an input variable: <pre><code>context.&lt;variable-name&gt; = context.steps.&lt;startNode-Name&gt;.&lt;inputVariable-name&gt;\n</code></pre> To call a function: <pre><code>context.&lt;UserDefined-Variable-Name&gt;= UserDefined-Function-Name(context.steps.&lt;startNode-Name&gt;.&lt;inputVariable-name&gt;\n</code></pre></p> <p>Note</p> <p>You cannot import packages in the Function node. However, you can use pre-existing libraries such as pandas or  NumPy.</p> </li> <li> <p>You can use the Context input/output feature to use a variable from the previous node or when testing a function.</p> <ul> <li>Context Input: Add the required variable; also, dummy input values can be given to test the defined function.</li> <li>Context Output: Shows the results of the function from the given input.</li> <li>Log: Monitor the state of the function and view the values.</li> </ul> </li> <li> <p>Click the Run button to test the script. Once the script is resolved successfully, the results are displayed in the Log section.</p> </li> <li>Close the Script Editor.</li> </ol> </li> </ul> </li> <li> <p>Click the Connections icon in the left navigation and select the Go to Node for both success and failure conditions. </p> <ol> <li>On Success &gt; Go to Node: After the current node is successfully executed, go to a selected node in the flow to execute next. For example, you can go to a Gen AI node to use the processed data from the Function node. </li> <li>On Failure &gt; Go to Node: If the execution of the current node fails, go to an appropriate node having a custom error message configured for this node.</li> </ol> </li> <li> <p>Finally, test the flow and fix any issues found: Click the Run Flow button at the top-right corner of the flow builder.</p> </li> </ol> <p>Standard Errors</p> <p>You can see compilation and runtime errors, if any, during the execution of the script/node.</p>"},{"location":"agents/agents-flows/types-of-nodes/gen-ai-node/","title":"Gen AI Node","text":"<p>The Gen AI node allows you to use LLM and Generative AI models to create custom prompts for your specific use case. You can choose a model, adjust its settings, and view the generated response.</p>"},{"location":"agents/agents-flows/types-of-nodes/gen-ai-node/#add-and-configure-a-gen-ai-node","title":"Add and Configure a Gen AI Node","text":"<p>Setting up a Gen AI node in an Agent Flow involves adding the node at the appropriate location in the flow and configuring various properties of the node, as explained below.</p> <p>Steps to add and configure the node:</p> <ol> <li> <p>Open the Agent Flow to which you want to add the node: go to Agents &gt; Agent Flow &gt; Go to Flow.  </p> </li> <li> <p>The Agent Flow opens in the Flow Builder. Click the \u201c+\u201d icon on any existing node on the canvas and and select Gen AI from the pop-up menu. (Alternatively, you can drag the Gen AI node from the Assets panel onto the canvas.)  </p> </li> <li> <p>Click the added node to open its properties dialog box. The General Settings for the node are displayed. </p> </li> <li> <p>Enter or select the following General Settings:</p> <ul> <li> <p>Custom Name: Enter an appropriate name for the node.</p> </li> <li> <p>Select Model: Select a model from the list of configured models. (For more information on models, see Model Studio.)</p> </li> <li> <p>System Prompt: Enter the System Prompt for your use case.  For example, \u201cGenerate a summary of the transcription of a conversation in a maximum of 5 lines without returning any special characters.\u201d</p> </li> <li> <p>Prompt: It allows you to pass a variable to the System Prompt. For example, you can store the conversation transcript in a variable named \u201cconversation\u201d and pass it on in the Prompt. Format:      <pre><code>{{context.variable_name}}\n</code></pre>      Example:    <pre><code>{{context.conversation}}\n</code></pre></p> </li> <li> <p>Examples: Add a few relevant examples to guide the model. Click the arrow to add examples of User input and expected AI output. </p> </li> <li> <p>Hyperparameters: Hyperparameters allow you to fine-tune the AI model's behavior to suit your needs. While the default settings work well for most cases, you can adjust them to find the right balance for your use case.</p> <ul> <li> <p>Temperature: Controls the randomness of the model's responses. Higher values lead to more random outputs, while lower values result in more focused outputs.</p> </li> <li> <p>Max Tokens: Sets the maximum length of the model's output. Lower values generate shorter responses, while higher values produce longer responses.</p> </li> <li> <p>Frequency Penalty: Penalizes common or frequent tokens, making the model's output less generic. Higher values produce more unique outputs, while lower values result in more common outputs.</p> </li> <li> <p>Presence Penalty: Penalizes new or rare tokens, making the model's output more common. Higher values lead to more common outputs, while lower values result in more unique outputs.</p> </li> <li> <p>Top P: Controls the diversity of the model's output by considering only the top tokens whose cumulative probability exceeds a threshold. Higher values produce more diverse outputs, while lower values result in more deterministic outputs.</p> </li> </ul> </li> </ul> </li> <li> <p>Click the Connections icon and select the Go to Node for both success and failure conditions. </p> <ol> <li> <p>On Success &gt; Go to Node: After the current node is successfully executed, go to a selected node in the flow to execute next, such as a Gen AI node, Function node, Condition node, API node, or End node.</p> </li> <li> <p>On Failure &gt; Go to Node: If the execution of the current node fails, go to the End node to display any custom error message from the Gen AI node.</p> </li> </ol> </li> <li> <p>Finally, test the flow and fix any issues found: Click the Run Flow button at the top-right corner of the flow builder.</p> </li> </ol> <p>Standard Error</p> <p>When the Model is not selected, the prompt details are not provided, or both, the following error message is displayed: \u201cProper data needs to be provided in the LLM node\u201d.</p>"},{"location":"agents/agents-flows/types-of-nodes/gen-ai-node/#access-the-output-of-the-gen-ai-node","title":"Access the Output of the Gen AI Node","text":"<p>The output of the Gen AI node is stored in a context variable and can be accessed via  <pre><code>{{context.steps.GenAINodeName.output}}\n</code></pre></p> <p>Note</p> <p>GALE can automatically recognize variables/outputs. To do this, just type \"context.steps.\" and you will see available context variables/nodes, including the nodes' outputs.</p>"},{"location":"agents/agents-flows/types-of-nodes/overview-of-nodes/","title":"Nodes Overview","text":"<p>In GALE's Agent Flow builder, nodes are the building blocks that connect different stages to execute end-to-end use cases. Transitions between nodes provide the logic that ties the flow together. </p> <p>You can add the following nodes to an Agent flow, based on your requirements:</p> <ul> <li>Gen AI Node: It contains the desired AI model, which will serve as your agent's core intelligence. Learn more.</li> <li>API Node: It allows you to make requests to external systems using SOAP or REST API calls, query information, and manipulate data to meet your requirements. Learn more. Learn more.</li> <li>Function Node: It lets you define a script using JavaScript or Python to process context variables or other variables used in the flow. Learn more.</li> <li>Condition Node: It helps create branches in the workflow based on specific conditions, controlling the execution flow. Learn more.</li> <li>End Node: It helps define the message displayed when the flow ends and maps the outputs sent out of the flow or agent. Learn more.</li> </ul>"},{"location":"agents/guardrails/add-a-scanner/","title":"Add a Scanner","text":"<p>You have the option to add an input or output scanner, facilitating the scanning and verification of a particular objective. Input scanners evaluate the inputs or prompts directed to the LLM node, while output scanners assess the responses received from the LLM.</p> <p>Note</p> <p>In the following procedure, you will learn how to add an input scanner. However, the steps are similar if you want to add an output scanner. You need to add an input scanner and output scanner separately based on your requirements.</p> <p>To add a scanner, follow these steps:</p> <ol> <li>Click Apps on the top navigation bar of the application.</li> <li>Select the required application to which you want to add the guardrail scanners. The Application is displayed.</li> <li> <p>Click the Guardrails tab from the left navigation pane. The Guardrails page is displayed.</p> <p></p> </li> <li> <p>Click Add scanner from the Input Scanners section. A pop-up with a list of options is displayed.</p> <p></p> </li> <li> <p>Select the required scanners and click Done. The selected scanner is added to the list.</p> <p></p> <p>Note</p> <p>You must deploy the required scanner first and only then it will be listed in this pop-up list.</p> </li> <li> <p>Click the required scanner from the list of added scanners to configure that scanner. The settings displayed are different for each scanner. For example, the settings for \u201cToxicity\u201d are Threshold and End the flow if the risk score is above. Similarly, the settings for the \u201cRegex\u201d scanner are Enter patterns to ban, End the flow if the risk score is above, and Match type.</p> <p>Note</p> <p>You can remove a scanner if you don\u2019t want to be charged if not in use, by clicking the Remove icon corresponding to the scanner name from the list of scanners as shown in the following image.</p> <p></p> </li> </ol>"},{"location":"agents/guardrails/manage-guardrails/","title":"Manage Guardrails","text":"<p>All the scanners have models at the back end so to initiate the necessary input and output scanners, you need to deploy a scanner. Once deployed, this scanner becomes accessible throughout GALE, allowing its utilization across all agents.</p> <p>To deploy a scanner, follow these steps:</p> <ol> <li>Click the Settings icon on the top navigation bar of the application. The Settings page is displayed.</li> <li> <p>Click the Manage Guardrails tab from the left navigation pane. The Manage guardrail models are displayed on the right side of the page.</p> <p></p> </li> <li> <p>Click the Deploy button corresponding to the name of the Scanner you want to deploy.</p> <p></p> <p>The deployment process is initiated and the status is displayed as \u201cDeploying\u201d. Once the scanner is deployed it is listed in the scanners list when you want to add a new scanner.</p> <p>Note</p> <p>You can click the Undeploy button corresponding to the scanner model if you no longer need it.</p> </li> </ol>"},{"location":"agents/guardrails/overview/","title":"Guardrails","text":"<p>Guardrails are safety measures that provide guidelines and limits to ensure that the responses of the ML models are aligned with ethical standards and societal expectations. You can deploy various guardrail models and use them to scan the inputs or prompts and output results. </p> <p>For example, deploying a \"Toxicity\" scanner involves analyzing and assessing the toxicity of a prompt, thereby safeguarding the health and safety of online interactions.</p>"},{"location":"agents/guardrails/test-guardrail/","title":"Test Guardrail","text":"<p>Once you've added and configured the necessary scanner, you can verify if it adheres to the specified standards. You have the option to test the effectiveness of an individual scanner or a group of scanners.</p> <p>To test a guardrail, follow these steps:</p> <ol> <li> <p>Click the Test button on the Guardrails page.</p> <p></p> <p>The Test Guardrails page is displayed.</p> </li> <li> <p>Enter a prompt in the Prompt input box or click the Input template to select a template.</p> <p></p> </li> <li> <p>Click Test. You can review the results that are displayed under the Scores and Results section.  It displays the details such as:</p> <ul> <li> <p>Validity: It implies that the prompt is valid or not.</p> </li> <li> <p>Risk Score: It implies the score of risk that the prompt holds based on the risk score value you have configured in the End the flow if the risk score is above field in the scanner settings section.</p> </li> <li> <p>Duration: It displays the time taken by the scanner to execute a particular prompt.</p> </li> </ul> </li> </ol>"},{"location":"data/overview/","title":"Overview","text":"<p>The data module streamlines data management by allowing you to store your datasets in the application instead of uploading them every time you test prompts in the playground or upload files for fine-tuning the model. Additionally, the module provides flexibility to store files of different file formats such as CSV, JSON, and JSONL without any additional formatting requirements, ultimately enhancing convenience for you while working with large datasets within the product.</p>"},{"location":"data/upload-a-dataset/","title":"Upload a Dataset","text":"<p>You can upload a dataset of your choice in CSV, JSON, or, JSONL format.</p> <p>To upload a dataset, follow these steps:</p> <ol> <li> <p>Click Data on the top navigation bar of the application. The Data page is displayed.</p> <p></p> </li> <li> <p>Click the Upload dataset button to upload your data from the location. The uploaded file is listed on the Data page.</p> <p></p> <p>Note</p> <p>When you Upload a file in the Playground and the fine-tuning wizard the uploaded file is saved under the Data tab and can be used later. Also, the dataset you upload here is displayed for you to choose in the training dataset section of the fine-tuning wizard.</p> </li> <li> <p>When you select the Advance mode in the Prompt Playground and click the Add dataset option you can view and select the dataset you have added from the list as shown in the following image.</p> <p></p> </li> </ol> <p>Note</p> <p>Click the three dots icon corresponding to the name of the dataset and select Delete to delete the dataset if you no longer require it and select Download to download the dataset. However, if you are using a data file in the Playground section and delete the file from the Data page the Playground experiments are impacted, and an error message is displayed. </p>"},{"location":"getting-started/core-capabilities-of-gale/","title":"Key Capabilities of GALE","text":"<p>The GALE platform boasts a multitude of capabilities that address the rapid changes in the dynamic landscape of Language Models (LLMs). The ever-evolving nature of LLMs presents challenges, and GALE is a versatile toolkit to navigate and harness the opportunities arising from these swift transformations.</p> <ul> <li> <p>Data privacy: When you train your LLM, you have greater control over the data used in the training process. This is crucial for organizations dealing with sensitive information, as it mitigates the risks associated with sharing proprietary or confidential data with external models. Keeping the training process in-house allows you to adhere to strict privacy regulations and safeguard sensitive information.</p> </li> <li> <p>Tailored to Domain-Specific Requirements: In many cases, off-the-shelf models may not fully address the intricacies of specific industries or domains. By training your LLM, you can incorporate domain-specific knowledge and nuances, ensuring the model is finely tuned to excel in tasks relevant to your organization's field.</p> </li> <li> <p>Cost-Effectiveness: While training your own LLM may involve initial resource investment, it is cost-effective in the long run. Avoiding recurring fees associated with external models and services may lead to significant cost savings over time, especially for organizations with sustained, high-volume usage.</p> </li> <li> <p>Alignment with Business Goals: By training your models, enterprises can gain greater control over the objectives, values, and behaviors of your systems. This enables a direct alignment with your business goals, ensuring that the models are finely tuned to meet specific organizational objectives. Through the training process, enterprises can shape and tune the models in a way that resonates with your business.</p> </li> <li> <p>Seamless Integration with Business Processes: Models trained on an enterprise's data, applications, and systems offer a level of seamless deployment and integration into business processes. The familiarity with internal data structures and processes makes the deployment and integration of these models more straightforward. This tight coupling ensures a smooth incorporation into existing workflows and interfaces.</p> </li> <li> <p>Unique Competitive Advantage: Creating proprietary Language Models (LLMs) through in-house training offers enterprises a distinctive competitive advantage that sets them apart in the market. These models developed exclusively with the organization's data, represent a unique intellectual asset that competitors may not possess. This level of customization can be a key factor in gaining dominance in the targeted markets.</p> </li> </ul>"},{"location":"getting-started/introduction/","title":"Welcome to GALE (Beta)","text":"<p>Welcome to the beta launch of GALE by Kore.ai! This initial release focuses on delivering key features to provide value to our early customers.</p>"},{"location":"getting-started/introduction/#introducing-all-new-gale-platform","title":"Introducing All-new GALE Platform","text":"<p>GALE is a new platform for building LLM-powered AI agents. It provides tools to integrate all the pieces necessary to power Gen AI agents that can be seamlessly integrated into your existing systems and workflows, enabling you to quickly unlock the benefits of Gen AI.</p> <p></p> <p>You don't need to be an AI expert or write complex code. The platform provides ready-to-use AI models and intuitive tools to create custom Gen AI solutions quickly.</p> <p>With GALE's user-friendly drag-and-drop interface, you can easily prototype, customize, and deploy AI agents tailored to your specific needs. The platform offers a range of popular open-source and commercial AI models that you can fine-tune as required. You can also chain together workflows, manage inputs/outputs, and implement guardrails - all without the need for coding expertise.</p> <p>Once your AI agent is ready, GALE simplifies the deployment process via API, allowing you to seamlessly integrate it into your existing systems and applications. This streamlined approach to leveraging Gen AI capabilities makes GALE the perfect solution for any business looking to accelerate their AI adoption.</p>"},{"location":"getting-started/introduction/#key-components-of-gale","title":"Key Components of GALE","text":"<p>Agents, Models, and Playground are the key components of GALE that work together to enable businesses to leverage AI capabilities effectively.</p> AgentsModelsPlayground <p>Agents allow you to create AI-powered workflows and automation with little to no coding required. Using a visual drag-and-drop interface, you can easily configure settings and combine multiple complex workflows. Guardrails ensure the models within these workflows operate responsibly, adhering to societal norms and your business requirements. The agents can seamlessly integrate with AWS, expanding the range of use cases. This user-friendly approach empowers you to leverage AI capabilities across various applications without extensive technical expertise.  </p> <p></p> <p>Learn more about Agents </p> <p>Models are the core of GALE. Based on your needs, you can choose from fine-tuned, commercial, or open-source AI models. Once you've selected the right models, you can easily integrate them into your AI agents. Guardrails ensure the models generate outputs responsibly and follow defined constraints. Additionally, you can deploy these AI agents via API endpoints and integrate them with your existing systems as required. </p> <p></p> <p>Learn more about Models </p> <p>GALE's Prompt Playground allows you to experiment and refine prompts to get the best performance from AI models. You can test different prompts across various models - external, fine-tuned, or open-source. The Playground helps you identify the ideal model and configurations for each prompt through an iterative process. This streamlined workspace enables you to optimize prompts rapidly for maximum model effectiveness.  </p> <p></p> <p>Learn more about Playground </p>"},{"location":"getting-started/introduction/#deployment-of-ai-at-scale","title":"Deployment of AI at Scale","text":"<p>GALE provides enterprise-grade features to deploy AI at scale:</p> <ul> <li>Security: Your data and intellectual property are protected by robust security measures.</li> <li>Scalability: As your AI applications grow and user numbers increase, GALE automatically scales to meet demand while maintaining consistent performance.</li> <li>Flexible Deployment: Based on your organization's preferences, you can deploy AI models on the cloud or on-premises infrastructure.</li> </ul> <p>With GALE's enterprise-ready capabilities, you can confidently scale your AI adoption while ensuring data security, reliable performance, and deployment flexibility to suit your unique business needs.</p>"},{"location":"getting-started/sing-up-for-beta/","title":"Sign up for Beta Testing","text":"<p>The GALE beta program is now open and accepting applications. Beta testers can use our no-code toolset to build and deploy AI applications. While GALE offers a wide range of effective AI models for diverse services, this beta program may not be ideal for every use case. Use the link below to tell us a bit about what you plan to build with GALE. We will consider each application to ensure the beta program fits well with the goals of each project. We appreciate your interest in GALE and look forward to collaborating with you.</p> <p>Sign up for Beta Testing </p>"},{"location":"integrations/how-to-enable-hugging-face/","title":"How to Enable Hugging Face","text":"<p>GALE seamlessly integrates with the Hugging Face platform, allowing you to incorporate cutting-edge text generation and text-to-text generation models. Any publicly available Hugging Face model can be swiftly deployed via GALE with minimal effort. To utilize private or exclusive Hugging Face models, you can effortlessly establish a connection by supplying your Hugging Face access tokens. This facilitates GALE in unleashing the complete capabilities of your Hugging Face account, regardless of whether you possess public or private assets.</p> <p>To integrate with your hugging face account, follow these steps:</p> <ol> <li> <p>Click the Settings icon on the top navigation bar of the application. The Integrations page is displayed.</p> <p></p> </li> <li> <p>Click the Hugging Face option from the list of Integrations. The Hugging Face section is expanded.</p> <p></p> </li> <li> <p>Click Add connection. The Hugging Face dialog is displayed.</p> <p></p> </li> <li> <p>Enter the following details in the dialog to create a connection:</p> <ul> <li>Provide a Connection name.</li> <li>Enter an Access token which is a unique identifier associated with your Hugging Face account.</li> </ul> </li> <li>Click Confirm to create a connection.</li> </ol>"},{"location":"integrations/how-to-enable-hugging-face/#testing-your-connection-to-hugging-face","title":"Testing your connection to Hugging Face","text":"<p>You can test your connection after you provide the details to verify the accuracy of the details.</p> <p>To test your connection, follow these steps:</p> <ol> <li> <p>Click the Test button on the Hugging Face dialog.</p> <p></p> <p>Once the connection is tested, you will receive feedback information.</p> </li> <li> <p>If the connection is successful, you can click Confirm and complete the connection process.</p> </li> <li>If the connection fails, you can verify the details entered or cancel the set-up process.</li> <li> <p>You can test the connection by clicking the Play button on the connections list.</p> <p></p> <p>Note</p> <p>If the connection fails a red icon is displayed corresponding to the name of the connection on the Connections list.</p> </li> <li> <p>Hover over the connection name and click the three dots icon corresponding to the Connection name. The list of options is displayed. Click Edit to modify the connection details and Delete to delete the connection.</p> <p></p> <p>Note</p> <p>Once the Hugging Face connection is completed, you can see your connection name in the drop-down box while selecting and deploying an Open-source model.  For more information about selecting and deploying, see Select and Deploy an Open-Source Model</p> </li> </ol>"},{"location":"integrations/how-to-integrate-with-s3-bucket/","title":"How to Integrate with S3 Bucket","text":"<p>The S3 Storage Integration functionality broadens GALE's capabilities by enabling connectivity with your AWS S3 account. It empowers you to import files from S3 and leverage them in developing high-quality AI applications for enterprises.</p> <p>To integrate with your S3 account, follow these steps:</p> <ol> <li> <p>Click the Settings icon on the top navigation bar of the application. The Integrations page is displayed.</p> <p></p> </li> <li> <p>Click the AWS S3 bucket option from the list of Integrations. The AWS S3 bucket section is expanded.</p> <p></p> </li> <li> <p>Click Add connection. The AWS S3 bucket dialog is displayed.</p> <p></p> </li> <li> <p>Enter the following details in the dialog to create a connection:</p> <ul> <li>Provide a Connection name.</li> <li>Enter an Access key which is a unique identifier associated with your AWS account.</li> <li>Enter a Secret key which is a confidential key paired with the Access Key ID.</li> <li>Enter a Bucket name which is configured in the S3 console.</li> </ul> </li> <li>Click Confirm to create a connection.</li> </ol>"},{"location":"integrations/how-to-integrate-with-s3-bucket/#testing-your-connection-to-s3","title":"Testing your connection to S3","text":"<p>You can test your connection after you provide the details to verify the accuracy of the details.</p> <p>To test your connection, follow these steps:</p> <ol> <li> <p>Click the Test button on the AWS S3 bucket dialog.</p> <p>Once the connection is tested, you will receive feedback information.</p> </li> <li> <p>If the connection is successful, you can click Confirm and complete the connection process.</p> </li> <li>If the connection fails, you can verify the details entered or cancel the set-up process.</li> <li> <p>From the connections table, you can test the connection by clicking the Play button.</p> <p>Note</p> <p>If the connection fails a red icon is displayed corresponding to the name of the connection on the Connections list.</p> </li> </ol>"},{"location":"integrations/how-to-integrate-with-s3-bucket/#how-to-use-files-from-the-connected-s3-buckets-in-the-agent-flow-builder","title":"How to use files from the connected S3 Buckets in the Agent Flow Builder","text":"<p>Once a connection is created and the integration of S3 Bucket is successful you can use the files in the Flow builder canvas.</p> <p>To use the files in the agents flow builder, follow these steps:</p> <ol> <li> <p>Create an Input variable with type Remote File. </p> </li> <li> <p>Add an API node and point to the remote file in the API node using the URL field. </p> <p>The file content will be available in the context object. You can access the file content in any other nodes using the context object.</p> </li> </ol>"},{"location":"integrations/how-to-integrate-with-wandb/","title":"How to Integrate with Weights and Biases","text":"<p>Connecting with Weights and Biases (WandB) allows users to link to the platform, ensuring that the fine-tuning data associated with the model being refined in GALE is seamlessly transmitted to the WandB console for additional analytics.</p> <p>To integrate with your Weights and Biases (WandB) account, follow these steps:</p> <ol> <li> <p>Click the Settings icon on the top navigation bar of the application. The Integrations page is displayed.</p> <p></p> </li> <li> <p>Click the Weights &amp; Biases option from the list of Integrations. The Weights &amp; Biases section is expanded.</p> <p></p> </li> <li> <p>Click Add connection. The Weights &amp; Biases dialog is displayed.</p> <p></p> </li> <li> <p>Enter the following details in the dialog to create a connection:</p> <ul> <li>Provide a Connection name.</li> <li>Enter an API key which is a unique identifier associated with your WandB account.</li> </ul> </li> <li>Click Confirm to create a connection.</li> </ol>"},{"location":"integrations/how-to-integrate-with-wandb/#testing-your-connection-to-weights-biases","title":"Testing your connection to Weights &amp; Biases","text":"<p>You can test your connection after you provide the details to verify the accuracy of the details.</p> <p>To test your connection, follow these steps:</p> <ol> <li> <p>Click the Test button on the Weights &amp; Biases dialog.</p> <p></p> <p>Once the connection is tested, you will receive feedback information.</p> </li> <li> <p>If the connection is successful, you can click Confirm and complete the connection process.</p> </li> <li>If the connection fails, you can verify the details entered or cancel the set-up process.</li> <li> <p>You can test the connection by clicking the Play button on the connections list.</p> <p></p> <p>Note</p> <p>If the connection fails a red icon is displayed corresponding to the name of the connection on the Connections list.</p> </li> <li> <p>Hover over the connection name and click the three dots icon corresponding to the Connection name. The list of options is displayed. Click Edit to modify the connection details and Delete to delete the connection.</p> <p></p> </li> </ol> <p>Note</p> <p>Once the WandB connection is completed, you can see your connection name in the drop-down box in the Create a fine-tuned model wizard in the Weights and Biases section.  For more information about the fine-tuning wizard, see Create a Fine-Tuned Model.</p>"},{"location":"models/overview/","title":"About Models","text":"<p>The Model Studio provides the capability to augment base models by integrating the proprietary data from your enterprise and fine-tuning them directly within the product. This streamlined process enables the base model's fine-tuning to easily achieve task-specific performance. You can seamlessly bring in models from external sources and open-source models, expanding the range of available models to address your needs.</p> <p>GALE provides you with 3 different options as part of the model studio:</p> <ol> <li>Fine-tuned model: This section, enables you to perform fine-tuning on an existing model, allowing you to create customized models tailored to your specific needs. For more information, see Fine-Tuned Models.</li> <li>Open-source model: In this section, you can can either choose to deploy from a curated list of 30+ most popular open-source models or bring in any text generation model of your choice from Hugging Face. For more information, see Open-Source Models.</li> <li>External models: In this section, you can add commercial models such as Open AI, Anthropic, Azure Open AI, Cohere, and Google. Moreover, if you've hosted any models and wish to integrate them into GALE using API connections, this can be seamlessly achieved in this section. For more information, see External Models.</li> </ol>"},{"location":"models/external-models/add-an-external-model-using-api-integration/","title":"Add an External Model using API Integration","text":"<p>Custom API Integration in GALE enables extensibility of use, where it allows you to bring in your models from an external ecosystem via API integration.</p> <p>To add an external model using API integration, follow these steps:</p> <ol> <li>Click Models on the top navigation bar of the application. The Models page is displayed.</li> <li> <p>Click the External models tab on the Models page.</p> <p></p> </li> <li> <p>Click Add a model under the External models tab. The Add an external model dialog is displayed.</p> <p></p> </li> <li> <p>Select the Custom integration option to connect models via API integration, and click Next.</p> <p>The Custom API integration dialog is displayed.</p> </li> <li> <p>Enter a Model name and Model endpoint URL in the respective fields.</p> <p></p> </li> <li> <p>In the Headers section, specify the headers that need to be sent along with the request payload such as Key and Value.</p> <p></p> </li> <li> <p>In the Variables section, you have 2 types:</p> <ul> <li>Prompt variable: The Prompt variable is by default set to mandatory. You can Turn ON the toggle button for the System prompt and examples if required.</li> <li>Custom variables: Click the Custom variables tab under the Variables section and click the +Custom variables button on the Custom variables section.</li> </ul> <p></p> <p>The Add custom variable dialog is displayed. Enter the Variable name, and Display name and select the Data type.</p> <p></p> </li> <li> <p>In the Body section, request body of the model you are trying to connect with in GALE.</p> <p></p> </li> <li> <p>In the Test response section, you need to provide a test response from the model:</p> <ul> <li>Click the Test button under the Test section on the Custom API Integration dialog.    The Sample Input dialog is displayed.</li> </ul> <p></p> <ul> <li>Enter a Prompt, Sample prompt, and Examples in the respective fields.</li> </ul> </li> <li> <p>Once the response is generated after the Test, you can configure the JSON path to capture the Output path, Input tokens, and Output tokens.</p> <p>Note</p> <p>Click the Save as draft button to save the model and the status is saved as Draft.</p> </li> <li> <p>Click Confirm to save the details and your external model is listed in the External model's list. The model can now be used in the playground and the Gen AI node of the agent flow builder.</p> <p>Note</p> <p>You can click the 3 dots icon corresponding to the Model name in the list of external models and edit or delete the model.</p> <p></p> </li> </ol>"},{"location":"models/external-models/add-an-external-model-using-easy-integration/","title":"Add an External Model using Easy Integration","text":"<p>In this topic, you can see the process of adding the Claude-V1 model from the provider Anthropic.</p> <p>To add an external model using easy integration, follow these steps:</p> <ol> <li>Click Models on the top navigation bar of the application. The Models page is displayed.</li> <li> <p>Click the External models tab on the Models page.</p> <p></p> </li> <li> <p>Click Add a model under the External models tab. The Add an external model dialog is displayed.</p> <p></p> </li> <li> <p>Select the Easy integration option to integrate models from Open AI, Anthropic, Google, or Cohere and click Next.</p> </li> <li> <p>Select a provider to integrate with and click Next.</p> <p></p> <p>A Pop-up with the list of all the Anthropic models that are supported in GALE is displayed.</p> <p></p> </li> <li> <p>Select the required Model and click Next.</p> </li> <li> <p>Enter the respective API key you have received from the provider in the API key field and click Confirm to start the integration.</p> <p></p> <p>The model is integrated and is listed in the External models list.</p> </li> </ol> <p>Note</p> <ul> <li>You can click the 3 dots icon corresponding to the Model name in the list of external models and edit or delete the model.</li> <li>You can set the Inference option using the toggle button corresponding to the Model name. If the Inferencing toggle is ON, you can use this model across GALE. If the toggle button is OFF, it means you cannot infer it anywhere in GALE. For example, if you turn OFF the toggle button, then in the playground, an error message is displayed that the model is not active even though you have added it in the external models tab.</li> </ul>"},{"location":"models/external-models/external-models-overview/","title":"External Models","text":"<p>GALE offers flexible options for integrating external models such as Open AI, Anthropic, Azure Open AI, Cohere, and Google.</p> <p>The integration is done in 2 ways:</p> <ul> <li>Through the Easy integration method, you can choose a model from a commercial provider such as Open AI, Anthropic, or Google and use the respective API key provided by the provider. For more information, see Add an External Model using Easy Integration.</li> <li>Alternatively, if you hosted your model externally, GALE provides a custom API integration method to seamlessly incorporate it into the platform. For more information, see Add an External Model using API Integration.</li> </ul> <p>With these options, GALE empowers you to leverage the full potential of your preferred models while enjoying the benefits of our platform's advanced capabilities.</p>"},{"location":"models/fine-tune-models/configure-your-fine-tuned-model/","title":"Configure your Fine-Tuned Model","text":"<p>You can modify the general details of your fine-tuned model if required.</p> <p>To modify the settings of your fine-tuned model, follow the steps:</p> <ol> <li> <p>Click the Configurations tab from the left panel on the Models page. The Configurations page is displayed.</p> <p></p> </li> <li> <p>Make any required changes and the changes are auto-saved.</p> </li> <li>You also have the option to suspend your deployed fine-tuned model using the Proceed to undeploy button. It immediately un-deploys the model and is not available for any inferencing requests.</li> </ol> <p>Note</p> <p>To delete a fine-tuned model, you must first un-deploy it and then delete it. </p>"},{"location":"models/fine-tune-models/create-a-fine-tuned-model/","title":"Create a Fine-Tuned Model","text":"<p>You can create a fine-tuned model in the Create a fine-tune model wizard, which involves the following 5 steps:</p> <ul> <li>General details</li> <li>Selecting a base model</li> <li>Fine-tuning configuration</li> <li>Adding the training and evaluation datasets</li> <li>Adding the test dataset (optional)</li> <li>Selecting a hardware</li> <li>Integrating with Weights &amp; Biases (optional)</li> </ul> <p>Let us now look into each step in detail.</p> <p>To create a fine-tuned model, follow these steps:</p> <ol> <li> <p>Click Models on the top navigation bar of the application. The Models page is displayed.</p> <p></p> </li> <li> <p>Click the Create a fine-tuned model button on the Models page. The Create a fine-tuned model dialog is displayed.</p> </li> <li> <p>In the General details section:</p> <ul> <li> <p>Enter a Model name and Description for your fine-tuned model.</p> <p></p> </li> <li> <p>Provide tags to ease the search for the model and click Next.</p> </li> </ul> <p>In the Base model section, do one of the following:</p> <ul> <li>Select form the Kore hosted models.</li> </ul> <p>Or</p> <ul> <li>Select Hugging Face connection to use. For more information about how to connect to Hugging Face account, see How to Connect to your Hugging Face Account.</li> </ul> <p></p> </li> <li> <p>In the Fine-tuning configuration section:</p> <ul> <li> <p>Select a Fine-tuning type that you want to fine-tune for your requirements.</p> </li> <li> <p>Enter the Number of Epochs which implies the number of times the entire data set is passed through the model during the training process.</p> <p></p> </li> <li> <p>Enter a number for Batch size which implies the number of training examples used in one iteration of training.</p> </li> <li> <p>Enter a value for the Learning rate which implies the size of the steps taken during the optimization of a model.</p> </li> <li> <p>Click Next to proceed to the next step.</p> </li> </ul> </li> <li> <p>In the Dataset section:</p> <ul> <li>Select the Training dataset which is the data that will be used in training the base model and acts as the foundation for the model's learning.</li> </ul> <p>Note</p> <p>The format accepted is JSONL, CSV, or JSON. The training file, evaluation file, and the test file follow a specific format. The file should have at least two columns with one column as prompt and other as completion. In the wizard, you have an option to download the sample as well.</p> <ul> <li> <p>Define the data for evaluation. You can use the same training data set in the evaluation process as well. In this step, you can either allocate a percentage of the training dataset to use for evaluation, or upload a new evaluation dataset, or skip the evaluation.</p> <p></p> </li> <li> <p>Click Next to proceed to the next step.</p> </li> </ul> </li> <li> <p>In the Test data section:</p> <ul> <li>Upload a dataset with which you want to test your fine-tuned model.</li> </ul> <p>Note</p> <p>The format accepted is JSONL, CSV, or JSON. </p> <p></p> <ul> <li>Click Next to proceed to the next step.</li> </ul> <p>Note</p> <p>If you change the training file or the evaluation file in the Dataset section of the wizard, then a warning is displayed in the Test data section. You can verify and proceed.</p> <p>In the Hardware section:</p> <ul> <li> <p>Select the hardware required for fine-tuning your model.</p> <p></p> </li> </ul> </li> <li> <p>In the Weights &amp; Biases section:</p> <ul> <li> <p>Select your WandB connection from the drop-down list. If you don't have a WandB connection, you can click the + New connection that is available in the drop-down list. For more information about how to create the WandB account, see How-to-Integrate-with-WandB.</p> <p>Note</p> <p>You need an account with Weights and Biases. Enabling the integration with the help of an API token will share your real-time fine-tuning status with the platform and you can comprehensively monitor the fine-tuning metrics of your model. You can use the API token they provided to create an integration and then all the data related to the fine-tuning process will be sent to the account related to that API token.</p> <p></p> </li> <li> <p>Click Next to proceed to the next step.</p> </li> </ul> </li> <li> <p>In the Review step, verify all the details that you provided earlier.</p> <p>Note</p> <p>If you want to make any modifications, you can go to the previous step by clicking the Back button or a particular step indicator on the left panel.</p> <p></p> </li> <li> <p>Click Start fine-tuning. The Overview page of your fine-tuned model is displayed with the status \u201cInitializing\u201d.</p> <p></p> <p>The different statuses that are involved in the process include:</p> <ul> <li> <p>Initializing</p> </li> <li> <p>Training in progress</p> </li> <li> <p>Testing in progress</p> </li> <li> <p>Fine-tuning completed</p> </li> </ul> <p>Note</p> <p>You can stop the process if required in the middle and resume it later, then the status is changed to \u201cStopped\u201d. Then a Re-trigger button is displayed to initiate the fine-tuning process again from the beginning. If the fine-tuning process fails, then the status is changed to \u201cFailed\u201d and you can view the reason for failure. You can make the required changes, and click the Re-trigger button to start the fine-tuning again.</p> <p>Once the fine-tuning is triggered, you can check the progress in real-time on the Overview page. You can click any model name from the list of fine-tuned models and the Overview page of the model is displayed.</p> <p>This page displays the following sections:</p> <ul> <li> <p>Training information: This section captures crucial information such as the type of training being performed, the step at which the training is currently, training duration, training loss, and validation loss, graphically displays them with a click of arrows, and plots the overall loss trend. You can click the arrow keys to access the graph.</p> </li> <li> <p>Test data information: This section indicates how well your fine-tuned model performed on the test dataset (if you provided any) with the help of a metric called the BLEU score.</p> </li> <li> <p>Training parameters: This section displays the summary of the parameters you have provided in the wizard and it is displayed for your convenience.</p> </li> <li> <p>System information: This section captures the information about the Hardware- CPUs and GPUs functioning at the backend and its utilization during the fine-tuning process.</p> </li> </ul> </li> </ol> <p>You can also download the training file for your reference from this page. You also have the option to download the test result and the test data from the test info section once the testing is completed.</p> <p>Note</p> <p>If you want to perform the testing again, you can click the Retry option corresponding to the Test info section on the Overview page and select a new test data set file or use the existing file and confirm to start the testing again. The status then is displayed as \u201cTesting in Progress\u201d.</p> <p></p> <p>After the model is fine-tuned, you can deploy the fine-tuned model and use it across GALE and also externally via the API endpoint that is generated after deploying the model.</p> <p>Note</p> <p>When fine-tuning is completed, you can use it to create another fine-tuned model on top of this model.</p>"},{"location":"models/fine-tune-models/deploy-a-fine-tuned-model/","title":"Deploy a fine-tuned model","text":"<p>Once the fine-tuning process is completed, you can deploy your fine-tuned model.</p> <p>To deploy your fine-tuned model, follow these steps:</p> <ol> <li> <p>Do one of the following:</p> <ul> <li> <p>Click the Deploy model button on the Overview page of your fine-tune model.</p> <p></p> </li> </ul> <p>Or</p> <ul> <li> <p>Click the Model Endpoint from the left panel on the of your fine-tune model and then click Deploy model button.</p> <p></p> </li> </ul> </li> <li> <p>Click Deploy model. The Deploy dialog is displayed.</p> </li> <li> <p>In the General details section:</p> <ul> <li> <p>Enter a Deployment name and Description for your model.</p> <p></p> </li> <li> <p>Provide tags to ease the search for the model and click Next.</p> </li> </ul> </li> <li> <p>In the Parameters section:</p> <ul> <li> <p>Select the Sampling Temperature to use for deployment.</p> </li> <li> <p>Select the Maximum length which implies the maximum number of tokens to generate.</p> </li> <li> <p>Select the Top p which is an alternative to sampling with temperature where the model considers the results of the tokens with top_p probability mass.</p> </li> <li> <p>Select the Top k value which is the number of highest probability vocabulary tokens to keep for top-k-filtering.</p> </li> <li> <p>Enter the Stop sequences which implies that where the model will stop generating further tokens.</p> </li> <li> <p>Enter the Inference batch size which is used to batch the concurrent requests at the time of model inferencing.</p> </li> <li> <p>Select the Min replicas which is the minimum number of model replicas to be deployed.</p> </li> <li> <p>Select the Max replicas which is the maximum number of model replicas to auto-scale.</p> </li> <li> <p>Select the Scale up delay (in seconds) which is how long to wait before scaling-up replicas.</p> </li> <li> <p>Select the Scale down replicas (in seconds) which is how long to wait before scaling down replicas.</p> <p></p> </li> </ul> </li> <li> <p>Click Next.</p> </li> <li> <p>In the Hardware section:</p> <ul> <li> <p>Select the Hardware name required for the deployment and click Next.</p> <p></p> </li> <li> <p>In the Review step, verify all the details that you provided earlier. Select the I accept all the terms and conditions check box.</p> <p></p> </li> </ul> <p>Note</p> <p>If you want to make any modifications, you can go to the previous step by clicking the Back button or a particular step indicator on the left panel.</p> </li> <li> <p>Click Deploy.</p> <p>After the deployment process is complete the status is changed to \u201cDeployed\u201d. You can now infer this model across GALE and externally. The deployment of your model will start and after the deployment process is complete, you can find the API endpoint created for your fine-tuned model.</p> </li> </ol>"},{"location":"models/fine-tune-models/export-your-fine-tuned-model/","title":"Export your Fine-Tuned Model","text":"<p>You can export your fine-tuned model for reference.</p> <p>To export your fine-tuned model, follow these steps:</p> <ol> <li> <p>Click the three dots icon corresponding to the Model name on the Models page. A pop-up with a list of options is displayed.</p> <p></p> </li> <li> <p>Click Export model from the list of options. The exported zip file is saved in your downloads folder.</p> </li> </ol>"},{"location":"models/fine-tune-models/fine-tune-models-overview/","title":"Fine-Tuned Models","text":"<p>Fine-tuning a pre-existing model is a common approach in creating fine-tuned models. By starting with a pre-trained model, which has its functions and knowledge, and building on top of it, you can save time and resources. Fine-tuning involves training the model on your specific dataset or domain to adapt it to your needs. This way, you can leverage the knowledge and features learned by the pre-trained model while tailoring it to your data and requirements. </p>"},{"location":"models/fine-tune-models/generate-an-api-key/","title":"Generate a New API Key","text":"<p>You can generate an API for your fine-tuned model and share it with other trusted users. It is essential to have a secure API key when trying to connect to this fine-tuned model in an external environment.  </p> <p>To generate a new API key for your fine-tuned model, follow these steps:</p> <ol> <li> <p>Click the API keys tab in the left panel on the Overview page of your fine-tuned model.</p> <p></p> </li> <li> <p>Click the Create a new API key button. The Create new API key dialog is displayed.</p> <p></p> </li> <li> <p>Enter a Name for the key and click the Generate key button. Your API key is now generated. Click Copy and close button to copy your API key and share it with others if required. </p> <p></p> </li> </ol>"},{"location":"models/fine-tune-models/view-the-generated-api-endpoint/","title":"View the Generated API Endpoint","text":"<p>After the model is deployed, the API endpoint is generated which implies that your fine-tuned model is ready for inferencing externally and across the other sections in GALE.</p> <p>Note</p> <p>You will receive an email notification after your model deployment is completed and an API is generated and ready to use.</p> <p>To view the API Endpoint, follow these steps:</p> <ol> <li> <p>Click the Model Endpoint tab in the left panel on the Models page of your fine-tuned model.</p> </li> <li> <p>Click the Copy icon to copy and share the API Endpoint.</p> <p></p> </li> </ol> <p>The API endpoint is available in 3 formats. You can copy and use the same as required.</p>"},{"location":"models/fine-tune-models/view-the-generated-api-endpoint/#api-endpoint-usecase","title":"API Endpoint Usecase","text":"<p>You can use the deployed fine-tuned model in GALE for the following use cases:</p> <ul> <li> <p>In the Prompt Playground to compare prompts against commercial, open-source, or any other fine-tune model.</p> </li> <li> <p>In an agent in the agent flow builder via the Gen AI Node.</p> </li> </ul>"},{"location":"models/open-source-models/configure-your-open-source-model/","title":"Configure your Open-Source Model","text":"<p>You can modify the general details of the open-source model if required.</p> <p>To modify the settings of the open-source model, follow the steps:</p> <ol> <li> <p>Click the Configurations tab from the left panel on the Models page. The Configurations page is displayed.</p> <p></p> </li> <li> <p>Make any required changes in the Description, or Tags fields, and the changes are auto-saved.</p> </li> <li>You also have the option to suspend your deployed custom model using the Proceed to undeploy button. It immediately un-deploys the model and is not available for any inferencing requests. Then the status of the model changes to \u201cReady to deploy\u201d. You can deploy the model again from the Deploy section to use it.</li> </ol> <p>Note</p> <p>To delete an open-source model, you must undeploy it and then only you can delete it.</p>"},{"location":"models/open-source-models/deploy-an-imported-model-from-hugging-face/","title":"Deploy an imported model from Hugging Face","text":"<p>You can deploy an open-source model by selecting the Hugging Face option in the deployment process.</p> <p>To deploy a model from Hugging Face, follow these steps:</p> <ol> <li>Click Models on the top navigation bar of the application. The Models page is displayed.</li> <li> <p>Click the Open-source models tab on the Models page.</p> <p></p> </li> <li> <p>Click the Deploy a model button. A pop-up with a list of available models is displayed.</p> <p></p> </li> <li> <p>Click the Hugging Face option from the list. The Hugging Face dialog is displayed.</p> </li> <li> <p>In the General details section:</p> <ul> <li> <p>Enter a Deployment name and Description for your model.</p> <p></p> </li> <li> <p>Provide tags to ease the search for the model and click Next.</p> </li> </ul> </li> <li> <p>In the Import model section:</p> <ul> <li> <p>Select the Hugging Face connection to use from the drop-down list. For more information about How to enable Hugging Face in GALE, see How to add a connection with Hugging Face.</p> <p></p> </li> <li> <p>Enter the Hugging Face model name from Hugging Face that you wish to import and click Next.</p> </li> </ul> </li> <li> <p>In the Parameters section:</p> <ul> <li> <p>Select the Sampling Temperature to use for deployment.</p> </li> <li> <p>Select the Maximum length which implies the maximum number of tokens to generate.</p> </li> <li> <p>Select the Top p which is an alternative to sampling with temperature where the model considers the results of the tokens with top_p probability mass.</p> </li> <li> <p>Select the Top k value which is the number of highest probability vocabulary tokens to keep for top-k-filtering.</p> </li> <li> <p>Enter the Stop sequences which implies that where the model will stop generating further tokens.</p> </li> <li> <p>Enter the Inference batch size which is used to batch the concurrent requests at the time of model inferencing.</p> </li> <li> <p>Select the Min replicas which is the minimum number of model replicas to be deployed.</p> </li> <li> <p>Select the Max replicas which is the maximum number of model replicas to auto-scale.</p> </li> <li> <p>Select the Scale up delay (in seconds) which is how long to wait before scaling-up replicas.</p> </li> <li> <p>Select the Scale down replicas (in seconds) which is how long to wait before scaling down replicas.</p> <p></p> </li> </ul> </li> <li> <p>Click Next.</p> </li> <li> <p>In the Hardware section:</p> <ul> <li> <p>Select the Hardware name required for the deployment and click Next.</p> <p></p> </li> <li> <p>In the Review step, verify all the details that you provided earlier. Select the I accept all the terms and conditions check box.</p> <p></p> </li> </ul> <p>Note</p> <p>If you want to make any modifications, you can go to the previous step by clicking the Back button or a particular step indicator on the left panel.</p> </li> <li> <p>Click Deploy.</p> </li> </ol>"},{"location":"models/open-source-models/generate-an-api-key-open-source/","title":"Generate a New API Key","text":"<p>You can generate an API key for your open-source model and share it with other trusted users. It is essential to have a secure API key when trying to connect to this open-source model in an external ecosystem.  </p> <p>To generate a new API key for your open-source model, follow these steps:</p> <ol> <li> <p>Click the API keys tab from the left panel on the Models page.</p> <p></p> </li> <li> <p>Click the Create a new API key button. The Create new API key dialog is displayed.</p> <p></p> </li> <li> <p>Enter a Name for the key and click the Generate key button. Click the Copy and close button to copy your API key and share it with others if required.</p> <p></p> <p>All the generated API keys are listed in the API key section. You can hover over any key and find the delete icon corresponding to the name of the key if you want to delete the key.</p> </li> </ol>"},{"location":"models/open-source-models/open-source-models-overview/","title":"Open-Source Models","text":"<p>Open-source models refer to the models for which the source code is openly available. You can deploy them in GALE and use them either, throughout GALE, or externally via a generated API endpoint. Kore.ai provides a curated list of 30+ most popular open source models that can be hosted directly in GALE. </p> <p>Additionally, if you want to bring in open-source models from Hugging Face, you can enable that option in GALE. For more information about How to enable Hugging Face in GALE, see How to Enable Hugging Face.</p>"},{"location":"models/open-source-models/select-and-deploy-an-open-source-model/","title":"Select and Deploy an Open-Source Model","text":"<p>Currently, we support thirty-plus open-source models and provide them as a service to our users.</p> <p>To select and deploy a model, follow these steps:</p> <ol> <li>Click Models on the top navigation bar of the application. The Models page is displayed.</li> <li> <p>Click the Open-source models tab on the Models page.</p> <p></p> </li> <li> <p>Click the Deploy a model button. A pop-up with a list of available models is displayed.</p> <p></p> </li> <li> <p>Select and click a model from the list. You can select Hugging Face also from the list of options. For more information about Hugging Face, see Deploy an Imported Model from Hugging Face.</p> <p>The Deploy dialog is displayed.</p> </li> <li> <p>In the General details section:</p> <ul> <li> <p>Enter a Deployment name and Description for your model.</p> <p></p> </li> <li> <p>Provide tags to ease the search for the model and click Next.</p> </li> </ul> </li> <li> <p>In the Parameters section:</p> <ul> <li> <p>Select the Sampling Temperature to use for deployment.</p> </li> <li> <p>Select the Maximum length which implies the maximum number of tokens to generate.</p> </li> <li> <p>Select the Top p which is an alternative to sampling with temperature where the model considers the results of the tokens with top_p probability mass.</p> </li> <li> <p>Select the Top k value which is the number of highest probability vocabulary tokens to keep for top-k-filtering.</p> </li> <li> <p>Enter the Stop sequences which implies that where the model will stop generating further tokens.</p> </li> <li> <p>Enter the Inference batch size which is used to batch the concurrent requests at the time of model inferencing.</p> </li> <li> <p>Select the Min replicas which is the minimum number of model replicas to be deployed.</p> </li> <li> <p>Select the Max replicas which is the maximum number of model replicas to auto-scale.</p> </li> <li> <p>Select the Scale up delay (in seconds) which is how long to wait before scaling-up replicas.</p> </li> <li> <p>Select the Scale down replicas (in seconds) which is how long to wait before scaling down replicas.</p> <p></p> </li> </ul> </li> <li> <p>Click Next.</p> </li> <li> <p>In the Hardware section:</p> <ul> <li> <p>Select the Hardware name required for the deployment and click Next.</p> <p></p> </li> </ul> </li> <li> <p>In the Review step, verify all the details that you provided earlier. Select the I accept all the terms and conditions check box.</p> <p></p> <p>Note</p> <p>If you want to make any modifications, you can go to the previous step by clicking the Back button or a particular step indicator on the left panel.</p> </li> <li> <p>Click Deploy.</p> <p>Note</p> <p>You will be charged for deployment and inferencing-related costs for each open-source model.</p> </li> </ol> <p>After the deployment process is complete the status is changed to \u201cDeployed\u201d. You can now infer this model across GALE and externally.</p> <p>Click the three dots icon corresponding to the Model name under the Open-source models tab on the Models page. A pop-up with a list of options is displayed. If you choose the API endpoint option, it will navigate you to the API keys section of the Model and if you select the Configurations option, it will take you to the Configurations section of the Model.</p> <p></p>"},{"location":"models/open-source-models/select-and-deploy-an-open-source-model/#re-deploy-a-deployed-model","title":"Re-deploy a Deployed Model","text":"<p>After initially deploying a model, if you want you can modify some parameter values and redeploy the updated model.</p> <p>Note</p> <p>To re-deploy a model you must first undeploy the existing model and then deploy the updated one. This means there will be some downtime when the model is unavailable.</p> <p>To re-deploy a deployed model, follow these steps:</p> <ol> <li>Click the required model name from the Open-source models list.</li> <li>Click the Deploy model button. The Model Configuration page is displayed.</li> <li>Modify the required fields and click the Deploy button. The model is deployed and status is \u201cDeployed\u201d.</li> </ol>"},{"location":"models/open-source-models/view-the-generated-api-endpoint/","title":"View the Generated API Endpoint","text":"<p>After the open-source model is deployed, the API endpoint is generated which implies that your model is ready for inferencing externally and across the other sections in GALE. </p> <p>The API endpoint is available in 3 formats.</p> <p>Note</p> <p>You will receive an email notification after your model deployment is completed and an API is generated, and it is ready to use.</p> <p>To view the API Endpoint, follow these steps:</p> <ol> <li> <p>Click the required model from the models listing. Click the Model Endpoint tab in the left panel on the Models page of your open-source model. The API endpoint created for this open-source model is displayed.</p> </li> <li> <p>To use this model as a service, the generated code is helpful. Click the Copy icon to copy and share the API Endpoint.</p> <p></p> </li> </ol> <p>Note</p> <p>Click the Deployment history tab on the Deploy page to view the history. This can be particularly useful for auditing and accountability purpose.</p> <p>You can either embed the curl or the code that is generated into your own applications or use it externally. </p>"},{"location":"playground/add-a-model/","title":"Add a Model","text":"<p>Once you have given your prompts in the Prompt box, you can test your prompts across different AI model(s) and decide on the required model.</p> <p>To add a model, follow these steps:</p> <ol> <li>Click the required Experiment from the Experiments page. The Prompt experiments page is displayed.</li> <li>Click Add Model in the model response section. A pop-up with a list of options is displayed.</li> <li> <p>Click Manage models from the list of options.</p> <p></p> <p>You will be redirected to the External models page to add a model. For more information about how to add an external model, see Add an external model.</p> <p>Note</p> <p>Follow the preceding process of adding an external model only if you are adding any model for the first time. If you have already added a model, it is automatically displayed in the pop-up list when you click the Add model button. For example, if you have added the Claude-v1 model from Anthropic then it is displayed in the pop-up and you click to select the model as shown in the following image.</p> <p></p> <p>You can add other models also to compare and decide which model provides the suitable output for your prompt. </p> </li> <li> <p>In the added model section click the + icon corresponding to the model\u2019s name.\u00a0 A pop-up with a list of options is displayed.</p> <p></p> </li> <li> <p>Repeat step 3 to add another model to compare the outputs. </p> </li> <li>Click the Model setting icon corresponding to the model\u2019s name to make any changes in the settings of the base model you have selected. </li> <li> <p>Click Generate Output after you have added the required number of models to compare. The Generated output for comparison is displayed in the Model section of the Prompt playground space for your reference as shown in the following image.</p> <p></p> </li> </ol> <p>Note</p> <p>You can click the response to view the expanded view of the response, click the copy icon corresponding to the response to copy and use the response, make any settings changes in the model to see a difference in the model response, and remove the model if required.</p>"},{"location":"playground/create-a-new-prompt-experiment/","title":"Create a New Prompt Experiment","text":"<p>A prompt experiment is a process of testing and comparing the performance of different AI models using a specific input called a prompt. The prompt can be a phrase, a question, or a paragraph of data, and the AI model generates an output based on the input.</p> <p>In a prompt experiment, you can create experiments in either a simple or an advanced mode. In the simple mode, you can easily input prompts and select from configured models to automatically generate outputs. In an advanced mode, you have more control over the experiment, allowing you to link your own data set, add few shot examples, and system prompts, to get the optimized results. </p> <p>Prompt experiments are useful for testing and comparing AI models for specific use cases and applications. </p> <p>To create a prompt experiment, follow these steps:</p> <ol> <li> <p>Click Playground on the top navigation bar of the application. The Experiments page is displayed.</p> <p></p> </li> <li> <p>Click the Create experiment button. The New experiment dialog is displayed.</p> <p></p> </li> <li> <p>Enter a name for your experiment in the Experiment name field.</p> </li> <li>Select the Type of experiment if it is Text-based, then click the Text generation option.</li> <li> <p>Click Create to start with your prompt experiment process. A blank Prompt experiment page is displayed where you can enter your prompt and add models to compare the generated outputs.</p> <p></p> </li> </ol>"},{"location":"playground/explore-other-actions-to-perform-in-the-prompt-playground/","title":"Explore Other Actions to Perform in the Prompt Playground","text":"<p>You can also perform other actions on the prompt page and use it for your reference. You can view the history of your experiment and restore the version of the prompt you like, export prompt data, and copy the experiment as a prompt or as an Gen AI node.</p> <p></p>"},{"location":"playground/explore-other-actions-to-perform-in-the-prompt-playground/#copy-a-prompt","title":"Copy a Prompt","text":"<p>You can copy a prompt experiment and use it for your reference for easy access to the other sections in the product.</p> <p>You have 2 options to copy your prompt experiment:</p> <ul> <li>Copy as a Prompt: If you select the copy as a prompt option, then the user prompt, the few shot examples, and the system prompt are all copied. </li> <li>Copy as Gen AI node: If you select the copy as Gen AI node option, then along with the user prompt, the few shot examples, and the system prompt, the bookmarked model and the settings applied to the model are also copied. Once it is copied you can paste it as an Gen AI node in the Flow builder canvas. </li> </ul> <p>To copy a prompt, follow these steps:</p> <ul> <li> <p>On the Prompts experiment page, click Copy on the header of the page. A pop-up with options is displayed.</p> <p></p> </li> <li> <p>Click as prompt or as Gen AI node as per your requirement and the experiment is copied.</p> </li> </ul>"},{"location":"playground/explore-other-actions-to-perform-in-the-prompt-playground/#restore-a-prompt-version-using-the-history","title":"Restore a Prompt Version using the History","text":"<p>You can review the timeline of prompts and their corresponding generated outputs, complete with date and time stamps. Additionally, you can restore a prompt from this section, enabling you to utilize it and implement any necessary modifications, thereby saving considerable time compared to creating a new prompt from scratch.</p> <p>To restore a prompt, follow these steps:</p> <ul> <li> <p>On the Prompts experiment page, click the History icon on the header of the page.</p> <p></p> <p>The history section is displayed with the list of all the old prompt experiments you created.</p> </li> <li> <p>Click the required old version of the experiment. The Restore option is displayed on the footer of the prompt experiment page.</p> <p></p> </li> <li> <p>Click Restore to work on the selected version of the prompt.</p> </li> </ul>"},{"location":"playground/explore-other-actions-to-perform-in-the-prompt-playground/#export-prompt-data","title":"Export Prompt Data","text":"<p>You can download the prompt and the related experiment data and export it as a CSV file which can be used for later reference.\u00a0</p> <p>To export a CSV file, follow these steps:</p> <ul> <li>On the Prompts experiment page, click the download icon on the header of the page.</li> </ul> <p>The prompt experiment is downloaded as a CSV file successfully and is available in the downloads section of your computer.</p>"},{"location":"playground/generate-output-using-advanced-mode/","title":"Generate Output using Advanced Mode","text":"<p>While using the prompt playground, you have to upload a dataset in advanced mode as input. You can add and pre-view the existing or newly uploaded datasets. You can also replace one dataset with another based on the requirement for a particular prompt and generate multiple outputs simultaneously. </p> <p>The advanced mode option helps you improve the prompt creation and testing process more easily and efficiently. You can define a prompt to send to the models, add a few examples for the model to understand the output you are expecting, and upload a data set with inputs. In this mode, you can tweak and refine your prompts, generate the outputs for the selected models, and review the generated responses.\u00a0\u00a0\u00a0</p> <p>On the Prompt page, you can find a Prompt sample auto-populated based on the template you have selected. This is additional information/instruction given to the LLM while it processes the prompt. You can modify this prompt if required.</p> <p>To generate an output using advanced mode, follow these steps:</p> <ol> <li> <p>On the Prompt page, click the Advance Mode toggle button to shift to the advanced mode from the simple mode of output generation.</p> <p></p> <p>The Prompt playground view is enhanced for you with other options to explore.</p> <p></p> </li> <li> <p>Click the +Add Dataset link under the Dataset section on the Prompt page to upload your CSV file with data.</p> <p></p> <p>The Dataset dialog is displayed.</p> </li> <li> <p>Click Upload file to upload a CSV file from your local computer and click Upload. You can see a preview of all the data in your CSV file. Click Proceed to accept the file.</p> </li> <li> <p>Click the arrow under the Examples section on the Prompt section to add a sample user input and sample AI response output.</p> <p></p> </li> <li> <p>Click Save to save the sample examples.</p> </li> <li> <p>Click the down arrow corresponding to the Input field. A pop-up with a list of numbers such as 5, 10, 15, and 20 are visible. This displays the number of rows you want to see in your generated output from the CSV file that you have selected. Select the Randomize check box if you want to select randomly otherwise the list is sequential.</p> </li> <li> <p>The value for the variables in the {{}} braces is populated from the uploaded CSV file. You can add variables to the prompt by opening the brackets. For example, {{ xyz }} is a variable in the prompt box.\u00a0</p> <p>The value of the variable is populated from the dataset or file you have uploaded. To make sure the value is mapped correctly between the variable and the file, for the data to flow, you need to make the column name a variable within those curly braces.</p> <p></p> <p>For example,\u00a0{{Name}} is a variable, from the file you uploaded where Name is a column in that CSV file. A maximum of 20 names or rows that you select can flow from the file to the prompt input column of the advanced mode.</p> </li> <li> <p>Click the + icon corresponding to the Add Model section to add the models you want to select and compare the generated outputs.</p> <p>Note</p> <p>Currently, you can add only a maximum of 3 models in the playground. For more information about how to add a model to the prompt, see Add an external model.</p> </li> <li> <p>Click Generate Output after you have added the required number of models to compare. The Generated output for comparison is displayed in the Model section of the Prompt playground space for your reference.</p> <p>Note</p> <p>You can view the matrix in the generated output section which helps in deciding which prompt and model are better for your requirement.</p> <p></p> </li> </ol> <p>It displays the total tokens metric which implies how many tokens are sent to the model and how many are sent back in the response, the time taken by the model to respond with the answer, and the response and request in the JSON format. You can click the View in JSON format icon at the bottom of the generated output section to view the request and response generated in JSON format in a separate dialog box as shown in the following image.</p> <p></p> <p>If you want to view all the details of the outputs across all the models you can turn ON the toggle button by clicking the info icon on the Models section of the Playground space as shown in the following image. If you turn OFF the toggle button, then the metrics is not displayed.</p> <p></p> <p>You can collect feedback on the model's responses to refine its performance. Feedback is collected through simple Thumbs Up or Down on responses in the playground. Giving feedback is optional and does not hinder generating more responses. Thumbs up is for good responses. Thumbs down is for incorrect, hypothetical, or disliked responses. When you click Thumbs down icon a pop-up is displayed and you can add additional feedback if required.</p> <p>Note</p> <p>This feedback option is only applicable for fine-tuned and open-source models.</p> <p></p>"},{"location":"playground/overview/","title":"About Playground","text":"<p>Prompts are the basic inputs you provide to large language models (LLMs) to generate a required response. Prompts can also be augmented with additional information, such as examples, to help the model understand the context of the input. This can improve the accuracy and relevance of the output, making it more valuable to the user.</p> <p>Designing effective prompts is critical to training and using LLMs. By providing clear and relevant inputs, you can ensure that the models can provide accurate and useful responses to your queries and tasks. The playground interface facilitates experimentation with various prompts and different types of AI models including commercial, open-source, or fine-tuned to achieve the intended outcome.</p>"},{"location":"playground/select-a-template-for-a-prompt/","title":"Select a Template for a Prompt","text":"<p>You can use the pre-defined templates available in GALE while providing prompts to make your experience easy and save time. There are different categories of templates that you can use to get the desired output. The different categories include analyzing documents, writing and conversation, learning, and coding. In each of the categories, there are a few templates that can be used for a specific task.\u00a0</p> <p>For example, if you select the \u201cWriting a blog post\u201d template from the Writing and Conversations category then the sample prompt is ready in the Prompt box which looks like this: \u201cGenerate a blog post on the topic {{topic}} in a {{ tone }} tone\u201d. Similarly, you can use the \u201cTeach me about GANs\u201d template from the Learning category, and the prompt will look like this: \u201cTeach me about the topic {{ topic name }} like I am a 5-year-old\u201d. You can provide the variables and generate the output for your reference. Variables are the values you provide in the curly braces when selecting a prompt template.</p> <p>Note</p> <p>In the simple mode, you input the required variable without the curly braces. In advanced mode, data is taken from the selected dataset file.\u00a0For more information about uploading a dataset, see Upload a dataset file.</p> <p>To select a template, follow these steps:</p> <ol> <li> <p>On the Prompts experiment page, click Templates corresponding to the Prompt box.</p> <p></p> <p>The list of templates is displayed.</p> </li> <li> <p>Click the required template from the category you require. For example, you can take a template \u201cText to bullet points\u201d and then the prompt is displayed in the Prompt box.</p> <p></p> </li> <li> <p>Enter a value for the variables by removing the {{ }} to get the desired output as shown in the following image.</p> <p>Note</p> <p>In the simple mode you must remove the {{}} and add the value in the prompt.</p> <p></p> <p>Once you generate an output, you will be able to view the output as shown in the following image.</p> <p></p> </li> </ol>"},{"location":"temp/test/","title":"Test","text":"Q&amp;A_1 <p>Q&amp;A_1_content</p> Q&amp;A_1 <p>Q&amp;A_1_content</p> <ul> <li> <p> HTML for content and structure</p> </li> <li> <p> JavaScript for interactivity</p> </li> <li> <p> CSS for text running out of boxes</p> </li> <li> <p> Internet Explorer ... huh?</p> </li> </ul> Tab 1Tab 2 <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer ... huh?</p> <p>Test  <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]</p> <p> License</p> <p>End of tab</p> <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes  Getting started</p> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site  Reference</p> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines  Customization</p> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]  License</p> <p> HTML for content and structure</p> <p> JavaScript for interactivity</p> <p> CSS for text running out of boxes</p> <p> Internet Explorer New ... huh?</p> <p> Virtual Assistant Integration The platform offers robust integration capabilities, enabling seamless connection with various systems and services. This ensures that your virtual assistant can work in harmony with your existing tools and infrastructure. Learn More Omnichannel Capabilities The platform provides omnichannel support, allowing your virtual assistant to engage with users across multiple channels such as web, mobile, and messaging apps. This ensures consistent and efficient customer interactions. Learn More Multilingual Support Kore.ai\u2019s virtual assistant is equipped with multilingual capabilities, enabling it to understand and communicate in different languages. This feature helps you cater to a diverse user base and expand your global reach. Learn More </p> Tab 1Tab 2 <p> Virtual Assistant Integration The platform offers robust integration capabilities, enabling seamless connection with various systems and services. This ensures that your virtual assistant can work in harmony with your existing tools and infrastructure. Learn More Omnichannel Capabilities The platform provides omnichannel support, allowing your virtual assistant to engage with users across multiple channels such as web, mobile, and messaging apps. This ensures consistent and efficient customer interactions. Learn More Multilingual Support Kore.ai\u2019s virtual assistant is equipped with multilingual capabilities, enabling it to understand and communicate in different languages. This feature helps you cater to a diverse user base and expand your global reach. Learn More </p> <p> Introduction to Dialog Tasks A core component of the XO Platform, an essential tool for building conversations that are connected to your business logic. Reference Introduction to Dialog Tasks A core component of the XO Platform,an essential tool for building conversations that are connected to your business logic. Reference Introduction to Dialog Tasks A core component of the XO Platform,an essential tool for building conversations that are connected to your business logic. Reference </p> <p> Define Use Cases: Use Cases are fundamental building blocks for automation. Build use cases to help specific audiences navigate well-defined steps that solve a clear intent. Learn More </p> <p> Leverage Natural Language: Leverage the Platform\u2019s NLP capabilities to train and optimize your automation workflows to handle complex use cases. Learn More </p> <p> Intelligence Management: Empower your automation workflows to handle nuances of human conversations, including interruptions, clarifications, and more. Learn More </p> <p> Test Workflows: Use an extensive suite of features to conduct rigorous testing of your automation workflows to ensure everything works as expected. Find and fix problems before they reach your users. Learn More </p>"},{"location":"temp/whats-new-in-this-release/","title":"What\u2019s New","text":"<p>Learn about the new features and enhancements included in v10.1 of Kore.ai Experience Optimization Platform which was released on April 16, 2023.</p> <p>The v10.1 of the Kore.ai XO Platform focuses on leveraging the power of Large Language Models and Generative AI to enable enterprises to create intelligent and context-specific conversational experiences. The release offers a copilot for smart assistance, better conversational capabilities, and delivers personalized responses.</p> <p>The key features and enhancements included in this release are listed below for your reference:</p>"},{"location":"temp/whats-new-in-this-release/#smart-copilot-for-iva-development","title":"Smart Copilot for IVA Development","text":""},{"location":"temp/whats-new-in-this-release/#enhanced-bot-creation-journey-with-use-case-suggestions","title":"Enhanced Bot Creation Journey with Use Case Suggestions","text":"<p>Create Virtual Assistants faster with the new bot creation process that lets you generate use cases automatically. Dialog Tasks are auto-created along with the bot, providing you with the base framework to fasttrack your VA creation journey. [Learn more].</p>"},{"location":"temp/whats-new-in-this-release/#automatic-dialog-generation","title":"Automatic Dialog Generation","text":"<p>This feature auto-generates conversations and dialog flows using the VA\u2019s purpose and intent description provided during the creation process. The Platform uses LLM and generative AI to create suitable Dialog Tasks for Conversation Design, Logic Building &amp; Training by including the required nodes in the flow.</p> <p>You can provide an intent description, and the Platform handles the Conversation Generation for the Dialog Flow. You can preview the conversation flow, view the Bot Action taken, improvise the intent description, and regenerate the conversation to make it more human-like. The nodes and the flow for the Business Logic are automatically built for your conversation, and you only need to configure the flow transition. Learn more .</p> <p></p>"},{"location":"temp/whats-new-in-this-release/#training-data-suggestions","title":"Training Data Suggestions","text":"<p>Quickly generate high-quality training data using suggested utterances for each intent. Review and add the utterances to create a robust training set for your bot.  Learn more .</p> <p></p>"},{"location":"temp/whats-new-in-this-release/#nlp-batch-test-case-suggestions","title":"NLP Batch Test Case Suggestions","text":"<p>Automatically generate NLP test cases for every intent, including the entity checks. Use the generated utterances to quickly create test suites in the builder.  Learn more .</p> <p></p>"},{"location":"temp/whats-new-in-this-release/#conversation-test-cases-suggestions","title":"Conversation Test Cases Suggestions","text":"<p>Get simulated user inputs covering end-user scenarios at every test step. Use the suggestions to create test suites instantly. You can view input/utterance suggestions at every conversation step simulating the various input types and scenarios. This feature helps check if the task/intent is robust enough to handle random user utterances. It helps you predict and simulate the end user\u2019s behavior and check if the VA can execute all the defined flows by generating user responses and presenting any digressions from the specified intent.  Learn more .</p> <p></p>"},{"location":"temp/whats-new-in-this-release/#dynamic-conversations","title":"Dynamic Conversations","text":""},{"location":"temp/whats-new-in-this-release/#dynamic-paraphrasing","title":"Dynamic Paraphrasing","text":"<p>You can now leverage Generative AI to rephrase bot responses based on conversation context and users\u2019 emotions, resulting in more empathetic and natural responses that enhance user experience and engagement. When the OpenAI or Azure-OpenAI integration is enabled, you can see a new setting to rephrase responses at the node level for Message, Entity, and Confirmation Nodes. The messages added as User Prompts, Error Prompts, and Bot Responses are rephrased during runtime using the integration.  Learn more .</p> <p></p>"},{"location":"temp/whats-new-in-this-release/#ai-assisted-adaptive-dialog","title":"AI-Assisted Adaptive Dialog","text":"<p>The AI-Assisted Dialog Node lets you leverage the full potential of LLMs and Generative AI models to quickly build conversations that involve complex flows and also provide human-like experiences. You can define the entities you would like to collect and also the business rules that govern the collection of these entities. The XO Platform orchestrates the conversation using contextual intelligence, ensuring that the conversation is always grounded to your enterprise business rules. You can also provide exit rules for handing off the conversation to the virtual assistant or the human agents.  Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#knowledge-graph-powered-by-llm","title":"Knowledge Graph Powered by LLM","text":"<p>The new Few-Shot Knowledge Graph leverages LLMs to understand the FAQs without the need for exhaustive ontology. All you need to do is add all FAQs to the root node/term. This significantly reduces the complexity of building and maintaining an ontology structure. Learn more.</p> <p>With the introduction of Few-shot models in ML and KG engines, rescoring by Ranking &amp; Resolver is no longer required for intent identification. Therefore, we have introduced a new version of Ranking &amp; Resolver (Version 2) for Few-shot models that only ranks intents based on scores from ML and KG engines. The version significantly improves the accuracy of intent identification.</p> <p>Multi-language Support for Zero-shot and Few-shot Models</p> <p>The Zero-shot and the Few-shot ML Models are now supported in all non-English languages.</p>"},{"location":"temp/whats-new-in-this-release/#pre-built-integrations","title":"Pre-built Integrations","text":""},{"location":"temp/whats-new-in-this-release/#integration-with-unblu-for-agent-transfer","title":"Integration with Unblu for Agent Transfer","text":"<p>Kore.ai\u2019s pre-built Agent Transfer integrations now allow you to seamlessly hand off the conversations to the Unblu agent system without writing any custom code using the BotKit. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#disable-or-delete-pre-built-action-integrations","title":"Disable or Delete Pre-built Action Integrations","text":"<p>You can now disable or delete a configured external Action integration.</p>"},{"location":"temp/whats-new-in-this-release/#additional-enhancements","title":"Additional Enhancements","text":""},{"location":"temp/whats-new-in-this-release/#external-nlu-for-universal-bots","title":"External NLU for Universal Bots","text":"<p>The Platform provides more flexibility in bot orchestration by allowing you to link some bots using external NLU engines and others using proprietary multi-engine NLP. With external NLU integration, you can continue to have the NLU training on an external system and build the conversation flow on the XO platform. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#analytics-details-in-webhook-v2-response","title":"Analytics Details in Webhook v2 Response","text":"<p>The Webhook v2 response now includes additional conversation flow-related analytics information to help you build custom analytics. You can set the AnalyticsDetails parameter to Include in the request to view meta tags related to all nodes, tasks, sub-task, and session_id details in the response. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#export-conversational-path-analysis-data","title":"Export Conversational Path Analysis Data","text":"<p>You can now export the Conversational Path Analysis data in a .csv file to analyze the flow of drop-off sessions and take the required actions. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#customize-authorization-profiles-for-a-conversion-session","title":"Customize Authorization Profiles for a Conversion Session","text":"<p>The Platform provides a new way to clear authorization profiles collected from the users. The authorization profiles can be auto-cleared as part of the session closure, or you can also use the koreUtil.clearAuthProfiles and koreUtil.clearAllAuthProfiles functions. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#improved-messaging-channel-support","title":"Improved Messaging Channel Support","text":"<p>SmartAssist Gateway is Kore.ai\u2019s native voice interface to deliver seamless and low-latency conversation experiences. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#plan-usage","title":"Plan &amp; Usage","text":"<p>Ecommerce Plans are now supported in the EU region. Also, wire transfer-based payments are now supported for Ecommerce Plans. Learn more.</p>"},{"location":"temp/whats-new-in-this-release/#entity-rule-enhancements","title":"Entity Rule Enhancements","text":"<ul> <li>Letters rule for the String Entity: The new Letters rule <code>(letters=a single number OR a range)</code> for the String entity allows you to extract a word of a specific length or a sequence of individual characters that meet the length criteria. Learn more.</li> <li>New Model Number Rule for Composite Entity: The new Model Number rule <code>(\"modelNumber\":true)</code> for Composite Entity allows you to set a specific number of letters and numbers to extract a unique identifier. For example, a social security number, membership ID, or other structured data on a voice channel where the user\u2019s utterance does not follow a strict regex pattern. Learn more.</li> <li>New Precondition Rule for all entity types allows you to define preconditions for entity extraction if one of the conditions is true. If the precondition is invalid then the entity extraction is skipped entirely. For example, a composite entity matches with a set of identification numbers, such as membership ID, provider ID, and RX number. You can set the precondition rule as <code>\"preConditions\" : [\"checkMemberID\"]</code>. Learn more.</li> </ul>"}]}